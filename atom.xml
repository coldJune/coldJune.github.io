<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Stay Hungary</title>
  
  <subtitle>Programming is an art form</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://coldjune.com/"/>
  <updated>2021-10-24T05:50:56.302Z</updated>
  <id>http://coldjune.com/</id>
  
  <author>
    <name>邓小俊</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>架构设计师备考</title>
    <link href="http://coldjune.com/2021/07/22/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%B8%88%E5%A4%87%E8%80%83/"/>
    <id>http://coldjune.com/2021/07/22/架构设计师备考/</id>
    <published>2021-07-22T12:25:44.000Z</published>
    <updated>2021-10-24T05:50:56.302Z</updated>
    
    <content type="html"><![CDATA[<h1 id="软考备考"><a href="#软考备考" class="headerlink" title="软考备考"></a>软考备考</h1><p><img src="/2021/07/22/架构设计师备考/知识点分布.png" alt="知识点分布"></p><h2 id="计算机组成与体系结构"><a href="#计算机组成与体系结构" class="headerlink" title="计算机组成与体系结构"></a>计算机组成与体系结构</h2><h3 id="Flynn分类法"><a href="#Flynn分类法" class="headerlink" title="Flynn分类法"></a>Flynn分类法</h3><div class="table-container"><table><thead><tr><th style="text-align:center">体系结构类型</th><th style="text-align:center">结构</th><th style="text-align:center">关键特性</th><th style="text-align:center">代表</th></tr></thead><tbody><tr><td style="text-align:center">单指令流单数据流(SISD)</td><td style="text-align:center">控制部分:一个<br>处理器:一个<br>主存模块:一个</td><td style="text-align:center"></td><td style="text-align:center">单处理器系统</td></tr><tr><td style="text-align:center">单指令流多数据流(SIMD)</td><td style="text-align:center">控制部分:一个<br>处理器:多个<br>主存模块:多个</td><td style="text-align:center">各处理器以异步的形式执行同一条指令</td><td style="text-align:center">并行处理机<br><font color="red">阵列处理机</font><br>超级向量处理机</td></tr><tr><td style="text-align:center">多指令流单数据流(MISD)</td><td style="text-align:center">控制部分:多个<br>处理器:一个<br>主存模块:多个</td><td style="text-align:center">被证明不可能，至少是不实际</td><td style="text-align:center">目前没有，有文献称流水线计算机为此类</td></tr><tr><td style="text-align:center">多指令多数据流(MIMD)</td><td style="text-align:center">控制部分:多个<br>处理器:多个<br>主存模块:多个</td><td style="text-align:center">能够实现作业、任务、指令等各级全面并行</td><td style="text-align:center">多处理机系统<br>多计算机</td></tr></tbody></table></div><ul><li>阵列处理机：适合数组类的运算，比如二维数组</li></ul><h3 id="CISC与RISC"><a href="#CISC与RISC" class="headerlink" title="CISC与RISC"></a>CISC与RISC</h3><div class="table-container"><table><thead><tr><th style="text-align:center">指令系统类型</th><th style="text-align:center">指令</th><th style="text-align:center">寻址方式</th><th style="text-align:center">实现方式</th><th style="text-align:center">其它</th></tr></thead><tbody><tr><td style="text-align:center">CISC(复杂)</td><td style="text-align:center">数量多，使用频率差别大，可变长格式</td><td style="text-align:center">支持多种</td><td style="text-align:center">微程序控制技术(微码)</td><td style="text-align:center">研制周期长</td></tr><tr><td style="text-align:center">RISC(精简)</td><td style="text-align:center">数量少，使用频率接近，订长格式，大部分为单周期指令，操作寄存器，只有Load/Store操作内存</td><td style="text-align:center">支持方式少</td><td style="text-align:center">增加了通用寄存器；硬布线逻辑控制为主；适合采用流水线</td><td style="text-align:center">优化编译，有效支持高级语言</td></tr></tbody></table></div><h3 id="流水线"><a href="#流水线" class="headerlink" title="流水线"></a>流水线</h3><h3 id="存储系统"><a href="#存储系统" class="headerlink" title="存储系统"></a>存储系统</h3><p><img src="/2021/07/22/架构设计师备考/层次化存储结构.png" alt="层次化存储结构"></p><h4 id="Cache"><a href="#Cache" class="headerlink" title="Cache"></a>Cache</h4><blockquote><p>提高CPU数据输入输出的速率，突破冯·诺伊曼瓶颈，即CPU与存储系统间数据传送带宽的限制</p></blockquote><ul><li>在计算机存储系统体系中，Cache是访问速度最快的层次(因寄存器在CPU中，大多数时候未将寄存器放在存储体系中讨论，<font color="red">最快的有寄存器选寄存器，没有选Cache</font>)</li><li>使用Cache改善性能的依据是程序的局部性原理</li></ul><p>如果以$h$代表对Cache的访问命中率，$t_1$表示Cache的周期时间，$t_2$表示主存储器周期时间，以读操作为例，使用“Cache+主存储器”的系统的平均周期为$t_3$，则:</p><script type="math/tex; mode=display">t_3=h\times t_1 +(1-h)\times t_2</script><p>其中，$(1-h)$又称为失效率(未命中率)</p><h4 id="局部性原理"><a href="#局部性原理" class="headerlink" title="局部性原理"></a>局部性原理</h4><ul><li>时间局部性</li><li>空间局部性</li><li>工作集理论：工作集是进程运行时被频繁访问的页面集合</li></ul><h4 id="主存"><a href="#主存" class="headerlink" title="主存"></a>主存</h4><h5 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h5><ul><li>随机存取存储器:掉电信息丢失<ul><li>DRAM(Dynamic RAM, 动态RAM) -SDRAM</li><li>SRAM(Static RAM, 静态RAM)</li></ul></li></ul><ul><li>只读存储器:掉电信息不丢失<ul><li>MROM(Mask ROM，掩模式ROM)</li><li>PROM(Programmable ROM，一次可编程ROM)</li><li>EPROM(Erasable PROM，可擦除的PROM)</li><li>闪速存储器(flash memory，闪存)</li></ul></li></ul><h5 id="编址"><a href="#编址" class="headerlink" title="编址"></a>编址</h5><p><img src="/2021/07/22/架构设计师备考/主存编制.png" alt="主存编制"></p><h4 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h4><p>内存地址从AC000H到C7FFFH，共有_K个地址单元，如果该内存地址按字(16bit)编址，由28片存储器芯片构成。已知构成此内存的芯片每片由16K个存储单元，则该芯片每个存储单元存储_位<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p><h4 id="磁盘结构与参数"><a href="#磁盘结构与参数" class="headerlink" title="磁盘结构与参数"></a>磁盘结构与参数</h4><blockquote><p>存取时间=寻道时间+等待时间(平均定位时间+转动延迟)<br><em>寻道时间指磁头移动到磁道所需的时间；等待时间为等待读写的扇区转到磁头下方所用的时间</em></p></blockquote><h4 id="例题2"><a href="#例题2" class="headerlink" title="例题2"></a>例题<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup></h4><p><img src="/2021/07/22/架构设计师备考/磁盘例题.png" alt="磁盘例题"></p><h3 id="校验码"><a href="#校验码" class="headerlink" title="校验码"></a>校验码</h3><h3 id="并行处理"><a href="#并行处理" class="headerlink" title="并行处理"></a>并行处理</h3><h2 id="系统配置与性能评价"><a href="#系统配置与性能评价" class="headerlink" title="系统配置与性能评价"></a>系统配置与性能评价</h2><h3 id="性能指标"><a href="#性能指标" class="headerlink" title="性能指标"></a>性能指标</h3><ul><li>字长和数据通路宽度</li><li>主存容量和存取速度</li><li><p>运算速度</p><ul><li>主频与CPU时钟周期</li><li>CPI与IPC</li><li>MIPS与MFLOPS<blockquote><script type="math/tex; mode=display">MIPS = 指令条数/(执行时间\times 10^6)=主频/CPI=主频\times IPC</script><script type="math/tex; mode=display">MFLOPS = 浮点操作次数/(执行时间\times 10^6)</script></blockquote></li></ul></li><li><p>吞吐量与吞吐率</p></li><li>响应时间与完成时间</li><li>兼容性<h3 id="阿姆达尔解决方案"><a href="#阿姆达尔解决方案" class="headerlink" title="阿姆达尔解决方案"></a>阿姆达尔解决方案</h3></li></ul><p>对系统中某组件采用某种更快的执行方式，所获得的系统性能的改变程度，取决于该组件被使用的频率，或所占总执行时间的比例。加速比计算公式如下：</p><script type="math/tex; mode=display">R=\frac{T_p}{T_i}=\frac{1}{(1-F_e)+F_e/S_e}</script><p>其中，$T_p$表示不使用改进组件时完成整个任务的时间，$T_i$表示使用改进组件时完成整个任务的时间。<br>加速比主要取决于两个因素：</p><ul><li>在原有的系统上，能被改进的部分在总执行时间中所占的比例。这个值称为改进比例，记为$F_e$，它总小于1</li><li>通过改进的执行方式所取得的性能提高，即如果整个系统使用了改进的执行方式，那么系统的执行速度会有多少提高，这个值等于在原来条件下系统执行时间与使用改进组件后系统的执行时间之比，记为$S_e$，它总大于1</li></ul><h4 id="例题-1"><a href="#例题-1" class="headerlink" title="例题"></a>例题</h4><p>在计算机系统中，某一功能的处理时间为整个系统运行时间的50%，若使该功能的处理速度加快10倍，根据Amdahl定律，这样做可以使整个系统的性能提高_倍。若要使整个系统的性能提高1.5倍，则该功能的处理速度应加快__倍。<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup></p><h3 id="性能评价方法"><a href="#性能评价方法" class="headerlink" title="性能评价方法"></a>性能评价方法</h3><ul><li>时钟频率法<blockquote><p>CPU、片面性极大，早期方式</p></blockquote></li><li>指令执行速度法<blockquote><p>单位时间执行指令数，片面性大(只衡量加法指令)</p></blockquote></li><li>等效指令速度法(吉普森混合法)<blockquote><p>每条指令使用概率乘以每条指令执行时间，相当于取平均值，依然局限在运算能力</p></blockquote></li><li>数据处理速率法(PDR)<blockquote><p>会考虑存储交互性</p></blockquote></li><li>综合理论性能法(CTP)<blockquote><p>考虑每一个处理部件、计算单元的有效计算率，根据字长调整，比较平衡地取得每个计算单位理论的性能值</p></blockquote></li><li>基准程序法<ul><li>Dhrystone基准程序</li><li>Linpack基准程序</li><li>Whetstone基准程序</li><li>SPEC基准程序(SPECmark、SPECint、SPECfp、SPECrate)</li><li>TPC基准程序<ul><li>TPC-A：OLTP环境下的数据库和硬件性能</li><li>TPC-B：不包括网络的纯事务处理，模拟企业计算环境</li><li>TPC-C：联机订货系统</li><li>TPC-D、TPC-H、TPC-R：决策支持系统</li><li>TPC-E：大型企业信息服务系统</li><li>TPC-W：通过Internet进行市场服务和销售的商业行为</li></ul></li></ul></li></ul><h3 id="性能检测方法"><a href="#性能检测方法" class="headerlink" title="性能检测方法"></a>性能检测方法</h3><ul><li>软件监控：使用软件对系统性能数据进行采集分析，此方法会消耗较多的系统资源</li><li>硬件监控：使用专用硬件设备对系统性能进行采集分析，适用于高负载的计算机系统 </li></ul><h2 id="操作系统基本原理"><a href="#操作系统基本原理" class="headerlink" title="操作系统基本原理"></a>操作系统基本原理</h2><h3 id="进程管理"><a href="#进程管理" class="headerlink" title="进程管理"></a>进程管理</h3><ul><li><p>状态<br><img src="/2021/07/22/架构设计师备考/进程的状态.png" alt="进程的状态"></p></li><li><p>前趋图<br><img src="/2021/07/22/架构设计师备考/前趋图.png" alt="前趋图"></p><blockquote><p>考虑哪些有先后，哪些可并行。前趋图描述一系列活动的先后约束关系。</p></blockquote></li><li><p>同步与互斥<br>互斥：在同一时刻只允许一个进程使用一个资源<br>同步：速度有差异，在一定情况下等待<br><img src="/2021/07/22/架构设计师备考/生产者消费者问题.png" alt="生产者消费者问题"></p></li><li><p>PV 操作</p><blockquote><p>临界资源：诸进程间需要互斥方式对其进行共享的资源，如打印机、磁带机等<br>临界区：每个进程中访问临界资源的那段代码称为临界区<br>信号量：一种特殊的变量(控制临界资源是否能够访问，为1其实就是锁)</p></blockquote></li></ul><p><img src="/2021/07/22/架构设计师备考/PV操作.png" alt="PV操作"></p><p>单缓冲区生产者、消费者问题PV原语描述，S1初始值为1，S2初始值为0<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">生产者:</span><br><span class="line">    生产一个产品;</span><br><span class="line">    P(S1);</span><br><span class="line">    送产品到缓冲区;</span><br><span class="line">    V(S2);</span><br><span class="line"></span><br><span class="line">消费者:</span><br><span class="line">    P(S2);</span><br><span class="line">    从缓冲区取产品;</span><br><span class="line">    V(S1);</span><br><span class="line">    消费产品;</span><br></pre></td></tr></table></figure></p><ul><li><p>PV操作与前趋图结合<br><img src="/2021/07/22/架构设计师备考/PV和前趋图结合.png" alt="PV和前趋图结合"></p></li><li><p>死锁问题</p><blockquote><p>一个进程等待一件不可能发生的事，则进程死锁。如果一个或多个进程产生死锁，就会造成系统死锁<br>四大条件：环路等待、互斥、保持和等待、不剥夺<br>死锁的预防：打破四大条件<br>死锁的避免：有序资源分配法、<font color="red">银行家算法</font></p></blockquote></li><li><p>银行家算法</p><blockquote><p>当一个进程对资源的最大需求量不超过系统的资源数时可以接纳该进程<br>进程可以分期请求资源，但请求的总数不能超过最大需求量<br>当系统现有的资源不能满足进程尚需资源数时，对进程的请求可以推迟分配，但总能使进程在有限的时间里得到资源</p></blockquote></li></ul><p><img src="/2021/07/22/架构设计师备考/死锁问题.png" alt="死锁问题"></p><h4 id="例题-2"><a href="#例题-2" class="headerlink" title="例题"></a>例题</h4><ul><li>例题1<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup><br><img src="/2021/07/22/架构设计师备考/PV例题1.png" alt="PV例题1"></li><li>例题2<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup><br><img src="/2021/07/22/架构设计师备考/PV例题2.png" alt="PV例题2"></li><li>例题3<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup><br><img src="/2021/07/22/架构设计师备考/PV例题3.png" alt="PV例题3"></li><li>例题4<sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup><br>系统有3个进程，A、B、C。这3个进程都需要5个系统资源。则系统至少有多少个资源不可能发生死锁。</li><li>例题5<sup id="fnref:8"><a href="#fn:8" rel="footnote">8</a></sup><br><img src="/2021/07/22/架构设计师备考/银行家算法.png" alt="银行家算法"></li></ul><h3 id="存储管理"><a href="#存储管理" class="headerlink" title="存储管理"></a>存储管理</h3><h4 id="页式存储"><a href="#页式存储" class="headerlink" title="页式存储"></a>页式存储</h4><p><img src="/2021/07/22/架构设计师备考/页式存储.png" alt="页式存储"></p><ul><li>优点：利用率高，碎片小，分配及管理简单</li><li>缺点：增加了系统开销(查表)；可能产生抖动现象</li></ul><h4 id="段式存储"><a href="#段式存储" class="headerlink" title="段式存储"></a>段式存储</h4><p><img src="/2021/07/22/架构设计师备考/段式存储.png" alt="段式存储"></p><h4 id="段页式存储"><a href="#段页式存储" class="headerlink" title="段页式存储"></a>段页式存储</h4><p><img src="/2021/07/22/架构设计师备考/段页式存储.png" alt="段页式存储"></p><ul><li>优点：空间浪费小，存储共享容易，存储保护容易，能动态链接</li><li>缺点：由于管理软件的增加，复杂性和开销也随之增加，需要的硬件以及占用的内容也有所增加，使得执行速度大大下降</li></ul><h4 id="快表"><a href="#快表" class="headerlink" title="快表"></a>快表</h4><p>快表是一块小容量的相联存储器(Associative Memory)，由高速缓存器组成，速度快，并且可以从硬件上保证按内容并行查找，一般用来存放当前访问最频繁的少数活动页面的页号。</p><h4 id="页面置换算法"><a href="#页面置换算法" class="headerlink" title="页面置换算法"></a>页面置换算法</h4><ul><li>最优(Optimal,OPT)算法</li><li>随机(RAND)算法</li><li><font color="red">先进先出(FIFO)算法</font>：有可能产生抖动。例如432143543215序列，用3个页面，比4个缺页要少<br><img src="/2021/07/22/架构设计师备考/FIFO算法.png" alt="FIFO算法"></li><li><font color="red">最近最少使用(LRU)算法</font>：不会抖动<h4 id="例题-3"><a href="#例题-3" class="headerlink" title="例题"></a>例题</h4></li><li>例题1<sup id="fnref:9"><a href="#fn:9" rel="footnote">9</a></sup><br><img src="/2021/07/22/架构设计师备考/页式存储例题.png" alt="页式存储例题"></li><li>例题2<sup id="fnref:10"><a href="#fn:10" rel="footnote">10</a></sup><br><img src="/2021/07/22/架构设计师备考/页面置换算法例题.png" alt="页面置换算法例题"></li><li>例题3<sup id="fnref:11"><a href="#fn:11" rel="footnote">11</a></sup><br><img src="/2021/07/22/架构设计师备考/页面置换例题2.png" alt="页面置换例题2"></li></ul><h3 id="文件管理"><a href="#文件管理" class="headerlink" title="文件管理"></a>文件管理</h3><h4 id="索引文件结构"><a href="#索引文件结构" class="headerlink" title="索引文件结构"></a>索引文件结构</h4><p><img src="/2021/07/22/架构设计师备考/索引文件结构.png" alt="索引文件结构"></p><h4 id="文件系统和树型目录结构"><a href="#文件系统和树型目录结构" class="headerlink" title="文件系统和树型目录结构"></a>文件系统和树型目录结构</h4><ul><li>文件属性:只读文件属性(R)、存档属性(A)、系统文件(S)、隐藏文件(H)</li><li>文件名组成:驱动器号、路径、主文件名、扩展名</li><li><font color="red">绝对路径:是从盘符开始的路径</font></li><li><font color="red">相对路径:是从当前路径开始的路径</font><br><img src="/2021/07/22/架构设计师备考/树型目录结构.png" alt="树型目录结构"><br>若当前路径为D1，要求F2路径，则绝对路径为：/D1/W2/F2，相对路径：W2/F2</li></ul><h4 id="空闲存储空间的管理"><a href="#空闲存储空间的管理" class="headerlink" title="空闲存储空间的管理"></a>空闲存储空间的管理</h4><ul><li>空闲区表法(空闲文件目录)</li><li>空闲链表法</li><li><font color="red">位示图法</font></li><li>成组连接法<br><img src="/2021/07/22/架构设计师备考/位示图法.png" alt="位示图法"><h4 id="例题-4"><a href="#例题-4" class="headerlink" title="例题"></a>例题</h4></li><li><p>例题1<sup id="fnref:12"><a href="#fn:12" rel="footnote">12</a></sup><br><img src="/2021/07/22/架构设计师备考/索引文件结构例题1.png" alt="索引文件结构例题1"></p></li><li><p>例题2<sup id="fnref:13"><a href="#fn:13" rel="footnote">13</a></sup><br><img src="/2021/07/22/架构设计师备考/位示图例题.png" alt="位示图例题"></p></li></ul><h3 id="设备管理"><a href="#设备管理" class="headerlink" title="设备管理"></a>设备管理</h3><h4 id="数据传输控制方式"><a href="#数据传输控制方式" class="headerlink" title="数据传输控制方式"></a>数据传输控制方式</h4><ul><li><font color="red">程序控制方式</font>（程序查询方式）：最低级的，CPU介入最多—查询，外设处于被动</li><li><font color="red">程序中断方式</font>：外设可以主动触发，效率更高</li><li><font color="red">DMA方式</font>(直接存取控制方式)：由专门的DMA控制器控制外设与内存的数据交换</li><li>通道</li><li>输入输出处理机</li></ul><h3 id="微内核操作系统"><a href="#微内核操作系统" class="headerlink" title="微内核操作系统"></a>微内核操作系统</h3><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">实质</th><th style="text-align:center">优点</th><th style="text-align:center">缺点</th></tr></thead><tbody><tr><td style="text-align:center">单体内核</td><td style="text-align:center">将图形、设备驱动及文件系统等功能全部在内核中实现，运行在内核状态和同一地址空间</td><td style="text-align:center">减少进程间通信和状态切换的系统开销，获得较高的运行效率</td><td style="text-align:center">内核庞大，占用资源较多且不易裁剪<br>系统的稳定性和安全性不好</td></tr><tr><td style="text-align:center">微内核</td><td style="text-align:center">只实现基本功能，将图形系统、文件系统、设备驱动及通信功能放在内核之外</td><td style="text-align:center">内核精炼，便于裁剪和移植<br>系统服务程序运行在用户地址空间，系统的可靠性、稳定性和安全性较高<br>可用于分布式系统</td><td style="text-align:center">用户状态和内核状态需要频繁切换，从而导致系统效率不如单体内核</td></tr></tbody></table></div><p><img src="/2021/07/22/架构设计师备考/微内核操作系统.png" alt="微内核操作系统"></p><h2 id="数据库系统"><a href="#数据库系统" class="headerlink" title="数据库系统"></a>数据库系统</h2><h3 id="三级模式-两级映射"><a href="#三级模式-两级映射" class="headerlink" title="三级模式-两级映射"></a>三级模式-两级映射</h3><p><img src="/2021/07/22/架构设计师备考/三级模式两级映射.png" alt="三级模式两级映射"></p><h3 id="数据库设计过程"><a href="#数据库设计过程" class="headerlink" title="数据库设计过程"></a>数据库设计过程</h3><p><img src="/2021/07/22/架构设计师备考/数据库设计过程.png" alt="数据库设计过程"></p><h3 id="E-R模型"><a href="#E-R模型" class="headerlink" title="E-R模型"></a>E-R模型</h3><p><img src="/2021/07/22/架构设计师备考/ER模型.png" alt="ER模型"></p><ul><li>集成的方法<ol><li>多个局部E-R图一次集成</li><li>逐步集成，用累加的方式一次集成两个局部E-R</li></ol></li><li>集成产生的冲突及解决方法<ol><li>属性冲突：包括属性域冲突和属性取值冲突</li><li>命名冲突：包括同名异义和异名同义</li><li>结构冲突：包括同一对象在不同应用中具有不同的抽象，以及同一实体在不同局部E-R图中所包含的属性个数和属性排列次序不完全相同</li></ol></li><li>E-R模型转关系模式<ol><li>一个实体转换为一个关系模式</li><li>1:1联系：最少可以转成2个关系模式，一个实体对应一个关系模式，将联系放入任何一个实体都可</li><li>1:n联系：最少可以转成2个关系模式，一个实体对应一个关系模式，可以把联系记录在n的一端</li><li>m:n联系： 最少可以转成3个关系模式，一个实体对应一个关系模式，联系需要一个单独的关系模式记录</li></ol></li></ul><h4 id="例题-5"><a href="#例题-5" class="headerlink" title="例题"></a>例题</h4><ul><li>例题1<sup id="fnref:14"><a href="#fn:14" rel="footnote">14</a></sup><br><img src="/2021/07/22/架构设计师备考/E-R模型转换.png" alt="E-R模型转换"></li></ul><h3 id="关系代数"><a href="#关系代数" class="headerlink" title="关系代数"></a>关系代数</h3><blockquote><p>并、交、差、<font color="red">笛卡尔积、投影、选择、联结</font></p></blockquote><ul><li><p>交并差<br><img src="/2021/07/22/架构设计师备考/关系1.png" alt="关系1"><br><img src="/2021/07/22/架构设计师备考/交.png" alt="交"><br><img src="/2021/07/22/架构设计师备考/并.png" alt="并"><br><img src="/2021/07/22/架构设计师备考/差.png" alt="差"></p></li><li><p>笛卡尔积、投影、选择<br><img src="/2021/07/22/架构设计师备考/关系1.png" alt="关系1"><br><img src="/2021/07/22/架构设计师备考/笛卡尔积.png" alt="笛卡尔积"><br><img src="/2021/07/22/架构设计师备考/投影.png" alt="投影"><br><img src="/2021/07/22/架构设计师备考/选择.png" alt="选择"></p></li><li><p>联结<br><img src="/2021/07/22/架构设计师备考/关系2.png" alt="关系2"><br><img src="/2021/07/22/架构设计师备考/联结.png" alt="联结"></p></li></ul><h3 id="规范化理论"><a href="#规范化理论" class="headerlink" title="规范化理论"></a>规范化理论</h3><blockquote><p>价值与用途：非规范化的关系模式，可能存在的问题包括：数据冗余，更新异常、插入异常、删除异常</p></blockquote><h4 id="函数依赖"><a href="#函数依赖" class="headerlink" title="函数依赖"></a>函数依赖</h4><blockquote><p>设R(U)是属性U上的一个关系模式，X和Y是U的子集，r为R的任一关系，如果对于r中的任意两个元组u，v，只要有$u[X]=v[X]$，就有$u[Y]=v[Y]$,则称X函数决定Y，或称Y函数依赖于X，记为$X\rightarrow Y$</p></blockquote><p><img src="/2021/07/22/架构设计师备考/部分函数依赖.png" alt="部分函数依赖"><br><img src="/2021/07/22/架构设计师备考/传递函数依赖.png" alt="传递函数依赖"></p><h4 id="键"><a href="#键" class="headerlink" title="键"></a>键</h4><p><img src="/2021/07/22/架构设计师备考/键.png" alt="键"></p><ul><li>求解候选键<ol><li>将关系模式的函数依赖关系用“有向图”的方式表示</li><li>找入度为0的属性，并以该属性集合为起点，尝试遍历有向图，若能正常遍历图中所有结点，则该属性集即为关系模式的候选键</li><li>若入度为0的属性不能遍历图中所有结点，则需要尝试性地将一些中间结点(即有入度，也有出度的结点)并入入度为0的属性集中，直至该集合能遍历所有结点，集合为候选键</li></ol></li></ul><h5 id="例题-6"><a href="#例题-6" class="headerlink" title="例题"></a>例题</h5><ul><li>例题1<sup id="fnref:15"><a href="#fn:15" rel="footnote">15</a></sup><br><img src="/2021/07/22/架构设计师备考/键例题1.png" alt="键例题1"></li><li>例题2<sup id="fnref:16"><a href="#fn:16" rel="footnote">16</a></sup><br><img src="/2021/07/22/架构设计师备考/键例题2.png" alt="键例题2"></li><li>例题3<sup id="fnref:17"><a href="#fn:17" rel="footnote">17</a></sup><br><img src="/2021/07/22/架构设计师备考/键例题3.png" alt="键例题3"></li></ul><h4 id="范式"><a href="#范式" class="headerlink" title="范式"></a>范式</h4><p><img src="/2021/07/22/架构设计师备考/范式.png" alt="范式"></p><ul><li>第一范式(1NF)：在关系模式R中，当且仅当所有域只包含原子值，即每个分量都是不可再分的数据项，则陈R是第一范式</li><li>第二范式(2NF)：当且仅当R是第一范式，且第一个非主属性完全依赖主键(<font color="red">不存在部分依赖</font>)时，则称R是第二范式</li><li>第三范式(3NF)：当且仅当R是1NF，且E中没有非主属性传递依赖的码时，则称R是第三范式</li><li>BC范式(BCNF)：设R是一个关系模式，F是它的依赖集，R属于BCNF当且仅当其F中每个依赖的决定因素必定包含R的某个候选码</li></ul><h5 id="例题-7"><a href="#例题-7" class="headerlink" title="例题"></a>例题</h5><ul><li>例题1<sup id="fnref:18"><a href="#fn:18" rel="footnote">18</a></sup><br><img src="/2021/07/22/架构设计师备考/范式例题1.png" alt="范式例题1"></li></ul><h4 id="模式分解"><a href="#模式分解" class="headerlink" title="模式分解"></a>模式分解</h4><ul><li><font color="red">保持函数依赖分解</font><blockquote><p>设数据库模式$\sigma = \{R1,R2,\dots,Rk\}$是关系模式R的一个分解，F是R上的函数依赖集，$\sigma$中每个模式Ri上的FD集是Fi。如果$\{F1,F2,\dots,Fk\}$与F是等价的(即相互逻辑蕴涵)，那么称分解$\sigma$保持FD。</p></blockquote></li><li><p>无损分解</p><blockquote><p>有损即不能还原，无损即可以还原</p></blockquote></li><li><p>无损联接分解</p><blockquote><p>指将一个关系模式分解成若干个关系模式后，通过自然联接和投影等运算仍能还原到原来的关系模式。</p></blockquote></li></ul><p>定理：如果R的分解为$\sigma={R_1,R_2}$，F为R所满足的函数依赖集合，分解$\sigma$具有无损联接性的充分必要条件是：</p><script type="math/tex; mode=display">R_1\cap R_2 \rightarrow (R_1-R_2)</script><p>或</p><script type="math/tex; mode=display">R_1 \cap R_2 \rightarrow (R_2-R_1)</script><p>其中，$R_1\cap R_2 $表示模式的交，为$R_1$与$R_2$中公共属性组成，$R_1-R_2$或$R_2-R_1$表示模式的差集，$R_1-R_2$表示$R_1$中去除$R_1$和$R_2$的公共属性所组成。当模式R分解成两个关系模式$R_1$和$R_2$时，如果$R_1$与$R_2$的公共属性能函数决定$R_1$中或$R_2$中的其它属性，这样的分解就具有无损联接性。(<font color="red">只适用于一分为二的分解</font>)</p><h5 id="例题-8"><a href="#例题-8" class="headerlink" title="例题"></a>例题</h5><ul><li><p>例题1<sup id="fnref:19"><a href="#fn:19" rel="footnote">19</a></sup><br><img src="/2021/07/22/架构设计师备考/模式分解例题1.png" alt="模式分解例题1"></p></li><li><p>例题2<sup id="fnref:20"><a href="#fn:20" rel="footnote">20</a></sup><br><img src="/2021/07/22/架构设计师备考/模式分解例题2.png" alt="模式分解例题2"></p></li></ul><h3 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h3><p><img src="/2021/07/22/架构设计师备考/并发控制.png" alt="并发控制"></p><ul><li>并发存在的问题<br><img src="/2021/07/22/架构设计师备考/并发存在的问题.png" alt="并发存在的问题"></li></ul><h4 id="封锁协议"><a href="#封锁协议" class="headerlink" title="封锁协议"></a>封锁协议</h4><ul><li>一级封锁协议。事务T在修改数据R之前必须先对其加X锁，直到事务结束才释放。<font color="red">可防止丢失修改</font></li><li>二级封锁协议。一级封锁协议加上事务T在读取数据R之前先对其加S锁，读完后即可释放S锁。<font color="red">可防止丢失修改，还可防止读“脏”数据</font></li><li>三级封锁协议。一级封锁协议加上事务T在读取数据R之前先对其加S锁，直到事务结束才释放。<font color="red">可防止丢失修改，防止读“脏”数据与防止数据重复读</font></li><li>两阶段协议。可串行化，可能发生死锁</li></ul><h3 id="数据库完整性约束"><a href="#数据库完整性约束" class="headerlink" title="数据库完整性约束"></a>数据库完整性约束</h3><ul><li>实体完整性约束：给数据表定义主键，约束的是主键的值不能为空和重复</li><li>参照完整性约束：外键完整性约束，允许为空</li><li>用户自定义完整性约束：可以设置属性值的要求<br>触发器：应对复杂的完整性约束，通过脚本约束一些复杂要求。上诉三种只能应付简单的要求。</li></ul><h3 id="数据库安全"><a href="#数据库安全" class="headerlink" title="数据库安全"></a>数据库安全</h3><div class="table-container"><table><thead><tr><th style="text-align:center">措施</th><th style="text-align:center">说明</th></tr></thead><tbody><tr><td style="text-align:center">用户标识和鉴定</td><td style="text-align:center">最外层的安全保护措施，可以使用用户账户、口令及随机数检验等方式</td></tr><tr><td style="text-align:center">存取控制</td><td style="text-align:center">对用户进行授权，包括操作类型（如查找、插入、删除、修改等动作）和数据对象（主要是数据范围）的权限</td></tr><tr><td style="text-align:center">密码存储和传输</td><td style="text-align:center">对远程终端信息用密码传输</td></tr><tr><td style="text-align:center">视图的保护</td><td style="text-align:center">对视图进行授权</td></tr><tr><td style="text-align:center">审计</td><td style="text-align:center">使用一个专用文件或数据库，自动将用户对数据库的所有操作记录下来</td></tr></tbody></table></div><h3 id="数据备份"><a href="#数据备份" class="headerlink" title="数据备份"></a>数据备份</h3><ul><li>冷备份：也称静态备份，是将数据库正常关闭，在停止状态下，将数据库的文件全部备份(复制)下来</li><li>热备份：也称为动态备份，是利用备份软件，在数据库正常运行的状态下，将数据库中的数据文件备份出来</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">备份方式</th><th style="text-align:left">优点</th><th style="text-align:left">缺点</th></tr></thead><tbody><tr><td style="text-align:center">冷备份</td><td style="text-align:left">非常快速的备份方法(只需复制文件)；<br>容易归档(简单复制即可)；<br>容易恢复到某个时间点上(只需将文件再复制回去)；<br>能与归档方法相结合，做数据库“最佳状态”的恢复；<br>低度维护，高度安全</td><td style="text-align:left">单独使用时，只能提供到某一时间点上的恢复；<br>在实施备份的全过程中，数据库必须要作备份而不能做其它工作；<br>若磁盘空间有限只能复制到磁带等其它外部存储设备上，速度会很慢；<br>不能按表或按用户恢复</td></tr><tr><td style="text-align:center">热备份</td><td style="text-align:left">可在表空间或数据库文件级备份，备份时间短；<br>备份时数据库仍可使用；<br>可达到秒级恢复(恢复到某一时间点上)；<br>可对几乎所有数据库实体做恢复；<br>恢复是快速的</td><td style="text-align:left">不能出错，否则后果严重；<br>若热备份不成功所得结果不可用于时间点的恢复；<br>困难于维护，所以特别小心，不允许”以失败告终”</td></tr></tbody></table></div><ul><li>完全备份：备份所有数据</li><li><font color="red">差量备份：仅备份上一次完全备份之后变化的数据</font></li><li>增量备份：备份上一次备份之后变化的数据</li></ul><h4 id="转储"><a href="#转储" class="headerlink" title="转储"></a>转储</h4><ul><li>静态海量转储：在系统中无运行事务时进行，每次转储全部数据库</li><li>静态增量转储：在系统中无运行事务时进行，每次只转储上一次转储后更新过的数据</li><li>动态海量转储：转储期间允许对数据库进行存取或修改，每次转储全部数据库</li><li>动态增量转储：转储期间允许对数据库进行存取和修改，每次只转储上一次转储后更新过的数据。</li></ul><p>日志文件：事务日志是针对数据库改变所做的记录，它可以记录针对数据库的任何操作，并将记录结果保存在独立的文件中</p><h3 id="数据库故障与恢复"><a href="#数据库故障与恢复" class="headerlink" title="数据库故障与恢复"></a>数据库故障与恢复</h3><div class="table-container"><table><thead><tr><th style="text-align:center">故障关系</th><th style="text-align:center">故障原因</th><th style="text-align:center">解决方法</th></tr></thead><tbody><tr><td style="text-align:center">事务本身的可预期故障</td><td style="text-align:center">本身逻辑</td><td style="text-align:center">在程序中预先设置RollBack语句</td></tr><tr><td style="text-align:center">事务本身的不可预期故障</td><td style="text-align:center">算术溢出、违反存储保护</td><td style="text-align:center">由DBMS的恢复子系统通过日志，撤销事务对数据库的修改，回退到事务初始状态</td></tr><tr><td style="text-align:center">系统故障</td><td style="text-align:center">系统停止运转</td><td style="text-align:center">通常使用检查点法</td></tr><tr><td style="text-align:center">介质故障</td><td style="text-align:center">外存被破坏</td><td style="text-align:center">一般使用日志重做业务</td></tr></tbody></table></div><h3 id="分布式数据库"><a href="#分布式数据库" class="headerlink" title="分布式数据库"></a>分布式数据库</h3><p><img src="/2021/07/22/架构设计师备考/分布式数据库.png" alt="分布式数据库"></p><ul><li>分布透明性<ul><li>分片透明性<ul><li>水平分片</li><li>垂直分片</li><li>混合分片</li></ul></li><li>位置透明性</li><li>局部数据模型透明性</li></ul></li><li>分布式数据库管理系统-组成<ul><li>LDBMS</li><li>GDBMS</li><li>全局数据字典</li><li>通信管理(CM)</li></ul></li><li>分布式数据库管理系统-结构<ul><li>全局控制集中的DDBMS</li><li>全局控制分散的DDBMS</li><li>全局控制部分分散的DDBMS</li></ul></li></ul><h3 id="数据库优化"><a href="#数据库优化" class="headerlink" title="数据库优化"></a>数据库优化</h3><p><img src="/2021/07/22/架构设计师备考/数据库优化.png" alt="数据库优化"></p><h3 id="数据仓库与数据挖掘"><a href="#数据仓库与数据挖掘" class="headerlink" title="数据仓库与数据挖掘"></a>数据仓库与数据挖掘</h3><ul><li>面向主题</li><li>集成的</li><li>相对稳定的(非易失的)</li><li>反映历史变化<br><img src="/2021/07/22/架构设计师备考/数据仓库.png" alt="数据仓库"></li></ul><h4 id="数据挖掘方法分类"><a href="#数据挖掘方法分类" class="headerlink" title="数据挖掘方法分类"></a>数据挖掘方法分类</h4><ul><li>方法<ul><li>决策树</li><li>神经网络</li><li>遗传算法</li><li>关联规则挖掘算法</li></ul></li><li>分类<ul><li>关联分析：挖掘出隐藏在数据间的相互关系</li><li>序列模式分析：侧重点是分析数据间的前后关系(因果关系)</li><li>分类分析：为每一个记录赋予一个标记再按标记分类</li><li>聚类分析：分类分析法的逆过程</li></ul></li></ul><h3 id="联邦数据库"><a href="#联邦数据库" class="headerlink" title="联邦数据库"></a>联邦数据库</h3><blockquote><p>联邦数据库系统(FDBS)是一个彼此协作却又相互独立的成员数据库(CDBS)的集合，它将成员数据库系统按不同程度进行集成，对该系统整体提供控制和协同操作的软件叫做联邦数据库管理系统(FDBMS)</p></blockquote><ul><li>联邦数据库特征<ul><li>分布性</li><li>异构性</li><li>自治性</li><li>透明性</li></ul></li><li>联邦数据库分类<ul><li>紧耦合</li><li>松耦合</li></ul></li></ul><h3 id="NoSQL"><a href="#NoSQL" class="headerlink" title="NoSQL"></a>NoSQL</h3><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">关系数据库模式</th><th style="text-align:left">NoSQL模式</th></tr></thead><tbody><tr><td style="text-align:center">并发支持</td><td style="text-align:center">支持并发、效率低</td><td style="text-align:left">并发性能高</td></tr><tr><td style="text-align:center">存储与查询</td><td style="text-align:center">关系表方式存储、SQL查询</td><td style="text-align:left">海量数据存储、查询效率高</td></tr><tr><td style="text-align:center">扩展方式</td><td style="text-align:center">向上扩展，升级服务器</td><td style="text-align:left">向外扩展，扩展集群</td></tr><tr><td style="text-align:center">索引方式</td><td style="text-align:center">B树、哈希等</td><td style="text-align:left">键值索引</td></tr><tr><td style="text-align:center">应用领域</td><td style="text-align:center">面向通用领域</td><td style="text-align:left">特定应用领域</td></tr></tbody></table></div><ul><li>缺点(存疑，目前已经算是比较成熟)</li><li>成熟度不够，大量关键特性有待实现</li><li>开源数据库产品的支持力度有限</li><li>数据挖掘与商务智能支持不足，现有的产品无法直接使用NoSQL数据库</li><li>NoSQL数据库专家较少，大部分都处于学习阶段<blockquote><p>SQL + NoSQL = MoreSQL/NewSQL</p></blockquote></li></ul><p><em>Redis、MongoDB、Flare…</em></p><h3 id="反规划化"><a href="#反规划化" class="headerlink" title="反规划化"></a>反规划化</h3><blockquote><p>由于规范化会使表不断地拆分，从而导致数据表过多。这样虽然减少了数据冗余，提高了增、删、改的速度，但会增加查询的工作量。系统需要进行多次连接，才能进行查询操作，使得系统效率大大下降。</p></blockquote><ul><li>技术手段<ul><li>增加派生性冗余列</li><li>增加冗余列</li><li>重新组表</li><li>分割表</li></ul></li></ul><h3 id="大数据基本概念"><a href="#大数据基本概念" class="headerlink" title="大数据基本概念"></a>大数据基本概念</h3><blockquote><p>数据量(Volume)、速度(Velocity)、多样性(Variety)、值(Value)</p></blockquote><div class="table-container"><table><thead><tr><th style="text-align:center">比较纬度</th><th style="text-align:center">传统数据</th><th style="text-align:center">大数据</th></tr></thead><tbody><tr><td style="text-align:center">数据量</td><td style="text-align:center">GB或TB级</td><td style="text-align:center">PB级或以上</td></tr><tr><td style="text-align:center">数据分析需求</td><td style="text-align:center">现有数据的分析和检测</td><td style="text-align:center">深度分析(关联分析、回归分析)</td></tr><tr><td style="text-align:center">硬件平台</td><td style="text-align:center">高端服务器</td><td style="text-align:center">集群平台</td></tr></tbody></table></div><ul><li><font color="red">大数据处理系统应具有的重要特性</font><ul><li>高度可扩展性</li><li>高性能</li><li>高度容错</li><li>支持异构环境</li><li>较短的分析延迟</li><li>易用且开放的接口</li><li>较低成本</li><li>向下兼容性</li></ul></li></ul><h2 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h2><h3 id="OSI-RM七层模型"><a href="#OSI-RM七层模型" class="headerlink" title="OSI/RM七层模型"></a>OSI/RM七层模型</h3><p><img src="/2021/07/22/架构设计师备考/七层模型.png" alt="七层模型"></p><h4 id="例题-9"><a href="#例题-9" class="headerlink" title="例题"></a>例题</h4><ul><li>例题1<sup id="fnref:21"><a href="#fn:21" rel="footnote">21</a></sup><br><img src="/2021/07/22/架构设计师备考/七层模型例题1.png" alt="七层模型例题1"></li></ul><h3 id="网络技术标准与协议"><a href="#网络技术标准与协议" class="headerlink" title="网络技术标准与协议"></a>网络技术标准与协议</h3><ul><li>TCP/IP协议：Internet，可扩展，可靠，应用最广，牺牲速度和效率</li><li>IPX/SPX协议：NOVELL，路由，大型企业网</li><li><p>NETBEUI协议：IBM，非路由，快速<br><img src="/2021/07/22/架构设计师备考/网络技术标准与协议.png" alt="网络技术标准与协议"></p></li><li><p>TCP</p><ul><li>三次握手<br><img src="/2021/07/22/架构设计师备考/三次握手.png" alt="三次握手"></li><li>可靠传输<br><img src="/2021/07/22/架构设计师备考/可靠传输.png" alt="可靠传输"></li></ul></li><li><p>DHCP</p><ol><li>客户机/服务器模型</li><li>租约默认为8天</li><li>当租约过半时，客户机需要向DHCP服务器申请续租</li><li>当租约超过87.5%时，如果仍然没有和当初提供IP的DHCP服务器联系上，则开始联系其他的DHCP服务器</li><li>固定分配、动态分配和自动分配</li><li>169.254.X.X（Windows）和0.0.0.0（Unix）说明未和DHCP服务器联系上</li></ol></li><li><p>DNS协议</p><ul><li>递归查询：服务器必须回答目标IP与域名的映射关系。<font color="red">主机向本地域名服务器的查询采用递归查询</font></li><li>迭代查询：服务器收到一次迭代查询回复一次结果，这个结果不一定是目标IP与域名的映射关系，也可以是其它DNS服务器的地址。<font color="red">本地域名服务器向根域名服务器的查询<strong>通常采用</strong>迭代查询</font><br><img src="/2021/07/22/架构设计师备考/DNS查询.png" alt="DNS查询"></li></ul></li></ul><h4 id="例题-10"><a href="#例题-10" class="headerlink" title="例题"></a>例题</h4><ul><li>例题1<sup id="fnref:22"><a href="#fn:22" rel="footnote">22</a></sup><br><img src="/2021/07/22/架构设计师备考/DNS例题.png" alt="DNS例题.png"></li></ul><h3 id="网络规划与设计"><a href="#网络规划与设计" class="headerlink" title="网络规划与设计"></a>网络规划与设计</h3><ul><li>网络规划原则<ul><li>实用性原则</li><li>开放性原则</li><li>先进性原则</li></ul></li><li>网络设计任务<ul><li>确定网络总体目标</li><li>确定总体设计原则</li><li>通信子网设计</li><li>资源子网设计</li><li>设备选型</li><li>网络操作系统与服务器资源设备</li><li>网络安全设计</li></ul></li><li>网络设计原则<ul><li>可用性：指网络或网络设备可用于执行预期任务时间所占总量的百分比</li><li>可靠性：网络设备或计算机持续执行预定功能的可能性</li><li>可恢复性：指网络从故障中恢复的难易程度和时间</li><li>适应性：指在用户改变应用要求时网络的应变能力</li><li>可伸缩性：指网络技术或设备随着用户需求的增长而扩充的能力</li></ul></li><li>网络实施原则<ul><li>可靠性原则</li><li>安全性原则</li><li>高效性原则</li><li>可扩展性原则</li></ul></li><li>网络实施步骤<ul><li>工程实施计划</li><li>网络设备到货验收</li><li>设备安装</li><li>系统测试</li><li>系统试运行</li><li>用户培训</li><li>系统转换</li></ul></li></ul><h4 id="逻辑设计"><a href="#逻辑设计" class="headerlink" title="逻辑设计"></a>逻辑设计</h4><blockquote><p>利用需求分析和现有网络体系分析的结果来设计逻辑网络结构，最后得到一份逻辑网络设计文档</p></blockquote><ul><li>逻辑网络设计图</li><li>IP地址方案</li><li>安全方案</li><li>具体的软硬件、广域网连接设备和基本服务</li><li>招聘和培训网络员工的具体说明</li><li>对软硬件、服务、员工和培训的费用初步估计</li></ul><h4 id="物理网络设计"><a href="#物理网络设计" class="headerlink" title="物理网络设计"></a>物理网络设计</h4><blockquote><p>物理网络设计是对逻辑网络设计的物理实现，通过对设备的具体物理分布、运行环境等确定，确保网络的物理连接服务逻辑连接的要求</p></blockquote><ul><li>网络物理结构图和布线方案</li><li>设备和部件的详细列表清单</li><li>软硬件和安装费用的估算</li><li>安装日程表，详细说明服务的时间以及期限</li><li>安装后的测试计划</li><li>用户的培训计划</li></ul><h4 id="分层设计"><a href="#分层设计" class="headerlink" title="分层设计"></a>分层设计</h4><ul><li>接入层：向本地网段提供用户接入</li><li>汇聚层：网络访问策略控制、数据包处理、过滤、寻址</li><li>核心层：数据交换</li></ul><p><img src="/2021/07/22/架构设计师备考/网络分层设计.png" alt="网络分层设计"></p><h3 id="无线网"><a href="#无线网" class="headerlink" title="无线网"></a>无线网</h3><ul><li><p>分类</p><ul><li>无线局域网(WLAN,802.11,WI-FI)</li><li>无线城域网(WMAN,802.16,WiMax)</li><li>无线广域网(WWAN,3G/4G)</li><li>无线个人网(WPAN,802.15,Bluetooth)</li></ul></li><li><p>优势</p><ul><li>移动性</li><li>灵活性</li><li>成本低</li><li>容易扩充</li></ul></li><li><p>无线局域网接入方式</p><ul><li>有接入点模式</li><li>无接入点模式(对等模式)</li></ul></li></ul><h3 id="网络接入技术"><a href="#网络接入技术" class="headerlink" title="网络接入技术"></a>网络接入技术</h3><ul><li><p>有限接入</p><ul><li>公用交换电话网络(PSTN)-(POS机，传真)</li><li>数字数据网(DDN)</li><li>综合业务数字网(ISDN)</li><li>非对称数字用户线路(ADSL)-<font color="red">介质是电话线，上下行不等</font></li><li>同轴光纤技术(HFC)-<font color="red">有线电视网络</font></li></ul></li><li><p>无线接入</p><ul><li>IEEE 802.11(WiFi)</li><li>IEEE 802.15(蓝牙Bluetooth)</li><li>红外(IrDA)</li><li>WAPI</li></ul></li><li><p>3G</p><ul><li>WCDMA</li><li>CDMA2000</li><li>TD-SCDMA</li></ul></li><li><p>4G</p><ul><li>LET-Advanced<ul><li>TDD(时分):由TD-SCDMA发展而来</li><li>FDD(频分):由WCDMA发展而来</li></ul></li><li>WirelessMAN- Advanced(802.16m)(WiMAX)</li></ul></li></ul><h3 id="网络存储技术"><a href="#网络存储技术" class="headerlink" title="网络存储技术"></a>网络存储技术</h3><h4 id="分类-1"><a href="#分类-1" class="headerlink" title="分类"></a>分类</h4><ul><li><p>直连式存储(DAS)：服务器直接和存储相连，可以接磁盘阵列，最原始的一种方式，适用于数据量不大，业务不复杂的场景<br><img src="/2021/07/22/架构设计师备考/DAS.png" alt="DAS"></p></li><li><p>网络附加存储(NAS)：存储附加于网络之上，<font color="red">即插即用的存储</font>，是一台存储服务器。<font color="red">网络在某些时间节点很繁忙，是由于NAS未将存储网络和业务网络分开导致</font><br><img src="/2021/07/22/架构设计师备考/NAS.png" alt="NAS"></p></li><li><p>存储区域网络(SAN)：将业务网络和存储网络完全分开，存储网络使用光纤网络，速率远高于IP网络，<font color="red">是首次提出业务网络和存储网络分开的技术</font>，性能卓越，<font color="red">缺点只有成本高</font><br><img src="/2021/07/22/架构设计师备考/SAN.png" alt="SAN"></p></li><li><p>IPSAN(iSCSI)：SAN的廉价方案，性能比SAN低<br><img src="/2021/07/22/架构设计师备考/IPSAN.png" alt="IPSAN"></p></li></ul><h4 id="Raid"><a href="#Raid" class="headerlink" title="Raid"></a>Raid</h4><ul><li><font color="red">Raid0(条块化)</font>:性能最高，并行处理，无冗余，损坏无法恢复</li><li><p><font color="red">Raid1(镜像结构)</font>:可用性，可恢复性好，仅有50%利用率<br><img src="/2021/07/22/架构设计师备考/Raid.png" alt="Raid"></p><blockquote><p>Raid0磁盘利用率为100&amp;，访问速度最快。Raid1磁盘利用率为50%，具备纠错功能。现在企业采用Raid0+1</p></blockquote></li><li><p><font color="red">Raid0+1(Raid10)</font>:Raid0与Raid1长处的结合，高效也可靠，利用率也只有50%</p></li><li>Raid3(奇偶校验并行传送): N+1模式，有固定的校验盘，坏一个盘可恢复</li><li><p><font color="red">Raid5(分布式奇偶校验的<strong>独立磁盘</strong>)</font>: N+1模式，无固定的校验盘，坏一个盘可恢复(相比Raid3，优势在于降低整个系统的磁盘出错损坏的概率)<br><img src="/2021/07/22/架构设计师备考/Raid5.png" alt="Raid5"></p><blockquote><p>Raid5磁盘利用率为(n-1)/n，具有容错功能</p></blockquote></li><li><p>Raid6(两种存储的奇偶校验):N+2模式，无固定的校验盘，坏两个盘可恢复</p></li></ul><h3 id="IPv6"><a href="#IPv6" class="headerlink" title="IPv6"></a>IPv6</h3><blockquote><p>IPv6是设计用于替代现行版本IP协议(IPv4)的下一代IP协议</p></blockquote><ul><li><p>特点</p><ul><li>IPv6地址长度为128位，<font color="red">地址空间增大了$2^{96}$倍</font></li><li>灵活的IP报文头部格式。使用一系列固定格式的扩展头部取代了IPv4种可变长度的选项字段。IPv6中选项部分的出现方式也有所变化，是路由器可以简单路过选项而不做任何处理，加快了报文处理速度</li><li>IPv6简化了报文头部格式，字段只有8个，加快报文转发，提高了吞吐量</li><li>提高安全性。身份认证和隐私权是IPv6的关键特性</li><li>支持更多的服务类型</li><li>允许协议继续演变，增加新的功能，使之适应未来技术的发展</li></ul></li><li><p>地址分类</p><ul><li>单播地址(Unicast):用于单个接口的标识符</li><li>任播地址(Anycast):泛播地址。一组接口的标识符，<font color="red">IPv4广播地址</font></li><li>组播地址(Multicast):IPv6的组播在功能上与IPv4中的组播类似</li></ul></li></ul><h3 id="物联网"><a href="#物联网" class="headerlink" title="物联网"></a>物联网</h3><blockquote><p>物联网(The Internet of Things)是实现物物相连的互联网络，其内涵包含两个方面：第一，物联网的核心和基础仍然是互联网，是在互联网基础上延伸和扩展的网络；第二，其用户端延伸和扩展到了任何物体与物体之间，使其进行信息交换和通信</p></blockquote><ul><li>感知层：识别物体、采集信息。如：二维码、RFID、摄像头、传感器</li><li>网络层：传递信息和处理信息。通信网与互联网的融合网络、网络管理中心、信息中心和智能处理中心等</li><li><p>应用层：解决信息处理和人机交互的问题<br><img src="/2021/07/22/架构设计师备考/物联网分层.png" alt="物联网分层"></p></li><li><p>RFID</p><blockquote><p>射频识别技术(Radio Frequency Identification,RFID)，又称电子标签，是一种通信技术，可通过无线电讯号识别特定目标并读写相关数据，而无需识别系统与特定目标之间建立机械或光学接触。该技术是物联网的一项核心技术，很多物联网应用都离不开它。</p></blockquote></li></ul><blockquote><p>RFID的基本组成部分通常包括：标签、阅读器、天线</p></blockquote><ul><li>二维码</li></ul><blockquote><p>二维码是用某种特定的几何图形按一定规律在平面(二维方向上)分布的黑白相间的图形记录数据符号信息的。在代码编制上巧妙地利用构成计算机内部逻辑基础的0、1比特流的概念，使用若干个与二进制相对应的几何形体来表示文字数值信息，通过图像输入设备或光电扫描设备自动识读以实现信息自动处理</p></blockquote><p>二维码常用的码制有：Data Matrix,Maxi Code,Aztec,QR Code,Vericode,PDF417,U1tacode,Code 49,Code 16k</p><ul><li>PDF417<ul><li>若采用扩展的字母数字压缩格式，可容纳1850个字符</li><li>若采用二进制/ASCII格式，可容纳1108个字节</li><li>若采用数字压缩格式，可容纳2710个数字</li></ul></li></ul><ul><li><p>传感网</p><blockquote><p>传感网是由随机分布的，集成有传感器(传感器有很多种类型，包括：温度、湿度、速度、气敏等)、数据处理单元和通信单元单元的微小节点，通过自组织的方式构成无线网络</p></blockquote></li><li><p>M2M</p><blockquote><p>M2M是将数据从一台终端传送到另一台终端，也就是机器与机器(Machine to Machine)的对话。但从广义上M2M可代表机器对机器(Machine to Machine)、人对机器(Man to Machine)、机器对人(Machine to Man)、移动网络对机器(Mobile to Machine)之间的连接和通信，它涵盖了所有实现在人、机器、系统之间建立通信连接的技术和手段</p></blockquote></li></ul><p><img src="/2021/07/22/架构设计师备考/物联网核心技术.png" alt="物联网核心技术"></p><h3 id="云计算"><a href="#云计算" class="headerlink" title="云计算"></a>云计算</h3><blockquote><p>云计算是一种基于互联网的计算方式，通过这种方式，共享的软硬件资源和信息可以按需提供给计算机和其它设备。云其实是网络、互联网的一种比喻说法。云计算的核心思想，是将大量用网络连接的计算资源统一管理和调度，构成一个计算资源池向用户按需服务。提供资源的网络被称为”云”。</p></blockquote><ul><li>狭义云计算指<font color="red">IT基础设施</font>的交付和使用模式，指通过网络以按需、易扩展的方式获取所需资源</li><li>广义云计算指<font color="red">服务</font>的交付和使用模式，指通过网络以按需、易扩展的方式获得所需服务。这种服务可以是IT和软件、互联网相关、也可是其他服务</li><li>特点<ul><li>集合了大量计算机，规模达到成千上万</li><li>多种软硬件技术相结合</li><li>对客户端设备的要求低</li><li>规模化效应</li></ul></li></ul><ul><li><p>类型</p><ul><li>软件即服务(SaaS)</li><li>平台即服务(PaaS)</li><li>基础设施即服务(IaaS)<br><img src="/2021/07/22/架构设计师备考/云计算服务类型.png" alt="云计算服务类型"></li></ul></li><li><p>应用</p><ul><li>存储服务</li><li>搜索</li><li>科学计算</li><li>安全应用</li><li>软件即服务</li></ul></li></ul><h2 id="企业信息化战略与实施"><a href="#企业信息化战略与实施" class="headerlink" title="企业信息化战略与实施"></a>企业信息化战略与实施</h2><h3 id="信息与信息化的概念"><a href="#信息与信息化的概念" class="headerlink" title="信息与信息化的概念"></a>信息与信息化的概念</h3><ul><li><p>信息</p><ul><li>维纳(Norber Wiener)：信息就是信息，既不是物质也不是能量</li><li>香农(Claude E.Shannon)：信息就是不确定性的减少</li><li>哲学界：信息是事物普遍联系的方式</li><li>其它：信息是事先不知道的报导</li></ul></li><li><p>信息化</p><ul><li>信息化就是计算机、通信和网络技术的现代化</li><li>信息化就是从物质生产占主导地位的社会向信息产业占主导地位社会转变的发展过程</li><li>信息化就是从工业社会向信息社会演进的过程</li></ul></li></ul><h3 id="信息系统的概念"><a href="#信息系统的概念" class="headerlink" title="信息系统的概念"></a>信息系统的概念</h3><blockquote><p>系统指多个元素有机地结合在一起，执行特定的功能以达到特定目标的集合体</p><p><font color="red">信息系统是输入数据，通过加工处理，产生信息的系统</font>，可以是人工的，手动的</p></blockquote><p><img src="/2021/07/22/架构设计师备考/信息系统概念.png" alt="信息系统概念"></p><h3 id="信息系统类型"><a href="#信息系统类型" class="headerlink" title="信息系统类型"></a>信息系统类型</h3><ul><li><p>数据环境分类</p><ul><li>数据文件</li><li>应用数据库：比数据文件的好处<font color="red">不用管具体操作，只需告诉要做什么；便于共享</font></li><li>主题数据库<ul><li>面向业务主题</li><li>信息共享</li><li>一次一处输入系统</li><li>由基本表组成</li></ul></li><li>信息检索系统</li></ul></li><li><p>应用层次分类</p><ul><li>战略级(企业最高管理层)</li><li>战术级(企业中层经理及其管理部门)</li><li>操作级(服务型企业的业务部门)</li><li>事务级(企业的管理业务人员)</li></ul></li></ul><h3 id="信息系统战略规划-方法"><a href="#信息系统战略规划-方法" class="headerlink" title="信息系统战略规划-方法"></a>信息系统战略规划-方法</h3><blockquote><p>以<font color="red">数据处理为核心</font>围绕职能部门需求</p></blockquote><ul><li>企业系统规划法(BSP):通过大量调研了解企业战略目标，通过战略目标拆分，得到一些过程和需要处理的数据，然后进行表格转换。用到了多种矩阵，比如UC矩阵，找出数据和过程相关性</li><li>关键成功因素法(CSF):有目的地找企业的关键成功因素</li><li>战略集合转化法(SST):企业战略是指导信息系统战略的一个前提，把企业战略相关的集合转化成信息战略的集合<br><strong>三种方法结合使用称为BCS方法</strong></li></ul><blockquote><p>以<font color="red">企业内部MIS为核心</font>围绕企业整体需求</p></blockquote><ul><li>战略数据规划法(SDP):以BSP为基础，规划企业全局数据，提出主题数据库的概念</li><li>信息工程法(IE):以BSP为基础，融合SDP。其不仅仅是一门方法，<font color="red">还是一门工程学科，把信息系统开发过程进行了工程化</font></li><li><del>战略栅格法(SG):使用2X2矩阵，从战略影响方面标出企业现有和未来的信息系统组合的特征。对企业生存前景的影响做分析</del></li></ul><blockquote><p>综合考虑企业内外环境，以<font color="red">集成为核心</font>，围绕企业战略需求</p></blockquote><ul><li>价值链分析法(VCA)</li><li>战略一致性模型(SAM)</li></ul><h3 id="政府信息化与电子政务"><a href="#政府信息化与电子政务" class="headerlink" title="政府信息化与电子政务"></a>政府信息化与电子政务</h3><p><img src="/2021/07/22/架构设计师备考/政府信息化与电子政务.png" alt="政府信息化与电子政务"></p><h3 id="企业信息化与电子商务"><a href="#企业信息化与电子商务" class="headerlink" title="企业信息化与电子商务"></a>企业信息化与电子商务</h3><h4 id="企业资源计划-ERP"><a href="#企业资源计划-ERP" class="headerlink" title="企业资源计划(ERP)"></a>企业资源计划(ERP)</h4><ul><li>财会管理<ul><li>会计核算<ul><li>总账</li><li>应收账</li><li>应付账</li><li>现金</li><li>固定资产</li><li>多币制</li></ul></li><li>财务管理<ul><li>财务计划</li><li>控制</li><li>分析</li><li>预测</li></ul></li></ul></li><li>物流管理<ul><li>分销管理</li><li>库存控制</li><li>采购管理</li></ul></li><li>生产控制管理<ul><li>主生产计划</li><li>物料需求计划</li><li>能力需求计划</li><li>车间控制</li><li>制造标准</li></ul></li><li>人力资源管理<ul><li>人力资源规划</li><li>招聘管理</li><li>工资核算</li><li>工时管理</li><li>差旅费核算</li></ul></li></ul><h4 id="客户关系管理-CRM"><a href="#客户关系管理-CRM" class="headerlink" title="客户关系管理(CRM)"></a>客户关系管理(CRM)</h4><p><img src="/2021/07/22/架构设计师备考/客户关系管理.png" alt="客户关系管理"></p><h4 id="供应链管理-SCM"><a href="#供应链管理-SCM" class="headerlink" title="供应链管理(SCM)"></a>供应链管理(SCM)</h4><p><img src="/2021/07/22/架构设计师备考/供应链管理.png" alt="供应链管理"></p><ul><li>设计原则<ul><li>自顶向下和自底向上结合(所有信息化体系的共性，即全局规划加具体实现)</li><li>简洁性原则</li><li>互补性原则</li><li>协调性原则</li><li>动态性原则</li><li>创新性原则</li><li>战略性原则</li></ul></li></ul><h4 id="商业智能-BI"><a href="#商业智能-BI" class="headerlink" title="商业智能(BI)"></a>商业智能(BI)</h4><p><img src="/2021/07/22/架构设计师备考/商业智能.png" alt="商业智能"></p><h4 id="电子数据交换"><a href="#电子数据交换" class="headerlink" title="电子数据交换"></a>电子数据交换</h4><p><img src="/2021/07/22/架构设计师备考/商业智能.png" alt="商业智能"></p><blockquote><p>EDI系统三要素：EDI软件和硬件、通信网络、数据标准化</p></blockquote><ul><li>EDI的特点<ul><li>EDI的使用对象是不同的组织之间，EDI传输的企业间的报文，是企业间信息交流的一种方式</li><li>EDI所传送的资料是一般业务资料，如发票、订单等，而不是指一般性的通知</li><li>EDI传输的报文是格式化的，是符合国际标准的，这是计算机能够自动处理报文的基本前提</li><li>EDI使用的数据通信网络一般是增值网、专用网</li><li>数据传输由收送双方的计算机系统直接传送、交换资料，不需要人工介入操作</li><li>EDI与传真或电子邮件的区别是：传真与电子邮件，需要人工阅读判断处理才能进入计算机系统。人工将资料重复输入计算机系统中，既浪费人力资源，也容易发生错误，而EDI不需要再将有关资料人工重复输入系统</li></ul></li></ul><p><strong>EDI在外贸领域仍在广泛应用</strong></p><h4 id="企业应用集成-常考"><a href="#企业应用集成-常考" class="headerlink" title="企业应用集成(常考)"></a>企业应用集成(常考)</h4><ul><li><p>过度性质的方案，未在数据上真正整合</p><ul><li><p>表示集成(界面集成)<br><img src="/2021/07/22/架构设计师备考/表示集成.png" alt="表示集成"></p></li><li><p>数据集成<br><img src="/2021/07/22/架构设计师备考/数据集成.png" alt="数据集成"></p></li><li><p>控制集成(应用集成，API集成)<br><img src="/2021/07/22/架构设计师备考/控制集成.png" alt="控制集成"></p></li></ul></li><li><p>业务流程集成(过程集成)：会考虑业务流程优化的问题，不局限于企业内部系统</p></li><li><p>存储体和交换数据的角度划分</p><ul><li>消息集成：适用于数据量小，但要求频繁地、立即地、异步地数据交换场合</li><li>共享数据库：实用性强、可以频繁交互、数据的交换属于同步方式</li><li>文件传输：适用于数据量大、交换频度小，即时性要求低的情况</li></ul></li></ul><h3 id="电子商务"><a href="#电子商务" class="headerlink" title="电子商务"></a>电子商务</h3><ul><li><p>四流</p><ul><li><font color="red">信息流</font>(核型)</li><li>资金流(辅助)</li><li>物流(辅助)</li><li><del>商流</del></li></ul></li><li><p>类型</p><ul><li>企业对消费者(B2C)</li><li>企业对企业(B2B)</li><li>消费者对消费者(C2C)</li><li>线上对线下(O2O)</li></ul></li></ul><p><img src="/2021/07/22/架构设计师备考/国家电子商务标准体系.png" alt="国家电子商务标准体系"></p><h3 id="信息系统开发方法"><a href="#信息系统开发方法" class="headerlink" title="信息系统开发方法"></a>信息系统开发方法</h3><ul><li>结构化法<ul><li>用户至上</li><li>严格区分工作节点，每阶段有任务和成果</li><li>强调系统开发过程的整体性和全局性</li><li>系统开发过程工程化，文档资料标准化</li><li>自顶向下，逐步分解(求精)</li></ul></li><li>原型法<ul><li>适用于需求不明确的开发</li><li>包括抛弃式原型和演化式原型</li></ul></li><li>面向对象方法<ul><li>更好的复用性</li><li>关键在于建立一个全面、合理、统一的模型</li><li>分析、设计、实现三个阶段，界限不明确</li></ul></li><li>面向服务方法<ul><li>SO方法有三个主要的抽象级别：操作、服务、业务流程</li><li>SOAD分为三个层次：基础设计层(底层服务构件)、应用结构层(服务之间的接口和服务级协定)和业务组织层(业务流程建模和服务流程编排)</li><li>服务建模：分为服务发现、服务规约和服务实现三个阶段</li></ul></li></ul><h2 id="软件工程"><a href="#软件工程" class="headerlink" title="软件工程"></a>软件工程</h2><h3 id="软件开发模型"><a href="#软件开发模型" class="headerlink" title="软件开发模型"></a>软件开发模型</h3><h4 id="瀑布模型-SDLC"><a href="#瀑布模型-SDLC" class="headerlink" title="瀑布模型(SDLC)"></a>瀑布模型(SDLC)</h4><ul><li><font color="red">结构化方法模型典型代表</font>，用于结构化开发</li><li><strong><font color="red">适合需求明确，二次开发的场景</font></strong>，或按其他方法把需求做明确再按瀑布模型开发</li><li>缺点：需求阶段难以把控<br><img src="/2021/07/22/架构设计师备考/瀑布模型.jpg" alt="瀑布模型"></li></ul><h4 id="增量模型与螺旋模型"><a href="#增量模型与螺旋模型" class="headerlink" title="增量模型与螺旋模型"></a>增量模型与螺旋模型</h4><ul><li><p>增量模型<br><img src="/2021/07/22/架构设计师备考/增量模型.jpg" alt="增量模型"></p></li><li><p>螺旋模型</p><ul><li>由多个模型组合，原型、瀑布模型、演化模型等(题目描述说针对需求不明确的情况只能选原型，<font color="red">遵循最匹配原则</font>)</li><li><font color="red">引入风险分析</font><br><img src="/2021/07/22/架构设计师备考/螺旋模型.jpg" alt="螺旋模型"></li></ul></li></ul><h4 id="构建组装模型-CBSD"><a href="#构建组装模型-CBSD" class="headerlink" title="构建组装模型(CBSD)"></a>构建组装模型(CBSD)</h4><ul><li>把软件开发中的各个模块做成构建，由构建组装形成软件</li><li>极大提高软件开发复用性，减小软件开发总时长，降低软件开发成本，提高软件可靠性<br><img src="/2021/07/22/架构设计师备考/构建组装模型.jpg" alt="构建组装模型"></li></ul><h4 id="V模型、喷泉模型和RAD"><a href="#V模型、喷泉模型和RAD" class="headerlink" title="V模型、喷泉模型和RAD"></a>V模型、喷泉模型和RAD</h4><ul><li><p>V模型</p><ul><li>与瀑布模型接近，测试有更重要的地位</li><li>测试计划提前，有助于尽早发现问题</li><li><font color="red">强调及早进行测试，测试贯穿开发整个过程中</font></li></ul></li><li><p>喷泉模型</p><ul><li><font color="red">面向对象模型</font></li></ul></li><li><p>RAD</p><ul><li>由SDLC和CBSD模型组合而成</li><li><font color="red">能快速构建应用系统</font><br><img src="/2021/07/22/架构设计师备考/V模型、喷泉模型和RAD.jpg" alt="V模型、喷泉模型和RAD"></li></ul></li></ul><h4 id="其他经典模型"><a href="#其他经典模型" class="headerlink" title="其他经典模型"></a>其他经典模型</h4><ul><li>原型和瀑布模型是互补的模型，原型强调在项目初期构造简易系统(界面式或初步系统)，<font color="red">针对需求不明确的情况，只应用于开发中需求分析的阶段</font></li><li>演化模型是指从最初的原型通过多步演化调整，最终变成软件产品</li><li>螺旋模型有原型、演化模型和瀑布模型的特征</li><li>增量模型由原型的思想和瀑布模型的思想构成，先完成一部分再完成一部分，最后完成整个产品(风险小很对)<br><img src="/2021/07/22/架构设计师备考/其他经典模型.jpg" alt="其他经典模型"></li></ul><h3 id="统一过程-UP-RUP"><a href="#统一过程-UP-RUP" class="headerlink" title="统一过程(UP/RUP)"></a>统一过程(UP/RUP)</h3><p><img src="/2021/07/22/架构设计师备考/统一过程.jpg" alt="统一过程"></p><h3 id="敏捷开发方法"><a href="#敏捷开发方法" class="headerlink" title="敏捷开发方法"></a>敏捷开发方法</h3><font color="red">适合小型项目，强调小步快跑</font><p><img src="/2021/07/22/架构设计师备考/敏捷开发方法.jpg" alt="敏捷开发方法"></p><h3 id="逆向工程"><a href="#逆向工程" class="headerlink" title="逆向工程"></a>逆向工程</h3><blockquote><p>由已经形成的产品反推设计和需求</p></blockquote><h2 id="需求工程"><a href="#需求工程" class="headerlink" title="需求工程"></a>需求工程</h2><h3 id="OOA"><a href="#OOA" class="headerlink" title="OOA"></a>OOA</h3><blockquote><p>OOA相关概念：对象、类(实体类、边界类、控制类)、抽象、封装、继承与泛化、多态、接口、消息、组件、模式和复用</p></blockquote><h4 id="UML"><a href="#UML" class="headerlink" title="UML"></a>UML</h4><ul><li>图<ul><li>分类<ul><li>结构图/静态图：类图、对象图、包图、组合结构图、构件图、部署图、制品图</li><li>行为图/动态图：用例图(用例)、顺序图/序列图、通信图/协作图、<del>定时图</del>、状态图、活动图、<del>交互概览图</del><font color="red">用例图(用例)分类有歧义，选择时先看其他选项，实在无选择再选这个，大多数时候归为动态，少部分时间归为静态</font></li></ul></li><li>功能<br><font color="red">部署图描述的是软件的构建应该部署在哪个硬件节点上，其他静态图描述的均为关系</font><ul><li>用例图(用例)：表达的是系统和外部的交互关系</li><li>顺序图/序列图：强调按时间关系</li><li>通信图/协作图：与顺序图相同，<font color="red">区别在于没有强调按时间顺序</font></li><li>状态图：表达状态的变迁转移的情况</li><li>活动图：和流程图结构一致<br><img src="/2021/07/22/架构设计师备考/UML.jpg" alt="UML"></li></ul></li></ul></li></ul><h3 id="需求分类和需求获取"><a href="#需求分类和需求获取" class="headerlink" title="需求分类和需求获取"></a>需求分类和需求获取</h3><ul><li>分类<ul><li>业务需求</li><li>用户需求</li><li>系统需求<ul><li>功能需求</li><li>性能需求(非功能需求)：响应时间、安全性、可靠性</li><li>设计约束：和功能与性能无关的影响</li></ul></li></ul></li><li>质量展开模型(QFD)<ul><li>基本需求：用户明确提出需要完成的</li><li>期望需求：用户未明确提出但理所应当觉得应该具有的功能</li><li>兴奋需求：用户未提出也没觉得应该做但做了的</li></ul></li><li>获取方法<ul><li>收集资料：了解企业现状</li><li>联合需求计划(开会)：已经获取初步需求，各方人员参会讨论;<font color="red">消耗资源多</font></li><li>用户访谈：找关键角色探讨对需求的想法；流程包括<font color="red">准备访谈、确定访谈对象(3个或3个以下一次)、准备问题(开放式/封闭式)、限制访谈时间(90min之内，长了拆分)、寻找异常和错误情况、做好相应记录、总结访谈</font><ul><li>结构化形式：逻辑层次严谨，依据充分；事先准备问题，有针对性提问；局限性更大</li><li>非结构化形式：开始只有粗略想法，根据访谈进度灵活调整；</li><li>优点：灵活度高，应用范围广，了解细节深入</li><li>缺点：用户忙难安排时间、信息量大难记录</li></ul></li><li>书面调查：用户访谈的补充形式，问卷下发用户；<ul><li>缺点：只能看到结果，不能了解选择时的疑问；用户不认真；问题不容易深入；问卷调查设计有难度；问卷发下去收不全(解释重要性)</li></ul></li><li>情节串联板：可以以讲故事思路将各个环节串联起来</li><li>现场观摩</li><li>参加业务实践</li><li>阅读历史文档：获取数据层次时有效</li><li>抽样调查：数据量大，解决时间，比较有性价比<br><img src="/2021/07/22/架构设计师备考/需求分类和需求获取.jpg" alt="需求分类和需求获取"></li></ul></li></ul><h3 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h3><p><img src="/2021/07/22/架构设计师备考/需求分析.jpg" alt="需求分析"></p><h4 id="数据流图-分层数据流图DFD"><a href="#数据流图-分层数据流图DFD" class="headerlink" title="数据流图(分层数据流图DFD)"></a>数据流图(分层数据流图DFD)</h4><ul><li>数据流：箭头指示的为数据流</li><li>加工：处理数据的部件</li><li>数据存储：存储部件(文件)</li><li>外部实体：位置在系统之外<br><font color="red">顶层图和0层图之间应该保持平衡，即数据流交换应该一致，输入输出要平衡</font><br><img src="/2021/07/22/架构设计师备考/数据流图.jpg" alt="数据流图"></li></ul><h4 id="状态转换图-STD"><a href="#状态转换图-STD" class="headerlink" title="状态转换图(STD)"></a>状态转换图(STD)</h4><blockquote><p>描述业务流程，描述行为</p></blockquote><p><img src="/2021/07/22/架构设计师备考/STD.jpg" alt="STD"></p><h4 id="ER图"><a href="#ER图" class="headerlink" title="ER图"></a>ER图</h4><p><img src="/2021/07/22/架构设计师备考/ER图.jpg" alt="ER图"></p><h4 id="数据字典"><a href="#数据字典" class="headerlink" title="数据字典"></a>数据字典</h4><blockquote><p>解释相关信息</p></blockquote><ul><li>数据元素</li><li>数据结构</li><li>数据流</li><li>数据存储</li><li>加工逻辑<ul><li>结构化语言</li><li>判定树</li><li>判定表</li></ul></li><li>外部实体</li></ul><h2 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h2><h3 id="处理流程设计"><a href="#处理流程设计" class="headerlink" title="处理流程设计"></a>处理流程设计</h3><h4 id="业务流程重组"><a href="#业务流程重组" class="headerlink" title="业务流程重组"></a>业务流程重组</h4><blockquote><p>BPR是对<font color="red">企业</font>流程进行<font color="red">根本性</font>的再思考和<font color="red">彻底性</font>的再设计，从而获得可以用诸如成本、质量、服务和速度等方面的业绩来衡量的<font color="red">显著性</font>成就</p></blockquote><p><img src="/2021/07/22/架构设计师备考/业务流程重组.jpg" alt="业务流程重组"></p><h4 id="业务流程管理"><a href="#业务流程管理" class="headerlink" title="业务流程管理"></a>业务流程管理</h4><blockquote><p>BPM是一种以<font color="red">规范化</font>的构造端到端的卓越业务<font color="red">流程</font>为中心，以<font color="red">持续的</font>提高组织业务绩效为目的的<font color="red">系统化</font>方法</p></blockquote><ul><li>PDCA闭环的管理过程<ul><li>明确业务流程所欲获取的成果</li><li>开发或计划系统的方法，实现以上成果</li><li>系统地部署方法，确保全面实施</li><li>根据对业务的检查和分析以及持续的学习活动，评估和审查所执行的方法，并进一步提出计划和实施改进措施</li></ul></li><li>流程管理包含三个层面：规范流程、优化流程和再造流程</li></ul><font color="red">BPM与BRP管理四项最根本的不同就在于流程管理并不要求对所有的流程进行再造。构造卓越的业务流程并不是流程再造，而是根据现有流程的具体情况，对流程进行规范化的设计</font><h3 id="人机界面设计"><a href="#人机界面设计" class="headerlink" title="人机界面设计"></a>人机界面设计</h3><ul><li>置于用户控制之下<ul><li>以不强迫用户进入不必要的或不希望的动作的方式来定义交互方式</li><li>提供灵活的交互</li><li>允许用户交互可以被中断和撤销</li><li>当技能级别增加时可以使交互流水化并允许定制交互</li><li>使用户隔离内部技术细节</li><li>设计应允许用户和出现在屏幕上的对象直接交互</li></ul></li><li>减少用户的记忆负担<ul><li>较少对短期记忆的要求</li><li>建立有意义的缺省</li><li>定义直觉性的捷径</li><li>界面的视觉布局应该基于真实世界的隐喻</li><li>以不断进展的方式提示信息</li></ul></li><li>保持界面的一致性<ul><li>允许用户将当前任务放入有意义的语境</li><li>在应用系列内保持一致性</li><li>如果去得交互模型已建立起了用户期望，除非有迫不得已的理由，不要改变它</li></ul></li></ul><h3 id="结构化设计"><a href="#结构化设计" class="headerlink" title="结构化设计"></a>结构化设计</h3><blockquote><p>分为概要设计、详细设计</p></blockquote><ul><li>基本原则<ul><li>自顶向下、逐步求精</li><li>信息隐藏</li><li>模块独立(高内聚、低耦合、复杂度)<ul><li>保持模块的大小适中</li><li>尽可能减少调用的深度</li><li>多扇入、少扇出</li><li>单入口、单出口</li><li>模块的作用域应该在模块之内</li><li>功能应该时可预测的</li></ul></li></ul></li></ul><h4 id="内聚与耦合"><a href="#内聚与耦合" class="headerlink" title="内聚与耦合"></a>内聚与耦合</h4><ul><li>内聚<blockquote><p>内聚程度从高到低</p></blockquote></li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">内聚类型</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:center">功能内聚</td><td style="text-align:left">完成一个单一功能，各个部分协同工作，缺一不可</td></tr><tr><td style="text-align:center">顺序内聚</td><td style="text-align:left">处理元素相关，而且必须顺序执行</td></tr><tr><td style="text-align:center">通信内聚</td><td style="text-align:left">所有处理元素集中在一个数据结构的区域上</td></tr><tr><td style="text-align:center">过程内聚</td><td style="text-align:left">处理元素相关，而且必须按特定的次序执行</td></tr><tr><td style="text-align:center">瞬时内聚(时间内聚)</td><td style="text-align:left">所包含的任务必须在同一时间间隔内执行</td></tr><tr><td style="text-align:center">逻辑内聚</td><td style="text-align:left">完成逻辑上相关的一组任务</td></tr><tr><td style="text-align:center">偶然内聚(巧合内聚)</td><td style="text-align:left">完成一组没有关系或松散关系的任务</td></tr></tbody></table></div><ul><li>耦合<blockquote><p>耦合程度由低到高</p></blockquote></li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">耦合类型</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:center">非直接耦合</td><td style="text-align:left">两个模块直接没有直接关系，它们之间的联系完全时通过主模块的控制和调用来实现的</td></tr><tr><td style="text-align:center">数据耦合</td><td style="text-align:left">一组模块借助参数表传递简单数据</td></tr><tr><td style="text-align:center">标记耦合</td><td style="text-align:left">一组模块通过参数表传递记录信息(数据结构)</td></tr><tr><td style="text-align:center">控制耦合</td><td style="text-align:left">模块之间传递的信息中包含用于控制模块内部逻辑的信息</td></tr><tr><td style="text-align:center">外部耦合</td><td style="text-align:left">一组模块都访问同一全局简单变量，而不是通过参数表传递该全局变量的信息</td></tr><tr><td style="text-align:center">公共耦合</td><td style="text-align:left">多个模块都访问同一个公共数据环境</td></tr><tr><td style="text-align:center">内容耦合</td><td style="text-align:left">一个模块直接访问另一个模块的内部数据；一个模块不通过正常入口转到另一个模块的内部；两个模块有一部分程序代码重叠；一个模块有多个入口</td></tr></tbody></table></div><h4 id="系统结构-模块结构"><a href="#系统结构-模块结构" class="headerlink" title="系统结构/模块结构"></a>系统结构/模块结构</h4><font color="red">变换型系统结构b重点掌握</font><p><img src="/2021/07/22/架构设计师备考/系统结构.jpg" alt="系统结构"></p><h3 id="面向对象设计-设计原则"><a href="#面向对象设计-设计原则" class="headerlink" title="面向对象设计-设计原则"></a>面向对象设计-设计原则</h3><ul><li>单一职责原则：设计目的单一的类</li><li>开放-封闭原则：对扩展开放，对修改封闭</li><li>里氏(Liskov)替换原则：子类可以替换父类</li><li>依赖倒置原则：要依赖于抽象，而不是具体实现；针对接口编程，不要针对实现编程</li><li>接口隔离原则：使用多个专门的接口比使用单一的总接口要好</li><li>组合重用原则：要尽量使用组合，而不是继承关系达到重用的目的</li><li>迪米特(Demeter)原则(最少只是法则)：一个对象应当对其它对象由尽可能少的了解</li></ul><h3 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h3><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><ul><li>架构模式：软件设计中的高层决策，例如C/S结构就属于架构模式，架构模式反映了开发软件系统过程中所作的基本设计决策(B/S、SOA)</li><li>设计模式：主要关注软件系统的设计，与具体的实现语言无关(<font color="red">在进行构件设计时</font>)</li><li>惯用法：最底层的模式，关注软件系统的设计与实现，实现时通过<font color="red">某种特定的程序设计语言</font>来描述构件与构件之间的关系。每种编程语言都有它自己特定的模式，即语言的惯用法。例如引用-计数就是C++语言中的一种惯用法</li></ul><h4 id="分类-2"><a href="#分类-2" class="headerlink" title="分类"></a>分类</h4><ul><li>创建型模式：工厂方法(factory method)模式、抽象工厂(abstract factory)模式、原型(prototype)模式、单例(singleton)模式、构建器(builder)模式</li><li>结构型模式：适配器(adapter)模式、桥接(bridge)模式、组合(composite)模式、装饰(decorator)模式、外观(facade)模式、享元(flyweight)模式、代理(proxy)模式</li><li><p>行为型模式：职责链(chain of responsibility)模式、命令(command)模式、解释器(interpreter)模式、迭代器(iterator)模式、中介者(mediator)模式、备忘录(memento)模式、观察者(observer)模式、状态(state)模式、策略(strategy)模式、模板方法(template method)模式、访问者(visitor)模式</p></li><li><p>创建型模式</p></li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">设计模式名称</th><th style="text-align:center">简要说明</th></tr></thead><tbody><tr><td style="text-align:center">Abstract Factory<br>抽象工厂模式</td><td style="text-align:center">提供一个接口，可以创建一系列相关或相互依赖的对象，而无需指定它们具体的类</td></tr><tr><td style="text-align:center">Builder<br>构建器模式</td><td style="text-align:center">将一个复杂类的表示与其构造相分离，使得相同的构建过程能够得出不同的表示</td></tr><tr><td style="text-align:center">Factory Method<br>工厂方法模式</td><td style="text-align:center">定义一个创建对象的接口，但由子类决定需要实例化哪一个类，工厂方法使得子类实例化的过程推迟</td></tr><tr><td style="text-align:center">Prototype<br>原型模式</td><td style="text-align:center">用原型实例指定创建对象的类型，并且通过拷贝这个原型来创建新的对象</td></tr><tr><td style="text-align:center">Singleton<br>单例模式</td><td style="text-align:center">保证一个类只有一个实例，并提供一个访问它的全局访问点</td></tr></tbody></table></div><ul><li>结构型模式</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">设计模式名称</th><th style="text-align:center">简要说明</th><th style="text-align:center">速记关键字</th></tr></thead><tbody><tr><td style="text-align:center">Adapter<br>适配器模式</td><td style="text-align:center">将一个类的接口转换成用户希望得到的另一种接口。它使原本不相容的接口得以协同工作</td><td style="text-align:center"><font color="red">转换</font>接口</td></tr><tr><td style="text-align:center">Bridge<br>桥接模式</td><td style="text-align:center">将类的抽象部分和它的实现部分分离开来，使它们可以独立地变化</td><td style="text-align:center">继承树拆分</td></tr><tr><td style="text-align:center">Composite<br>组合模式</td><td style="text-align:center">将对象组合成树型结构以表示“<font color="red">整体-部分</font>”的层次结构，使得用户对单个对象和组合对象的使用具有一致性</td><td style="text-align:center">树形目录结构</td></tr><tr><td style="text-align:center">Decorator<br>装饰模式</td><td style="text-align:center">动态地给一个对象添加一些额外的职责。它提供了用子类扩展功能的一个灵活的替代，比派生一个子类更加灵活</td><td style="text-align:center"><font color="red">附加职责</font></td></tr><tr><td style="text-align:center">Facade<br>外观模式</td><td style="text-align:center">定义一个<font color="red">高层接口</font>，为子系统中的一组接口提供一个一致的外观，从而简化该子系统的使用</td><td style="text-align:center">对外统一接口</td></tr><tr><td style="text-align:center">Flyweight<br>享元模式</td><td style="text-align:center">提供支持大量细粒度对象共享的方法</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">Proxy<br>代理模式</td><td style="text-align:center">为其他对象提供一种代理以控制这个对象的访问</td></tr></tbody></table></div><ul><li>行为型模式</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">设计模式名称</th><th style="text-align:center">简要说明</th><th style="text-align:center">速记关键字</th></tr></thead><tbody><tr><td style="text-align:center">Chain of Responsibility<br>职责链模式</td><td style="text-align:center">通过给多个对象处理请求的机会，减少请求的发送者与接收者之间的耦合。将接收对象链接起来，在链中传递请求，直到有一个对象处理这个请求</td><td style="text-align:center"><font color="red">传递职责</font></td></tr><tr><td style="text-align:center">Command<br>命令模式</td><td style="text-align:center">将一个请求封装为一个对象，从而可用不同的请求对客户进行参数化，将请求排队或记录请求日志，支持可撤销操作</td><td style="text-align:center">日志记录，可<font color="red">撤销</font></td></tr><tr><td style="text-align:center">Interpreter<br>解释器模式</td><td style="text-align:center">给定一种语言，定义它的文法表示，并定义一个解释器，该解释器用来根据文法表示来解释语言中的句子</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">Iterator<br>迭代器模式</td><td style="text-align:center">提供一种方法来顺序访问一个聚合对象中的各个元素而不需要暴露该对象的内部表示</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">Mediator<br>中介者模式</td><td style="text-align:center">用一个中介对象来封装一系列的对象交互，它使各对象不需要显示地相互调用，从而达到低耦合，还可以独立地改变对象间的交互</td><td style="text-align:center">不直接引用</td></tr><tr><td style="text-align:center">Memento<br>备忘录模式</td><td style="text-align:center">在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，从而可以在以后将对象恢复到原先保存的状态</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">Observer<br>观察者模式</td><td style="text-align:center">定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并自动更新</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">State<br>状态模式</td><td style="text-align:center">允许一个对象在其内部状态改变时改变它的行为</td><td style="text-align:center">状态变成类</td></tr><tr><td style="text-align:center">Strategy<br>策略模式</td><td style="text-align:center">定义一系列算法，把它们一个个封装起来，并且使它们之间可互相替换，从而让算法可以独立于使用它的用户而变化</td><td style="text-align:center">多方案切换</td></tr><tr><td style="text-align:center">Template Method<br>模板方法模式</td><td style="text-align:center">定义一个操作中的算法骨架，而将一些步骤延迟到子类中，使得子类可以不改变一个算法的接口即可重新定义算法的某些特定步骤</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">Vistor<br>访问者模式</td><td style="text-align:center">表示一个作用于对象结构中的各元素的操作，使得在不改变各元素的类的前提下定义作用于这些元素的新操作</td></tr></tbody></table></div><h3 id="软件测试"><a href="#软件测试" class="headerlink" title="软件测试"></a>软件测试</h3><h4 id="原则和类型"><a href="#原则和类型" class="headerlink" title="原则和类型"></a>原则和类型</h4><ul><li><p>原则</p><ul><li>尽早、不断地进行测试</li><li>程序员避免测试自己设计的程序</li><li>既要选择有效、合理的数据、也要选择无效、不合理的数据</li><li>修改后进行回归测试</li><li>尚未发现的错误数量与该程序已发现的错误数成正比</li></ul></li><li><p>分类</p><ul><li>动态测试<ul><li>黑盒测试法</li><li>白盒测试发</li><li>灰盒测试法</li></ul></li><li>静态测试<ul><li>桌前检查</li><li>代码走查</li><li>代码审查</li></ul></li></ul></li></ul><h4 id="测试用例设计"><a href="#测试用例设计" class="headerlink" title="测试用例设计"></a>测试用例设计</h4><ul><li>黑盒测试<ul><li>等价类划分：把所有数据进行归类，同一类的选一个进行测试</li><li>边界值分析：端点、略小于下区间的值、略大于大区间的值</li><li>错误推测</li><li>因果图：由果分析因</li></ul></li><li>白盒测试<ul><li>基本路径测试</li><li>循环覆盖测试</li><li><font color="red">逻辑覆盖测试</font>：<font color="red">语句覆盖(层次最低)、判定覆盖(真假分支各走一遍)、条件覆盖(拆分判定)</font>、条件判定覆盖、修正的条件判断覆盖、条件组合覆盖、点覆盖、边覆盖、<font color="red">路径覆盖(层次最高)</font></li></ul></li></ul><h4 id="测试阶段"><a href="#测试阶段" class="headerlink" title="测试阶段"></a>测试阶段</h4><ul><li>单元测试：模块级，局部功能，模块相关接口</li><li>集成测试：各个模块联合测试，测试模块之间衔接、接口（增量式组装工作量更大但更全面）</li><li>确认测试</li><li>系统测试：偏重于压力性能等(<font color="red">负载测试(高并发)、强度测试(资源突然下降)、容量测试</font>)<br><img src="/2021/07/22/架构设计师备考/测试阶段.jpg" alt="测试阶段"></li></ul><h4 id="面向对象的测试"><a href="#面向对象的测试" class="headerlink" title="面向对象的测试"></a>面向对象的测试</h4><ul><li>算法层(单元测试)：包括等价类划分测试、组合功能测试（基于判定表的测试）、递归函数测试和多态消息测试</li><li>类层(模块测试)：包括不变式边界测试、模态类测试和非模态类测试</li><li>模板层/类树层(集成测试)：包括多态服务测试和展平测试</li><li>系统层(系统测试)</li></ul><h4 id="测试管理"><a href="#测试管理" class="headerlink" title="测试管理"></a>测试管理</h4><ul><li>测试团队管理</li><li>测试计划管理</li><li><font color="red">错误(缺陷)跟踪管理</font><ul><li>错误植入法：$a_1:b_1=a_2:b_2$，人为植入错误，从结果查看哪些使植入的，按比例估算错误数，以此考核团队成员是否有效发现错误。(估算错误数)</li><li>两组并行测试：$DN=(a\times b)/c$，a代表a团队测出的错误数，b代表b团队测出的错误数，c代表俩团队共同测出的错误数。(估算错误数)</li><li>错误曝光率(DRE)：$DRE=e/(e+d)$，e表示测试阶段发现的问题，d表示用户使用时发现的问题，两者之和为缺陷的总数。(客观、准确，缺点是只有交付之后才能计算)</li></ul></li><li>测试件管理</li></ul><h4 id="软件调试"><a href="#软件调试" class="headerlink" title="软件调试"></a>软件调试</h4><ul><li>软件调试方法<ul><li>蛮力法：主要是想是“通过计算机找错”，低效，耗时</li><li>回溯法：从出错处人工沿控制流程往回追踪，直至发现出错的根源，复杂程度由于回溯路径多，难以实施</li><li>原因排除法：主要思想是演绎和归纳，用二分法实现</li></ul></li><li>软件调试和测试的区别<ul><li>测试的目的是找出存在的错误，而调试的目的是定位错误并修改程序以修正错误</li><li>调试时测试之后的活动，测试和调试在目标、方法和思路上都有所不同</li><li>测试从一个已知的条件开始，使用预先定义的过程，有预知的结果；调试从一个未知的条件开始，结束的过程不可预计</li><li>测试过程可以事先设计，进度可以事先确定；调试不能描述过程或持续时间</li></ul></li></ul><h3 id="系统运行与维护"><a href="#系统运行与维护" class="headerlink" title="系统运行与维护"></a>系统运行与维护</h3><blockquote><p>软件维护时生命周期的一个完整部分。可以将软件维护定义为需要提供软件支持的全部活动，这些活动包括在交付前完成的活动，以及交付后完成的活动。交付前完成的活动包括交付后运行的计划和维护计划等；交付后的活动包括软件修改、培训、帮助资料等</p></blockquote><ul><li>可维护性<ul><li>易分析性：源代码理解容易</li><li>易改变性：修改代码比较容易(耦合度低)</li><li>稳定性</li><li>易测试性</li></ul></li><li>维护类型<ul><li>改正性维护(25%)/正确性维护：用户发现缺陷则修正缺陷</li><li>适应性维护(20%)：环境改变(操作系统、数据环境)，<font color="red">软件需要适应的情况均属于此范畴</font></li><li>完善性维护(50%)：在系统运行过程中扩充功能，改善性能</li><li>预防性维护(5%)：现在不维护将来可能导致问题</li></ul></li></ul><h3 id="软件过程改进-CMMI"><a href="#软件过程改进-CMMI" class="headerlink" title="软件过程改进(CMMI)"></a>软件过程改进(CMMI)</h3><ul><li>阶段式：组织能力成熟度</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">成熟度等级</th><th style="text-align:left">过程域</th></tr></thead><tbody><tr><td style="text-align:center">已管理级(项目级)</td><td style="text-align:left">需求管理有、项目计划、配置管理、项目监督与控制、供应商合同管理、度量和分析、过程和产品质量保证</td></tr><tr><td style="text-align:center">已定义级(<font color="red">组织级、文档化、标准化、知识由隐性变为显性</font>)</td><td style="text-align:left">需求开发、技术解决方案、产品集成、验证、确认、组织级过程焦点、组织级过程定义、组织级培训、集成项目管理、风险管理、集成化的团队、决策分析和解决方案、组织级集成环境</td></tr><tr><td style="text-align:center">定量管理级(<font color="red">量化</font>)</td><td style="text-align:left">组织级过程性能、定量项目管理</td></tr><tr><td style="text-align:center">优化级</td><td style="text-align:left">组织级改革与实施、因果分析和解决方案</td></tr></tbody></table></div><ul><li>连续式：软件过程能力</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">连续式分组</th><th style="text-align:left">过程域</th></tr></thead><tbody><tr><td style="text-align:center">过程管理</td><td style="text-align:left">组织级过程焦点、组织级过程定义、组织级培训、组织级过程性能、组织级改革与实施</td></tr><tr><td style="text-align:center">项目管理</td><td style="text-align:left">项目计划、项目监督与控制、供应商合同管理、集成项目管理、风险管理、集成化的团队、定量项目管理</td></tr><tr><td style="text-align:center">工程</td><td style="text-align:left">需求管理、需求开发、技术解决方案、产品集成、验证、确认</td></tr><tr><td style="text-align:center">支持</td><td style="text-align:left">配置管理、度量和分析、过程和产品质量保证、决策分析和解决方案、组织级集成环境、因果分析和解决方案</td></tr></tbody></table></div><h2 id="项目管理"><a href="#项目管理" class="headerlink" title="项目管理"></a>项目管理</h2><h3 id="范围管理"><a href="#范围管理" class="headerlink" title="范围管理"></a>范围管理</h3><ul><li>范围定义<ul><li>产品范围：需求调研获取到的信息</li><li>工作范围：完成项目需要开展的一系列工作</li></ul></li><li>创建WBS：工作包的分解，界定项目范围<br><img src="/2021/07/22/架构设计师备考/范围管理.jpg" alt="范围管理"></li></ul><h3 id="时间管理"><a href="#时间管理" class="headerlink" title="时间管理"></a>时间管理</h3><ul><li>活动定义：把活动找出来</li><li>活动排序：采取拓扑排序的方式</li><li>活动资源估算：人员、时间、物料、服务器、设备等</li><li>活动历时估算：活动需要多少时间<ul><li>三点估算法：$\frac{best+4\times mid+ worst}{6}$</li><li>自下而上的估算：必须先完成WBS分解</li></ul></li><li>制订进度计划：</li><li>进度控制：<br><img src="/2021/07/22/架构设计师备考/时间管理.jpg" alt="时间管理"><h4 id="单代号网络图"><a href="#单代号网络图" class="headerlink" title="单代号网络图"></a>单代号网络图</h4></li><li><font color="red">FS: A完成B才能开始</font></li><li>FF：A完成B才能完成，谁先开始没有约定</li><li>SS：A开始B才能开始</li><li>SF：A开始B才能结束，例如新老系统切换，新系统运行才能下线老系统<br><img src="/2021/07/22/架构设计师备考/单代号网络图.jpg" alt="单代号网络图"></li><li>整推<ul><li>ES：最早开始时间(上一个活动的最大EF)</li><li>EF：最早结束时间(ES+持续时间)</li></ul></li><li>逆推<ul><li>LS：最晚开始时间(LF-持续时间)</li><li>LF：最晚结束时间(下一个节点最小的LS)<br>$总时差=ES-LS=EF-LF$<font color="red">总时差等于0的节点连起来就为关键路径</font><font color="red">关键路径越少越好，否则管理难度增大</font></li></ul></li></ul><h4 id="双代号网络图"><a href="#双代号网络图" class="headerlink" title="双代号网络图"></a>双代号网络图</h4><blockquote><p>边表示活动，节点表示事件；虚线画的活动不会给活动名或者给一个活动名而不是给历时(虚活动，虚构出来的活动，表达依赖关系不能直接去掉但不占用资源)</p></blockquote><p><img src="/2021/07/22/架构设计师备考/双代号网络图.jpg" alt="双代号网络图"></p><ul><li>求解关键路径<br>关键路径为1-2-3-4-6-7-9 (A、E、H、I、K)<br><img src="/2021/07/22/架构设计师备考/双代号网络图求解.jpg" alt="双代号网络图求解"></li></ul><h4 id="关键路径法"><a href="#关键路径法" class="headerlink" title="关键路径法"></a>关键路径法</h4><blockquote><p>关键路径法是在制定进度计划时使用的一种进度网络分析技术。关键路线法沿用项目进度网络路线进行正向与反向分析，从而计算出所有计划活动理论上的最早开始与完成日期、最迟开始与完成日期，不考虑任何资源限制</p></blockquote><ul><li>总时差(松弛时间)：在不延误总工期的前提下，该活动的机动时间。活动的总时差等于该活动最迟完成时间与最早完成时间之差，或该活动最迟开始时间之差</li><li>自由时差：在不影响紧后活动的最早开始时间前提下，该活动的机动时间<ul><li>对于有紧后活动的活动，其自由时差等于所有紧后活动最早开始时间减本活动最早完成时间所得之差的最小值</li><li>对于没有紧后活动的活动，也就是以网络计划终点节点为完成节点的活动，其自由时差等于计划工期与本活动最早完成时间之差</li></ul></li><li><p>对于网络计划中以终点节点为完成节点的活动，其自由时差与总时差相等。此外，由于活动的自由时差时其总时差的构成部分，所以，当活动的总时差为零时，其自由时差必然为零，可不必进行专门计算</p></li><li><p>自由时差例题<sup id="fnref:23"><a href="#fn:23" rel="footnote">23</a></sup><br><img src="/2021/07/22/架构设计师备考/自由时差例题.jpg" alt="自由时差例题"></p></li></ul><h3 id="甘特图"><a href="#甘特图" class="headerlink" title="甘特图"></a>甘特图</h3><blockquote><p>细横线：代表计划值；粗横线：代表实际完成值</p></blockquote><p><img src="/2021/07/22/架构设计师备考/甘特图.jpg" alt="甘特图"></p><ul><li>优点：甘特图直观、简单、容易制作，便于理解，能很清晰地标识出直到每一项任务的起始与结束时间，一般适用比较简单的小型项目，可用于WBS的任何层次、进度控制、资源优化、编制资源和费用计划</li><li>缺点：不能系统地表达一个项目所包含的各项工作之间的复杂关系，难以进行定量的计算和分析，以及计划的优化等</li></ul><h3 id="成本管理"><a href="#成本管理" class="headerlink" title="成本管理"></a>成本管理</h3><ol><li>成本估算<ul><li>自顶向下的估算</li><li>自底向上的估算</li></ul></li><li>成本预算<ul><li>直接成本与间接成本：直接成本指由项目组花掉的钱(人力成本等，项目经理能控制的)；间接成本指公摊性质的成本(项目经理无法控制的)，以每天多少成本衡量</li><li>管理储备：项目经理无权动用，要企业高层审批</li><li>零基准预算</li></ul></li><li>成本控制<ul><li>挣值分析</li></ul></li></ol><h4 id="挣值管理"><a href="#挣值管理" class="headerlink" title="挣值管理"></a>挣值管理</h4><ul><li>计算工作量的预算成本(PV)：$PV=计划工作量 \times 预算定额$(<font color="red">顺序3</font>)</li><li>已完成工作量的实际成本(AC)：项目实际花掉的钱，<font color="red">考题一般会直接给出</font>(<font color="red">顺序1</font>)</li><li><font color="red">已完成工作量</font>的预算成本(EV)：$EV=已完成工作量 \times 预算定额$(<font color="red">顺序2</font>)</li><li>完工预算(BAC)：$BAC = 完工时的PV总和$</li><li>进度偏差：$SV=EV-PV$，为负代表进度滞后</li><li>成本偏差：$CV=EV-AC$，为负代表成本超支</li><li>进度绩效指数：$SPI=EV/PV$，小于1表示不好，等于1表示与计划持平，大于1表示超预期</li><li>成本绩效指数：$CPI=EV/AC$，小于1表示不好，等于1表示与计划持平，大于1表示超预期</li><li>剩余工作的成本(ETC)：<br>按计划走(<font color="red">非典型偏差</font>)：$ETC=BAC-EV$<br>不按计划走(<font color="red">典型偏差</font>)：$ETC=\frac{BAC-EV}{CPI}$</li><li>完工预估(EAC)：$EAC=AC+ETC$</li></ul><ul><li>例题1<sup id="fnref:24"><a href="#fn:24" rel="footnote">24</a></sup><blockquote><p>希赛教育在线测试项目涉及对10个函数代码的编写（假设每个函数代码的编写工作量相等），项目由2个程序员进行结对编程，计划在10天内完成，总体预算时1000元，每个函数的平均成本时100元，项目进行到第5天，实际消耗费用时400元，完成了3个函数的编写。</p></blockquote></li></ul><p><img src="/2021/07/22/架构设计师备考/挣值曲线.jpg" alt="挣值曲线"></p><h3 id="质量管理"><a href="#质量管理" class="headerlink" title="质量管理"></a>质量管理</h3><ul><li><p>质量模型<br><img src="/2021/07/22/架构设计师备考/质量模型.jpg" alt="质量模型"></p></li><li><p>外部和内部质量<br><img src="/2021/07/22/架构设计师备考/外部和内部质量.jpg" alt="外部和内部质量"></p></li><li><p>质量管理过程(PDCA循环)<br><img src="/2021/07/22/架构设计师备考/PDCA循环.jpg" alt="PDCA循环"></p></li><li><p>质量保证和质量控制</p><ul><li>质量保证一般是<font color="red">每隔一定时间</font>(例如，每个阶段末)进行的，主要通过系统的质量审计和过程分析来保证项目的质量(<font color="red">强调过程</font>)</li><li>质量控制是<font color="red">实时监控项目的具体结果</font>，以判断它们是否符合相关质量标准，制定有效方案，以消除产生质量问题的原因(<font color="red">强调结果</font>)</li><li>一定时间内质量控制的结果也是质量保证的质量审计对象。质量保证的成果又可以指导下一阶段的质量工作，包括质量控制和质量改进</li></ul></li><li><p>质量工具</p><ul><li>核对表：即checklist，清单</li><li>帕累托分析(排列图)：统计错误出现的频次，按从高到底排列，先解决小部分高频次的问题</li><li>因果分析(鱼骨图)：鱼头是要解决的问题，鱼骨是朔源，由果反推因<br><img src="/2021/07/22/架构设计师备考/质量工具.jpg" alt="质量工具"></li></ul></li><li><p>项目管理三角形<br><img src="/2021/07/22/架构设计师备考/项目管理三角形.jpg" alt="项目管理三角形"></p></li></ul><h3 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h3><blockquote><p>IEEE对配置项的定义为硬件、软件或二者兼有的集合，为配置管理制定的</p></blockquote><ul><li>在配置管理过程中作为一个单独的实体对待，可作为配置项管理的有：外部交付的软件产品和数据、指定的内部软件工作产品和数据、指定的用于创建或支持软件产品的支持工具、供方/供应商提供的软件和客户提供的设备/软件</li><li>典型配置项：项目计划书、需求文档、设计文档、源代码、可执行代码、测试用例、运行软件所需的各种数据(它们经评审和检查通过后进入软件配置管理(SCM))</li><li>配置项的主要属性：名称、标识符、文件状态、版本、作者和日期等。<font color="red">所有配置项都被保存在配置库里，确保不会混淆、丢失、配置项及其历史记录反映了软件的演化过程</font></li></ul><h4 id="配置库"><a href="#配置库" class="headerlink" title="配置库"></a>配置库</h4><ul><li>开发库(动态库、程序员库、工作库；动态系统、开发者系统、开发系统、工作空间)：开发阶段(不断地调整修改阶段用的)，管辖内容程度最低，修改基本没有约束</li><li>受控库(主库、系统库；主系统、受控系统)：完成测试(测试通过)后放入，<font color="red">管理系统的基线</font>，不允许随意修改，修改需要走变更控制流程</li><li><p>产品库(<font color="red">备份库</font>、静态库、软件仓库；静态系统)：<font color="red">完全不能修改</font></p></li><li><p>检查点：只在规定的时间间隔内对项目进行检查，比较实际与计划之间的差异，并根据差异进行调整</p></li><li>里程碑：完成阶段性工作的标志，不同类型的项目里程碑不同</li><li>基线：指一个(或一组)配置项在项目生命周期的不同时间点上通过正式评审而进入正式受控的一种状态，基线是一些重要的里程碑。但相关交付成果要通过正式评审，并作为后续工作的基准和出发点。基线一旦建立后其变化需要受控制</li><li><p>变更控制<br><img src="/2021/07/22/架构设计师备考/变更控制.jpg" alt="变更控制"></p></li><li><p>版本控制</p><ul><li>草稿版：0.YZ</li><li>正式版：X.Y</li><li>修改版：X.YZ<br><img src="/2021/07/22/架构设计师备考/版本控制.jpg" alt="版本控制"></li></ul></li></ul><h3 id="风险管理"><a href="#风险管理" class="headerlink" title="风险管理"></a>风险管理</h3><h4 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h4><blockquote><p>关心未来、关心变化、关心选择</p></blockquote><ul><li>风险存在的客观性和普遍性</li><li>某一具体风险发生的偶然性和大量风险发生的必然性</li><li>风险的可变性</li><li>风险的多样性和多层次性</li><li><font color="red">基本属性：随机性和相对性</font></li><li>风险承受能力<br><img src="/2021/07/22/架构设计师备考/风险承受能力.jpg" alt="风险承受能力"></li></ul><h4 id="分类-3"><a href="#分类-3" class="headerlink" title="分类"></a>分类</h4><ul><li>项目风险<ul><li>潜在的预算、进度、人员和组织(<font color="red">预算本身不足</font>)、资源、用户和需求问题</li><li>项目复杂性、规模和结构的不确定性</li></ul></li><li>技术风险<ul><li>潜在的设计、实现、接口、测试和维护方面的问题</li><li>规格说明的多义性、技术上的不确定性、技术陈旧、最新技术(不成熟)</li></ul></li><li>商业风险<ul><li>市场风险：系统虽然很优秀但不是市场真正所想要的</li><li>策略风险：系统不再符合企业的信息系统战略</li><li>销售风险：开发了销售部门不清楚如何推销的系统</li><li>管理风险：由于重点转移或人员变动而失去上级支持(<font color="red">预算足够，但是上层不给</font>)</li><li>预算风险：开发过程没有得到预算或人员的保证(<font color="red">预算足够，但是上层不给</font>)</li></ul></li></ul><h4 id="风险曝光度"><a href="#风险曝光度" class="headerlink" title="风险曝光度"></a>风险曝光度</h4><blockquote><p>风险曝光度(Risk Exposure):计算方法是风险出现的概率乘以风险可能造成的损失</p></blockquote><ul><li>例<blockquote><p>假设正在开发的软件项目可能存在一个未被发现的错误，而这个错误出现的概率是0.5%，给公司造成的损失将是1000000元，那么这个错误的风险曝光度应为$1000000 \times 0.5\%=5000元$</p></blockquote></li></ul><h3 id="项目管理工具"><a href="#项目管理工具" class="headerlink" title="项目管理工具"></a>项目管理工具</h3><ul><li><font color="red">能做什么(项目管理相关的工作辅助)</font>：任务调度、成本估算、资源分配、预算跟踪、人时统计、配置控制、确定关键路径、松弛时间、超前时间和滞后时间，生成一定格式的报表和报告</li><li><font color="red">不能做什么(开发技术相关的辅助工作)</font>：不能指导软件设计人员按软件生存周期各个阶段的适用技术进行设计工作</li></ul><h2 id="软件架构设计"><a href="#软件架构设计" class="headerlink" title="软件架构设计"></a>软件架构设计</h2><h3 id="软件架构风格"><a href="#软件架构风格" class="headerlink" title="软件架构风格"></a>软件架构风格</h3><blockquote><p>架构设计的一个核心问题是能否达到架构级的软件复用<br>架构风格反映了领域中众多系统所共有的结构和语义特性，并指导如何将各个构件有效地组织成一个完整的系统<br>架构风格定义了用于描述系统的术语表和一组指导构建系统的规则</p></blockquote><ul><li>数据流风格：批处理序列、管道-过滤器</li><li>调用/返回风格：主程序/子程序、、面向对象、层次结构</li><li>独立构件风格：进程通信、事件驱动系统(隐式调用)</li><li>虚拟机风格：解释器、基于规则的系统</li><li>仓库风格：数据库系统、超文本系统、黑板系统</li></ul><h4 id="数据流风格"><a href="#数据流风格" class="headerlink" title="数据流风格"></a>数据流风格</h4><ul><li>批处理序列：构件为一系列固定顺序的计算单元，构件之间只通过数据传递交互。每个处理步骤是一个独立的程序，<font color="red">每一步必须在其前一步结束后才能开始，数据必须是完整的，以整体的方式传递。整个处理过程没有用户交互</font></li><li><font color="red">管道-过滤器</font>：每个构件都有一组输入和输出，构件读输入的数据流，经过内部处理，然后产生输出数据流，<font color="red">支持流式处理，不必等一批全部处理完在走下一个</font>。（这个过程通常是通过对输入数据流的变换或计算来完成的，包括通过计算或增加信息以丰富数据、通过浓缩或删除以精简数据、通过改变记录方式以转化数据和递增地转化数据等。）这里的构件称为过滤器，连接件就是数据流传输的管道，将一个过滤器的输出传到另一个过滤器的输入</li></ul><h4 id="调用-返回风格"><a href="#调用-返回风格" class="headerlink" title="调用/返回风格"></a>调用/返回风格</h4><ul><li>主程序/子程序：单线程控制，把问题划分为若干个处理步骤，构件即为主程序和子程序，子程序通常可合成为模块。过程调用作为交互机制，即充当连接件的角色。调用关系具有层次性，其语义逻辑表现为主程序的正确性取决于它调用的子程序的正确性。(<font color="red">结构化开发中常见</font>)</li><li>面向对象：<font color="red">显式调用</font>。构件是对象，对象是抽象数据类型的实例。在抽象数据类型中，数据的表示和它们的相应操作被封装起来，对象的行为体现在其接受和请求的动作。连接件即是对象间交互的方式，对象是通过函数和过程的调用来交互的</li><li>层次结构：构建组织成一个层次结构，连接件通过决定层间如何交互的协议来定义。每层为上一层提供服务，使用下一层的服务，只能见到与自己邻接的层。通过层次结构，可以将大的问题分解为若干个渐进的小问题逐步解决，可以隐藏问题的复杂度，修改某一层，最多影响相邻的两层(通常只能影响上层)(<font color="red">缺点：层次多则效率低、层次划分没有定论</font>)</li></ul><h4 id="独立构件风格"><a href="#独立构件风格" class="headerlink" title="独立构件风格"></a>独立构件风格</h4><ul><li>进程通信：<font color="red">独立构件</font>。构件是独立的过程，连接件是消息传递。构件通常是命名过程，消息传递的方式可以是点对点，异步或同步方式，以及远程过程(方法)调用等</li><li><font color="red">事件驱动系统：隐式调用</font>。构件不直接调用一个过程，而是触发或广播一个或多个事件。构件中的过程在一个或多个事件中注册，当某个事件被触发时，系统自动调用在这个事件中注册的所有过程。一个事件的触发就导致了另一个模块中的过程调用。这种风格中的构件是匿名的过程，它们之间交互的连接件往往是以过程之间的隐式调用来实现的。<font color="red">主要优点是为软件复用提供了强大的支持，为构件的维护和演化带来了方便；其缺点是构件放弃了对系统计算的控制</font></li></ul><h4 id="虚拟机风格"><a href="#虚拟机风格" class="headerlink" title="虚拟机风格"></a>虚拟机风格</h4><ul><li>解释器：解释器通常包括一个完成解释工作的解释引擎、一个包含将被解释的代码的存储区、一个记录解释引擎当前工作状态的数据结构，以及一个记录源代码被解释执行的进度的数据结构。具有解释器风格的软件中含有一个虚拟机，<font color="red">可以仿真硬件的执行过程和一些关键应用，其缺点是执行效率比较低</font></li><li>基于规则的系统：基于规则的系统包括规则集、规则解释器、规则/数据选择器和工作内存，一般用在人工智能领域和DSS中</li></ul><h4 id="仓库风格"><a href="#仓库风格" class="headerlink" title="仓库风格"></a>仓库风格</h4><blockquote><font color="red">以数据为核心</font></blockquote><ul><li>数据库系统：<font color="red">数据共享</font>。构件主要有两大类，一类是中央共享数据源，保存当前系统的数据状态；另一类是多个独立处理单元，处理单元对数据元素进行操作</li><li>黑板系统：包括知识源、黑板和控制三部分。知识源包括若干独立计算的不同单元，提供解决问题的知识。知识源响应黑板的变化，也只修改黑板；黑板是一个全局数据库，包含问题域解空间的全部状态，是知识源相互作用的唯一媒介；知识源响应是通过黑板状态的变化来控制的。黑板系统通常应用在对于解决问题没有确定性算法的软件中(<font color="red">信号处理、问题规划和编译器优化等</font>)</li><li>超文本系统：构件以网状链接方式相互连接，用户可以在构件之间进行按照人类的联想思维方式任意跳转到相关构件。超文本是一种非线性的网状信息组织方式。它以结点为基本单位，链作为结点之间的联想式关联。超文本系统通常应用在互联网领域</li></ul><h4 id="C-S架构"><a href="#C-S架构" class="headerlink" title="C/S架构"></a>C/S架构</h4><ul><li>两层C/S架构<blockquote><p>开发成本较高、客户端程序设计复杂、信息内容和形式单一、用户界面风格不一、<font color="red">软件移植困难、软件维护和升级困难</font>、新技术不能轻易应用</p></blockquote></li></ul><p><img src="/2021/07/22/架构设计师备考/两层CS架构.jpg" alt="两层CS架构"></p><ul><li>三层C/S架构<blockquote><p>各层在逻辑上保持相对独立，整个系统的逻辑结构更为清晰，能提高系统和软件的可维护性和可扩展性<br>允许灵活有效地选用相应的平台和硬件系统，具有良好的可升级性和开放性<br>各层可以并行开发，各层也可以选择各自最适合的开发语言<br>功能层有效地隔离表示层与数据层，为严格的安全管理奠定了坚实的基础；整个系统的管理层次也更加合理和可控制</p></blockquote></li></ul><p><img src="/2021/07/22/架构设计师备考/三层CS架构1.jpg" alt="三层CS架构1"><br><img src="/2021/07/22/架构设计师备考/三层CS架构2.jpg" alt="三层CS架构2"></p><h4 id="三层B-S架构"><a href="#三层B-S架构" class="headerlink" title="三层B/S架构"></a>三层B/S架构</h4><ul><li>B/S架构缺乏对动态页面的支持能力，没有集成有效的数据库处理功能</li><li>B/S架构的安全性难以控制</li><li>采用B/S架构的应用系统，在数据查询等响应速度上，要远远低于C/S架构</li><li>B/S架构的数据提交一般以页面为单位，数据的动态交互性不强，不利于OLTP应用</li></ul><p><img src="/2021/07/22/架构设计师备考/三层BS架构.jpg" alt="三层BS架构"></p><h4 id="混合架构风格"><a href="#混合架构风格" class="headerlink" title="混合架构风格"></a>混合架构风格</h4><ul><li>内外有别模型：内部C/S发挥性能优势，外部B/S架构</li><li>查改有别模型</li></ul><p><img src="/2021/07/22/架构设计师备考/混合架构风格.jpg" alt="混合架构风格"></p><h4 id="富互联网应用-RIA"><a href="#富互联网应用-RIA" class="headerlink" title="富互联网应用(RIA)"></a>富互联网应用(RIA)</h4><ul><li>RIA结合了C/S架构反应速度快、交互性强的优点、以及B/S架构传播范围广及容易传播的特性</li><li>RIA简化并改进了B/S架构的用户交互</li><li>数据能够被缓存在客户端，从而可以实现一个比基于HTML的响应速度更快且数据往返于服务器的次数更少的用户界面</li></ul><p><img src="/2021/07/22/架构设计师备考/RIA.jpg" alt="RIA"></p><h5 id="AJAX"><a href="#AJAX" class="headerlink" title="AJAX"></a>AJAX</h5><ul><li>基于HTML和CSS标准的表示</li><li>使用DOM进行动态显示和交互</li><li>使用XML和XLST进行数据交换及相关操作</li><li>使用XMLHttpRequest与服务器进行异步通信</li><li>使用JavaScript绑定一切</li></ul><h4 id="mushup"><a href="#mushup" class="headerlink" title="mushup"></a>mushup</h4><ul><li>RSS：一种用于对网站内容进行描述和同步的格式，是目前最广泛的Web资源发布方式</li><li>REST：从资源的角度看待整个网络，各处的资源由URI确定，客户端的应用通过URI获取资源的表示</li><li>SOAP：一种基于XML的数据格式定义，用来进行Web服务调用过程中的参数调用和返回</li><li>ATOM：一种基于XML的文档格式和基于HTTP的协议，用来聚合网络内容</li></ul><p><img src="/2021/07/22/架构设计师备考/mushup.jpg" alt="mushup"></p><h4 id="基于服务的架构-SOA"><a href="#基于服务的架构-SOA" class="headerlink" title="基于服务的架构(SOA)"></a>基于服务的架构(SOA)</h4><blockquote><p>服务是一种为了满足某项业务需求的操作、规则等的逻辑组合，它包含一系列有序活动的交互，为实现用户目标提供支持</p></blockquote><ul><li>特色：松散耦合、粗粒度(服务&gt;构件&gt;对象)、标准化接口</li><li>与传统构件的区别<ul><li>服务构件粗粒度，传统构件细粒度居多</li><li>服务构件的接口是标准的，主要是WSDL接口，传统构件常以具体API形式出现</li><li>服务构建的实现与语言无关，传统构件绑定某种特定的语言</li><li>服务构件可以通过构件容器提供QoS服务，传统构件完全由程序代码直接控制</li></ul></li><li>实现方式<br><img src="/2021/07/22/架构设计师备考/SOA实现方式.jpg" alt="SOA实现方式"><ul><li>Web Service<br><img src="/2021/07/22/架构设计师备考/WebService.jpg" alt="WebService"></li></ul></li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">功能</th><th style="text-align:center">协议</th></tr></thead><tbody><tr><td style="text-align:center">发现服务</td><td style="text-align:center"><font color="red">UDDI</font>、DISCO</td></tr><tr><td style="text-align:center">描述服务</td><td style="text-align:center"><font color="red">WSDL</font>、XML Schema</td></tr><tr><td style="text-align:center">消息格式层</td><td style="text-align:center"><font color="red">SOAP</font>、REST</td></tr><tr><td style="text-align:center">编码格式层</td><td style="text-align:center">XML</td></tr><tr><td style="text-align:center">传输协议层</td><td style="text-align:center">HTTP、TCP/IP、SMTP等</td></tr></tbody></table></div><ul><li>ESB<br><img src="/2021/07/22/架构设计师备考/ESB.jpg" alt="ESB"><ul><li>提供位置透明性的消息路由和寻址服务</li><li>提供服务注册和命名的管理功能</li><li>支持多种消息传递范型</li><li>支持多种可以广泛使用的传输协议</li><li>支持多种数据格式及其相互转换</li><li>提供日志和监控功能</li></ul></li></ul><h3 id="软件架构评估"><a href="#软件架构评估" class="headerlink" title="软件架构评估"></a>软件架构评估</h3><h4 id="质量属性"><a href="#质量属性" class="headerlink" title="质量属性"></a>质量属性</h4><ul><li><p><font color="red">性能</font></p><blockquote><p>性能(performance)是指系统的<font color="red">响应能力</font>，即要经过多长事件才能对某个事件做出响应，或者在某段时间内系统所能处理的事件的个数。经常用单位事件内所处理事务的数量或系统完成某个事务处理所需的时间来对性能进行定量的表示。性能测试经常要使用基准测试程序（用以测量性能指标的特定事务集或工作量环境）</p></blockquote></li><li><p>可靠性</p><blockquote><p>可靠性(reliability)是软件系统在应用或系统错误面前，在意外或错误使用的情况下维持软件系统的功能特性的基本能力。可靠性通常用平均失效等待时间(Mean Time To Failure，简称MTTF)和平均失效间隔时间(Mean Time Between Failure，简称MTBF)来衡量。在<font color="red">失效率</font>为常数和修复时间很短的情况下，MTTF和MTBF几乎相等</p></blockquote></li><li><p><font color="red">可用性</font></p><blockquote><p>可用性(avaliability)是系统能够正常运行的<font color="red">时间比例</font>。经常用两次故障之间的时间长度或在出现故障时系统能够恢复正常的速度来表示。</p></blockquote></li><li><p><font color="red">安全性</font></p><blockquote><p>安全性(security)时滞系统在向合法用户提供服务的同时能够阻止非授权用户使用的企图或拒绝服务的能力。安全性时根据系统可能收到的安全威胁的类型来分类的。安全性又可划分为<font color="red">机密性、完整性、不可否认性及可控性</font>等特性</p></blockquote></li><li><p><font color="red">可修改性</font></p><blockquote><p>可修改性(modifiability)是指能够快速地以较高的性能价格比对系统进行变更的能力。通常以某些具体的变更为基准，通过考察这些变更的代价衡量可修改性(<font color="red">设计阶段就需要考虑</font>)</p></blockquote></li><li><p>功能性</p><blockquote><p>功能性(functionality)是系统所能完成所期望的工作的能力。一项任务的完成需要系统中许多或大多数构件的相互协作</p></blockquote></li><li><p><del>可变性</del></p><blockquote><p>可变性(changeability)是指系统结构经扩充或变更而成为新体系结构的能力。这种新体系结构应该符合预先定义的规则，在某些具体方面不同于所有的体系结构。当要将某个体系结构作为一系列相关产品(例如，软件产品线)的基础时，可变性是很重要的</p></blockquote></li><li><p><del>互操作性</del></p><blockquote><p>作为系统组成部分的软件不是独立存在的，经常与其它系统或自身环境相互作用。为了支持互操作性(interoperation)，软件体系结构必须为外部可视的功能特性和数据结构提供精心设计的软件入口，程序和用其他编程语言编写的软件系统的交互作用就是互操作性的问题，这种互操作性也影响应用的软件体系结构</p></blockquote></li></ul><h4 id="概念表述"><a href="#概念表述" class="headerlink" title="概念表述"></a>概念表述</h4><ul><li>敏感点：变化值很小但对结果影响很大的点(敏感度很高的值，往往是一个)</li><li>权衡点：影响到多个质量属性的特性，多个都是属于敏感点(多个质量属性的折中)</li><li>风险点：潜在的存在问题的隐患</li><li>非风险点</li></ul><h4 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h4><p><img src="/2021/07/22/架构设计师备考/评估方法.jpg" alt="评估方法"></p><ul><li>基于调查问卷(检查表)的方式(最客观的方式)</li><li>基于度量的方式</li><li><font color="red">基于场景的方式</font><br><img src="/2021/07/22/架构设计师备考/基于场景的方式.jpg" alt="基于场景的方式"></li></ul><h5 id="基于场景的方式"><a href="#基于场景的方式" class="headerlink" title="基于场景的方式"></a>基于场景的方式</h5><blockquote><p>确定应用领域的功能和软件架构的结构之间的映射<br>设计用于体现待评估质量属性的场景<br>分析软件架构对场景的支持程度</p></blockquote><ul><li><p>架构权衡分析法(ATAM)<br><img src="/2021/07/22/架构设计师备考/架构权衡分析法.jpg" alt="架构权衡分析法"></p></li><li><p>软件架构分析法(SAAM)<br><img src="/2021/07/22/架构设计师备考/软件架构分析法.jpg" alt="软件架构分析法"></p></li><li><p>成本效益分析法(CBAM)</p></li></ul><h3 id="软件产品线"><a href="#软件产品线" class="headerlink" title="软件产品线"></a>软件产品线</h3><blockquote><p>过程驱动、特定领域、技术支持、以架构为中心</p></blockquote><p><img src="/2021/07/22/架构设计师备考/软件产品线.jpg" alt="软件产品线"></p><ul><li><p>过程模型-双生命周期模型<br><img src="/2021/07/22/架构设计师备考/双生命周期模型.jpg" alt="双生命周期模型"></p></li><li><p>过程模型-SEI模型<br><img src="/2021/07/22/架构设计师备考/SEI模型.jpg" alt="SEI模型"></p></li><li><p><del>过程模型-三生命周期模型</del><br><img src="/2021/07/22/架构设计师备考/三生命周期模型.jpg" alt="三生命周期模型"></p></li></ul><h4 id="组织结构"><a href="#组织结构" class="headerlink" title="组织结构"></a>组织结构</h4><ul><li><font color="red">设立独立的核心资源小组</font>：核心的、行业共性的开发工作(绝大多数部分)</li><li>不设立独立的核心资源小组：核心开发和应用开发在一个小组，但仍然会区分核心部分和应用部分，两者分别对待</li><li>动态的组织结构</li></ul><h4 id="建立方式"><a href="#建立方式" class="headerlink" title="建立方式"></a><font color="red">建立方式</font></h4><ul><li>将现有产品演化为产品线</li><li>用软件产品线替代现有产品集</li><li>全新软件产品线的演化</li><li>全新软件产品线的开发</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:left">演化方式</th><th style="text-align:left">革命方式</th></tr></thead><tbody><tr><td style="text-align:center">基于现有产品</td><td style="text-align:left">基于现有产品架构设计产品线的架构，经演化现有构件，开发产品线构件</td><td style="text-align:left">核心资源的开发基于现有产品集的需求和可预测的、将来的需求的超集</td></tr><tr><td style="text-align:center">全新产品线</td><td style="text-align:left">产品线核心资源随产品新成员的需求而演化</td><td style="text-align:left">开发满足所有预期产品线成员的需求的核心资源</td></tr></tbody></table></div><h3 id="中间件技术"><a href="#中间件技术" class="headerlink" title="中间件技术"></a>中间件技术</h3><blockquote><p>中间件是一种独立的系统软件或服务程序，可以帮助分布式应用软件在不同的技术之间共享资源</p></blockquote><ul><li>负责客户机与服务器之间的连接和通信，以及客户机与应用层之间的高效率通信机制</li><li>提供应用层不同服务之间的互操作机制，以及应用层与数据库之间的连接和控制机制</li><li>提供多层架构的应用开发和运行的平台，以及应用开发框架，支持模块化的应用开发</li><li>屏蔽硬件、操作系统、网络和数据库的差异</li><li>提供应用的负载均衡和高可用性、安全机制与管理功能，以及交易管理机制，保证交易的一致性</li><li>提供一组通用的服务去执行不同的功能，避免重复的工作和使应用之间可以协作</li></ul><p><img src="/2021/07/22/架构设计师备考/中间件技术.jpg" alt="中间件技术"></p><h4 id="主要中间件"><a href="#主要中间件" class="headerlink" title="主要中间件"></a>主要中间件</h4><ul><li>远程过程调用</li><li>对象请求代理</li><li>远程方法调用</li><li>面向消息的中间件</li><li>事务处理监控器</li></ul><p><img src="/2021/07/22/架构设计师备考/主要中间件.jpg" alt="主要中间件"></p><ul><li>Corba(公共对象请求代理体系结构)<br><img src="/2021/07/22/架构设计师备考/Corba.jpg" alt="Corba"></li></ul><h3 id="典型应用架构"><a href="#典型应用架构" class="headerlink" title="典型应用架构"></a>典型应用架构</h3><h4 id="J2EE-分布式多层应用程序"><a href="#J2EE-分布式多层应用程序" class="headerlink" title="J2EE-分布式多层应用程序"></a>J2EE-分布式多层应用程序</h4><ul><li>业务层<ul><li>会话Bean：短暂会话</li><li>实体Bean：持久化数据</li><li>消息驱动Bean：会话Bean+JMS<br><img src="/2021/07/22/架构设计师备考/J2EE.jpg" alt="J2EE"></li></ul></li></ul><h4 id="NET"><a href="#NET" class="headerlink" title=".NET"></a>.NET</h4><ul><li>通用语言运行环境：支持多种语言，各语言被转换为通用语言运行规范，在通用语言运行环境上运行(对应java的虚拟机)<br><img src="/2021/07/22/架构设计师备考/NET1.jpg" alt="NET1"><br><img src="/2021/07/22/架构设计师备考/NET2.jpg" alt="NET2"></li></ul><h4 id="NET与J2EE"><a href="#NET与J2EE" class="headerlink" title=".NET与J2EE"></a>.NET与J2EE</h4><ul><li>JVM和CLR：同样思想下的产物</li><li>对多层分布式应用的支持：没有多大差异</li><li>安全性</li><li>应用程序的部署</li><li>可移植性：.NET的可移植性较差(依附于微软自己的操作系统平台)，J2EE可移植性较好</li><li>外部支持：.NET支持语言多一下</li></ul><h4 id="MVC设计模式"><a href="#MVC设计模式" class="headerlink" title="MVC设计模式"></a>MVC设计模式</h4><ul><li>主动MVC<br><img src="/2021/07/22/架构设计师备考/主动MVC.jpg" alt="主动MVC"></li><li>被动MVC<br><img src="/2021/07/22/架构设计师备考/被动MVC.jpg" alt="被动MVC"></li></ul><h4 id="MVP设计模式"><a href="#MVP设计模式" class="headerlink" title="MVP设计模式"></a>MVP设计模式</h4><ul><li>MVP是MVC的变种</li><li>MVP实现了V与M之间的解耦(V不直接使用M，修改V不会影响M)</li><li>MVP更好的支持单元测试(业务逻辑在P中，可以脱离V来测试这些逻辑；可以将一个P用于多个V，而不需要改变P的逻辑)</li><li>MVP中V要处理界面事件，业务逻辑在P中，MVC中界面事件由C处理</li></ul><p><img src="/2021/07/22/架构设计师备考/MVP设计模式.jpg" alt="MVP设计模式"></p><h2 id="信息安全分析与设计"><a href="#信息安全分析与设计" class="headerlink" title="信息安全分析与设计"></a>信息安全分析与设计</h2><h3 id="信息系统安全属性"><a href="#信息系统安全属性" class="headerlink" title="信息系统安全属性"></a>信息系统安全属性</h3><ul><li>保密性：最小授权原则、防暴露、信息加密、物理加密</li><li>完整性：安全协议、校验码、密码校验、数字签名、公证</li><li>可用性：综合保障（IP过滤、业务流控制、路由选择控制、审计跟踪）</li><li>不可抵赖性：数字签名</li></ul><h3 id="对称加密技术"><a href="#对称加密技术" class="headerlink" title="对称加密技术"></a>对称加密技术</h3><ul><li>DES：替换+移位、56位密钥、64位数据块、速度快、密钥易生成<ul><li>3DES(三重DES)：两个56位的密钥K1、K2（加密：K1加密-&gt;K2解密-&gt;K1加密；解密：k1解密-&gt;K2加密-&gt;K1解密）</li></ul></li><li>AES：高级加密标准Rijndael加密法，是美国联邦政府采用的一种区块加密标准。这个标准用来替代原先的DES。堆区要求是“至少与3DES一样安全”</li><li>RC-5：RSA数据安全公司的很多产品都使用了RC-5</li><li>IDEA算法：128位密钥、64位数据块、比DES的加密性好、对计算机功能要求相对低，PGP</li></ul><p><img src="/2021/07/22/架构设计师备考/对称加密技术.jpg" alt="对称加密技术"></p><font color="red">优点：加密速度快、效率高；缺点：加密强度不高、密钥分发困难</font><h3 id="非对称加密技术"><a href="#非对称加密技术" class="headerlink" title="非对称加密技术"></a>非对称加密技术</h3><ul><li>RSA：512位（或1024位）密钥、计算量极大、破解难</li><li><font color="red">Elgamal：其基础是Diffie-Hellman密钥交换算法</font></li><li>ECC：椭圆曲线算法</li><li>其它非对称算法包括：<font color="red">背包算法、Rabin、D-H</font></li></ul><p><img src="/2021/07/22/架构设计师备考/非对称加密技术.jpg" alt="非对称加密技术"></p><font color="red">优点：破解难；缺点：加密速度慢，不适合加密大数据量</font><h3 id="信息摘要"><a href="#信息摘要" class="headerlink" title="信息摘要"></a>信息摘要</h3><blockquote><p>单向散列函数（单向Hash函数）、固定长度的散列值</p></blockquote><p><img src="/2021/07/22/架构设计师备考/信息摘要.jpg" alt="信息摘要"><br><strong>常用的信息摘要算法有MD5、SHA等，市场上广泛使用的MD5、SHA算法的散列值分别位128位和160位，由于SHA通常采用的密钥长度较长，因此安全性高于MD5</strong></p><h3 id="数字签名"><a href="#数字签名" class="headerlink" title="数字签名"></a>数字签名</h3><blockquote><p>防抵赖的技术、没有保密的职能只有识别身份的作用</p></blockquote><p><img src="/2021/07/22/架构设计师备考/数字签名.jpg" alt="数字签名"></p><h3 id="数字信封与PGP"><a href="#数字信封与PGP" class="headerlink" title="数字信封与PGP"></a>数字信封与PGP</h3><ul><li><p>数字信封</p><ol><li>发送方将原文用对称加密传输，而将对称密钥用接收方公钥加密发送给对方</li><li>接收方收到电子信封，用自己的私钥解密信封，取出对称密钥解密得到原文</li></ol></li><li><p>PGP协议</p><ul><li>PGP可用于电子邮件、也可以用于文件存储。采用了杂合算法，包括IDEA、RSA、MD5、ZIP数据压缩算法</li><li>PGP承认两种不同的证书格式：PGP证书和X.509证书</li><li>PGP证书包含PGP版本号、证书持有者的公钥、证书持有者的信息、证书拥有者的数字签名、证书的有效期、密钥首选的对称加密算法</li><li>X.509证书包含证书版本、证书的序列号、签名算法标识、证书有效期、证书发行商名字、证书主体名、<font color="red">主体公钥信息</font>、发布者的数字签名</li></ul></li></ul><h3 id="练习题-设计邮件加密系统"><a href="#练习题-设计邮件加密系统" class="headerlink" title="练习题-设计邮件加密系统"></a>练习题-设计邮件加密系统</h3><p>要求邮件以加密方式传输，邮件最大附件内容可达500MB，发送者不可抵赖，若邮件被第三方截获，第三方无法篡改<sup id="fnref:25"><a href="#fn:25" rel="footnote">25</a></sup></p><h3 id="PKI公钥体系"><a href="#PKI公钥体系" class="headerlink" title="PKI公钥体系"></a>PKI公钥体系</h3><blockquote><p>防欺骗</p></blockquote><ul><li><p>运行流程<br><img src="/2021/07/22/架构设计师备考/PKI公钥体系运作流程.jpg" alt="PKI公钥体系运作流程"></p></li><li><p>PKI公钥体系分层</p><blockquote><p>CA、RA、证书受理点、密钥管理中心-KMC</p></blockquote></li></ul><p><img src="/2021/07/22/架构设计师备考/PKI公钥体系分层.jpg" alt="PKI公钥体系分层"></p><h3 id="信息系统安全保障层次"><a href="#信息系统安全保障层次" class="headerlink" title="信息系统安全保障层次"></a>信息系统安全保障层次</h3><ul><li>身份认证<ul><li>用户名+口令</li><li>数字证书</li><li>生物特征识别</li></ul></li><li>访问控制<ul><li>自主访问控制(DAC)：权限赋予过程有自主权利，给相应的主体赋予能够访问哪些客体的权限(存在安全风险)</li><li>访问控制列表(ACL)：从客体出发，看哪些主体能访问客体(给资源指定能访问的主体列表)</li><li>强制访问控制(MAC)：对主体和客体分级</li><li>基于角色的访问控制模型(RBAC)</li><li>基于任务的访问控制(TBAC)</li></ul></li></ul><p><img src="/2021/07/22/架构设计师备考/信息系统安全保障层次.jpg" alt="信息系统安全保障层次"></p><h3 id="安全审计与安全系统设计原则"><a href="#安全审计与安全系统设计原则" class="headerlink" title="安全审计与安全系统设计原则"></a>安全审计与安全系统设计原则</h3><ul><li>安全审计的作用<ul><li>震慑、警告</li><li>发现计算机的滥用情况</li><li>提供有效的追纠证据</li><li>帮助发现系统的入侵和漏洞</li><li>帮助发现系统性能上的不足</li></ul></li><li>设计原则<ul><li><font color="red">木桶原则</font>：首先加强短板</li><li>整体性原则</li><li>安全性评价与平衡原则</li><li>标准化和一致性原则</li><li>技术与管理相结合原则</li><li>统筹规划，分步实施原则</li><li>等级性原则</li><li>动态发展原则</li><li>易操作性原则</li></ul></li></ul><h3 id="网络安全-各个网络层次的安全保障"><a href="#网络安全-各个网络层次的安全保障" class="headerlink" title="网络安全-各个网络层次的安全保障"></a>网络安全-各个网络层次的安全保障</h3><ul><li>SET：面向电子商务</li><li>SSL：做选择时不要先对SSL所属的层次做定义，先对其他做判断<br><img src="/2021/07/22/架构设计师备考/各个网络层次的安全保障.jpg" alt="各个网络层次的安全保障"></li></ul><h3 id="网络威胁与攻击"><a href="#网络威胁与攻击" class="headerlink" title="网络威胁与攻击"></a>网络威胁与攻击</h3><div class="table-container"><table><thead><tr><th style="text-align:center">威胁名称</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:center">重放攻击(ARP)/ARP欺骗攻击</td><td style="text-align:left">所截获的某次合法的通信数据拷贝，出于非法的目的而被重新发送</td></tr><tr><td style="text-align:center">拒绝服务(DOS)</td><td style="text-align:left">对信息或其它资源的合法访问被无条件地阻止</td></tr><tr><td style="text-align:center">窃听</td><td style="text-align:left">用各种可能的合法或非法的手段窃取系统中的信息资源和敏感信息。例如对通信线路中传输的信号进行搭线监听，或者利用通信设备在工作过程中产生的电磁泄漏截取游用信息等</td></tr><tr><td style="text-align:center">业务流分析</td><td style="text-align:left">通过对系统进行<font color="red">长期监听</font>，利用<font color="red">统计分析方法</font>对诸如通信频度、通信的信息流向、通信总量的变化等参数进行研究，从而发现有价值的通信和规律</td></tr><tr><td style="text-align:center">信息泄露</td><td style="text-align:left">信息被泄露或透露给某个非授权的实体</td></tr><tr><td style="text-align:center">破坏信息的完整性</td><td style="text-align:left">数据被非授权地进行增删、修改或破坏而受到损失</td></tr><tr><td style="text-align:center">非授权访问</td><td style="text-align:left">某一资源被非授权的人、或以非授权的方式使用</td></tr><tr><td style="text-align:center">假冒</td><td style="text-align:left">通过欺骗通信系统(或用户)达到非法用户冒充合法用户，或者特权小的用户冒充特权大的用户的目的。黑客大多时采用假冒进行攻击</td></tr><tr><td style="text-align:center">旁路控制</td><td style="text-align:left">攻击者利用<font color="red">系统的安全缺陷或安全性上的脆弱之处</font>获得非授权的权利或特权。例如，攻击者通过各种攻击手段发现原本应保密，但是却又暴露出来的一些系统“特性”。利用这些“特性”，攻击者可以绕过防线守卫者侵入系统的内部</td></tr><tr><td style="text-align:center">授权侵犯</td><td style="text-align:left">被授权以某一目的的使用某一系统或资源的个人，却将此权限用于其它非授权的目的，也称为“内部攻击”</td></tr><tr><td style="text-align:center">特洛伊木马</td><td style="text-align:left">软件中含有一个察觉不出的或者无害的程序段，当它被执行时，会破坏用户的安全</td></tr><tr><td style="text-align:center">陷阱门</td><td style="text-align:left">在某个系统或某个部件中设置了“机关”，使得当提供特定的输入数据时允许违反安全策略</td></tr><tr><td style="text-align:center">抵赖</td><td style="text-align:left">这是一种来自用户的攻击，比如：否认自己曾经发布过的某条信息，伪造一份对方来行等</td></tr></tbody></table></div><ul><li>DoS(拒绝服务)与DDoS<blockquote><p>破坏系统的可用性</p></blockquote></li></ul><p><img src="/2021/07/22/架构设计师备考/DDoS.jpg" alt="DDoS"></p><h3 id="防火墙"><a href="#防火墙" class="headerlink" title="防火墙"></a>防火墙</h3><blockquote><p>防外不防内</p></blockquote><p><img src="/2021/07/22/架构设计师备考/防火墙.jpg" alt="防火墙"></p><ul><li>网络级：层次低，效率高(只检测IP头可以伪造)<ul><li>状态检测：检测TCP/IP连接信息</li></ul></li><li>应用级：层次高，效率低(开箱检查)<ul><li><font color="red">屏蔽子网：在外网和内网之间建立屏蔽子网区/隔离区/DMZ非军事区，既不属于内部网络也不属于外部网络。主要放对外提供服务的服务器</font></li></ul></li></ul><h3 id="入侵检测"><a href="#入侵检测" class="headerlink" title="入侵检测"></a>入侵检测</h3><ul><li><p>入侵检测流程<br><img src="/2021/07/22/架构设计师备考/入侵检测流程.jpg" alt="入侵检测流程"></p></li><li><p>入侵检测特点<br><img src="/2021/07/22/架构设计师备考/入侵检测特点.jpg" alt="入侵检测特点"></p></li></ul><h3 id="计算机病毒与木马"><a href="#计算机病毒与木马" class="headerlink" title="计算机病毒与木马"></a>计算机病毒与木马</h3><ul><li>病毒：编制或者在计算机程序中插入的破坏计算机功能或破坏数据，影响计算机使用并且<font color="red">能够自我复制</font>的一组计算机指令或者程序代码。病毒具有：传染性、隐藏性、潜伏性、破坏性、针对性、衍生性、寄生性、未知性</li><li><p>木马：计算机木马是一种后门程序，常被黑客用作<font color="red">控制远程计算机</font>的工具</p></li><li><p>病毒分类</p><ul><li>系统引导型病毒</li><li>文件外壳型病毒</li><li>目录型病毒：破坏目录文件</li><li>蠕虫病毒（Worm）：熊猫烧香、罗密欧与朱丽叶、恶魔、尼达姆、冲击波(感染可执行文件)</li><li>木马（Trojan）：QQ消息尾巴木马</li><li>宏病毒（Macro）：美丽莎（Melissa）、台湾1号(感染Office体系的)</li></ul></li><li>几种代表性病毒<ul><li>CIH病毒：史上唯一破坏硬件的病毒</li><li>红色代码：蠕虫病毒+木马</li></ul></li></ul><h2 id="系统可靠性分析和设计"><a href="#系统可靠性分析和设计" class="headerlink" title="系统可靠性分析和设计"></a>系统可靠性分析和设计</h2><h3 id="系统故障模型"><a href="#系统故障模型" class="headerlink" title="系统故障模型"></a>系统故障模型</h3><blockquote><p>部件失效、物理干扰、操作或设计不当引起的错误状态</p></blockquote><ul><li>表现形式：永久性、间歇性、瞬时性</li><li>逻辑级的故障模型：短路故障、开路故障、桥接故障(物理层次)</li><li>数据结构级的故障：独立差错、算数差错、单向差错</li><li><font color="red">软件故障和软件差错</font>：非法转移、误转移、死循环、空间溢出、数据执行、无理数据</li><li>系统级的故障模型</li></ul><h3 id="可靠性指标"><a href="#可靠性指标" class="headerlink" title="可靠性指标"></a>可靠性指标</h3><p><img src="/2021/07/22/架构设计师备考/可靠性指标.jpg" alt="可靠性指标"></p><ul><li>平均无故障事件(MTTF)：$MTTF = \frac{1}{\lambda}$，$\lambda$为失效率</li><li>平均故障修复时间(MTTR)：$MTTR = \frac{1}{\mu}$，$\mu$为修复率</li><li>平均故障间隔事件(MTBF)：$MTBF=MTTR+MTTF$</li><li>系统可用性：$\frac{MTTF}{MTTR+MTTF}\times 100\%$</li></ul><font color="red">在实际应用中，一般MTTR很小，所以通常认为$MTBF \approx MTTF$</font><ul><li>可靠性和可用性<blockquote><font color="red">系统可靠性</font>是系统在规定的时间内及规定的环境条件下，完成规定功能的能力，也就是系统无故障运行的概率<font color="red">系统可用性</font>是指在某个给定的时间点上系统能够按照需求执行的效率提高可靠性需要强调减少<font color="red">系统中断(故障)的次数</font>，提高可用性需要强调<font color="red">减少从灾难中恢复的事件</font></blockquote></li><li>例<br>假设同一型号的1000台计算机，在规定的条件下工作1000小时，其中有10台出现故障。<br>这种计算机千小时的可靠度R为$\frac{(1000-10)}{1000}=0.99$<br>失效率为$\frac{10}{1000 \times 1000}=1\times 10^{-5}$<br>$MTTF=\frac{1}{1\times 10^{-5}}=10^{5}小时$</li></ul><h3 id="可靠性分析"><a href="#可靠性分析" class="headerlink" title="可靠性分析"></a>可靠性分析</h3><ul><li><p>串联系统<br><img src="/2021/07/22/架构设计师备考/串联系统.jpg" alt="串联系统"></p></li><li><p>并联系统</p><ul><li>失效率可以用$1-R$求得即1减去可靠度<br><img src="/2021/07/22/架构设计师备考/并联系统.jpg" alt="并联系统"></li></ul></li><li><p><del>N模冗余系统</del><br><img src="/2021/07/22/架构设计师备考/N模冗余系统.jpg" alt="N模冗余系统"></p></li><li><p>混合系统<br><img src="/2021/07/22/架构设计师备考/混合系统.jpg" alt="混合系统"></p></li></ul><h3 id="系统容错"><a href="#系统容错" class="headerlink" title="系统容错"></a>系统容错</h3><ul><li>避错技术：测试、验证等</li><li>容错技术<ul><li>结构冗余（硬件冗余、软件冗余）<ul><li>静态冗余（屏蔽冗余、被动冗余、模冗余系统）：通过表决和比较来屏蔽系统的错误，没有过多检测和反复的过程</li><li>动态冗余（主动冗余：备份系统、集群系统）：通过检测定位问题然后进行恢复<ul><li>故障检测</li><li>故障定位</li><li>故障恢复</li></ul></li><li>混合冗余：</li></ul></li><li>信息冗余（校验码）</li><li>事件冗余（重复多次进行相同得计算）</li><li>冗余附加（为实现上述冗余技术所需的资源和技术）</li></ul></li></ul><h4 id="冗余系统"><a href="#冗余系统" class="headerlink" title="冗余系统"></a>冗余系统</h4><ul><li>故障检测</li><li>故障屏蔽</li><li>故障限制</li><li>复执</li><li>故障诊断</li><li>系统重配置</li><li>系统恢复<ul><li>前向恢复：<font color="red">使当前的计算继续下去</font>，把系统恢复成连贯的正确状态，弥补当前状态的不连贯情况</li><li>后向恢复：系统恢复到前一个正确状态，继续执行</li></ul></li><li>系统重新启动</li><li>修复</li><li>系统重组合</li></ul><p>后向恢复简单地把变量恢复到检查点的取值；前向恢复将对一些变量的状态进行修改和处理，且这个恢复过程将由程序设计者设计<br>前向恢复适用于可预见的易定义的的错误；后向恢复可屏蔽不可预见的错误</p><h3 id="软件容错"><a href="#软件容错" class="headerlink" title="软件容错"></a>软件容错</h3><ul><li>N版本程序设计<blockquote><p>与通常软件开发过程不同的是，N版本程序设计增加了三个新的阶段：相异成份规范评审、相异性确认、背对背测试<br>N版本程序的同步、N版本程序之间的通信、表决算法（全等表决、非精确表决、Cosmetie表决）、一致比较问题、数据相异性</p></blockquote></li></ul><p><img src="/2021/07/22/架构设计师备考/N版本程序设计.jpg" alt="N版本程序设计"></p><ul><li>恢复块方法<blockquote><p>设计时应保证实现主块和后备块之间的独立性，避免相关错误的产生，使主块和备份块之间的共性错误降到最低程度<br>必须保证验证测试程序的正确性</p></blockquote></li></ul><p><img src="/2021/07/22/架构设计师备考/恢复块方法.jpg" alt="N版本程序设计"></p><ul><li>N版本和恢复块比较</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">恢复块方法</th><th style="text-align:center">N版本程序设计</th></tr></thead><tbody><tr><td style="text-align:center">硬件运行环境</td><td style="text-align:center">单机</td><td style="text-align:center">多机</td></tr><tr><td style="text-align:center">错误检测方法</td><td style="text-align:center">验证测试程序</td><td style="text-align:center">表决</td></tr><tr><td style="text-align:center">恢复策略</td><td style="text-align:center">后向恢复</td><td style="text-align:center">前向恢复</td></tr><tr><td style="text-align:center">实时性</td><td style="text-align:center">差</td><td style="text-align:center">好</td></tr></tbody></table></div><ul><li><p>防卫式程序设计</p><blockquote><p>对于程序中存在的错误和不一致性，通过在程序中包含错误检查代码和错误恢复代码，使得一旦错误发生，程序能撤销错误状态，恢复到一个已知的正确状态中去<br>实现策略：错误检测、破坏估计、错误恢复</p></blockquote></li><li><p>双机容错</p><ul><li>双机热备模式（主系统、备用系统）</li><li>双机互备模式（同时提供不同的服务，心不跳则接管）</li><li>双机双工模式（同时提供相同的服务，集群的一种）</li></ul></li></ul><p><img src="/2021/07/22/架构设计师备考/双机容错.jpg" alt="双机容错"></p><h3 id="集群技术"><a href="#集群技术" class="headerlink" title="集群技术"></a>集群技术</h3><blockquote><p>可伸缩性、高可用性、可管理性、高性价比、高透明性</p></blockquote><ul><li>高性能计算集群</li><li>负载均衡集群<ul><li>基于特定软件的负载均衡</li><li>基于DNS的负载均衡</li><li>基于NAT的负载均衡</li><li>反向代理负载均衡</li><li>混合型负载均衡</li></ul></li><li>高可用性集群</li></ul><h4 id="负载均衡算法"><a href="#负载均衡算法" class="headerlink" title="负载均衡算法"></a>负载均衡算法</h4><ul><li>静态算法：轮转算法、加权轮转算法、最小连接数算法、加权最小连接数算法、源地址哈希散列算法、目标地址哈希散列算法、随机算法</li><li>动态算法：加权百分比算法</li></ul><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">112、4</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;">C、B</span><a href="#fnref:2" rev="footnote"> ↩</a></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">3.</span><span style="display: inline-block; vertical-align: top;">1.8、3</span><a href="#fnref:3" rev="footnote"> ↩</a></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">4.</span><span style="display: inline-block; vertical-align: top;">A、C</span><a href="#fnref:4" rev="footnote"> ↩</a></li><li id="fn:5"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">5.</span><span style="display: inline-block; vertical-align: top;">C、A、A</span><a href="#fnref:5" rev="footnote"> ↩</a></li><li id="fn:6"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">6.</span><span style="display: inline-block; vertical-align: top;">D、A、C</span><a href="#fnref:6" rev="footnote"> ↩</a></li><li id="fn:7"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">7.</span><span style="display: inline-block; vertical-align: top;">13，计算公式：a*(n-1)+1</span><a href="#fnref:7" rev="footnote"> ↩</a></li><li id="fn:8"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">8.</span><span style="display: inline-block; vertical-align: top;">B</span><a href="#fnref:8" rev="footnote"> ↩</a></li><li id="fn:9"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">9.</span><span style="display: inline-block; vertical-align: top;">D、B(访问位为1的不能淘汰，只能淘汰为0的)</span><a href="#fnref:9" rev="footnote"> ↩</a></li><li id="fn:10"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">10.</span><span style="display: inline-block; vertical-align: top;">12、5、9</span><a href="#fnref:10" rev="footnote"> ↩</a></li><li id="fn:11"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">11.</span><span style="display: inline-block; vertical-align: top;">B、C(指令一次性读入，只产生一次缺页中断，数据跨页产生两次)</span><a href="#fnref:11" rev="footnote"> ↩</a></li><li id="fn:12"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">12.</span><span style="display: inline-block; vertical-align: top;">C、D</span><a href="#fnref:12" rev="footnote"> ↩</a></li><li id="fn:13"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">13.</span><span style="display: inline-block; vertical-align: top;">D($\frac{4195+1}{32}$)、B(第132字第0位置为：4192，第1位置：4193，第2位置：4194，第3位置：4195)，字从1开始算，位置从0开始算</span><a href="#fnref:13" rev="footnote"> ↩</a></li><li id="fn:14"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">14.</span><span style="display: inline-block; vertical-align: top;">C</span><a href="#fnref:14" rev="footnote"> ↩</a></li><li id="fn:15"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">15.</span><span style="display: inline-block; vertical-align: top;">A<img src="/2021/07/22/架构设计师备考/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%B8%88%E5%A4%87%E8%80%83/%E9%94%AE%E4%BE%8B%E9%A2%981%E5%9B%BE.png" alt="键例题1图"></span><a href="#fnref:15" rev="footnote"> ↩</a></li><li id="fn:16"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">16.</span><span style="display: inline-block; vertical-align: top;">ABCD<img src="/2021/07/22/架构设计师备考/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%B8%88%E5%A4%87%E8%80%83/%E9%94%AE%E4%BE%8B%E9%A2%982%E5%9B%BE.png" alt="键例题2图"></span><a href="#fnref:16" rev="footnote"> ↩</a></li><li id="fn:17"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">17.</span><span style="display: inline-block; vertical-align: top;">B<img src="/2021/07/22/架构设计师备考/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%B8%88%E5%A4%87%E8%80%83/%E9%94%AE%E4%BE%8B%E9%A2%983%E5%9B%BE.png" alt="键例题3图"></span><a href="#fnref:17" rev="footnote"> ↩</a></li><li id="fn:18"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">18.</span><span style="display: inline-block; vertical-align: top;">C、D、A</span><a href="#fnref:18" rev="footnote"> ↩</a></li><li id="fn:19"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">19.</span><span style="display: inline-block; vertical-align: top;">是<img src="/2021/07/22/架构设计师备考/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%B8%88%E5%A4%87%E8%80%83/%E6%A8%A1%E5%BC%8F%E5%88%86%E8%A7%A3%E4%BE%8B%E9%A2%981%E7%AD%94%E6%A1%88.png" alt="模式分解例题1答案"><img src="/2021/07/22/架构设计师备考/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%B8%88%E5%A4%87%E8%80%83/%E6%A8%A1%E5%BC%8F%E5%88%86%E8%A7%A3%E4%BE%8B%E9%A2%981%E7%AD%94%E6%A1%881.png" alt="模式分解例题1答案1"><img src="/2021/07/22/架构设计师备考/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%B8%88%E5%A4%87%E8%80%83/%E6%A8%A1%E5%BC%8F%E5%88%86%E8%A7%A3%E4%BE%8B%E9%A2%981%E7%AD%94%E6%A1%882.png" alt="模式分解例题1答案2"></span><a href="#fnref:19" rev="footnote"> ↩</a></li><li id="fn:20"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">20.</span><span style="display: inline-block; vertical-align: top;">是、否<img src="/2021/07/22/架构设计师备考/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%B8%88%E5%A4%87%E8%80%83/%E6%A8%A1%E5%BC%8F%E5%88%86%E8%A7%A3%E4%BE%8B%E9%A2%982%E7%AD%94%E6%A1%88.png" alt="模式分解例题2答案"></span><a href="#fnref:20" rev="footnote"> ↩</a></li><li id="fn:21"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">21.</span><span style="display: inline-block; vertical-align: top;">B</span><a href="#fnref:21" rev="footnote"> ↩</a></li><li id="fn:22"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">22.</span><span style="display: inline-block; vertical-align: top;">A</span><a href="#fnref:22" rev="footnote"> ↩</a></li><li id="fn:23"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">23.</span><span style="display: inline-block; vertical-align: top;">程序员A1:2;程序员A2:0；程序员B:0；单元测试A:1；单元测试B:0； 集成测试:0</span><a href="#fnref:23" rev="footnote"> ↩</a></li><li id="fn:24"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">24.</span><span style="display: inline-block; vertical-align: top;">AC:400，EV:300，PV：500，SV=-200，CV=-100，SPI=0.6，CPI=0.75，ETC=700(按计划)/933.33(不按计划走)，EAC=1100(按计划)/1333.33(不按计划)</span><a href="#fnref:24" rev="footnote"> ↩</a></li><li id="fn:25"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">25.</span><span style="display: inline-block; vertical-align: top;">加密解密技术、对称加密技术、数字信封、数字摘要、数字签名</span><a href="#fnref:25" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      软考备考
    
    </summary>
    
      <category term="软考" scheme="http://coldjune.com/categories/%E8%BD%AF%E8%80%83/"/>
    
    
  </entry>
  
  <entry>
    <title>面试记录</title>
    <link href="http://coldjune.com/2020/08/16/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"/>
    <id>http://coldjune.com/2020/08/16/面试记录/</id>
    <published>2020-08-16T12:02:13.000Z</published>
    <updated>2020-08-16T12:41:32.000Z</updated>
    
    <content type="html"><![CDATA[<ol><li>concurrentHashMap并发实现方式<blockquote><p>分段锁、读写效率、</p></blockquote></li><li>synchronized关键字<blockquote><p>监视对象、无中断、锁对象(Class也是对象)</p></blockquote></li><li>zookeeper选举<blockquote><p>Paxos、ZAB(Zookeeper相关只是可以参考《从Paxos到Zookeeper  分布式一致性原理与实践》)</p></blockquote></li><li>redis锁<blockquote><p>setNx方法</p></blockquote></li><li>一致性hash<blockquote><p>环、hash、虚拟节点</p></blockquote></li><li>this引用逃逸<blockquote><p>未初始化完成、构造器启动线程（参考《Java并发编程》）</p></blockquote></li><li>violate关键字<blockquote><p>轻量级、非原子性、同步、读写屏障、禁止指令重排</p></blockquote></li><li>单例模式<blockquote><p>DCL双重检验、静态内部类、枚举、</p></blockquote></li><li>cpu负载100%可能的原因（面试官说比如高并发对共享hasmap操作造成循环链表）</li><li>java并发工具集<blockquote><p>线程池(参数)、阻塞队列(QUEUE)、原子操作(Atomic*)、Future等</p></blockquote></li><li>不停机升级服务<blockquote><p>切流量、循环起</p></blockquote></li><li>zookeeper实现机制<blockquote><p>Watcher(Zookeeper相关只是可以参考《从Paxos到Zookeeper  分布式一致性原理与实践》)</p></blockquote></li><li>tcp滑动窗口<blockquote><p>缓冲区、ACK信号(参考《计算机网路》)</p></blockquote></li><li>socket编程<blockquote><p>阻塞、NIO、IO多路复用</p></blockquote></li><li>拦截器和过滤器区别</li></ol><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">拦截器</th><th style="text-align:center">过滤器</th></tr></thead><tbody><tr><td style="text-align:center">实现方式</td><td style="text-align:center">反射</td><td style="text-align:center">函数回调</td></tr><tr><td style="text-align:center">依赖</td><td style="text-align:center">不依赖Servlet容器</td><td style="text-align:center">依赖Servelet容器</td></tr><tr><td style="text-align:center">作用范围</td><td style="text-align:center">action请求</td><td style="text-align:center">所有请求</td></tr><tr><td style="text-align:center">action上下文、值栈对象</td><td style="text-align:center">能访问</td><td style="text-align:center">不能访问</td></tr><tr><td style="text-align:center">action的生命周期</td><td style="text-align:center">可以多次调用</td><td style="text-align:center">一次</td></tr><tr><td style="text-align:center">业务侵入</td><td style="text-align:center">拦截器可以获取IOC容器中的各个bean，可调用业务逻辑</td><td style="text-align:center">不能</td></tr></tbody></table></div><ol><li>spring事务<blockquote><p>传播机制、声明式、隔离级别、只读、超时、回滚</p></blockquote></li><li>主键索引和非主键索引区别<blockquote><p>非主键索引的叶子节点存放的是主键的值，主键索引的叶子节点存放的是整行数据，其中非主键索引也被称为二级索引，而主键索引也被称为聚簇索</p></blockquote></li><li>如何检测链表中的环<blockquote><p>双指针、快慢</p></blockquote></li><li>大文件如何查找IP<blockquote><p>hash，分割文件</p></blockquote></li></ol>]]></content>
    
    <summary type="html">
    
      关于个人面试遇到的面试题记录，只记录问题，做简单解析
    
    </summary>
    
      <category term="Java" scheme="http://coldjune.com/categories/Java/"/>
    
    
      <category term="Java" scheme="http://coldjune.com/tags/Java/"/>
    
      <category term="面试" scheme="http://coldjune.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>设计模式</title>
    <link href="http://coldjune.com/2020/06/21/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    <id>http://coldjune.com/2020/06/21/设计模式/</id>
    <published>2020-06-21T14:36:53.000Z</published>
    <updated>2020-07-05T10:26:49.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2020/06/21/设计模式/设计模式.jpeg" alt="设计模式"></p><h1 id="面向对象"><a href="#面向对象" class="headerlink" title="面向对象"></a>面向对象</h1><ul><li>特性：封装、继承、抽象、多态</li><li>面向对象编程：以类和对象作为组织代码的基本单元，将四大特性作为代码设计和实现的基石</li><li>面向对象编程语言：支持类和对象的语法机制，能方便地实现面向对象编程四大特性的编程语言</li></ul><h2 id="封装-Encapsulation"><a href="#封装-Encapsulation" class="headerlink" title="封装(Encapsulation)"></a>封装(Encapsulation)</h2><ul><li>信息隐藏或数据访问保护</li><li>需要语言语法提供访问权限控制</li><li>提高类中属性可控性</li><li>提高类的易用性</li></ul><h2 id="抽象-Abstraction"><a href="#抽象-Abstraction" class="headerlink" title="抽象(Abstraction):"></a>抽象(Abstraction):</h2><ul><li>隐藏方法的具体实现</li><li>并不一定要为实现类定义接口类（万物皆可抽象）</li></ul><h2 id="继承-Inheritance"><a href="#继承-Inheritance" class="headerlink" title="继承(Inheritance):"></a>继承(Inheritance):</h2><ul><li>代码复用</li><li>过度使用使可读性可维护性变差</li></ul><h2 id="多态-Polymorphism"><a href="#多态-Polymorphism" class="headerlink" title="多态(Polymorphism):"></a>多态(Polymorphism):</h2><ul><li>继承加方法重写实现</li><li>接口实现</li><li>提高代码的可扩展性和复用性</li></ul><h2 id="面向对象和面向过程"><a href="#面向对象和面向过程" class="headerlink" title="面向对象和面向过程"></a>面向对象和面向过程</h2><div class="table-container"><table><thead><tr><th style="text-align:center">面向对象</th><th style="text-align:center">面向过程</th></tr></thead><tbody><tr><td style="text-align:center">以类和对象作为组织代码的基本单元</td><td style="text-align:center">以过程（方法、函数、操作等）作为组织代码的基本单元，是一种流程化的编程风格</td></tr><tr><td style="text-align:center">方法和其数据结构绑定</td><td style="text-align:center">方法和其数据结构分开</td></tr><tr><td style="text-align:center">更能应对大规模复杂程序开发，使用类先建模后实现（模块化）</td><td style="text-align:center">大规模复杂程序开发呈现网状结构，梳理逻辑困难</td></tr><tr><td style="text-align:center">更易复用、扩展、维护</td><td style="text-align:center">不易复用、扩展和维护（要实现代价更高）</td></tr><tr><td style="text-align:center">更高级、人性化和智能（人的思维方式）</td><td style="text-align:center">不够高级、人性化和智能（计算机思维方式，顺序编程）</td></tr></tbody></table></div><h2 id="似对象实过程"><a href="#似对象实过程" class="headerlink" title="似对象实过程"></a>似对象实过程</h2><ul><li>滥用set/get方法(set使封装性丧失/get返回对象使上层能够修改对象导致数据不一致)</li><li>滥用全局变量和全局方法（实在要用可以细化分类，尽量哪儿使用哪儿定义/职责单一）</li><li>定义数据和方法分离的类</li><li>基于贫血模型的开发模式</li></ul><h2 id="抽象类和接口"><a href="#抽象类和接口" class="headerlink" title="抽象类和接口"></a>抽象类和接口</h2><div class="table-container"><table><thead><tr><th style="text-align:center">抽象类</th><th style="text-align:center">接口</th></tr></thead><tbody><tr><td style="text-align:center">不允许实例化(new报错)，只能被继承</td><td style="text-align:center">不能是实例化，只能实现</td></tr><tr><td style="text-align:center">可以包含属性和方法，方法可以实现也可以不实现(抽象方法)</td><td style="text-align:center">不能包含属性，只能声明方法不能包含具体实现</td></tr><tr><td style="text-align:center">子类继承抽象类必须实现抽象方法</td><td style="text-align:center">类实现接口时必须实现接口声明的所有方法</td></tr><tr><td style="text-align:center">一种特殊的类 (is-a)</td><td style="text-align:center">表示具有某些功能(has-a)/协议(contract)</td></tr><tr><td style="text-align:center">自下而上，现有子类代码重复然后抽象为父类</td><td style="text-align:center">自上而下，先考虑接口再考虑具体实现</td></tr></tbody></table></div><h3 id="抽象类"><a href="#抽象类" class="headerlink" title="抽象类"></a>抽象类</h3><ul><li>代码复用</li><li>能使用多态特性(父类无法实例化，子类强制要求实现抽象方法)</li></ul><h4 id="无抽象类语法的问题："><a href="#无抽象类语法的问题：" class="headerlink" title="无抽象类语法的问题："></a>无抽象类语法的问题：</h4><ul><li>影响父类代码可读性</li><li>忘记重新父类的方法（抽象类中为抽象方法的部分）</li><li>父类能被实例化，增加类被误用的风险</li></ul><h3 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h3><ul><li>提高复用性</li><li>解耦(侧重)</li></ul><h3 id="模拟实现抽象类和接口"><a href="#模拟实现抽象类和接口" class="headerlink" title="模拟实现抽象类和接口"></a>模拟实现抽象类和接口</h3><ul><li>不能实例化(显式定义构造函数且并让其拥有访问控制，比如java修饰为protected）</li><li>成员变量(不定义）</li><li>子类必须实现方法(abstract/virtual修饰，不支持的语言如python直接在父类方法抛出异常)</li></ul><h2 id="基于接口（抽象）而非实现编程-program-to-an-interface-not-to-an-implementation-："><a href="#基于接口（抽象）而非实现编程-program-to-an-interface-not-to-an-implementation-：" class="headerlink" title="基于接口（抽象）而非实现编程(program to an interface,not to an implementation)："></a>基于接口（抽象）而非实现编程(program to an interface,not to an implementation)：</h2><ul><li>抽象层面的接口指的一组协议或约定</li><li>代码层面上接口可理解为编程语法的接口类或抽象类</li><li>将接口和实现分离，暴露稳定的接口，封装不稳定的实现（实现更改时调用方不用更改，提高可扩展性）</li></ul><h3 id="如何遵循："><a href="#如何遵循：" class="headerlink" title="如何遵循："></a>如何遵循：</h3><ul><li>函数命名不能暴露任何实现细节</li><li>封装具体的实现细节</li><li>为实现类定义抽象的接口</li><li>功能如只有一种实现方式，未来也不会改动（没必要实现接口）</li></ul><h2 id="多用组合少用继承"><a href="#多用组合少用继承" class="headerlink" title="多用组合少用继承"></a>多用组合少用继承</h2><h3 id="不推荐继承的原因"><a href="#不推荐继承的原因" class="headerlink" title="不推荐继承的原因"></a>不推荐继承的原因</h3><ul><li>继承层次过深过复杂影响代码可维护性</li><li>父类修改影响所有子类</li></ul><h3 id="组合："><a href="#组合：" class="headerlink" title="组合："></a>组合：</h3><ul><li>职责单一，可复用（通过组合、接口、委托）</li><li>需要更细粒度的拆分/更多的类和接口</li></ul><h3 id="如何选择"><a href="#如何选择" class="headerlink" title="如何选择"></a>如何选择</h3><ul><li>继承：类之间继承结构稳定、层次浅，关系不复杂，无法改变类中方法只能继承</li><li>组合：系统不稳定、层次深，关系复杂</li></ul><h2 id="贫血模型、充血模型和领域驱动设计-DDD-："><a href="#贫血模型、充血模型和领域驱动设计-DDD-：" class="headerlink" title="贫血模型、充血模型和领域驱动设计(DDD)："></a>贫血模型、充血模型和领域驱动设计(DDD)：</h2><h3 id="贫血模型"><a href="#贫血模型" class="headerlink" title="贫血模型"></a>贫血模型</h3><ul><li>只包含数据不包含业务逻辑的类（如Entity）</li><li>将数据与操作分离，破坏了OOP的封装性</li><li>重Service轻BO（BO只包含数据）</li><li>面向SQL开发</li></ul><h3 id="充血模型"><a href="#充血模型" class="headerlink" title="充血模型"></a>充血模型</h3><ul><li>数据和对应的业务逻辑封装在一个类里</li><li>轻Service重Domain（Domain包括数据和业务逻辑）</li><li>领域模型相当于可复用的业务中间件</li></ul><h3 id="DDD"><a href="#DDD" class="headerlink" title="DDD"></a>DDD</h3><ul><li>指导如何解耦业务系统，划分业务模块，定义业务领域模型及其交互</li></ul><h3 id="贫血盛行原因"><a href="#贫血盛行原因" class="headerlink" title="贫血盛行原因"></a>贫血盛行原因</h3><ul><li>业务系统简单，基于CRUD都能完成</li><li>充血模型设计更有难度</li><li>思维固化</li></ul><h3 id="充血模型场景"><a href="#充血模型场景" class="headerlink" title="充血模型场景"></a>充血模型场景</h3><ul><li>复杂系统（包括各种利息计算模型和还款模型的金融系统）</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">贫血模型</th><th style="text-align:center">充血模型</th></tr></thead><tbody><tr><td style="text-align:center">业务逻辑全在service</td><td style="text-align:center">部分业务逻辑移到domain</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">controller和repository层两者基本相同</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">保留service不移除是为了和repository层交互</td></tr></tbody></table></div><h1 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h1><h2 id="单一职责原则"><a href="#单一职责原则" class="headerlink" title="单一职责原则"></a>单一职责原则</h2><ul><li>一个类或模块只负责完成一个职责或功能</li><li>实现代码高内聚低耦合，提高代码复用性、可读性和可维护性</li><li>拆分过细会降低内聚性</li></ul><h3 id="判断是否职责是否单一"><a href="#判断是否职责是否单一" class="headerlink" title="判断是否职责是否单一"></a>判断是否职责是否单一</h3><ul><li>类中代码行数、函数或属性过多（200行/10个）</li><li>类依赖的其他类过多，或者依赖类的其他类过多</li><li>私有方法过多</li><li>类中的大量方法集中操作类中的某几个属性</li></ul><h2 id="开闭原则"><a href="#开闭原则" class="headerlink" title="开闭原则"></a>开闭原则</h2><ul><li>软件实体（类模块、类、方法等）应该对扩展开放，对修改关闭</li><li>以最小修改代码的代价来完成新功能的开发</li><li>同样的改动，在粗粒度下被认为是修改，细粒度下被认定为扩展</li></ul><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><ul><li>具备扩展意识、抽象意识、封装意识</li><li>事先留好扩展点</li><li>多态、依赖注入、基于接口而非实现编程，以及大部分的设计模式（比如，装饰、策略、模板、职责链、状态）</li></ul><h2 id="里氏替换原则"><a href="#里氏替换原则" class="headerlink" title="里氏替换原则"></a>里氏替换原则</h2><ul><li>子类对象能够替换父类对象出现的任何地方，并且保证原来程序的逻辑行为不变及正确性不被破坏</li><li>按照协议设计：子类设计时要遵守父类的行为约定（输入、输出、异常的约定甚至注释中罗列的任何特殊说明）</li></ul><h2 id="接口隔离原则"><a href="#接口隔离原则" class="headerlink" title="接口隔离原则"></a>接口隔离原则</h2><ul><li>客户端（接口的调用者或使用者）不应该强迫依赖它不需要的接口</li></ul><h3 id="接口含义"><a href="#接口含义" class="headerlink" title="接口含义"></a>接口含义</h3><ul><li>一组API接口集合：某个为服务或类库的接口，部分接口只被部分调用者使用就应该将这部分接口给力出来单独提供给对应的调用者</li><li>单个API接口或函数：函数的设计要功能单一，不将多个不同的功能逻辑在一个函数中实现</li><li>OOP中的接口概念</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">接口隔离</th><th style="text-align:center">单一职责</th></tr></thead><tbody><tr><td style="text-align:center">更侧重于接口设计</td><td style="text-align:center">针对模块、类、接口</td></tr><tr><td style="text-align:center">提供了判断接口是否单一的标准：通过调用者如何使用接口</td><td style="text-align:center">拆分粒度可大可小、可粗可细，没有明确的标准</td></tr></tbody></table></div><h2 id="依赖反转原则-依赖倒置原则"><a href="#依赖反转原则-依赖倒置原则" class="headerlink" title="依赖反转原则/依赖倒置原则"></a>依赖反转原则/依赖倒置原则</h2><ul><li>高层（调用者）模块不依赖低层（被调用者）模块，高层模块和低层模块应该通过抽象来互相依赖；抽象不依赖具体实现细节，具体实现细节依赖抽象</li><li>控制反转：控制指对程序执行流程的控制，反转指的是使用框架前程序员自己控制程序执行；使用框架后整个执行流程通过框架控制</li><li>依赖注入：不通过 new 的方式在类内部创建依赖类的对象，而是将依赖的类对象在外部创建好之后，通过构造函数、函数参数等方式传递（或注入）给类来使用</li></ul><h2 id="KISS原则"><a href="#KISS原则" class="headerlink" title="KISS原则"></a>KISS原则</h2><ul><li>尽量保持简单</li><li>本身便复杂的问题用复杂的方法解决不算违背KISS原则</li></ul><h3 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h3><ul><li>不要使用复杂的技术或过于高级的特性</li><li>善于使用已经有的工具类</li><li>不要过度优化</li></ul><h2 id="YAGNI原则"><a href="#YAGNI原则" class="headerlink" title="YAGNI原则"></a>YAGNI原则</h2><ul><li>不要设计当前用不到的功能</li></ul><h2 id="DRP原则"><a href="#DRP原则" class="headerlink" title="DRP原则"></a>DRP原则</h2><ul><li>不要重复你自己</li></ul><h3 id="重复情况"><a href="#重复情况" class="headerlink" title="重复情况"></a>重复情况</h3><ul><li>实现逻辑重复：实现相同但语义不同不视为违反DRP；对于重复的代码可以抽象为更细粒度的函数来解决</li><li>功能语义重复：功能语义重复就算实现不同，也认为违反了DRP</li><li>代码执行重复</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">代码复用性</th><th style="text-align:center">代码复用</th><th style="text-align:center">DRP原则</th></tr></thead><tbody><tr><td style="text-align:center">表示代码可被复用的特性或能力</td><td style="text-align:center">表示一种行为：开发新功能时复用已经存在的代码</td><td style="text-align:center">不要写重复的代码</td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">不重复不代表可复用</td></tr><tr><td style="text-align:center">从代码开发者的角度</td><td style="text-align:center">从代码使用者的角度</td><td style="text-align:center"></td></tr></tbody></table></div><h3 id="提高复用性"><a href="#提高复用性" class="headerlink" title="提高复用性"></a>提高复用性</h3><blockquote><p>第一次不考虑复用性，第二次用到再来重构</p></blockquote><ul><li>减少代码耦合</li><li>满足单一职责原则：粒度越细越容易被复用</li><li>模块化：将功能独立的代码封装成模块</li><li>业务与非业务逻辑分离：越是业务无关的代码越容易复用</li><li>通用代码下沉：越底层的代码越通用，只允许上层调用下层和同层，不允许下层调用上层</li><li>继承、多态、抽象、封装：越抽象越不依赖具体实现；隐藏可变细节，暴露不变接口</li><li>应用模版等设计模式</li><li>泛型编程</li></ul><h2 id="迪米特法则（最小知识原则）"><a href="#迪米特法则（最小知识原则）" class="headerlink" title="迪米特法则（最小知识原则）"></a>迪米特法则（最小知识原则）</h2><ul><li>每个模块只应该了解那些与它关系密切的模块</li><li>高内聚：相近的功能应该放到同一个类中，不相近的功能不放到同一个类</li><li>低耦合：类与类之间的依赖关系简单清晰</li></ul><h1 id="规范与重构"><a href="#规范与重构" class="headerlink" title="规范与重构"></a>规范与重构</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><ul><li>重构是一种对软件内部结构的改善，目的是在不改变软件的可见行为的情况下，使其更易理解，修改成本更低</li><li>持续重构</li><li>重构对象</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">大规模高层次（大型重构）</th><th style="text-align:center">小规模低层次（小型重构）</th></tr></thead><tbody><tr><td style="text-align:center">对象：系统、模块、代码结构、类与类之间的关系</td><td style="text-align:center">对象：类、函数、变量等代码级</td></tr><tr><td style="text-align:center">手段：分层、模块化、解耦、抽象可复用组件</td><td style="text-align:center">手段：规范命名、规范注释、消除超大类或函数、提取重复代码</td></tr><tr><td style="text-align:center">提前做好完善的重构计划，每个阶段完成一部分在开始下一阶段，保证代码一直处于可运行逻辑正确的状态</td><td style="text-align:center">因范围小，随时都可以</td></tr></tbody></table></div><h2 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h2><div class="table-container"><table><thead><tr><th style="text-align:center">集成测试</th><th style="text-align:center">单元测试</th></tr></thead><tbody><tr><td style="text-align:center"></td><td style="text-align:center">研发工程师自己编写，测试代码正确性</td></tr><tr><td style="text-align:center">整个系统或某个功能模块，是端到端的测试</td><td style="text-align:center">类或者函数是否按照预期逻辑执行，代码层级</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">粒度更小</td></tr></tbody></table></div><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><ul><li>单元测试能有效发现代码中的bug</li><li>单元测试能发现代码设计上的问题</li><li>单元测试是对集成测试的有力补充</li><li>写单元测试的过程本身就是重构的过程</li><li>阅读单元测试能快速熟悉代码</li><li>单元测试是TDD可落地执行的改进方案</li></ul><h3 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h3><ul><li>编写单元测试尽管繁琐但并不耗时，大多可以copy-paste</li><li>可以稍微放低对单元测试代码质量的要求</li><li>覆盖率作为衡量单元测试的唯一标准是不合理的</li><li>单元测试不要依赖被测试代码的具体实现逻辑</li><li>单元测试框架无法测试，多半是因为代码的可测试性不好</li></ul><h2 id="可测试性"><a href="#可测试性" class="headerlink" title="可测试性"></a>可测试性</h2><ul><li>针对代码编写单元测试的难易程度</li></ul><h3 id="方法-3"><a href="#方法-3" class="headerlink" title="方法"></a>方法</h3><ul><li>使用依赖注入而不是new</li><li>多用组合少用继承</li><li>mock解决外部以来的服务问题（面向接口而非实现编程）</li></ul><h3 id="测试不友好的代码"><a href="#测试不友好的代码" class="headerlink" title="测试不友好的代码"></a>测试不友好的代码</h3><ul><li>代码中包含未决行为逻辑</li><li>滥用可变全局变量</li><li>滥用静态方法</li><li>使用复杂的继承关系</li><li>高度耦合的代码</li></ul><h2 id="解耦"><a href="#解耦" class="headerlink" title="解耦"></a>解耦</h2><ul><li>解耦保证代码松耦合高内聚，是控制代码复杂度的有效手段</li></ul><h3 id="判断方法"><a href="#判断方法" class="headerlink" title="判断方法"></a>判断方法</h3><ul><li>间接：看代码修改是否牵一发而动全身</li><li>直接：画出模块与模块、类与类之间的依赖关系图，根据依赖关系图的复杂性判断是否需要解耦</li></ul><h3 id="方法-4"><a href="#方法-4" class="headerlink" title="方法"></a>方法</h3><ol><li>封装和抽象</li><li>中间层<ul><li>引入一个中间层，包裹老的接口，提供新的接口定义</li><li>新开发的代码依赖中间层提供的新接口</li><li>将依赖老接口的代码改为调用新接口</li><li>确保所有的代码都调用新接口之后，删除掉老的接口</li></ul></li><li>模块化</li><li>其它设计思想和原则<ul><li>单一职责原则</li><li>基于接口而非实现编程</li><li>依赖注入</li><li>多用组合少用继承</li><li>迪米特法则</li></ul></li></ol><h2 id="编码规范"><a href="#编码规范" class="headerlink" title="编码规范"></a>编码规范</h2><h3 id="命名"><a href="#命名" class="headerlink" title="命名"></a>命名</h3><ul><li>长度：以能准确达意为目标，众人熟知的用缩写，函数内临时变量可以短，类名等作用域大的用长命名</li><li>利用上下文简化命名</li><li>命名要可读可搜索：不用生僻难发音的单词，统一规约方便搜索</li><li>命名接口和抽象类：接口加I前缀或者不加而其实现类加impl后缀；抽象类加Abstract前缀或不加；项目里保证统一</li></ul><h3 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h3><ul><li>内容<ul><li>做什么/为什么/怎么做：简单的类名不能包涵太多信息，需要注释详尽描述；注释起到总结性作用、文档的作用；总结性注释让代码结构更清晰</li></ul></li><li>多少<ul><li>太多意味着代码可读性不高，需要大量注释，且后续维护困难；类和函数要写注释，要尽量详尽、全面；函数内部注释较小，靠好的命名约束，提高可读性</li></ul></li></ul><h3 id="代码风格"><a href="#代码风格" class="headerlink" title="代码风格"></a>代码风格</h3><ol><li>类和函数多大合适<ul><li>函数大小不超过显示屏的垂直高度（50行）</li><li>类行数过多：当一个类的代码阅读困难；实现某个功能不知道该用哪个函数；只用到一个小功能需要引入整个类</li></ul></li><li>一行代码多长合适<ul><li>一行代码最长不能超过IDE显示的宽度</li></ul></li><li>善用空行分割单元块<ul><li>成员变量与函数之间</li><li>静态成员变量和普通成员变量、函数之间</li><li>成员变量之间</li></ul></li><li>四格缩进还是两格缩进<ul><li>跟业内推荐的风格统一，跟著名开源项目统一</li><li>推荐两格缩进：节省空间；四格缩进代码嵌套层次过深，累计缩进过多，容易导致一行折成两行</li><li>不用tab键缩进，不同ide下tab键的显示宽度不同</li></ul></li><li>打括号是否要另起一行<ul><li>将括号放到语句同一行：节省代码行数</li><li>跟随业内标准和开源项目</li></ul></li><li>类中成员的排列顺序<ul><li>成员变量排在函数前面</li><li>成员变量和函数之间按照先静态（静态成员变量或静态函数）后普通（非静态成员变量或非静态函数）的方式排列</li><li>成员变量和函数之间按照作用域范围从大到小的顺序排列，先写public成员变量或函数，然后写protected，最后是private</li><li>把有调用关系的函数放一块儿，一个public调用一个private则两者放一块儿</li></ul></li></ol><h3 id="编程技巧"><a href="#编程技巧" class="headerlink" title="编程技巧"></a>编程技巧</h3><ul><li>把代码分割成更小的单元块</li><li>避免函数参数过多<ul><li>考虑函数职责是否单一，是否能通过拆分为多个函数的方式减少参数</li><li>将函数的参数封装成对象</li></ul></li><li>勿用函数参数来控制逻辑：存在控制标志可以考虑拆分为不同函数，保持职责单一</li><li>函数设计要职责单一</li><li>移除过深的嵌套层次<ul><li>去掉多余的if或else语句</li><li>使用编程语言提供的continue、break、return关键字提前退出嵌套</li><li>调整执行顺序减少嵌套</li><li>将部分嵌套逻辑封装成函数调用</li><li>使用多态来替代if-else、switch-case条件判断的方法</li></ul></li><li>学会使用解释性变量<ul><li>常量取代魔法数字</li><li>使用解释性变量来解释复杂表达式</li></ul></li></ul><h2 id="发现代码质量问题"><a href="#发现代码质量问题" class="headerlink" title="发现代码质量问题"></a>发现代码质量问题</h2><h3 id="常规checklist"><a href="#常规checklist" class="headerlink" title="常规checklist"></a>常规checklist</h3><ul><li>目录设置是否合理</li><li>模块划分是否清晰</li><li>代码结构是否满足“高内聚、松耦合”</li><li>是否遵循经典的设计原则和设计思想（SOLID、DRY、KISS、YAGNI、LOD 等）</li><li>设计模式是否应用得当、是否有过度设计</li><li>代码是否容易扩展，如果要添加新功能，是否容易实现</li><li>代码是否可以复用，是否可以复用已有的项目代码或类库，是否有重复造轮子</li><li>代码是否容易测试，单元测试是否全面覆盖了各种正常和异常的情况</li><li>代码是否易读，是否符合编码规范（比如命名和注释是否恰当、代码风格是否一致等）</li></ul><h3 id="业务需求checklist"><a href="#业务需求checklist" class="headerlink" title="业务需求checklist"></a>业务需求checklist</h3><ul><li>代码是否实现了预期的业务需求</li><li>逻辑是否正确，是否处理了各种异常情况</li><li>日志打印是否得当，是否方便 debug 排查问题</li><li>接口是否易用，是否支持幂等、事务等</li><li>代码是否存在并发问题，是否线程安全</li><li>性能是否有优化空间，比如，SQL、算法是否可以优化</li><li>是否有安全漏洞，比如输入输出校验是否全面</li></ul><h2 id="函数出错返回什么"><a href="#函数出错返回什么" class="headerlink" title="函数出错返回什么"></a>函数出错返回什么</h2><ul><li>返回错误码（有异常处理机制尽量不用错误码）</li><li>返回null值（查询类表示数据不存在可用）</li><li>返回空对象（空字符串和空集合）</li><li>抛出异常对象</li></ul><h3 id="处理异常"><a href="#处理异常" class="headerlink" title="处理异常"></a>处理异常</h3><ul><li>直接吞掉</li><li>原封不动re-throw</li><li>包装成新的异常re-throw</li></ul><h3 id="原则"><a href="#原则" class="headerlink" title="原则"></a>原则</h3><ul><li>如果 func1() 抛出的异常是可以恢复，且 func2() 的调用方并不关心此异常，可以在 func2() 内将 func1() 抛出的异常吞掉</li><li>如果 func1() 抛出的异常对 func2() 的调用方来说，也是可以理解的、关心的 ，并且在业务概念上有一定的相关性，可以选择直接将 func1 抛出的异常 re-throw；</li><li>如果 func1() 抛出的异常太底层，对 func2() 的调用方来说，缺乏背景去理解、且业务概念上无关，可以将它重新包装成调用方可以理解的新异常，然后 re-throw</li></ul><h1 id="设计模式与范式：创建型"><a href="#设计模式与范式：创建型" class="headerlink" title="设计模式与范式：创建型"></a>设计模式与范式：创建型</h1><h2 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h2><blockquote><p>一个类只允许创建一个对象（或者叫实例）</p></blockquote><h3 id="为什么使用单例模式"><a href="#为什么使用单例模式" class="headerlink" title="为什么使用单例模式"></a>为什么使用单例模式</h3><ul><li>处理资源访问冲突</li><li>表示全局唯一类</li></ul><h3 id="如何实现一个单例"><a href="#如何实现一个单例" class="headerlink" title="如何实现一个单例"></a>如何实现一个单例</h3><ul><li>构造函数需要private访问权限，这样才能避免外部通过new创建实例</li><li>考虑对象创建时的线程安全问题</li><li>考虑是否支持延迟加载</li><li>考虑getInstance()性能是否足够高（是否加锁）</li></ul><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><ul><li>饿汉式：在类加载的时候，instance 静态实例就已经创建并初始化好了；不支持延迟加载</li><li>懒汉式：使用时再初始化，但因为加锁导致并行度低；支持延迟加载</li><li>双重检测：即支持延迟加载又支持高并行</li><li>静态内部类：运用静态内部类的特性，类似饿汉式但是做到了延迟加载，instance的唯一性和线程安全性都由JVM保证，所以这种方式即保证线程安全又支持懒加载</li><li>枚举：通过java枚举类型本身的特性保证线程安全和实例的唯一性</li></ul><h3 id="单例模式存在的问题"><a href="#单例模式存在的问题" class="headerlink" title="单例模式存在的问题"></a>单例模式存在的问题</h3><ul><li>对OOP特性的支持不友好</li><li>单例会隐藏类之间的依赖关系</li><li>单例对代码的扩展性不友好</li><li>单例对代码的可测试性不友好</li><li>单例不支持有参数的构造函数</li></ul><h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><ul><li>创建完实例后再调用一个init()函数传递参数</li><li>将参数放到getInstance()方法中（存在调用两次传递不同参数的问题，可以在传递两次参数不同时给予提示）</li><li>将参数放到另一个全局变量中（最推荐的方式）</li></ul><h3 id="替代解决方案"><a href="#替代解决方案" class="headerlink" title="替代解决方案"></a>替代解决方案</h3><ul><li>可以使用静态方法而不是单例保证全局唯一（但存在比单例更多的问题，不支持延迟加载，不灵活</li><li>工厂模式保证类对象全局唯一性</li><li>IOC容器保证类对象全局唯一性</li></ul><h3 id="其他知识点"><a href="#其他知识点" class="headerlink" title="其他知识点"></a>其他知识点</h3><ul><li>单例类对象中的唯一性的作用范围是进程唯一的</li><li>线程唯一的单例可以通过hashmap实现，key存储线程id，value存储对象；Java提供的ThreadLocal并发工具类可以实现线程单例</li><li>集群间单例可以通过将对象存储在外存，通过序列化反序列化获取对象，通过加锁避免其他进程获取对象</li><li>多例模式可以通过Map存储对象类型和对象之间的对应关系来控制对象个数</li><li>对于Java而言，单例的作用域并非进程而是类加载器（因为双亲委托模式）</li></ul><h2 id="工厂模式"><a href="#工厂模式" class="headerlink" title="工厂模式"></a>工厂模式</h2><h3 id="分类-1"><a href="#分类-1" class="headerlink" title="分类"></a>分类</h3><ul><li>简单工厂</li><li>工厂方法</li><li>抽象工厂</li></ul><h3 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h3><ul><li>代码中存在 if-else 分支判断，动态地根据不同的类型创建不同的对象。针对这种情况，考虑使用工厂模式，将if-else 创建对象的代码抽离出来，放到工厂类中（简单工厂模式）</li><li>单个对象本身的创建过程比较复杂，比如做各种初始化操作。在这种情况下，考虑使用工厂模式，将对象的创建过程封装到工厂类中（工厂方法模式）</li></ul><h3 id="作用-1"><a href="#作用-1" class="headerlink" title="作用"></a>作用</h3><ul><li>封装变化：创建逻辑有可能变化，封装成工厂类之后，创建逻辑的变更对调用者透明</li><li>代码复用：创建代码抽离到独立的工厂类之后可以复用</li><li>隔离复杂性：封装复杂的创建逻辑，调用者无需了解如何创建对象</li><li>控制复杂度：将创建代码抽离出来，让原本的函数或类职责更单一，代码更简洁</li></ul><h3 id="DI容器设计"><a href="#DI容器设计" class="headerlink" title="DI容器设计"></a>DI容器设计</h3><ul><li>配置解析：容器读取配置文件，根据配置文件提供的信息来创建对象</li><li>对象创建：利用反射机制动态加载创建对象</li><li>对象生命周期管理：如返回单例对象还是调用一次创建一个、是否支持懒加载、配置对象init和destroy方法</li></ul><h2 id="建造者模式"><a href="#建造者模式" class="headerlink" title="建造者模式"></a>建造者模式</h2><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><ul><li>属性过多，避免构造方法参数列表过长</li><li>属性之间有一定的依赖关系或者约束条件</li><li>希望创建不可变对象，对象一旦创建后不能改变，所以不能暴露set方法设置属性值</li></ul><h3 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h3><ul><li>私有化构造函数</li><li>定义静态内部类Builder，暴露set方法设置属性</li><li>调用Builder的build方法创建对象</li></ul><h3 id="和工厂模式的区别"><a href="#和工厂模式的区别" class="headerlink" title="和工厂模式的区别"></a>和工厂模式的区别</h3><ul><li>工厂模式：创建不同的同一类型对象，由给定的参数来创建哪种类型的对象</li><li>建造者模式：创建一种类型的复杂对象，通过可设置的参数定制化创建对象</li></ul><h2 id="原型模式"><a href="#原型模式" class="headerlink" title="原型模式"></a>原型模式</h2><ul><li>基于原型来创建对象</li></ul><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><ul><li>对象中的数据需要进行复杂的计算才能获得</li><li>需要从RPC、网络、数据库、文件系统等慢速I/O中读取</li></ul><h3 id="实现方式-1"><a href="#实现方式-1" class="headerlink" title="实现方式"></a>实现方式</h3><ul><li>深拷贝：即复制索引也复制数据，得到的是完全独立的对象</li><li>浅拷贝：只复制索引本身，不复制数据，得到的对象和原始对象共享一份数据（除非操作非常耗时，否则不推荐浅拷贝）<br><strong>在 Java 语言中，Object 类的 clone() 方法执行的就是浅拷贝。它只会拷贝对象中的基本数据类型的数据（比如，int、long），以及引用对象（SearchWord）的内存地址，不会递归地拷贝引用对象本身</strong></li></ul><h3 id="深拷贝实现"><a href="#深拷贝实现" class="headerlink" title="深拷贝实现"></a>深拷贝实现</h3><ul><li>递归拷贝对象、对象的引用对象以及引用对象的引用对象，直到要拷贝的对象只包含基本数据类型数据，没有引用对象为止</li><li>先将对象序列化再反序列化为新的对象</li></ul><h3 id="应用方式"><a href="#应用方式" class="headerlink" title="应用方式"></a>应用方式</h3><ul><li>先通过浅拷贝复制对象，然后对需要更新的部分采用深拷贝，即利用了浅拷贝节省时间、空间的优点，又兼顾了深拷贝所具备的数据不共享性，不会因为更改而影响老数据的使用</li></ul><h1 id="设计模式与范式：结构型"><a href="#设计模式与范式：结构型" class="headerlink" title="设计模式与范式：结构型"></a>设计模式与范式：结构型</h1><h2 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h2><blockquote><p>在不改变原始类（或叫被代理类）代码的情况下，通过引入代理类来给原始类附加功能</p></blockquote><h3 id="静态代理"><a href="#静态代理" class="headerlink" title="静态代理"></a>静态代理</h3><ul><li>代理类和原始类实现相同的接口，原始类只负责业务功能，代理类负责在业务代码执行前后附加其他逻辑代码，并通过委托的方式调用原始类来执行业务代码（需要原始类和代理类有相同的接口）</li><li>如果原始类与代理类没有相同的接口，并且原始类的代码并非自己维护，对于这种外部类扩展采用继承的方式，通过代理类继承原始类，然后扩展附加功能</li></ul><h4 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h4><ul><li>代理类中需要将原始类所有方法实现一遍，并且每个方法都附加相似的代码逻辑</li><li>如果要添加的附加功能的类不止一个，需要针对每个类创建一个代理类</li></ul><h3 id="动态代理"><a href="#动态代理" class="headerlink" title="动态代理"></a>动态代理</h3><ul><li>不事先为每个原始类编写代理类，而是在运行的时候，动态地创建原始类对应的代理类<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MetricsCollectorProxy</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> MetricsCollector metricsCollector;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">MetricsCollectorProxy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.metricsCollector = <span class="keyword">new</span> MetricsCollector();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Object <span class="title">createProxy</span><span class="params">(Object proxiedObject)</span> </span>&#123;</span><br><span class="line">    Class&lt;?&gt;[] interfaces = proxiedObject.getClass().getInterfaces();</span><br><span class="line">    DynamicProxyHandler handler = <span class="keyword">new</span> DynamicProxyHandler(proxiedObject);</span><br><span class="line">    <span class="keyword">return</span> Proxy.newProxyInstance(proxiedObject.getClass().getClassLoader(), interfaces, handler);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">DynamicProxyHandler</span> <span class="keyword">implements</span> <span class="title">InvocationHandler</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Object proxiedObject;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DynamicProxyHandler</span><span class="params">(Object proxiedObject)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.proxiedObject = proxiedObject;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">invoke</span><span class="params">(Object proxy, Method method, Object[] args)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">      <span class="keyword">long</span> startTimestamp = System.currentTimeMillis();</span><br><span class="line">      Object result = method.invoke(proxiedObject, args);</span><br><span class="line">      <span class="keyword">long</span> endTimeStamp = System.currentTimeMillis();</span><br><span class="line">      <span class="keyword">long</span> responseTime = endTimeStamp - startTimestamp;</span><br><span class="line">      String apiName = proxiedObject.getClass().getName() + <span class="string">":"</span> + method.getName();</span><br><span class="line">      RequestInfo requestInfo = <span class="keyword">new</span> RequestInfo(apiName, responseTime, startTimestamp);</span><br><span class="line">      metricsCollector.recordRequest(requestInfo);</span><br><span class="line">      <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//MetricsCollectorProxy使用举例</span></span><br><span class="line">MetricsCollectorProxy proxy = <span class="keyword">new</span> MetricsCollectorProxy();</span><br><span class="line">IUserController userController = (IUserController) proxy.createProxy(<span class="keyword">new</span> UserController());</span><br></pre></td></tr></table></figure></li></ul><h3 id="使用场景-1"><a href="#使用场景-1" class="headerlink" title="使用场景"></a>使用场景</h3><ul><li>业务系统的非功能性需求开发：监控、统计、鉴权、限流、事务、幂等、日志</li><li>在RPC、缓存中使用</li></ul><h2 id="桥接模式"><a href="#桥接模式" class="headerlink" title="桥接模式"></a>桥接模式</h2><ul><li>将抽象和实现解耦，让它们可以独立变化</li><li>一个类存在两个（或多个）变化的维度，可以通过组合的方式，让两个（或多个）纬度可以独立扩展</li></ul><h3 id="使用场景-2"><a href="#使用场景-2" class="headerlink" title="使用场景"></a>使用场景</h3><ul><li>需要分离抽象和实现的业务场景（参见jdbc Driver源码）</li></ul><h2 id="装饰器模式"><a href="#装饰器模式" class="headerlink" title="装饰器模式"></a>装饰器模式</h2><h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><ul><li>解决继承关系过于复杂的问题，通过组合来替代继承</li></ul><h3 id="作用-2"><a href="#作用-2" class="headerlink" title="作用"></a>作用</h3><ul><li>给原始类增强功能</li></ul><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul><li>可以对原始类嵌套使用多个装饰器（装饰器类需要跟原始类继承相同的抽象类或接口）</li></ul><h2 id="适配器模式"><a href="#适配器模式" class="headerlink" title="适配器模式"></a>适配器模式</h2><ul><li>将不兼容的接口转换为可兼容的接口，让原本由于接口不兼容而不能一起工作的类可以一起工作</li></ul><h3 id="实现方式-2"><a href="#实现方式-2" class="headerlink" title="实现方式"></a>实现方式</h3><ul><li>类适配器：使用继承实现</li><li>对象适配器：使用组合实现</li></ul><h3 id="选择依据"><a href="#选择依据" class="headerlink" title="选择依据"></a>选择依据</h3><ul><li>如果待转化的接口方法不多，两种均可</li><li>如果待转化的接口方法很多，而且大多数和待适配的接口相同，推荐使用类适配器，因为适配器能复用父类的方法，比起对象适配器代码量更少</li><li>如果待转化的接口方法很多，而大多数与待适配的接口不同，推荐使用对象适配器，因为组合结构相对于继承更灵活</li></ul><h3 id="使用场景-3"><a href="#使用场景-3" class="headerlink" title="使用场景"></a>使用场景</h3><ul><li>封装有缺陷的接口设计</li><li>统一多个类的接口设计</li><li>替换以来的外部系统</li><li>兼容老版本接口</li><li>适配不同格式的数据</li></ul><h3 id="代理、桥接、装饰器、适配器-4-种设计模式的区别"><a href="#代理、桥接、装饰器、适配器-4-种设计模式的区别" class="headerlink" title="代理、桥接、装饰器、适配器 4 种设计模式的区别"></a>代理、桥接、装饰器、适配器 4 种设计模式的区别</h3><ul><li>代理模式：代理模式在不改变原始类接口的条件下，为原始类定义一个代理类，主要目的是控制访问，而非加强功能，这是它跟装饰器模式最大的不同。</li><li>桥接模式：桥接模式的目的是将接口部分和实现部分分离，从而让它们可以较为容易、也相对独立地加以改变。</li><li>装饰器模式：装饰者模式在不改变原始类接口的情况下，对原始类功能进行增强，并且支持多个装饰器的嵌套使用。</li><li>适配器模式：适配器模式是一种事后的补救策略。适配器提供跟原始类不同的接口，而代理模式、装饰器模式提供的都是跟原始类相同的接口</li></ul><h2 id="门面模式"><a href="#门面模式" class="headerlink" title="门面模式"></a>门面模式</h2><blockquote><p>门面模式为子系统提供一组统一的接口，定义一组高层接口让子系统更易用</p></blockquote><h3 id="组织门面接口"><a href="#组织门面接口" class="headerlink" title="组织门面接口"></a>组织门面接口</h3><ul><li>门面接口不多，可以和非门面接口放在一起不做特殊标记</li><li>门面接口很多，在已有的接口上再重新抽象一层专门放置门面接口，从类、包的命名上跟原来的接口层做区分</li><li>门面接口特别多，可以将门面接口放到一个新的子系统中</li></ul><h3 id="应用场景-1"><a href="#应用场景-1" class="headerlink" title="应用场景"></a>应用场景</h3><ul><li>通过将多个接口调用替换为一个门面接口调用来解决因需要调用多个接口造成的性能问题</li><li>通过提供一组更加简单易用、更高层的接口来解决易用性问题</li><li>通过门面模式包装需要保证事务性的多个接口来解决分布式事务问题</li></ul><h2 id="组合模式"><a href="#组合模式" class="headerlink" title="组合模式"></a>组合模式</h2><blockquote><p>将一组对象组织（Compose）成树形结构，以表示一种“部分 - 整体”的层次结构。组合让客户端可以统一单个对象和组合对象的处理逻辑</p></blockquote><h3 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h3><ul><li>业务场景必须能表示成树形结构</li></ul><h2 id="享元模式"><a href="#享元模式" class="headerlink" title="享元模式"></a>享元模式</h2><blockquote><p>当一个系统中存在大量重复对象的时候，如果这些重复的对象是不可变对象，就可以利用享元模式将对象设计成享元，在内存中只保留一份实例，供多处代码引用</p></blockquote><h3 id="代码结构"><a href="#代码结构" class="headerlink" title="代码结构"></a>代码结构</h3><ul><li>通过工厂模式，在工厂类中通过一个map来缓存已经创建过的享元对象来达到复用的目的</li></ul><h3 id="享元模式-vs-单例、缓存、对象池"><a href="#享元模式-vs-单例、缓存、对象池" class="headerlink" title="享元模式 vs 单例、缓存、对象池"></a>享元模式 vs 单例、缓存、对象池</h3><ul><li>单例：在单例模式中，一个类只能创建一个对象，而在享元模式中，一个类可以创建多个对象，每个对象被多处代码引用共享</li><li>缓存：平时所讲的缓存，主要是为了提高访问效率，而非复用</li><li>池化技术：池化技术中的“复用”可以理解为“重复使用”，主要目的是节省时间；享元模式中的“复用”可以理解为“共享使用”，在整个生命周期中，都是被所有使用者共享的，主要目的是节省空间</li></ul><h3 id="享元在Integer中的使用"><a href="#享元在Integer中的使用" class="headerlink" title="享元在Integer中的使用"></a>享元在Integer中的使用</h3><ul><li>在 Java Integer 的实现中，-128 到 127 之间的整型对象会被事先创建好，缓存在 IntegerCache 类中。当使用自动装箱或者 valueOf() 来创建这个数值区间的整型对象时，会复用 IntegerCache 类事先创建好的对象。IntegerCache 类就是享元工厂类，事先创建好的整型对象就是享元对象</li></ul><h3 id="享元在String中的使用"><a href="#享元在String中的使用" class="headerlink" title="享元在String中的使用"></a>享元在String中的使用</h3><ul><li>String 类的享元模式的设计，跟 Integer 类稍微有些不同。Integer 类中要共享的对象，是在类加载的时候，就集中一次性创建好的。对于字符串来说，是在某个字符串常量第一次被用到的时候，存储到常量池中，当之后再用到的时候，直接引用常量池中已经存在</li></ul><h1 id="设计模式与规范：行为型"><a href="#设计模式与规范：行为型" class="headerlink" title="设计模式与规范：行为型"></a>设计模式与规范：行为型</h1><h2 id="观察者模式"><a href="#观察者模式" class="headerlink" title="观察者模式"></a>观察者模式</h2><blockquote><p>观察者模式也称为发布订阅模式，在对象之间定义一个一对多的依赖，当一个对象状态改变的时候，所有依赖的对象都会自动收到通知</p></blockquote><h3 id="实现方式-3"><a href="#实现方式-3" class="headerlink" title="实现方式"></a>实现方式</h3><ul><li>同步阻塞：观察者和被观察者代码在同一个线程内执行，被观察者一直阻塞，直到所有的观察者代码都执行完成之后，才执行后续的代码</li><li>异步非阻塞：在每个 执行函数中，创建一个新的线程执行代码；基于 EventBus 来实现</li><li>进程内的实现方式：以上两种均为进程内实现方式</li><li>跨进程的实现方式：基于消息队列的方式</li></ul><h2 id="模版模式"><a href="#模版模式" class="headerlink" title="模版模式"></a>模版模式</h2><blockquote><p>模板方法模式在一个方法中定义一个算法骨架，并将某些步骤推迟到子类中实现。模板方法模式可以让子类在不改变算法整体结构的情况下，重新定义算法中的某些步骤</p></blockquote><h3 id="作用-3"><a href="#作用-3" class="headerlink" title="作用"></a>作用</h3><ul><li>复用<ul><li>Java InputStream</li><li>Java AbstractList</li></ul></li><li>扩展：基于这个作用，模板模式常用在框架的开发中，让框架用户可以在不修改框架源码的情况下，定制化框架的功能<ul><li>Java Servlet</li><li>JUnit TestCase</li></ul></li></ul><h3 id="回调"><a href="#回调" class="headerlink" title="回调"></a>回调</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><ul><li>A 类事先注册某个函数 F 到 B 类，A 类在调用 B 类的 P 函数的时候，B 类反过来调用 A 类注册给它的 F 函数。这里的 F 函数就是“回调函数”。A 调用 B，B 反过来又调用 A，这种调用机制就叫作“回调”。</li></ul><h4 id="分类-2"><a href="#分类-2" class="headerlink" title="分类"></a>分类</h4><ul><li>同步回调：函数返回之前执行回调函数（像模板模式）</li><li>异步回调：函数返回之后执行回调函数（像观察者模式）</li></ul><h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><ul><li>JdbcTemplate：JdbcTemplate 通过回调的机制，将不变的执行流程抽离出来，放到模板方法 execute() 中，将可变的部分设计成回调 StatementCallback，由用户来定制。query() 函数是对 execute() 函数的二次封装，让接口用起来更加方便。</li><li>setClickListener：往 setOnClickListener() 函数中注册好回调函数之后，并不需要等待回调函数执行</li><li>addShutdownHook：Tomcat和JVM的shutdown hook；JVM 提供了 Runtime.addShutdownHook(Thread hook) 方法，可以注册一个 JVM 关闭的 Hook。当应用程序关闭的时候，JVM会自动调用Hook代码</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">回调</th><th style="text-align:center">模板模式</th></tr></thead><tbody><tr><td style="text-align:center">应用场景几乎一致</td><td style="text-align:center">应用场景几乎一致</td></tr><tr><td style="text-align:center">基于组合关系来实现，把一个对象传递给另一个对象，是一种对象之间的关系</td><td style="text-align:center">基于继承关系来实现，子类重写父类的抽象方法，是一种类之间的关系</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">像 Java 这种只支持单继承的语言，基于模板模式编写的子类，已经继承了一个父类，不再具有继承的能力</td></tr><tr><td style="text-align:center">可以使用匿名类来创建回调对象，可以不用事先定义类</td><td style="text-align:center">针对不同的实现都要定义不同的子类</td></tr><tr><td style="text-align:center">回调就更加灵活，只需要往用到的模板方法中注入回调对象即可</td><td style="text-align:center">如果某个类中定义了多个模板方法，每个方法都有对应的抽象方法，那即便我们只用到其中的一个模板方法，子类也必须实现所有的抽象方法</td></tr></tbody></table></div><h2 id="策略模式"><a href="#策略模式" class="headerlink" title="策略模式"></a>策略模式</h2><blockquote><p>定义一族算法类，将每个算法分别封装起来，让它们可以互相替换。策略模式可以使算法的变化独立于使用它们的客户端</p></blockquote><h3 id="策略定义"><a href="#策略定义" class="headerlink" title="策略定义"></a>策略定义</h3><ul><li>包含一个策略接口和一组实现这个接口的策略类。所有的策略类都实现相同的接口，客户端代码基于接口而非实现编程，可以灵活地替换不同的策略</li></ul><h3 id="策略创建"><a href="#策略创建" class="headerlink" title="策略创建"></a>策略创建</h3><ul><li>使用策略的时候通过类型来判断创建哪个策略使用</li><li>为了封装创建细节，把根据类型创建策略的逻辑抽离出来放到工厂类中</li><li>无状态可以缓存策略，不用每次创建</li><li>有状态需要每次创建</li></ul><h3 id="策略使用"><a href="#策略使用" class="headerlink" title="策略使用"></a>策略使用</h3><ul><li>运行时动态确定使用哪种策略，即在程序运行期间根据配置、用户输入、计算结果等不确定因素动态决定使用哪种策略</li></ul><h3 id="解决if-esle过多的问题"><a href="#解决if-esle过多的问题" class="headerlink" title="解决if-esle过多的问题"></a>解决if-esle过多的问题</h3><ul><li>不每次创建的策略实际是使用查表法，根据类型查表替代根据类型分支判断</li><li>每次创建的策略实际是将原本的if-else分支判断转移到工厂之中</li></ul><h3 id="作用-4"><a href="#作用-4" class="headerlink" title="作用"></a>作用</h3><ul><li>解耦策略的定义、创建和使用，控制代码的复杂度，让每个部分都不至于过于复杂、代码量过多</li><li>对于复杂代码来说，还能让其满足开闭原则，添加新策略的时候，最小化、集中化代码改动，减少引入 bug 的风险</li></ul><h2 id="职责链模式"><a href="#职责链模式" class="headerlink" title="职责链模式"></a>职责链模式</h2><blockquote><p>将请求的发送和接收解耦，让多个接收对象都有机会处理这个请求。将这些接收对象串成一条链，并沿着这条链传递这个请求，直到链上的某个接收对象能够处理它为止</p></blockquote><h3 id="实现方式-4"><a href="#实现方式-4" class="headerlink" title="实现方式"></a>实现方式</h3><ul><li>用链表存储处理器</li><li>用数组存储处理器</li></ul><h3 id="应用场景-2"><a href="#应用场景-2" class="headerlink" title="应用场景"></a>应用场景</h3><ul><li>敏感词过滤</li><li>过滤器（Servlet Filter）</li><li>拦截器（Spring Interceptor）</li></ul><h3 id="为什么"><a href="#为什么" class="headerlink" title="为什么"></a>为什么</h3><ul><li>可以应对代码复杂性</li><li>让代码满足开闭原则，提高代码扩展性</li><li>配置链更灵活，可以选择配置哪几个处理器而不是全部</li></ul><h3 id="Servlet-Filter"><a href="#Servlet-Filter" class="headerlink" title="Servlet Filter"></a>Servlet Filter</h3><ul><li>tomcat ApplicationFilterChain：使用递归实现，可以做到双向过滤</li></ul><h3 id="Spring-Interceptor"><a href="#Spring-Interceptor" class="headerlink" title="Spring Interceptor"></a>Spring Interceptor</h3><ul><li>因为请求和响应分开拦截，所以未使用递归</li></ul><h3 id="AOP、Servlet-Filter、Spring-Interceptor选择"><a href="#AOP、Servlet-Filter、Spring-Interceptor选择" class="headerlink" title="AOP、Servlet Filter、Spring Interceptor选择"></a>AOP、Servlet Filter、Spring Interceptor选择</h3><blockquote><p>根据需求粒度进行选择</p></blockquote><ul><li>Servlet Filter：与框架无关，对所有请求响应有效，能处理原始请求，但无法获取请求控制器的信息</li><li>Spring Interceptor：与框架耦合，可以通过Spring提供配置，相比而言更灵活</li><li>AOP：业务内拦截，更细粒度</li></ul><h2 id="状态模式"><a href="#状态模式" class="headerlink" title="状态模式"></a>状态模式</h2><h3 id="状态机实现方式"><a href="#状态机实现方式" class="headerlink" title="状态机实现方式"></a>状态机实现方式</h3><ul><li>分支逻辑法：参照状态转移图，将每一个状态转移，原模原样地直译成代码。编写的代码会包含大量的 if-else 或 switch-case 分支判断逻辑，甚至是嵌套的分支判断逻辑<br><img src="/2020/06/21/设计模式/状态机.jpeg" alt="状态机"></li><li>查表法：状态机用二维表来表示，在二维表中，第一维表示当前状态，第二维表示事件，值表示当前状态经过事件之后，转移到的新状态及其执行的动作<br><img src="/2020/06/21/设计模式/查表法.jpeg" alt="查表法"></li><li>状态模式：通过将事件触发的状态转移和动作执行，拆分到不同的状态类中，来避免分支判断逻辑</li></ul><h2 id="迭代器模式"><a href="#迭代器模式" class="headerlink" title="迭代器模式"></a>迭代器模式</h2><p>迭代器模式将集合对象的遍历操作从集合类中拆分出来，放到迭代器类中，让两者的职责更加单一<br><img src="/2020/06/21/设计模式/迭代器.jpeg" alt="迭代器"></p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><ul><li>迭代器中需要定义 hasNext()、currentItem()、next() 三个最基本的方法</li><li>待遍历的容器对象通过依赖注入传递到迭代器类中</li><li>容器通过 iterator() 方法来创建迭代器<br><img src="/2020/06/21/设计模式/迭代器实现.jpeg" alt="迭代器实现"></li></ul><h3 id="使用迭代器的原因"><a href="#使用迭代器的原因" class="headerlink" title="使用迭代器的原因"></a>使用迭代器的原因</h3><ul><li>迭代器模式封装集合内部的复杂数据结构，开发者不需要了解如何遍历，直接使用容器提供的迭代器即可</li><li>迭代器模式将集合对象的遍历操作从集合类中拆分出来，放到迭代器类中，让两者的职责更加单一</li><li>迭代器模式让添加新的遍历算法更加容易，更符合开闭原则。除此之外，因为迭代器都实现自相同的接口，在开发中，基于接口而非实现编程，替换迭代器也变得更加容易</li></ul><h3 id="修改集合导致未决行为"><a href="#修改集合导致未决行为" class="headerlink" title="修改集合导致未决行为"></a>修改集合导致未决行为</h3><ul><li>遍历时不允许增删元素（无法得知结束点，实现困难）</li><li>增删元素后让遍历报错（设置modCount和expectedModCount，修改之后更新modCount，迭代时每次检查两个值，不相等则报错）</li></ul><h3 id="安全删除集合元素（Java）"><a href="#安全删除集合元素（Java）" class="headerlink" title="安全删除集合元素（Java）"></a>安全删除集合元素（Java）</h3><ul><li>增加一个lastRet成员变量来记录游标指向的前一个元素，通过迭代器去删除这个元素的时候，更新迭代器中的游标和 lastRet 值，来保证不会因为删除元素而导致某个元素遍历不到</li></ul><h3 id="实现支持快照功能的迭代器"><a href="#实现支持快照功能的迭代器" class="headerlink" title="实现支持快照功能的迭代器"></a>实现支持快照功能的迭代器</h3><ul><li>在迭代器类中定义一个成员变量 snapshot 来存储快照。每当创建迭代器的时候，都拷贝一份容器中的元素到快照中，后续的遍历操作都基于这个迭代器自己持有的快照来进行（由于拷贝，会增加内存消耗）</li><li>为每个元素保存两个时间戳，一个是添加时间戳 addTimestamp，一个是删除时间戳 delTimestamp。当元素被加入到集合中的时候，将 addTimestamp 设置为当前时间，将 delTimestamp 设置成最大长整型值（Long.MAX_VALUE）。当元素被删除时，将 delTimestamp 更新为当前时间，表示已经被删除，只做标记删除（三个数组，一个元素数组，两个时间戳数组，为了支持随机下表访问，再增加一个元素数组，一个真实删除，一个作为快照数组逻辑删除）</li></ul><h2 id="访问者模式"><a href="#访问者模式" class="headerlink" title="访问者模式"></a>访问者模式</h2><blockquote><p>允许一个或多个操作应用到一组对象上，解耦操作和对象本身</p></blockquote><p><img src="/2020/06/21/设计模式/访问者模式.jpeg" alt="访问者模式"></p><h3 id="设计意图"><a href="#设计意图" class="headerlink" title="设计意图"></a>设计意图</h3><ul><li>解耦操作和对象本身</li><li>保持类职责单一</li><li>满足开闭原则</li><li>应对代码的复杂性</li></ul><h3 id="设计难点"><a href="#设计难点" class="headerlink" title="设计难点"></a>设计难点</h3><ul><li>难点在代码实现。原因是函数重载在大部分面向对象编程语言中是静态绑定的。调用类的哪个重载函数，是在编译期间，由参数的声明类型决定的，而非运行时，根据参数的实际类型决定的</li></ul><h3 id="应用场景-3"><a href="#应用场景-3" class="headerlink" title="应用场景"></a>应用场景</h3><ul><li>访问者模式针对的是一组类型不同的对象（PdfFile、PPTFile、WordFile）。尽管这组对象的类型是不同的，但是它们继承相同的父类（ResourceFile）或者实现相同的接口。在不同的应用场景下，我们需要对这组对象进行一系列不相关的业务操作（抽取文本、压缩等），但为了避免不断添加功能导致类（PdfFile、PPTFile、WordFile）不断膨胀，职责越来越不单一，以及避免频繁地添加功能导致的频繁代码修改，我们使用访问者模式，将对象与操作解耦，将这些业务操作抽离出来，定义在独立细分的访问者类（Extractor、Compressor）中<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">ResourceFile</span> </span>&#123;</span><br><span class="line">  <span class="keyword">protected</span> String filePath;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">ResourceFile</span><span class="params">(String filePath)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.filePath = filePath;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">abstract</span> <span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accept</span><span class="params">(Visitor vistor)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PdfFile</span> <span class="keyword">extends</span> <span class="title">ResourceFile</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">PdfFile</span><span class="params">(String filePath)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(filePath);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accept</span><span class="params">(Visitor visitor)</span> </span>&#123;</span><br><span class="line">    visitor.visit(<span class="keyword">this</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//...PPTFile、WordFile跟PdfFile类似，这里就省略了...</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Visitor</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">visit</span><span class="params">(PdfFile pdfFile)</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">visit</span><span class="params">(PPTFile pdfFile)</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">visit</span><span class="params">(WordFile pdfFile)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Extractor</span> <span class="keyword">implements</span> <span class="title">Visitor</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">visit</span><span class="params">(PPTFile pptFile)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    System.out.println(<span class="string">"Extract PPT."</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">visit</span><span class="params">(PdfFile pdfFile)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    System.out.println(<span class="string">"Extract PDF."</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">visit</span><span class="params">(WordFile wordFile)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    System.out.println(<span class="string">"Extract WORD."</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Compressor</span> <span class="keyword">implements</span> <span class="title">Visitor</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">visit</span><span class="params">(PPTFile pptFile)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    System.out.println(<span class="string">"Compress PPT."</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">visit</span><span class="params">(PdfFile pdfFile)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    System.out.println(<span class="string">"Compress PDF."</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">visit</span><span class="params">(WordFile wordFile)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    System.out.println(<span class="string">"Compress WORD."</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ToolApplication</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    Extractor extractor = <span class="keyword">new</span> Extractor();</span><br><span class="line">    List&lt;ResourceFile&gt; resourceFiles = listAllResourceFiles(args[<span class="number">0</span>]);</span><br><span class="line">    <span class="keyword">for</span> (ResourceFile resourceFile : resourceFiles) &#123;</span><br><span class="line">      resourceFile.accept(extractor);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Compressor compressor = <span class="keyword">new</span> Compressor();</span><br><span class="line">    <span class="keyword">for</span>(ResourceFile resourceFile : resourceFiles) &#123;</span><br><span class="line">      resourceFile.accept(compressor);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> List&lt;ResourceFile&gt; <span class="title">listAllResourceFiles</span><span class="params">(String resourceDirectory)</span> </span>&#123;</span><br><span class="line">    List&lt;ResourceFile&gt; resourceFiles = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    <span class="comment">//...根据后缀(pdf/ppt/word)由工厂方法创建不同的类对象(PdfFile/PPTFile/WordFile)</span></span><br><span class="line">    resourceFiles.add(<span class="keyword">new</span> PdfFile(<span class="string">"a.pdf"</span>));</span><br><span class="line">    resourceFiles.add(<span class="keyword">new</span> WordFile(<span class="string">"b.word"</span>));</span><br><span class="line">    resourceFiles.add(<span class="keyword">new</span> PPTFile(<span class="string">"c.ppt"</span>));</span><br><span class="line">    <span class="keyword">return</span> resourceFiles;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="单分派（Single-Dispatch）"><a href="#单分派（Single-Dispatch）" class="headerlink" title="单分派（Single Dispatch）"></a>单分派（Single Dispatch）</h3><ul><li>执行哪个对象的哪个方法，只跟“对象”的运行时类型有关</li><li>执行哪个对象的方法，根据对象的运行时类型来决定</li><li>执行对象的哪个方法，根据方法参数的编译时类型来决定</li></ul><h3 id="双分派（Double-Dispatch）"><a href="#双分派（Double-Dispatch）" class="headerlink" title="双分派（Double Dispatch）"></a>双分派（Double Dispatch）</h3><ul><li>执行哪个对象的哪个方法，跟“对象”和“方法参数”两者的运行时类型有关</li><li>执行哪个对象的方法，根据对象的运行时类型来决定</li><li>执行对象的哪个方法，根据方法参数的运行时类型来决定。</li></ul><h2 id="备忘录模式"><a href="#备忘录模式" class="headerlink" title="备忘录模式"></a>备忘录模式</h2><blockquote><p>在不违背封装原则的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，以便之后恢复对象为先前的状态</p></blockquote><h3 id="要求"><a href="#要求" class="headerlink" title="要求"></a>要求</h3><ul><li>存储副本以便后期恢复</li><li>在不违背封装原则的前提下，进行对象的备份和恢复</li></ul><h3 id="应用场景-4"><a href="#应用场景-4" class="headerlink" title="应用场景"></a>应用场景</h3><ul><li>防丢失</li><li>撤销</li><li>恢复</li></ul><h3 id="与备份的区别"><a href="#与备份的区别" class="headerlink" title="与备份的区别"></a>与备份的区别</h3><ul><li>备忘录模式：侧重于代码的设计和实现</li><li>备份：侧重架构设计和产品设计</li></ul><h3 id="大对象备份问题"><a href="#大对象备份问题" class="headerlink" title="大对象备份问题"></a>大对象备份问题</h3><ul><li>只备份必要的恢复信息，结合最新的数据来恢复</li><li>全量备份和增量备份相结合</li><li>低频全量备份，高频增量备份，两者结合来做恢复</li></ul><h2 id="命令模式"><a href="#命令模式" class="headerlink" title="命令模式"></a>命令模式</h2><blockquote><p>命令模式将请求（命令）封装为一个对象，这样可以使用不同的请求参数化其他对象（将不同请求依赖注入到其他对象），并且能够支持请求（命令）的排队执行、记录日志、撤销等（附加控制）功能</p></blockquote><h3 id="应用场景-5"><a href="#应用场景-5" class="headerlink" title="应用场景"></a>应用场景</h3><ul><li>用来控制命令的执行，比如，异步、延迟、排队执行命令、撤销重做命令、存储命令、给命令记录日志等等</li></ul><h3 id="与策略模式的区别"><a href="#与策略模式的区别" class="headerlink" title="与策略模式的区别"></a>与策略模式的区别</h3><ul><li>策略模式：不同的策略具有相同的目的、不同的实现、互相之间可以替换</li><li>命令模式：不同的命令具有不同的目的，对应不同的处理逻辑，并且互相之间不可替换</li></ul><h2 id="解释器模式"><a href="#解释器模式" class="headerlink" title="解释器模式"></a>解释器模式</h2><blockquote><p>解释器模式为某个语言定义它的语法（或者叫文法）表示，并定义一个解释器用来处理这个语法</p></blockquote><h3 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h3><ul><li>思想：将语法解析的工作拆分到各个小类中，以此来避免大而全的解析类</li><li>做法：语法规则拆分成一些小的独立的单元，然后对每个单元进行解析，最终合并为对整个语法规则的解析</li><li></li></ul><h2 id="中介模式"><a href="#中介模式" class="headerlink" title="中介模式"></a>中介模式</h2><blockquote><p>中介模式定义了一个单独的（中介）对象，来封装一组对象之间的交互。将这组对象之间的交互委派给与中介对象交互，来避免对象之间的直接交互</p></blockquote><p><img src="/2020/06/21/设计模式/中介模式.jpeg" alt="中介模式"></p><h3 id="与观察者模式的区别"><a href="#与观察者模式的区别" class="headerlink" title="与观察者模式的区别"></a>与观察者模式的区别</h3><ul><li>观察者模式：参与者之间的交互比较有条理，一般都是单向的，一个参与者只有一个身份，要么是观察者，要么是被观察者</li><li>中介模式：参与者之间的交互关系错综复杂，既可以是消息的发送者、也可以同时是消息的接收者</li></ul>]]></content>
    
    <summary type="html">
    
      关于23种经典的设计模式总结
    
    </summary>
    
      <category term="架构" scheme="http://coldjune.com/categories/%E6%9E%B6%E6%9E%84/"/>
    
    
      <category term="架构" scheme="http://coldjune.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>高并发设计</title>
    <link href="http://coldjune.com/2020/04/04/%E9%AB%98%E5%B9%B6%E5%8F%91%E8%AE%BE%E8%AE%A1/"/>
    <id>http://coldjune.com/2020/04/04/高并发设计/</id>
    <published>2020-04-04T10:44:57.000Z</published>
    <updated>2020-04-22T12:01:28.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h1><h2 id="通用设计方法"><a href="#通用设计方法" class="headerlink" title="通用设计方法"></a>通用设计方法</h2><ul><li>横向扩展(Scale out)</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">Scale up(纵向扩展）</th><th style="text-align:center">Scale out（横向扩展）</th></tr></thead><tbody><tr><td style="text-align:center">通过购买性能更好的硬件提升并发处理能力</td><td style="text-align:center">将多个低性能的机器组成一个分布式集群来共同抵御高并发流量</td></tr><tr><td style="text-align:center">简单</td><td style="text-align:center">引入一定的复杂度</td></tr><tr><td style="text-align:center">系统设计初期</td><td style="text-align:center">系统并发超过单机限制</td></tr></tbody></table></div><ul><li><p>缓存-&gt;提升系统的访问性能</p><ol><li>CPU执行指令和内存寻址ns（纳秒）级别，千兆网卡读取数据微秒级别</li><li>磁盘因为物理结构存在寻道时间，是计算机中慢的一环</li></ol></li><li><p>异步</p></li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">同步</th><th style="text-align:center">异步</th></tr></thead><tbody><tr><td style="text-align:center">调用方要阻塞等待被调用方逻辑执行完成并返回</td><td style="text-align:center">不用等待被调用方就可执行其他逻辑</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">放入消息队列并返回用户正在处理</td></tr></tbody></table></div><p><img src="/2020/04/04/高并发设计/12306异步处理示意图.jpeg" alt="12306异步处理示意图"><br><strong>高并发设计是循序渐进的，不能毕其功于一役</strong></p><h2 id="分层设计"><a href="#分层设计" class="headerlink" title="分层设计"></a>分层设计</h2><h3 id="mvc-三层架构"><a href="#mvc-三层架构" class="headerlink" title="mvc/三层架构"></a>mvc/三层架构</h3><p><img src="/2020/04/04/高并发设计/MVC架构图.jpeg" alt="MVC架构图"><br><img src="/2020/04/04/高并发设计/三层架构示意图.jpeg" alt="三层架构示意图"></p><ul><li>表现层：展示数据和接受用户指令</li><li>逻辑层：复杂业务逻辑</li><li>数据访问层：处理和存储之间的交互</li></ul><h3 id="分层的好处"><a href="#分层的好处" class="headerlink" title="分层的好处"></a>分层的好处</h3><ol><li>简化系统设计，不同的人专注做一件事</li><li>高复用</li><li>更容易做横向扩展（高并发的基础）</li></ol><h3 id="做系统分层"><a href="#做系统分层" class="headerlink" title="做系统分层"></a>做系统分层</h3><p><img src="/2020/04/04/高并发设计/阿里系统分层规约.jpeg" alt="阿里系统分层规约"></p><ul><li>终端显示层：各端模版渲染并执行显示</li><li>开放接口层：Service层封装为开放接口并做网关安全控制和流量控制</li><li>Web层：对访问控制转发/基本参数校验/不复用业务逻辑简单处理</li><li>Service层：业务逻辑层</li><li>Manager层：通用业务逻辑处理（通用能力下沉/封装对第三方接口调用，如支付等）</li><li>DAO层：数据访问层</li><li>外部接口或第三方平台：其他部分或公司提供的外部接口</li></ul><h3 id="分层的不足"><a href="#分层的不足" class="headerlink" title="分层的不足"></a>分层的不足</h3><ol><li>增加代码复杂度</li><li>通过网络交互带来性能损失</li></ol><h3 id="设计思想"><a href="#设计思想" class="headerlink" title="设计思想"></a>设计思想</h3><ul><li>单一职责原则：每个类只有单一的功能（每一层职责单一，层与层边界清晰）</li><li>迪米特法则：对其他对象尽可能少的了解，不能跨层访问</li><li>开闭原则：对扩展开放，对修改封闭</li></ul><h2 id="高并发设计的目标：高性能、高可用、可扩展"><a href="#高并发设计的目标：高性能、高可用、可扩展" class="headerlink" title="高并发设计的目标：高性能、高可用、可扩展"></a>高并发设计的目标：高性能、高可用、可扩展</h2><blockquote><p>高并发：运用系统设计手段让系统能处理更多用户请求流量</p></blockquote><h3 id="性能优化原则"><a href="#性能优化原则" class="headerlink" title="性能优化原则"></a>性能优化原则</h3><ul><li>问题导向：不要盲目提早优化</li><li>二八原则：即20%的精力优化80%的问题，抓住主要矛盾</li><li>数据支撑：优化使响应时间减少量和吞吐提升量</li><li>持续性：达到目标为止</li></ul><h3 id="性能度量指标"><a href="#性能度量指标" class="headerlink" title="性能度量指标"></a>性能度量指标</h3><blockquote><p>吞吐量和响应时间呈倒数关系，响应时间200ms是一个分界点，之前感受不到延迟；1s也是一个分界点，超过有明显等待的感觉</p></blockquote><ul><li>响应时间平均值：敏感度较低，瞬时改变可能无法反应，只能作为一个参考</li><li>响应时间最大值：过于敏感</li><li>分位数：排除偶发极慢请求影响，分位数越高对慢请求的影响越敏感<br><img src="/2020/04/04/高并发设计/分位值示意图.jpeg" alt="分位值示意图"></li></ul><h3 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h3><ul><li>提升系统处理核心：增加系统并行处理能力（思路简单，吞吐量=并发进程数/响应时间）</li><li>减少单次任务响应时间</li></ul><h4 id="减少单次任务响应时间的方式"><a href="#减少单次任务响应时间的方式" class="headerlink" title="减少单次任务响应时间的方式"></a>减少单次任务响应时间的方式</h4><ul><li>CPU密集型：更高效的算法或减少运算次数，通过Profile工具找到消耗CPU消耗时间最多的模块（Linux的perf/eBPF）</li><li>IO密集型：数据库问题看锁表和索引等/网络IO问题看网络参数能否优化，是否有大量超时重传和丢包；采用工具或对每一步骤做分时监控发现问题<br><img src="/2020/04/04/高并发设计/性能测试拐点模型.jpeg" alt="性能测试拐点模型"></li></ul><h2 id="高可用（High-Availability，HA）：系统具备较高的无故障运行能力"><a href="#高可用（High-Availability，HA）：系统具备较高的无故障运行能力" class="headerlink" title="高可用（High Availability，HA）：系统具备较高的无故障运行能力"></a>高可用（High Availability，HA）：系统具备较高的无故障运行能力</h2><h3 id="可用性度量"><a href="#可用性度量" class="headerlink" title="可用性度量"></a>可用性度量</h3><ul><li>MTBF(Mean Time Between Failure)：平均故障间隔，即系统平均正常运行时间，越长越稳定</li><li>MTTR(Mean Time To Repair)：故障的平均恢复时间，即平均故障时间，越小对用户影响越小</li><li>Availability=MTBF/(MTBF+MTTR)：通过几个九描述系统可用性<br><img src="/2020/04/04/高并发设计/不同标准对应的故障时间.jpeg" alt="不同标准对应的故障时间"></li></ul><h3 id="高可用设计思路"><a href="#高可用设计思路" class="headerlink" title="高可用设计思路"></a>高可用设计思路</h3><h4 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h4><ul><li>Design for failure</li><li>故障转移（failover）</li><li>完全对等的节点：随机访问另一个节点即可</li><li>不对等的节点（主备）：需要选主操作</li><li>超时控制：收集系统之间的调用日志，统计比如99%响应时间，据此设置超时时间</li><li>降级：为了保证核心业务的稳定而牺牲非核心业务</li><li>限流：对并发请求进行限速</li></ul><h4 id="系统运维"><a href="#系统运维" class="headerlink" title="系统运维"></a>系统运维</h4><ul><li>灰度发布：系统变更不一次性推到线上，而是按比例逐步推进</li><li>故障演练：对系统进行一些破坏性手段，观察局部故障时系统的表现从而发现潜在问题（混沌工程）</li></ul><h3 id="扩展性"><a href="#扩展性" class="headerlink" title="扩展性"></a>扩展性</h3><h4 id="提升扩展性的复杂性"><a href="#提升扩展性的复杂性" class="headerlink" title="提升扩展性的复杂性"></a>提升扩展性的复杂性</h4><ul><li>处理核心增长和并行处理能力增长并非线性关系</li><li>数据库、缓存、依赖的第三方、负载均衡、交换机带宽会成为系统扩展的瓶颈</li></ul><h4 id="高可扩展的设计思路"><a href="#高可扩展的设计思路" class="headerlink" title="高可扩展的设计思路"></a>高可扩展的设计思路</h4><h5 id="拆分"><a href="#拆分" class="headerlink" title="拆分"></a>拆分</h5><blockquote><p>把复杂的系统拆分成独立具有单一职责的模块</p></blockquote><h6 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h6><ul><li>存储拆分考虑业务纬度</li><li>当业务拆分也达到单机极限时考虑按照数据特征做水平拆分（数据迁移成本极高，尽量一次性增加足够节点）</li><li>数据库拆分之后尽量不使用事务（超过一个数据库时涉及两阶段提交，协调各数据库成本极高）<br><img src="/2020/04/04/高并发设计/按照数据库业务拆分后的部署图.jpeg" alt="按照数据库业务拆分后的部署图"></li></ul><h5 id="业务层"><a href="#业务层" class="headerlink" title="业务层"></a>业务层</h5><ul><li>业务维度：相同业务拆分为单独业务池，每个业务依赖于自己的数据库资源（减少扩容复杂性）</li><li>重要性维度：将业务分为核心池和非核心池（优先保证核心池功能，降级非核心池功能以保证系统稳定性）</li><li>请求来源维度：根据接入客户端类型不同划分业务池<br><img src="/2020/04/04/高并发设计/业务池拆分示意图.jpeg" alt="业务池拆分示意图"><br><img src="/2020/04/04/高并发设计/关系池拆分示意图.jpeg" alt="关系池拆分示意图"></li></ul><h1 id="存储-1"><a href="#存储-1" class="headerlink" title="存储"></a>存储</h1><h2 id="池化技术"><a href="#池化技术" class="headerlink" title="池化技术"></a>池化技术</h2><blockquote><p>以空间换时间</p></blockquote><h3 id="原因：建立数据库连接耗时"><a href="#原因：建立数据库连接耗时" class="headerlink" title="原因：建立数据库连接耗时"></a>原因：建立数据库连接耗时</h3><ul><li>TCP三次握手</li><li>服务端校验密码<br><img src="/2020/04/04/高并发设计/数据库交互过程.jpeg" alt="数据库交互过程"></li></ul><h3 id="用连接池预先建立数据库连接"><a href="#用连接池预先建立数据库连接" class="headerlink" title="用连接池预先建立数据库连接"></a>用连接池预先建立数据库连接</h3><ul><li>最小连接数（10左右）</li><li>最大连接数（20～30左右）</li></ul><h4 id="检测连接是否可用"><a href="#检测连接是否可用" class="headerlink" title="检测连接是否可用"></a>检测连接是否可用</h4><ul><li>启用一个线程定期检测连接池中的连接是否可用（select 1）（推荐）</li><li>获取链接之后先校验连接是否可用（引入多余开销，测试使用）</li></ul><h3 id="用线程池预先创建线程：JDK1-5引入ThreadPoolExcutor"><a href="#用线程池预先创建线程：JDK1-5引入ThreadPoolExcutor" class="headerlink" title="用线程池预先创建线程：JDK1.5引入ThreadPoolExcutor"></a>用线程池预先创建线程：JDK1.5引入ThreadPoolExcutor</h3><h4 id="核心参数"><a href="#核心参数" class="headerlink" title="核心参数"></a>核心参数</h4><ul><li>coreThreadCount</li><li>maxThreadCount</li></ul><h4 id="适用场景与注意事项"><a href="#适用场景与注意事项" class="headerlink" title="适用场景与注意事项"></a>适用场景与注意事项</h4><ul><li>适用于CPU密集型的任务（创建相当于CPU核心数的线程）</li><li>需要监控线程池的等待队列</li><li>不能使用无界队列，否则导致任务不会被抛弃从而大量任务占据大量内存，引发full gc导致宕机<br><img src="/2020/04/04/高并发设计/JDK线程池提交任务示意图.jpeg" alt="JDK线程池提交任务示意图"></li></ul><h2 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h2><h3 id="主从读写分离"><a href="#主从读写分离" class="headerlink" title="主从读写分离"></a>主从读写分离</h3><p><img src="/2020/04/04/高并发设计/主从异步复制的过程.jpeg" alt="主从异步复制的过程"></p><ul><li>主从复制：从库过多导致主库资源消耗（一般挂3～5个从库即可）</li><li>数据冗余解决延迟问题（一次性发送所有数据而不是关键数据）</li><li>使用缓存（适合新增数据的场景）</li><li>查询主库（不推荐）</li></ul><p><strong>要关注主从延迟带来的问题（正常时间为毫秒级）</strong></p><p><img src="/2020/04/04/高并发设计/主从延迟影响示意图.jpeg" alt="主从延迟影响示意图"></p><h3 id="访问数据库的方式"><a href="#访问数据库的方式" class="headerlink" title="访问数据库的方式"></a>访问数据库的方式</h3><ul><li>TDDL(Taobao Distributed Data Layer)：以代码形式内嵌运行在应用程序内部/配置多个数据源（简单易用，无多余的部署成本）</li><li>单独部署的代理层方案：由代理层管理数据源，应用只需访问代理层（所有Sql都要跨两次网络</li></ul><p><img src="/2020/04/04/高并发设计/数据库代理层示意图.jpeg" alt="数据库代理层示意图"></p><p><strong>互联网优先考虑性能而不是强一致性</strong></p><p><img src="/2020/04/04/高并发设计/系统架构图_1.jpeg" alt="系统架构图_1"></p><h2 id="分库分表："><a href="#分库分表：" class="headerlink" title="分库分表："></a>分库分表：</h2><p><strong>4核8G云服务器MySQL5.7做benchmark可以支撑500TPS和10000QPS</strong></p><h3 id="垂直拆分"><a href="#垂直拆分" class="headerlink" title="垂直拆分"></a>垂直拆分</h3><ul><li>按照业务类型拆分，专库专用（无法解决单表过大的问题）</li></ul><h3 id="水平拆分"><a href="#水平拆分" class="headerlink" title="水平拆分"></a>水平拆分</h3><ul><li>将单一数据表按照规则拆分到多个数据库</li></ul><ol><li>按照某一个字段的hash值进行拆分（实体表，如用户表）</li><li>按照某一个字段的区间进行拆分（列表数据，如某一个人的订单）/需提前建好</li></ol><h3 id="引入的问题解决"><a href="#引入的问题解决" class="headerlink" title="引入的问题解决"></a>引入的问题解决</h3><ul><li>分区键：建立ID和查询字段的映射表（只有少数字段，也可以分库分表）</li><li>数据库特性难以实现：join、计数等操作（可以将计数记录在redis等缓存中）<br><img src="/2020/04/04/高并发设计/系统架构图_2.jpeg" alt="系统架构图_2"></li></ul><h2 id="分库分表后全局id唯一性保证："><a href="#分库分表后全局id唯一性保证：" class="headerlink" title="分库分表后全局id唯一性保证："></a>分库分表后全局id唯一性保证：</h2><h3 id="主键选择"><a href="#主键选择" class="headerlink" title="主键选择"></a>主键选择</h3><ul><li>业务字段（不适用）</li><li>使用生成的唯一ID</li></ul><h4 id="搭建发号器服务生成"><a href="#搭建发号器服务生成" class="headerlink" title="搭建发号器服务生成"></a>搭建发号器服务生成</h4><h5 id="UUID（不适合）"><a href="#UUID（不适合）" class="headerlink" title="UUID（不适合）"></a>UUID（不适合）</h5><h6 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h6><ul><li>性能好</li><li>不依赖于三方系统</li></ul><h6 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h6><ul><li>无序性</li><li>不具备业务含义</li><li>占用空间大（32个16进制数）</li></ul><h5 id="SnowFlake算法："><a href="#SnowFlake算法：" class="headerlink" title="SnowFlake算法："></a>SnowFlake算法：</h5><ul><li>ID单调递增能支持排序和提高写入性能</li><li>简单易实现</li><li>全局唯一性</li><li>包含一定的业务含义<br><img src="/2020/04/04/高并发设计/Snowflake算法示意图.jpeg" alt="Snowflake算法示意图"></li></ul><h3 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h3><ol><li><p>嵌入到业务代码，分布在业务服务器中</p><ul><li>优点：不需要跨网络调用</li><li>缺点：需要更多的机器id位来支持更多业务服务器（引入Zookeeper等分布一致性组件确保每次机器重启获得唯一的机器id）</li></ul></li><li><p>独立部署发号器服务</p></li></ol><ul><li>优点：<ul><li>减少机器码位数，留更多位给最后的自增信息位</li><li>因为机器位少或者是没有，可以将机器位写入配置文件而不用引入三方组件<br>*</li></ul></li><li>缺点：多一次网络调用</li></ul><h3 id="使用发号器的缺点"><a href="#使用发号器的缺点" class="headerlink" title="使用发号器的缺点"></a>使用发号器的缺点</h3><ul><li>依赖系统时间戳：发现系统时钟不准停止发号直至准确</li><li>请求发号器QPS不高，比如每毫秒一个会导致最后一位都为1，从而使分库分表分配不均</li></ul><h4 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h4><ul><li>时间戳记录到秒</li><li>生成器的起始序号做随机</li></ul><h2 id="数据库和NoSQL互补"><a href="#数据库和NoSQL互补" class="headerlink" title="数据库和NoSQL互补"></a>数据库和NoSQL互补</h2><h3 id="使用NoSQL的原因"><a href="#使用NoSQL的原因" class="headerlink" title="使用NoSQL的原因"></a>使用NoSQL的原因</h3><ul><li>弥补了传统数据库性能的不足</li><li>数据库变更方便，不需要更改原来的数据结构</li><li>适合互联网项目大数据量场景</li></ul><h3 id="使用NoSQL的作用"><a href="#使用NoSQL的作用" class="headerlink" title="使用NoSQL的作用"></a>使用NoSQL的作用</h3><ul><li>提升写入性能：随机写转换为顺序写，大多数使用基于LSM树的存储引擎，牺牲一定读性能来换取写性能的提升（HBase、Cassandra、LevelDB）</li><li>场景补充：为搜索建立倒排索引</li><li>提升扩展性：天生支持分布式，支持数据冗余和数据分片的特性<br><img src="/2020/04/04/高并发设计/LSM树示意图.jpeg" alt="LSM树示意图"><br><img src="/2020/04/04/高并发设计/MongoDB分片架构示意图.jpeg" alt="MongoDB分片架构示意图"><br><img src="/2020/04/04/高并发设计/系统架构图_3.jpeg" alt="系统架构图_3"></li></ul><h1 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h1><p><img src="/2020/04/04/高并发设计/存储的响应速度.jpeg" alt="存储的响应速度"></p><h2 id="缓存基础"><a href="#缓存基础" class="headerlink" title="缓存基础"></a>缓存基础</h2><h3 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h3><ul><li>Linux内存管理中的TLB组件</li><li>http缓存</li></ul><p><img src="/2020/04/04/高并发设计/HTTP缓存机制.jpeg" alt="HTTP缓存机制"></p><h3 id="缓存和缓冲区"><a href="#缓存和缓冲区" class="headerlink" title="缓存和缓冲区"></a>缓存和缓冲区</h3><div class="table-container"><table><thead><tr><th style="text-align:center">缓存</th><th style="text-align:center">缓冲区</th></tr></thead><tbody><tr><td style="text-align:center">空间换时间的优化手段</td><td style="text-align:center">临时存储数据的区域，类似于消息队列，数据最终要输入到其他地方</td></tr></tbody></table></div><p><img src="/2020/04/04/高并发设计/缓冲区机制.jpeg" alt="缓冲区机制"></p><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><ul><li>静态缓存：缓存静态资源</li><li>分布式缓存：缓存动态请求</li><li>热点本地缓存：极端热点数据查询</li></ul><h3 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h3><ul><li>适合读多写少，最好数据带有热点属性</li><li>给系统带来一定复杂度</li><li>有数据不一致风险</li><li>通常使用内存，但内存有限，成本高</li><li>带来运维成本</li></ul><h2 id="读写策略"><a href="#读写策略" class="headerlink" title="读写策略"></a>读写策略</h2><h3 id="Cache-Aside（旁路缓存）策略"><a href="#Cache-Aside（旁路缓存）策略" class="headerlink" title="Cache Aside（旁路缓存）策略"></a>Cache Aside（旁路缓存）策略</h3><ul><li>应同时变更数据库和缓存，否则会带来数据不一致</li><li>直接更新缓存会带来丢失更新的问题</li><li>同样存在数据不一致的可能，但由于写数据库比缓存慢，所以概率极小</li><li>写入频繁会导致缓存频繁清理，影响缓存命中率</li></ul><ol><li>更新数据时更新缓存，更新缓存前加一个分布式锁</li><li>更新数据时更新缓存，给缓存一个较短的过期时间</li></ol><h4 id="读策略"><a href="#读策略" class="headerlink" title="读策略"></a>读策略</h4><ol><li>从缓存读取数据</li><li>缓存命中则直接返回</li><li>缓存不命中则从数据库查询</li><li>查询到数据后将数据写入缓存并返回给用户</li></ol><h4 id="写策略"><a href="#写策略" class="headerlink" title="写策略"></a>写策略</h4><ol><li>更新数据库记录</li><li>删除缓存记录</li></ol><h3 id="Read-Write-Through（读穿-写穿策略）"><a href="#Read-Write-Through（读穿-写穿策略）" class="headerlink" title="Read/Write Through（读穿/写穿策略）"></a>Read/Write Through（读穿/写穿策略）</h3><ul><li>用户只与缓存打交道<br><img src="/2020/04/04/高并发设计/读穿写穿策略示意图.jpeg" alt="读穿写穿策略示意图"></li></ul><h4 id="write-through"><a href="#write-through" class="headerlink" title="write through"></a>write through</h4><ol><li>查询要写入的数据在缓存是否存在</li><li>存在则更新缓存，由缓存组件同步更新到数据库</li><li>缓存不存在则发生Write Miss</li></ol><ul><li>Write Allocate（按写分配）：写入缓存相应位置并由缓存组件同步更新到数据库</li><li>No-Write Allocate（不按写分配）：不写入缓存直接更新数据库（少一次缓存写入，常用）</li></ul><h4 id="Read-Through"><a href="#Read-Through" class="headerlink" title="Read Through"></a>Read Through</h4><ol><li>查询缓存数据是否存在</li><li>存在直接返回</li><li>不存在由缓存组件同步数据</li></ol><h3 id="Write-Back（写回）策略"><a href="#Write-Back（写回）策略" class="headerlink" title="Write Back（写回）策略"></a>Write Back（写回）策略</h3><blockquote><p>计算机体系中的设计，不能运用到常用的数据库和缓存场景</p></blockquote><h4 id="写策略-1"><a href="#写策略-1" class="headerlink" title="写策略"></a>写策略</h4><ol><li>写入数据时只写入缓存，把缓存块标记为脏</li><li>脏块再次被使用时将其中的数据写入后端<br><img src="/2020/04/04/高并发设计/WriteBack写策略示意图.jpeg" alt="WriteBack写策略示意图"></li></ol><h4 id="读策略-1"><a href="#读策略-1" class="headerlink" title="读策略"></a>读策略</h4><ol><li>缓存命中则返回</li><li>缓存不命中则寻找一个可用的缓存块</li><li>缓存块为脏则先将之前的数据写入后端，并从后端加载数据到缓存块</li><li>不是脏块则由缓存组件将后端数据加载到缓存，并设置为非脏并返回数据<br><img src="/2020/04/04/高并发设计/WriteBack读策略示意图.jpeg" alt="WriteBack读策略示意图"><br><img src="/2020/04/04/高并发设计/系统架构图_4.jpeg" alt="系统架构图_4"></li></ol><h2 id="缓存的高可用"><a href="#缓存的高可用" class="headerlink" title="缓存的高可用"></a>缓存的高可用</h2><h3 id="客户端方案"><a href="#客户端方案" class="headerlink" title="客户端方案"></a>客户端方案</h3><blockquote><p>客户端配置多个缓存节点，通过缓存写入和读取算法策略实现分布式，提高可用性</p></blockquote><ul><li>写入数据时要进行数据分片</li><li>读数据利用多组缓存做容错提升可用性</li></ul><h4 id="如何分片"><a href="#如何分片" class="headerlink" title="如何分片"></a>如何分片</h4><ul><li>hash分片：对缓存的key做hash算法，然后对总的缓存节点个数取余（节点数目变化造成缓存不可用，降低命中率，最好有另外一层缓存兜底）<br><img src="/2020/04/04/高并发设计/Hash分片算法示意图.jpeg" alt="Hash分片算法示意图"></li><li>一致性hash分片：将hash值的空间组织成一个圆环，将节点做hash后放在圆环上，对key做同样的hash然后在圆环上找到顺时针方向碰到的第一个节点（解决节点数目变化带来的问题）（缓存节点分布不均会导致部分节点压力过大）（脏数据问题）<br><img src="/2020/04/04/高并发设计/一致性Hash算法示意图.jpeg" alt="一致性Hash算法示意图"><br><img src="/2020/04/04/高并发设计/一致性Hash算法增加和删除缓存节点是的缓存节点变化.jpeg" alt="一致性Hash算法增加和删除缓存节点是的缓存节点变化"><blockquote><p>脏数据：节点掉线后又恢复（设置缓存过期时间解决）</p></blockquote></li></ul><p><img src="/2020/04/04/高并发设计/一致性Hash脏数据问题.jpeg" alt="一致性Hash脏数据问题"></p><h4 id="主从机制（能解决大多数场景）"><a href="#主从机制（能解决大多数场景）" class="headerlink" title="主从机制（能解决大多数场景）"></a>主从机制（能解决大多数场景）</h4><ul><li>每一组master配置一组slave</li><li>优先从slave读数据</li><li>读取不到则穿透到master并将数据回种到slave</li></ul><blockquote><p>slave宕机有master兜底</p></blockquote><p><img src="/2020/04/04/高并发设计/主从部署模式.jpeg" alt="主从部署模式"></p><h4 id="多副本"><a href="#多副本" class="headerlink" title="多副本"></a>多副本</h4><ul><li>在master/slave之间增加一个副本层</li><li>先选择一个副本组进行查询</li><li>失败则查询master/slave，然后回种到副本组</li></ul><h5 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h5><ul><li>极端流量场景，slave网卡成为瓶颈</li><li>副本组要比master/slave小，只存储更热的数据<br><img src="/2020/04/04/高并发设计/多副本部署模式.jpeg" alt="多副本部署模式"></li></ul><h4 id="中间代理层方案"><a href="#中间代理层方案" class="headerlink" title="中间代理层方案"></a>中间代理层方案</h4><ul><li>在应用代码和缓存节点之间增加代理层，客户端所有写入读取请求都通过代理层，代理层内置高可用策略提高缓存系统可用性</li><li>通过通用协议实现多语言复用<br><img src="/2020/04/04/高并发设计/中间代理层方案示意图.jpeg" alt="中间代理层方案示意图"></li></ul><h3 id="服务端方案"><a href="#服务端方案" class="headerlink" title="服务端方案"></a>服务端方案</h3><h4 id="Redis-Sentinel方案-gt-2-4"><a href="#Redis-Sentinel方案-gt-2-4" class="headerlink" title="Redis Sentinel方案(&gt;2.4)"></a>Redis Sentinel方案(&gt;2.4)</h4><blockquote><p>主节点挂了之后自动将从节点提升为主节点</p></blockquote><ol><li>配置master地址，监控master状态</li><li>master一段时间无反应则认为挂了，选取一个从节点提升为主节点</li><li>把所有其他从节点设置为新主的从节点<br><img src="/2020/04/04/高并发设计/RedisSentinel部署架构图.jpeg" alt="RedisSentinel部署架构图"></li></ol><h2 id="缓存穿透解决"><a href="#缓存穿透解决" class="headerlink" title="缓存穿透解决"></a>缓存穿透解决</h2><ul><li>缓存中查不到数据而不得不从后端查询</li><li>核心缓存命中率要保持99%以上，非核心缓存的命中率要保持90%以上</li><li>少量穿透无害，大量穿透会压垮后端</li></ul><h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><ul><li>互联网数据量大而缓存有限，无法存储所有数据</li><li>28原则，经常访问的是20%的数据，剩下80%不常访问</li></ul><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ul><li>回种空值：数据库查询到为空值时会发生异常时向缓存回种一个空值，并设置一个较短的过期时间（如果大量空值请求会使缓存中空值占用大量空间而使正常数据穿透，需评估缓存容量）</li><li><p>布隆过滤器：使用hash算法将元素映射到数组，查询元素使用相同的hash算法（因为hash碰撞会把不是集合中的元素判断为集合中，不支持删除元素）（其false positive的特性尤其适合缓存穿透：判断不在则一定不在）（使用多个hash，删除可以通过打标实现）<br><img src="/2020/04/04/高并发设计/布隆过滤器示意图.jpeg" alt="布隆过滤器示意图"><br><img src="/2020/04/04/高并发设计/用户查询场景使用布隆过滤器示意图.jpeg" alt="用户查询场景使用布隆过滤器示意图"></p></li><li><p>狗桩效应：极热数据失效导致大量穿透</p></li></ul><ol><li>启动后台线程从数据库加载数据到缓存，未加载之前直接返回不穿透</li><li>通过Memcached或Redis设置分布式锁，未获取锁的不允许穿透<br><img src="/2020/04/04/高并发设计/系统架构图_5.jpeg" alt="系统架构图_5"></li></ol><h2 id="CDN静态资源加速"><a href="#CDN静态资源加速" class="headerlink" title="CDN静态资源加速"></a>CDN静态资源加速</h2><ul><li>就近访问</li><li>CDN：将静态资源分发到位于多个地理位置机房的服务器上</li></ul><h3 id="如何让请求到达CDN节点"><a href="#如何让请求到达CDN节点" class="headerlink" title="如何让请求到达CDN节点"></a>如何让请求到达CDN节点</h3><ul><li>通过DNS解析映射节点域名和实际ip</li><li>DNS解析性能问题（向上多次查询）<blockquote><p>启动时对要解析的域名做预解析，把解析结果存放在本地LRU缓存中</p></blockquote></li></ul><p><img src="/2020/04/04/高并发设计/DNS本地缓存示意图.jpeg" alt="DNS本地缓存示意图"></p><h3 id="如何找到离用户最近的CDN节点"><a href="#如何找到离用户最近的CDN节点" class="headerlink" title="如何找到离用户最近的CDN节点"></a>如何找到离用户最近的CDN节点</h3><p>GSLB（Global Server Load Balance，全局负载均衡）：对于部署在不同地域的服务器之间做负载均衡</p><ul><li>是一种负载均衡服务器，让流量平均分配是下面管理的服务器负载更均衡</li><li>需要保证流量流经的服务与流量源头在边缘上比较接近<br><img src="/2020/04/04/高并发设计/CDN域名解析示意图.jpeg" alt="CDN域名解析示意图"></li></ul><h2 id="数据迁移"><a href="#数据迁移" class="headerlink" title="数据迁移"></a>数据迁移</h2><h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><ul><li>在线迁移</li><li>保证数据完整性</li><li>迁移过程中能回滚</li></ul><h3 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h3><h4 id="双写"><a href="#双写" class="headerlink" title="双写"></a>双写</h4><ol><li>将新库配置为源库的从库</li><li>改造业务代码，要同时写入新库和旧库，写入新库失败的日志单独记录，方便恢复数据</li><li>数据校验（全量过多可抽样检验）</li><li>读流量切换到新库（全量切换可能有未知影响，可灰度发布）</li><li>存在任何问题可切换到旧库</li><li>确认无问题后将双写改为只写新库<br><img src="/2020/04/04/高并发设计/双写迁移方案示意图.jpeg" alt="双写迁移方案示意图"></li></ol><h5 id="考虑"><a href="#考虑" class="headerlink" title="考虑"></a>考虑</h5><ul><li>在迁移之前写好数据校验工具或脚本，做充分测试</li><li>自建机房到云需考虑网络延迟和带宽</li><li>迁移过程随时可回滚，风险最低；时间周期长，有改造成本<br><img src="/2020/04/04/高并发设计/数据从自建机房迁移到云上的方案.jpeg" alt="数据从自建机房迁移到云上的方案"></li></ul><h4 id="级联同步（适合自建机房到云）"><a href="#级联同步（适合自建机房到云）" class="headerlink" title="级联同步（适合自建机房到云）"></a>级联同步（适合自建机房到云）</h4><blockquote><p>简单易施，无改造成本；切换写需暂停业务</p></blockquote><ol><li>新库配置为旧库从库，用作数据同步</li><li>新增备库为新库从库，用作数据备份</li><li>同时写入三个库待数据一致则切换读流量到新库</li><li>暂停业务写入，将写流量切换到新库（需选低峰期）</li></ol><p><img src="/2020/04/04/高并发设计/级联迁移方案示意图.jpeg" alt="级联迁移方案示意图"><br><img src="/2020/04/04/高并发设计/级联迁移方案回滚示意图.jpeg" alt="级联迁移方案回滚示意图"></p><h4 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h4><blockquote><p>缓存迁移的重点是保持缓存热度</p></blockquote><h5 id="使用副本组预热缓存"><a href="#使用副本组预热缓存" class="headerlink" title="使用副本组预热缓存"></a>使用副本组预热缓存</h5><ul><li>在云端布置一个副本组</li><li>云上的副本组足够热之后（命中率&gt;90%）将云上机房的缓存服务器指向该组（云上请求发生穿透会存在跨专线访问数据库的问题）<br><img src="/2020/04/04/高并发设计/副本组迁移方案示意图.jpeg" alt="副本组迁移方案示意图"></li></ul><h5 id="改造云上副本组"><a href="#改造云上副本组" class="headerlink" title="改造云上副本组"></a>改造云上副本组</h5><ul><li>云上部署多组副本组，自建机房写入请求优先写入自建机房缓存节点，异步写入云上节点</li><li>指定部分流量走云上（比如10%），使穿透可控</li><li>云上缓存命中率达90%后在云上部署应用服务器，云上的应用服务器走云上节点<br><img src="/2020/04/04/高并发设计/改进后的副本组迁移方案示意图.jpeg" alt="改进后的副本组迁移方案示意图"></li></ul><h1 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h1><h2 id="秒杀场景"><a href="#秒杀场景" class="headerlink" title="秒杀场景"></a>秒杀场景</h2><h3 id="读请求过高："><a href="#读请求过高：" class="headerlink" title="读请求过高："></a>读请求过高：</h3><ul><li>热点数据使用缓存策略</li><li>能静态化的尽量静态化</li><li>限流策略（对同一个请求做丢弃处理）</li></ul><h3 id="写请求过高"><a href="#写请求过高" class="headerlink" title="写请求过高"></a>写请求过高</h3><h4 id="消息队列-1"><a href="#消息队列-1" class="headerlink" title="消息队列"></a>消息队列</h4><blockquote><p>平衡低速系统和高速系统处理任务的时间差</p></blockquote><ul><li>削峰填谷</li><li>异步处理</li><li>系统模块之间松耦合<br><img src="/2020/04/04/高并发设计/系统解耦合示意图.jpeg" alt="系统解耦合示意图"><br><img src="/2020/04/04/高并发设计/削峰在秒杀活动中的应用.jpeg" alt="削峰在秒杀活动中的应用"><br><img src="/2020/04/04/高并发设计/系统架构图_6.jpeg" alt="系统架构图_6"></li></ul><h2 id="消息投递"><a href="#消息投递" class="headerlink" title="消息投递"></a>消息投递</h2><h3 id="消息丢失"><a href="#消息丢失" class="headerlink" title="消息丢失"></a>消息丢失</h3><p><img src="/2020/04/04/高并发设计/消息丢失示意图.jpeg" alt="消息丢失示意图"></p><ul><li>生产过程中丢失：网络抖动导致消息生产超时（重传2～3次）（有重复的风险）</li><li>消息队列中丢失：消息队列意外未刷盘（消息队列部署集群方式保证多个副本）</li><li>有一定容忍度：不建议集群</li><li>消费过程中丢失：消息消费时由于业务异常导致未执行完成（接受和处理完消息后再更新消息进度）<br><img src="/2020/04/04/高并发设计/消息刷盘示意图.jpeg" alt="消息刷盘示意图"><br><img src="/2020/04/04/高并发设计/Kafka复制示意图.jpeg" alt="Kafka复制示意图"></li></ul><h3 id="消息只被消费一次"><a href="#消息只被消费一次" class="headerlink" title="消息只被消费一次"></a>消息只被消费一次</h3><ul><li>在生产消费中增加冥等性保证：每条消息生成唯一id，消费时比对id</li><li>事务机制：避免过程中掉电宕机等异常（成本高、一般不考虑）</li><li>使用乐观锁：在数据中增加一个版本号，更新时带上版本号查询并更新版本号，则相同的版本号的重复数据将不会更新<br><img src="/2020/04/04/高并发设计/ProducerIdempotency示意图.jpeg" alt="ProducerIdempotency示意图"></li></ul><h2 id="消息延迟"><a href="#消息延迟" class="headerlink" title="消息延迟"></a>消息延迟</h2><h3 id="监控消息延迟"><a href="#监控消息延迟" class="headerlink" title="监控消息延迟"></a>监控消息延迟</h3><ul><li>使用消息队列自带的工具监控（JMX和kafka-consumer-groups.sh）</li><li>生成监控消息的方式监控：循环写入一个内容为消息生成时间的特殊消息，比对消息消费时间和生成时间的差值<blockquote><p>两种结合使用效果更佳</p></blockquote></li></ul><p><img src="/2020/04/04/高并发设计/消息监控程序示意图.jpeg" alt="消息监控程序示意图"></p><h3 id="减少延迟"><a href="#减少延迟" class="headerlink" title="减少延迟"></a>减少延迟</h3><h3 id="消费端"><a href="#消费端" class="headerlink" title="消费端"></a>消费端</h3><ul><li>优化消费代码提升性能</li><li>增加消费者数量</li></ul><h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><ul><li>kafka创建多个分区：Kafka一个分区只能有一个消费者，所以增加消费者无用<br><img src="/2020/04/04/高并发设计/Kafka消费示意图.jpeg" alt="Kafka消费示意图"></li><li>消费者使用多线程并行异步处理，可以一次性多拉取几条消息（注意线程空转的问题，可在拉取不到消息时使线程暂停10～100ms）<br><img src="/2020/04/04/高并发设计/多线程消费队列示意图.jpeg" alt="多线程消费队列示意图"></li></ul><h3 id="消息队列-2"><a href="#消息队列-2" class="headerlink" title="消息队列"></a>消息队列</h3><ul><li>选择高性能存储方式：比如使用本地磁盘的pagecache</li><li>配合零拷贝技术：sendfile减少数据被拷贝次数<br><img src="/2020/04/04/高并发设计/数据从磁盘写入网络的过程.jpeg" alt="数据从磁盘写入网络的过程"><br><img src="/2020/04/04/高并发设计/使用Sendfile后数据拷贝过程.jpeg" alt="使用Sendfile后数据拷贝过程"></li></ul><h1 id="分布式服务"><a href="#分布式服务" class="headerlink" title="分布式服务"></a>分布式服务</h1><h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><h3 id="一体化架构（项目初期）"><a href="#一体化架构（项目初期）" class="headerlink" title="一体化架构（项目初期）"></a>一体化架构（项目初期）</h3><h4 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h4><ul><li>开发简单直接，项目和代码集中管理</li><li>只需维护一个工程，维护人力成本低</li><li>排查问题只需排查一个应用，目标性强</li></ul><h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h4><ul><li>数据库连接成为瓶颈</li><li>增加研发成本，抑制了研发效率提升</li><li>代码过多构建耗时<br><img src="/2020/04/04/高并发设计/一体化架构分业务池部署示意图.jpeg" alt="一体化架构分业务池部署示意图"></li></ul><h3 id="微服务化"><a href="#微服务化" class="headerlink" title="微服务化"></a>微服务化</h3><ul><li>按照业务做横向拆分，解决数据库层面的扩展性</li><li>将业务无关功能下沉为单独服务<br><img src="/2020/04/04/高并发设计/服务化部署示意图.jpeg" alt="服务化部署示意图"><br><img src="/2020/04/04/高并发设计/系统架构图_7.jpeg" alt="系统架构图_7"></li></ul><h2 id="构造微服务"><a href="#构造微服务" class="headerlink" title="构造微服务"></a>构造微服务</h2><h3 id="服务拆分原则"><a href="#服务拆分原则" class="headerlink" title="服务拆分原则"></a>服务拆分原则</h3><ul><li>单一服务高内聚低耦合</li><li>拆分粒度：先粗略拆分再逐渐细化</li><li>服务接口定义需有扩展性</li><li>避免影响产品日常迭代</li></ul><h4 id="方式"><a href="#方式" class="headerlink" title="方式"></a>方式</h4><ul><li>优先剥离独立的边界服务</li><li>优先剥离被依赖的服务</li></ul><h3 id="微服务化的问题"><a href="#微服务化的问题" class="headerlink" title="微服务化的问题"></a>微服务化的问题</h3><ul><li>服务调用接口从跨进程到跨网络，需要引入服务注册中心</li><li>多个服务有错综复杂的依赖关系：被依赖的服务出问题导致整个依赖链故障（熔断、降级、限流、超时控制）</li><li>链路上故障难以排查（引入分布式追踪工具、更细致的服务端监控报表）</li></ul><h2 id="RPC框架"><a href="#RPC框架" class="headerlink" title="RPC框架"></a>RPC框架</h2><h3 id="提升网络传输性能"><a href="#提升网络传输性能" class="headerlink" title="提升网络传输性能"></a>提升网络传输性能</h3><h4 id="高性能IO模型"><a href="#高性能IO模型" class="headerlink" title="高性能IO模型"></a>高性能IO模型</h4><ul><li>同步阻塞I/O</li><li>同步非阻塞I/O</li><li>同步多路I/O复用（推荐）</li><li>信号驱动I/O</li><li>异步I/O</li></ul><blockquote><p>网络参数调优：比如强交互场景socket开启tcp_nodelay，使包发送不用等待/设置接受缓冲区和发送缓冲区大小</p></blockquote><p><img src="/2020/04/04/高并发设计/网络调用示意图.jpeg" alt="网络调用示意图"></p><h3 id="选择合适的序列化方法"><a href="#选择合适的序列化方法" class="headerlink" title="选择合适的序列化方法"></a>选择合适的序列化方法</h3><h4 id="考虑因素"><a href="#考虑因素" class="headerlink" title="考虑因素"></a>考虑因素</h4><ul><li>时间性能</li><li>空间性能：过大的二进制串占据传输带宽影响效率</li><li>跨语言跨平台</li><li>扩展性</li></ul><h4 id="序列化备选方案"><a href="#序列化备选方案" class="headerlink" title="序列化备选方案"></a>序列化备选方案</h4><ul><li>JSON：简单易用、可读（性能要求不高，数据占用带宽不大的情况下选用）</li><li>Thrift：Facebook开源的高性能序列化协议，时间空间上都有较高性能（有配套RPC框架，性能要求高并需要一体化解决方案选用）</li><li>Protobuf：谷歌开源的序列化协议（性能要求高、存储的数据占用空间大选用）</li></ul><blockquote><p>Thrift和Protobuf 引入IDL(Interface Description language)，通过特定编译器转换成各语言对应的代码实现跨语言（IDL的存在带来使用上的不便）</p></blockquote><p><img src="/2020/04/04/高并发设计/RPC调用过程图.jpeg" alt="RPC调用过程图"></p><h2 id="注册中心"><a href="#注册中心" class="headerlink" title="注册中心"></a>注册中心</h2><ul><li>不重启客户端变更服务节点</li><li>实现优雅关闭：先停流量再停服务<br><img src="/2020/04/04/高并发设计/RPC通信过程图.jpeg" alt="RPC通信过程图"></li></ul><h3 id="服务状态管理"><a href="#服务状态管理" class="headerlink" title="服务状态管理"></a>服务状态管理</h3><ul><li><p>主动探测：注册中心每隔一段时间RPC服务暴露的端口是否可用<br><img src="/2020/04/04/高并发设计/主动探测方式.jpeg" alt="主动探测方式"></p></li><li><p>心跳模式：RPC服务每隔一段时间向注册中心发送心跳<br><img src="/2020/04/04/高并发设计/心跳机制示意图.jpeg" alt="心跳机制示意图"></p></li><li>避免服务过度摘除：达到一定阈值停止摘除并触发告警</li><li>通知风暴：控制注册中心管理集群的规模/扩容注册中心节点<br><img src="/2020/04/04/高并发设计/混合云部署图.jpeg" alt="混合云部署图"></li></ul><p><img src="/2020/04/04/高并发设计/系统架构图_8.jpeg" alt="系统架构图_8"></p><h2 id="分布式TRACE"><a href="#分布式TRACE" class="headerlink" title="分布式TRACE"></a>分布式TRACE</h2><h3 id="一体化架构慢请求排查"><a href="#一体化架构慢请求排查" class="headerlink" title="一体化架构慢请求排查"></a>一体化架构慢请求排查</h3><ol><li>使用requestID跟踪调用链</li><li>使用静态代理的方式实现切面编程打印调用日志（静态代理AspectJ比动态代理Spring AOP性能好一些）</li><li>增加日志采样率而不是全量打印</li><li>把日志打印到消息队列而不是本地文件（解决需要登录到服务器查看日志的问题）<br><img src="/2020/04/04/高并发设计/排查程序架构图.jpeg" alt="排查程序架构图"></li></ol><h3 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h3><ul><li>traceId（requestId）+spanId（记录rpc调用）（spanid和tranceId在线程上下文获取，然后生成本次rpc调用的spanId，再将tranceId和本次调用spanId序列化发送给服务方）<br><img src="/2020/04/04/高并发设计/RPC调用关系图.jpeg" alt="RPC调用关系图"></li></ul><h4 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h4><ul><li>开源组件选择较低采样率，观察系统性能后再调整到合适数值（Zipkin/Jaeger）</li><li>自研避坑可提供开关控制打印日志时间</li></ul><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><h3 id="负载均衡服务器分类"><a href="#负载均衡服务器分类" class="headerlink" title="负载均衡服务器分类"></a>负载均衡服务器分类</h3><h4 id="代理类负载均衡服务"><a href="#代理类负载均衡服务" class="headerlink" title="代理类负载均衡服务"></a>代理类负载均衡服务</h4><ul><li>以单独的服务方式部署，所有请求都经过负载均衡服务器，在负载均衡服务中选择一个合适的服务节点，由负载均衡服务调用这个服务节点来实现流量分发</li><li>需承担全部流量，性能要求高</li></ul><h5 id="方式-1"><a href="#方式-1" class="headerlink" title="方式"></a>方式</h5><ul><li>LVS：在OSI模型的第四层传输层工作，又称四层负载</li><li>Nginx：在OSI模型的第七层应用层工作，又称七层负载</li></ul><h5 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h5><ul><li>在入口处部署LVS将流量分发到多个Nginx服务器上，再由Nginx服务器分发到应用服务器上</li><li>QPS未超过10万不建议引入LVS</li><li>适用于普通Web服务，不适用于微服务（服务节点存储在注册中心，LVS很难拿到，微服务之间使用RPC而不是Http，Nginx很难满足）</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">LVS</th><th style="text-align:center">Nginx</th></tr></thead><tbody><tr><td style="text-align:center">做请求包转发，客户端和后端直接建立连接，后续不再经过LVS服务器，性能高</td><td style="text-align:center">性能相比而言会差一些，但也能承担每秒几万次的请求</td></tr><tr><td style="text-align:center">由于在第四层，所以不能针对URL做更细致的请求分发</td><td style="text-align:center">配置上更加灵活，还能感知后端服务是否出现问题</td></tr></tbody></table></div><p><img src="/2020/04/04/高并发设计/代理负载均衡服务示意图.jpeg" alt="代理负载均衡服务示意图"></p><h4 id="客户端负载均衡服务"><a href="#客户端负载均衡服务" class="headerlink" title="客户端负载均衡服务"></a>客户端负载均衡服务</h4><blockquote><p>将负载均衡的服务内嵌在RPC客户端中</p></blockquote><ul><li>和客户端部署在同一个进程</li><li>结合注册中心使用，注册中心提供服务节点的完整列表</li><li>客户端拿到列表后使用负载均衡服务的策略选取一个合适的节点发送请求</li></ul><p><img src="/2020/04/04/高并发设计/客户端负载均衡服务示意图.jpeg" alt="客户端负载均衡服务示意图"></p><h3 id="负载均衡策略"><a href="#负载均衡策略" class="headerlink" title="负载均衡策略"></a>负载均衡策略</h3><h4 id="静态策略"><a href="#静态策略" class="headerlink" title="静态策略"></a>静态策略</h4><blockquote><p>选择服务节点时不参考后端服务的实际运行情况</p></blockquote><ul><li>轮询（RoundRobin，RR）：记录上次请求后端服务的地址或序号，在请求时按照服务列表的顺序，请求下一个后端服务节点（平均分配流量到所有负载节点，未考虑服务配置，无法发挥性能）</li><li>带权重的轮询：给节点加上权重值，解决轮询的问题</li><li>Nginx：ip_hash和url_hash</li><li>LVS：请求源地址和目标地址hash</li><li>Dubbo：一致性hash和随机选取</li></ul><p><strong>优先考虑轮询和带权重轮询（Nginx优先使用轮询）</strong></p><h4 id="动态策略"><a href="#动态策略" class="headerlink" title="动态策略"></a>动态策略</h4><blockquote><p>依据后端服务的一些负载特性来决定选取哪一个节点（优先使用）</p></blockquote><ul><li>选取负载最小、资源最空闲的服务来调用</li><li>Dubbo的LeastActive策略：优先选择活跃连接数最少的服务</li><li>Spring Cloud 中Ribbon 提供的WeightedResponseTimeRule：是使用响应时间给每个服务节点计算一个权重，然后依据这个权重，来给调用方分配服务节点</li></ul><h3 id="检测节点可用性"><a href="#检测节点可用性" class="headerlink" title="检测节点可用性"></a>检测节点可用性</h3><ul><li>淘宝开源的 Nginx 模块nginx_upstream_check_module：定期探测后端服务的一个指定接口，根据返回状态码判断是否存活，不存活次数达到阈值则从负载均衡服务器中摘除这个服务</li><li>节点检测能帮助实现优雅关闭</li></ul><h4 id="优雅关闭流程"><a href="#优雅关闭流程" class="headerlink" title="优雅关闭流程"></a>优雅关闭流程</h4><ol><li>服务刚启动时初始化默认的Http状态码为500，Nginx认为服务不可用，则能等待服务依赖的资源加载完成，避免服务初始启动的波动</li><li>完成初始化后状态码改为200，Nginx两次探测后就能标示为可用</li><li>服务关闭时先把状态码改为500，等待Nginx探测为不可用后，流量将不会发往该节点</li><li>等待服务处理完所有请求后重启服务</li></ol><h2 id="API网关"><a href="#API网关" class="headerlink" title="API网关"></a>API网关</h2><blockquote><p>api网关是一种架构模式，它将一些服务共有的功能整合在一起独立部署成单独的一层，来解决一些服务治理的问题</p></blockquote><h3 id="分类-1"><a href="#分类-1" class="headerlink" title="分类"></a>分类</h3><h4 id="入口网关"><a href="#入口网关" class="headerlink" title="入口网关"></a>入口网关</h4><blockquote><p>部署在负载均衡服务器和应用服务器之间</p></blockquote><ul><li>提供客户端一个统一接入地址，将用户请求动态路由到不同的业务服务，并且做一些必要的协议转换</li><li>植入一些服务治理的策略（熔断、降级、流量控制、分流等）</li><li>客户端的认证和鉴权</li><li>做黑白名单</li><li>请求日志记录</li></ul><p><img src="/2020/04/04/高并发设计/入口网关示意图.jpeg" alt="入口网关示意图"></p><h4 id="出口网关"><a href="#出口网关" class="headerlink" title="出口网关"></a>出口网关</h4><blockquote><p>应用服务器和第三方系统之间</p></blockquote><ul><li>对调用外部的API做统一的认证、授权以及控制访问</li></ul><p><img src="/2020/04/04/高并发设计/出口网关示意图.jpeg" alt="出口网关示意图"></p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><ul><li>考虑性能（首要任务，关键在于I/O模型）</li><li>扩展性：将每一个操作定义成filter，使用责任链模式将filter串起，责任链可以动态组织filter，实现解耦，方便动态增删</li><li>使用线程池并行执行请求：防止线程阻塞，需针对不同的服务做线程隔离或保护</li></ul><h4 id="线程池使用方式"><a href="#线程池使用方式" class="headerlink" title="线程池使用方式"></a>线程池使用方式</h4><ul><li>后端服务多，针对不同服务采用不同线程池</li><li>线程池内部针对不同服务甚至不同接口做线程保护（比如设置每个服务最多使用线程数）</li></ul><h4 id="开源组件"><a href="#开源组件" class="headerlink" title="开源组件"></a>开源组件</h4><ul><li>Kong：运行在Nginx的Lua程序</li><li>Zuul：Spring全家桶成员</li><li>Tyk：Go实现的轻量网关</li></ul><h3 id="引入网关"><a href="#引入网关" class="headerlink" title="引入网关"></a>引入网关</h3><ul><li>将API网关从Web层独立出来：将协议转换、限流、黑白名单等事情挪到 API 网关中来处理，形成独立的入口网关层</li><li>服务接口数据聚合</li></ul><h4 id="服务接口数据聚合"><a href="#服务接口数据聚合" class="headerlink" title="服务接口数据聚合"></a>服务接口数据聚合</h4><ul><li>再独立一组网关做服务聚合、超时控制（前一种为流量网关，此种为业务网关）</li><li>抽取独立的服务层，专门做接口聚合的操作（接口数据聚合是业务操作，推荐这个方案）</li></ul><p><img src="/2020/04/04/高并发设计/网关部署示意图.jpeg" alt="网关部署示意图"><br><img src="/2020/04/04/高并发设计/系统架构图_9.jpeg" alt="系统架构图_9"></p><h2 id="多机房部署"><a href="#多机房部署" class="headerlink" title="多机房部署"></a>多机房部署</h2><blockquote><p>在不同的IDC机房中部署多套服务，这些服务共享同一套业务数据并都可以承接来自用户的流量</p></blockquote><h3 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h3><ul><li>延迟：同地双机房1～3ms/国内异地双机房50ms/国际双机房100～200ms</li></ul><p><img src="/2020/04/04/高并发设计/跨机房读取数据示意图_1.jpeg" alt="跨机房读取数据示意图_1"><br><img src="/2020/04/04/高并发设计/跨机房读取数据示意图_2.jpeg" alt="跨机房读取数据示意图_2"></p><h3 id="逐步迭代多机房部署方案"><a href="#逐步迭代多机房部署方案" class="headerlink" title="逐步迭代多机房部署方案"></a>逐步迭代多机房部署方案</h3><blockquote><p>数据读取和服务调用尽量保持在同一个机房内</p></blockquote><ul><li><p>同城双活：机房级别容灾，无法做到城市级别容灾（复杂度低，延迟低）<br><img src="/2020/04/04/高并发设计/同城双活示意图.jpeg" alt="同城双活示意图"></p></li><li><p>异地多活：城市级别容灾（可用性高）</p></li></ul><h4 id="异地多活"><a href="#异地多活" class="headerlink" title="异地多活"></a>异地多活</h4><h5 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h5><ul><li>基于存储系统的主从复制</li><li>基于消息队列的方式</li></ul><p><img src="/2020/04/04/高并发设计/基于消息队列的方式.jpeg" alt="基于消息队列的方式"></p><h2 id="服务治理"><a href="#服务治理" class="headerlink" title="服务治理"></a>服务治理</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><ul><li>数据平面：负责数据传输，</li><li>控制平面：控制服务治理策略的植入</li></ul><p><strong>出于性能考虑会将服务治理策略植入到数据平面，控制平面负责服务治理策略数据的下发</strong></p><h3 id="方式-2"><a href="#方式-2" class="headerlink" title="方式"></a>方式</h3><ul><li>Istio：将组件分为数据平面和控制平面，数据平面即为sidecar，控制平面负责服务治理策略执行（每次请求都要通过控制平面，性能存在瓶颈）</li></ul><p><img src="/2020/04/04/高并发设计/Istio架构示意图.jpeg" alt="Istio架构示意图"></p><ul><li>sidecar</li></ul><h4 id="sidecar"><a href="#sidecar" class="headerlink" title="sidecar"></a>sidecar</h4><ul><li><p>iptables：使用Linux内核防火墙软件的管理工具，Istio默认使用（对业务完全透明，高并发下有性能损耗）<br><img src="/2020/04/04/高并发设计/流入流量示意图.jpeg" alt="流入流量示意图"><br><img src="/2020/04/04/高并发设计/流出流量示意图.jpeg" alt="流出流量示意图"></p></li><li><p>轻量级客户端：在RPC客户端配置sidecar的部署端口，通过轻量级客户端将调用服务的请求发送给sidecar（建议）<br><img src="/2020/04/04/高并发设计/轻量客户端示意图.jpeg" alt="轻量客户端示意图"></p></li><li><p>Cilium：从socket层面转发，避免iptables的损耗</p></li></ul><h4 id="开源框架"><a href="#开源框架" class="headerlink" title="开源框架"></a>开源框架</h4><ul><li>Istio</li><li>Linkerd</li><li>SOFAMesh</li></ul><h1 id="维护"><a href="#维护" class="headerlink" title="维护"></a>维护</h1><h2 id="系统监控"><a href="#系统监控" class="headerlink" title="系统监控"></a>系统监控</h2><h3 id="监控指标"><a href="#监控指标" class="headerlink" title="监控指标"></a>监控指标</h3><ul><li>延迟：请求的响应时间（接口、数据库、缓存）</li><li>通信量：即吞吐量，单位时间内请求量的大小</li><li>错误：当前发生的系统错误数（4<strong>、5</strong>和代码业务出错）</li><li>饱和度：服务或资源到达上限的程度（CPU使用率、内存使用率等）</li></ul><p><img src="/2020/04/04/高并发设计/监控指标.jpeg" alt="监控指标"></p><h3 id="采集"><a href="#采集" class="headerlink" title="采集"></a>采集</h3><ul><li>Agent：在数据源的服务器上部署自研或者开源的 Agent 来收集收据，发送给监控系统</li><li>埋点：面向切面实现或在资源客户端中直接计算调用资源或者服务的耗时、调用量、慢请求数，并且发送给监控服务器（先对埋点做汇总，避免过高请求量到达监控）</li><li>日志：Tomcat和Nginx日志，通过日志采集工具发送到监控服务器（Apache Flume、Fluentd和Filebeat）</li></ul><h3 id="处理和存储"><a href="#处理和存储" class="headerlink" title="处理和存储"></a>处理和存储</h3><h4 id="消息队列（两个）"><a href="#消息队列（两个）" class="headerlink" title="消息队列（两个）"></a>消息队列（两个）</h4><ul><li>接收数据后存到Elasticsearch，然后用Kibana展示，用作原始数据查询</li><li>流式中间件对数据作处理（storm、spark）</li></ul><h5 id="处理类型"><a href="#处理类型" class="headerlink" title="处理类型"></a>处理类型</h5><ul><li>解析数据格式（url、请求量、响应时间）</li><li>聚合运算（响应时间分位值，非200请求等）</li><li>将数据存储到时序数据库（InfluxDB、OpenTSDB、Graphite）</li><li>通过Grafana 来连接时序数据库，将监控数据绘制成报表</li></ul><p><img src="/2020/04/04/高并发设计/监控系统架构示意图.jpeg" alt="￼监控系统架构示意图"></p><h3 id="报表"><a href="#报表" class="headerlink" title="报表"></a>报表</h3><ul><li>访问趋势报表：接入的是 Web 服务器，和应用服务器的访问日志，展示了服务整体的访问量、响应时间情况、错误数量、带宽等信息。主要反映的是服务的整体运行情况，帮助你来发现问题</li><li>性能报表：对接的是资源和依赖服务的埋点数据，展示了被埋点资源的访问量和响应时间情况。它反映了资源的整体运行情况</li><li>资源报表：对接的是使用 Agent 采集的资源的运行情况数据。当某一个资源出现了问题，就可以进一步从这个报表中，发现资源究竟出现了什么问题，是连接数异常增高还是缓存命中率下降</li></ul><h2 id="应用性能管理"><a href="#应用性能管理" class="headerlink" title="应用性能管理"></a>应用性能管理</h2><blockquote><p>APM：对应用各个层面做全方位的监测，期望及时发现可能存在的问题，并加以解决，从而提升系统的性能和可用性</p></blockquote><h3 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a>搭建</h3><ul><li>数据采集：在客户端植入SDK，SDK采集数据通过固定接口定时发送服务端</li><li>处理和存储：加密传输数据，存储到消息中间件，做聚合运算，绘制报表</li></ul><p><img src="/2020/04/04/高并发设计/APM系统示意图.jpeg" alt="APM系统示意图￼"></p><h3 id="监控的数据："><a href="#监控的数据：" class="headerlink" title="监控的数据："></a>监控的数据：</h3><ul><li>客户端网络问题（首要）：埋点的方式</li></ul><p><img src="/2020/04/04/高并发设计/客户端网络问题监控.jpeg" alt="￼客户端网络问题监控"></p><h3 id="价值"><a href="#价值" class="headerlink" title="价值"></a>价值</h3><ul><li>数据为用户上报真实数据，能准确真实实时反应用户操作体验</li><li>是性能优化的指向标，做优化行为时能够反馈用户性能数据，引导业务正向优化接口性能、可用性等指标</li><li>能监控CDN链路质量，弥补CDN监控依赖CDN厂商，但CDN厂商无法感知客户端到CDN链路的问题</li><li>能上报一些异常数据：登录失败、下单失败等</li></ul><h2 id="压力测试"><a href="#压力测试" class="headerlink" title="压力测试"></a>压力测试</h2><ul><li>压力测试指的是在高并发大流量下进行测试</li><li>应该周期性进行</li><li>应该包含整个调用链</li><li>流量发起应尽量接近客户端，远离服务</li></ul><h3 id="搭建-1"><a href="#搭建-1" class="headerlink" title="搭建"></a>搭建</h3><h4 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h4><ul><li>流量的隔离</li><li>风险的控制</li></ul><h4 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h4><h5 id="流量构造和产生模块"><a href="#流量构造和产生模块" class="headerlink" title="流量构造和产生模块"></a>流量构造和产生模块</h5><ul><li>拷贝入口流量存储到数据流量工厂（流量拷贝工具GoRelay）</li><li>对流量染色，标记为压测数据</li></ul><h5 id="压测数据隔离模块"><a href="#压测数据隔离模块" class="headerlink" title="压测数据隔离模块"></a>压测数据隔离模块</h5><ul><li>针对读取数据的请求，不能压测的组件或服务采用Mock</li><li>写入数据到影子库（同一个实例的不同Schema），缓存则增加特定前缀</li></ul><h5 id="系统健康度检查和压测流量干预模块"><a href="#系统健康度检查和压测流量干预模块" class="headerlink" title="系统健康度检查和压测流量干预模块"></a>系统健康度检查和压测流量干预模块</h5><ul><li>逐步增大流量，观察瓶颈</li><li>开发流量监控组件，设置性能阈值（cpu使用率、慢请求比例等）</li></ul><p><img src="/2020/04/04/高并发设计/全链路压测系统架构示意图.jpeg" alt="￼全链路压测系统架构示意图"></p><h2 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h2><h3 id="方式-3"><a href="#方式-3" class="headerlink" title="方式"></a>方式</h3><h4 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h4><ul><li>把配置文件存储的目录标准化为特定的目录</li><li>使用版本管理工具管理配置项</li><li>相同配置项放在一个目录供多个机房共用</li><li>将不同的配置放在以机房名为名称的不同目录</li><li>先读取特定的配置再读取公共配置</li></ul><h4 id="配置中心（推荐Apollo）"><a href="#配置中心（推荐Apollo）" class="headerlink" title="配置中心（推荐Apollo）"></a>配置中心（推荐Apollo）</h4><h5 id="变更推送"><a href="#变更推送" class="headerlink" title="变更推送"></a>变更推送</h5><ol><li>轮询查询：应用程序想配置中心注册一个监听器，定期查询配置是否改变（多个服务器拉取配置，配置中心带宽可能成为瓶颈，通过计算配置的MD5判断是否改变来解决）（实时性要求不高，建议采用）</li><li>长连推送：配置中心服务端保存每个连接关注的配置列表，比轮询复杂但更实时</li></ol><p><img src="/2020/04/04/高并发设计/轮询查询实现变更推动示意图.jpeg" alt="￼轮询查询实现变更推动示意图"></p><h3 id="配置中心高可用"><a href="#配置中心高可用" class="headerlink" title="配置中心高可用"></a>配置中心高可用</h3><blockquote><p>让配置中心旁路化：配置中心宕机，或者配置中心依赖的存储宕机，仍然能够保证应用程序可以启动</p></blockquote><ul><li>增加缓存：配置中心客户端上增加两级缓存，第一级为内存的缓存，第二级为文件的缓存</li></ul><h4 id="缓存方式"><a href="#缓存方式" class="headerlink" title="缓存方式"></a>缓存方式</h4><ul><li>内存缓存：配置中心客户端获取后同步写入，降低客户端和配置中心的交互频率，提升性能</li><li>文件缓存：异步写入，做为容灾，配置中心发生故障，应用程序优先使用文件中的配置，虽无法获取变更，但仍可以起起来，算是降级</li></ul><h2 id="降级熔断"><a href="#降级熔断" class="headerlink" title="降级熔断"></a>降级熔断</h2><blockquote><p>怕的不是宕是慢，慢会引发雪崩效应</p></blockquote><ul><li>熔断：发起服务调用的时候，如果返回错误或者超时的次数超过一定阈值，则后续的请求不再发向远程服务而是暂时返回错误（是一种有限状态机，在三个状态之间转换）<br><img src="/2020/04/04/高并发设计/熔断状态变更示意图.jpeg" alt="￼熔断状态变更示意图"></li><li>降级：站在整体系统负载的角度上，放弃部分非核心功能或者服务，保证整体的可用性的方法，是一种有损的系统容错方式</li></ul><h3 id="降级分类"><a href="#降级分类" class="headerlink" title="降级分类"></a>降级分类</h3><ul><li>限流降级</li><li>开关降级：在代码中预先埋设一些开关，可通过配置中心控制（需区分哪些是核心业务哪些不是）</li></ul><h3 id="降级策略"><a href="#降级策略" class="headerlink" title="降级策略"></a>降级策略</h3><ul><li>读取数据：直接返回降级数据（缓存数据，非核心则返回固定数据）</li><li>轮询查询：降低获取数据频率</li><li>写数据：同步写变成异步写<br><strong>只有演练的开关才是有用的开关</strong></li></ul><h2 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h2><ul><li>通过限制到达系统的并发请求数量，保证系统能够正常响应部分用户请求，对于超过限制的流量，通过拒绝服务的方式保证整体系统的可用性</li><li>部署在服务的入口层，比如Api网关</li><li>微服务架构中在RPC客户端引入限流策略，保证单个服务的可用性</li><li>阈值放在配置中心动态配置</li></ul><h3 id="纬度"><a href="#纬度" class="headerlink" title="纬度"></a>纬度</h3><ul><li>系统每分钟处理的请求数</li><li>单个接口每分钟处理的请求数</li><li>单个IP/用户ID/设备ID/在一段时间内发送的请求数</li><li>服务于第三方应用的平台限制appKey的访问接口速度</li></ul><h3 id="限流算法"><a href="#限流算法" class="headerlink" title="限流算法"></a>限流算法</h3><h4 id="固定窗口和滑动窗口"><a href="#固定窗口和滑动窗口" class="headerlink" title="固定窗口和滑动窗口"></a>固定窗口和滑动窗口</h4><blockquote><p>无法限制短时间的集中流量</p></blockquote><div class="table-container"><table><thead><tr><th style="text-align:center">固定窗口</th><th style="text-align:center">滑动窗口</th></tr></thead><tbody><tr><td style="text-align:center">记录时间范围内的请求量，超过则触发限流策略返回请求失败</td><td style="text-align:center">将时间窗口划分为多个小窗口</td></tr><tr><td style="text-align:center">实现简单，但无法限制短时间内的集中流量</td><td style="text-align:center">解决了临界时间点上突发流量无法控制的问题，但因为增加了时间片存储，空间复杂度有所升高</td></tr></tbody></table></div><p><img src="/2020/04/04/高并发设计/固定窗口算法缺陷示意图.jpeg" alt="￼￼固定窗口算法缺陷示意图"><br><img src="/2020/04/04/高并发设计/滑动窗口算法示意图.jpeg" alt="滑动窗口算法示意图"></p><h4 id="漏桶和令牌桶算法"><a href="#漏桶和令牌桶算法" class="headerlink" title="漏桶和令牌桶算法"></a>漏桶和令牌桶算法</h4><blockquote><p>推荐使用令牌桶</p></blockquote><div class="table-container"><table><thead><tr><th style="text-align:center">漏桶算法</th><th style="text-align:center">令牌桶算法</th></tr></thead><tbody><tr><td style="text-align:center">在流量产生端和接受端增加一个漏桶，流量暂存在里面，出口按照固定速率将流量漏出到接受端，当流量超过漏桶承受极限时多余的流量触发限流策略</td><td style="text-align:center">设置放入令牌的时间间隔和令牌桶的大小，每个请求先获取令牌，没用令牌则等待或直接拒绝服务</td></tr><tr><td style="text-align:center">随机产生的流量被整形成平滑的流量</td><td style="text-align:center">随机产生的流量被整形成平滑的流量</td></tr><tr><td style="text-align:center">使用消息队列存储，队列流量溢出则拒绝</td><td style="text-align:center">单机使用变量，分布式可以使用redis（减少交互可以每一次获取一批令牌）</td></tr><tr><td style="text-align:center">会增加请求响应时间</td></tr></tbody></table></div><p><img src="/2020/04/04/高并发设计/漏桶算法示意图.jpeg" alt="漏桶算法示意图"><br><img src="/2020/04/04/高并发设计/令牌桶算法示意图.jpeg" alt="令牌桶算法示意图"></p>]]></content>
    
    <summary type="html">
    
      关于Java高并发设计的知识点
    
    </summary>
    
      <category term="Java" scheme="http://coldjune.com/categories/Java/"/>
    
    
      <category term="高并发" scheme="http://coldjune.com/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>JVMInAction</title>
    <link href="http://coldjune.com/2020/03/16/JVMInAction/"/>
    <id>http://coldjune.com/2020/03/16/JVMInAction/</id>
    <published>2020-03-16T06:51:41.000Z</published>
    <updated>2020-04-04T10:53:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>由于总结到最后发现脑图变得无比庞大，所以这里就不再贴出图片了。<br>可以到<a href="https://github.com/coldJune/blog/tree/master/source/_posts/JVMInAction/实战Java虚拟机.xmind" target="_blank" rel="noopener">这里</a>查看xmind的源文件，里面各个章节有到相应源码的连接<br>也可以到<a href="https://github.com/coldJune/blog/tree/master/source/_posts/JVMInAction/实战Java虚拟机.pdf" target="_blank" rel="noopener">这里</a>查看导出的pdf<br>也可以到<a href="https://github.com/coldJune/blog/tree/master/source/_posts/JVMInAction/实战Java虚拟机.png" target="_blank" rel="noopener">这里</a>查看导出的图片</p>]]></content>
    
    <summary type="html">
    
      《实战JAVA虚拟机  JVM故障诊断与性能优化》总结
    
    </summary>
    
      <category term="Java" scheme="http://coldjune.com/categories/Java/"/>
    
    
      <category term="JVM" scheme="http://coldjune.com/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>java并发编程脑图</title>
    <link href="http://coldjune.com/2020/02/12/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E8%84%91%E5%9B%BE/"/>
    <id>http://coldjune.com/2020/02/12/java并发编程脑图/</id>
    <published>2020-02-12T03:08:03.000Z</published>
    <updated>2020-02-13T09:54:04.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2020/02/12/java并发编程脑图/Java并发.png" alt="Java并发"><br><a href="https://github.com/coldJune/multiThreadAndConcurrence" target="_blank" rel="noopener">相关源码</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/2020/02/12/java并发编程脑图/Java并发.png&quot; alt=&quot;Java并发&quot;&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/coldJune/multiThreadAndConcurrence&quot; target=&quot;_bl
      
    
    </summary>
    
      <category term="Java" scheme="http://coldjune.com/categories/Java/"/>
    
    
      <category term="Java" scheme="http://coldjune.com/tags/Java/"/>
    
      <category term="并发" scheme="http://coldjune.com/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Spring脑图</title>
    <link href="http://coldjune.com/2020/02/08/Spring%E8%84%91%E5%9B%BE/"/>
    <id>http://coldjune.com/2020/02/08/Spring脑图/</id>
    <published>2020-02-08T02:42:23.000Z</published>
    <updated>2020-02-13T09:54:09.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2020/02/08/Spring脑图/Spring.png" alt="Spring脑图"><br><a href="https://github.com/coldJune/spring" target="_blank" rel="noopener">相关源码</a></p>]]></content>
    
    <summary type="html">
    
      Spring脑图总结
    
    </summary>
    
      <category term="Java" scheme="http://coldjune.com/categories/Java/"/>
    
    
      <category term="Java" scheme="http://coldjune.com/tags/Java/"/>
    
      <category term="Spring" scheme="http://coldjune.com/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>机器学习总结</title>
    <link href="http://coldjune.com/2019/08/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    <id>http://coldjune.com/2019/08/12/机器学习总结/</id>
    <published>2019-08-12T12:12:43.000Z</published>
    <updated>2021-10-24T05:52:30.409Z</updated>
    
    <content type="html"><![CDATA[<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设用<strong>P</strong>来评估计算机程序在某任务类<strong>T</strong>上的性能，若一个程序通过利用经验<strong>E</strong>在<strong>T</strong>中任务上获得了性能改善，则我们就说关于<strong>T</strong>和<strong>P</strong>，该程序对<strong>E</strong>进行了学习。<br><br>Mitcell,1997</p><h1 id="模型评估与选择"><a href="#模型评估与选择" class="headerlink" title="模型评估与选择"></a>模型评估与选择</h1><h2 id="误差"><a href="#误差" class="headerlink" title="误差"></a>误差</h2><ul><li><p>误差</p><blockquote><p><strong>误差</strong>是学习器的实际预测输出与样本真实输出之间的差异，其中在训练集上的误差称为<strong>训练误差</strong>或者<strong>经验误差</strong>，在新样本上的误差称为<strong>泛化误差</strong>。</p></blockquote></li><li><p>过拟合与欠拟合</p><blockquote><p><strong>过拟合</strong>是指学习器把训练样本学习得“太好”，可能将训练样本的一些特点当做所有潜在样本都具有的一般性质而导致泛化性能下降。<strong>欠拟合</strong>则相反，它表示对训练样本的一般性质都未曾学到。欠拟合可以克服而过拟合只能缓解。</p></blockquote></li></ul><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><ul><li><p>留出法</p><blockquote><p><strong>留出法</strong>直接将训练集划分为两个不相交的子集，一个作为训练集，一个作为测试集。为了保证被划分后的数据拥有和原始数据同样的分布，避免因数据划分而引入额外的偏差影响最终的结果，可以采用<strong>分层采样</strong>(<em>stratified sampling</em>)来保留类别比例；因一个数据集可能存在多种划分方式，如果单次使用留出法可能导致结果不够稳定可靠，一般可采用随机划分、重复进行实验后取平均值作为留出法的评估结果；数据划分将导致最后的模型不是整个数据集的训练结果，而只是一部分数据训练出来的，这将降低评估结果的<strong>保真性</strong>(<em>fidelity</em>)，由于没有完美的解决方案，一般是将大约$\frac{2}{3}$~$\frac{4}{5}$的样本用作训练，剩余用于测试(测试集至少应含30个样例)</p></blockquote></li><li><p>交叉验证法</p><blockquote><p><strong>交叉验证法</strong>将数据分为$k$个大小相似的互斥子集，每个子集尽可能保持数据分布的一致性(分层采样)，每次用$k-1$个子集的并集作为训练集，剩下的那个作为测试集，如此进行$k$次则可通过$k$组训练/测试集得到$k$个测试结果，最后取均值。交叉验证法又称为<strong>k折交叉验证</strong>(<em>k-fold cross validation</em>)，它评估结果的稳定性和保真性很大程度上取决于$k$，这里$k$的取值常用10；与留出法类似，一个数据集可能存在多种划分，为减小划分引入的差别，k折验证法需要使用不同的划分进行$p$次，最终的结果是这p次k折交叉验证结果的均值。</p></blockquote></li><li><p>留一法</p><blockquote><p><strong>留一法</strong>(<em>Leave-One-Out, LOO</em>)是交叉验证法的特例，它将大小为$m$的数据集划分成$m$个子集，即每个子集只包含一个样本，这样就不会受随机划分的影响，同时也让用训练集训练的模型和期望评估的用整个数据集训练的模型相似(两个数据集样本数差一)，使结果更为准确。但是当数据量变大时，留一法需要训练$m$个模型，这个计算开销是巨大而不能忍受的。</p></blockquote></li><li><p>自助法</p><blockquote><p>所谓<strong>自助法</strong>(<em>booststrapping</em>)就是通过<strong>自助采样</strong>(<em>booststrap sampling</em>)<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>从原始数据集$D$中有放回地随机选取$m$个样本组成训练用数据集$D’$，因为是有放回的采样，所以$D$中的一部分样本可能在$D’$中多次出现，而另一部分样本则不会出现，样本在$m$次采样中始终不出现的概率为$(1-\frac{1}{1})^m$，对$m$取极限可得$\lim_{m \rightarrow \inf}{(1- \frac{1}{m})^m} = \frac{1}{e} \approx 0.368$。这说明通过自助采样之后有$36.8\%$的数据未参与训练，因此我们可以使用这部分数据作为测试数据集，这样获得的测试结果叫做<strong>包外估计</strong>(<em>out-of-bag estimate</em>)。虽然自助法在数据集较小，难以有效划分有效训练集/测试集时很有效，并且由于它能参数多个不同的训练集，在集成学习中也能发挥巨大的作用，但由于它产生的数据集改变了原始数据集的分布，引入了估计偏差，因此在数据量足够多时还是使用留一法或交叉验证法会更好一些。</p></blockquote></li></ul><h2 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h2><h3 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;回归任务中最常用的性能度量是<strong>均方误差</strong>，即对各个样本预测值$f(\boldsymbol{x}_i)$与对应真实值$y_i$的差值的平方进行求和再取平均数：<script type="math/tex">E(x;D)=\frac{1}{m}\sum^1_m(f(\boldsymbol{x}_i-y_i))^2</script></p><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><h4 id="错误率与精度"><a href="#错误率与精度" class="headerlink" title="错误率与精度"></a>错误率与精度</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>错误率</strong>是分类错误的样本数占样本总数的比例，<strong>精度</strong>是分类正确的样本数占样本总数的比例，两者相加为$1$。<br></p><ul><li>错误率<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup><script type="math/tex; mode=display">E(f;D)=\frac{1}{m}\sum_m^1\boldsymbol{I}(f(\boldsymbol{x}_i \ne y_i))</script></li><li>精度<script type="math/tex; mode=display">acc(f;D)=\frac{1}{m}\sum_m^1\boldsymbol{I}(f(\boldsymbol{x}_i = y_i))</script><h4 id="查准率-准确率-、查全率-召回率-和F1"><a href="#查准率-准确率-、查全率-召回率-和F1" class="headerlink" title="查准率(准确率)、查全率(召回率)和F1"></a>查准率(准确率)、查全率(召回率)和F1</h4>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>查准率</strong>表示分类结果中真正为正的样本(<em>真正例</em>)在分类为正的样本中所占的比例，<strong>查全率</strong>表示分类结果中真正为正的样本在总样本中所占的比例。对于这两个度量标准，可以通过混淆矩阵进行直观的展现，<br><img src="/2019/08/12/机器学习总结/混淆矩阵.png" alt="混淆矩阵"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中<strong>真正例</strong>(<em>true positive</em>)表示预测为真实际也为真，<strong>假反例</strong>(<em>false negative</em>)表示实际为真预测为加，<strong>假正例</strong>(<em>false negative</em>)表示预测为真实际为假，<strong>真反例</strong>(<em>true negative</em>)表示实际为假预测也为假，这四种情形对应的样例数之和为总的样本数。而查准率和查全率用可以用这几种情形进行表示</li><li>查准率(准确率)<script type="math/tex; mode=display">P = \frac{TP}{TP+FP}</script></li><li>查全率(召回率)<script type="math/tex; mode=display">F = \frac{TP}{TP+FN}</script></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;查准率和查全率是一对相互矛盾的度量，查准率高则查全率低，反之亦然。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>P-R曲线</strong>又名<strong>PR图</strong>，其横轴为查全率，纵轴为查准率，P-R曲线往往是非平滑非单调的。如果一个学习器的P-R曲线被另一个学习器的曲线完全包住，则说明后者的性能优于前者；如果两者有交叉，则只能在具体的查准率和查全率下进行比较。<br><img src="/2019/08/12/机器学习总结/PR图.png" alt="P-R图"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>平衡点</strong>(<em>Break-Event Point,BEP</em>)是一个综合考虑查准率和查全率的度量，它的取值为“查准率=查全率”时的值，一般而言，BEP越大学习器越优。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>F1度量</strong>同样时综合考虑查准率和查全率的度量，它比BEP复杂一些。F1是查准率和查全率的调和平均$\frac{1}{F1}=\frac{1}{2}\cdot (\frac{1}{P}+\frac{1}{R})$，它比算数平均$\frac{P+R}{2}$和几何平均$\sqrt{P\times R}$更重视较小值。</p><ul><li>F1<script type="math/tex; mode=display">F1=\frac{2\times P\times R}{P+R}=\frac{2\times TP}{样例总数+TP-TN}</script></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当应用对查准率和查全率的重视程度不同时，就要是F1的一般形式$F_\beta$来表达出对查准率/查全率的偏好，$\beta&gt;0$度量了查全率和查准率的相对重要性，$\beta=1$将退化成F1度量；$\beta&gt;1$时查全率的影响更大；$\beta&lt;1$时查准率的影响更大。</p><ul><li>$F_\beta$<script type="math/tex; mode=display">F_\beta=\frac{(1+\beta)\times P\times R}{(\beta^2\times P)+R}</script></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在多分类任务中，需要考虑的混淆矩阵将不止一个，可能需要在$n$个混淆矩阵上综合考虑查全率和查准率，这时候有两种不同的度量。一种是先在各个混淆矩阵上计算出各自的查准率和查全率$(P_1,R_1),(P_2,R_2),\cdots,(P_n,R_n)$，然后求平均值，这样得到的是<strong>宏查准率</strong>(<em>macro-P</em>)，<strong>宏查全率</strong>(<em>macro-R</em>)，<strong>宏F1</strong>(<em>macro-F1</em>);另一种是先计算混淆矩阵对应元素的平均值,$\overline{TP}(TP),\overline{FP}(FP),\overline{TN}(TN),\overline{FN}(FN)$，在基于这些平均值计算出<strong>微查准率</strong>(<em>micro-P</em>)，<strong>微查全率</strong>(<em>micro-R</em>)，<strong>微F1</strong>(<em>micro-F1</em>)。</p><ul><li>宏查准率，宏查全率，宏F1<script type="math/tex; mode=display">P_{macro}=\frac{1}{n}\sum_{i=1}^nP_i</script><script type="math/tex; mode=display">R_{macro}=\frac{1}{n}\sum_{i=1}^nR_i</script><script type="math/tex; mode=display">F1_{macro}=\frac{2\times P_{macro}\times R_{macro}}{P_{macro}+R_{macro}}</script></li><li>微查准率，微查全率，微F1<script type="math/tex; mode=display">P_{micro}=\frac{\overline{TP}}{\overline{TP}+\overline{FP}}</script><script type="math/tex; mode=display">R_{micro}=\frac{\overline{TP}}{\overline{TP}+\overline{FN}}</script><script type="math/tex; mode=display">F1_{micro}=\frac{2\times P_{micro} \times R_{micro}}{P_{micro}+R_{micro}}</script></li></ul><h4 id="ROC与AUC"><a href="#ROC与AUC" class="headerlink" title="ROC与AUC"></a>ROC与AUC</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>阈值</strong>是在分类过程中确定样本属于哪一类的标准值，大于阈值则划分为正类，否则为反类。如果将预测结果进行排序，最可能为正例的排在前面(概率大的)，最不可能的排在后面(概率小的)，则阈值便成为了区分正反例的<strong>截断点</strong>。如果更看重查准率，则可选取排序中靠前的位置进行截断(阈值大)，如果更看中查全率，则可选取排序中靠后的位置进行截断(阈值小)。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>受试者工作特征</strong>(<em>Receiver Operating Characteristic, ROC</em>)是通过考察排序本身的好坏和截断点的不同来研究学习器的泛化性能。ROC曲线的纵轴是<strong>真正例率</strong>(<em>True Positive Rate, TPR</em>)，横轴为<strong>假正例率</strong>(<em>False Positive Rate, FPR</em>)，对预测结果进行排序，然后按顺序逐个把样本当成正例进行预测，每次计算出这两个重要的值，然后以它们作为坐标作图。给定$m^+$个正例和$m^-$个反例，具体步骤如下：</p><ol><li>根据学习器预测结果对样例进行排序</li><li>将分类阈值设为最大(所有样例均为反例，真正例率和假正例率均为0)，在坐标$(0,0)$处标记一个点</li><li>将分类阈值依次设置为每个样例的预测值(即依次将每个样例标记为正例)。假设前一个标记点为$(x,y)$,则如果当前样例为正例，则标记为$(x,y+\frac{1}{m^+})$，若为反例则标记为$(x+\frac{1}{m^-},y)$</li><li>用线段将相邻的点连接</li></ol><ul><li>真正例率<script type="math/tex; mode=display">TPR = \frac{TP}{TP+FN}</script></li><li>假正例率<script type="math/tex; mode=display">FPR = \frac{FP}{FP+TN}</script></li><li>ROC<br><img src="/2019/08/12/机器学习总结/ROC和AUC.png" alt="ROC和AUC"></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;与PR图类似，如果一个学习器的ROC曲线完全被另一个包住，则后者的性能优于前者；如果两个学习器的ROC曲线发生交叉则难以判定。AUC适用于这种交叉情况下的性能比较。<strong>AUC</strong>(<em>Area Under ROC Curve</em>)是ROC曲线下的面积，假定ROC曲线是由坐标${(x_1,y_1),(x_2,y_2),\cdots,(x_m,y_m)}$的点连接形成，则AUC的计算公式为：</p><script type="math/tex; mode=display">AUC=\frac{1}{2}\sum_{i=1}^{m-1}(x_{i+1}-x_i)\cdot(y_i+y_{i+1})</script><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AUC考虑的是样本预测的排序质量，因此它与排序误差有紧密的关系。$\boldsymbol{l_{rank}}$对应的是ROC曲线之上的面积，是对排序损失的的定义，若一个正例在ROC曲线上对应标记点的坐标为$(x,y)$，则$x$恰是排序在其前的反例所占的比例，即假正例率，因此<script type="math/tex">AUC=1-l_{rank}</script></p><ul><li>$l_{rank}$<script type="math/tex; mode=display">l_{rank}=\frac{1}{m^+m^-}\sum_{x^+ \in D+}\sum_{x^-\in D^-}(\boldsymbol{I}(f(x^+)<f(x^-))+\frac{1}{2}\boldsymbol{I}(f(x^+)=f(x^-)))</script>其中$m^+$表示正例个数，$m^-$表示反例个数，$D^+$表示正例集合，$D^-$表示反例集合。公式的含义为：考虑每一对正反例，若正例的预测值小于反例，则记一分，若想等则记0.5分，将所有分值相加并除以总共的对数则得到排序的损失(loss)。</li></ul><h4 id="代价敏感错误率和代价曲线"><a href="#代价敏感错误率和代价曲线" class="headerlink" title="代价敏感错误率和代价曲线"></a>代价敏感错误率和代价曲线</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>代价敏感错误率</strong>是为权衡不同类型错误造成的不同损失，通过给错误赋予非均等代价(<em>unequal cost</em>)以达到最小化总体代价(<em>total cost</em>)<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>的目的一种度量方式。</p><ul><li>代价矩阵<br><img src="/2019/08/12/机器学习总结/代价矩阵.png" alt="代价矩阵"><br>$cost_{ij}$表示将第$i$类样本预测为第$j$样本的代价，$cost_{ii}$一般为0，如果第0类判别为第1类的损失更大，则$cost_{01}&gt;cost_{10}$，损失相差越大，则$cost_{01}$和$cost_{10}$的值差别越大，同时两则的差值重要的是代价比值而非绝对差值。</li><li>代价敏感错误率<script type="math/tex; mode=display">E(f;D:cost)=\frac{1}{m}(\sum_{x_i\in D^+}\boldsymbol{I}(f(\boldsymbol{x}_i)\ne y_i)\times cost_{01}+ \sum_{x_i\in D^-}\boldsymbol{I}(f(\boldsymbol{x}_i)\ne y_i)\times cost_{10})</script>$D^+$为正例子集，$D^-$为反例子集，$cost_{01}$表示第0类预测为第1类的代价，$cost_{10}$表示第1类预测为第0类的代价；若$cost_{ij}$不限于0、1，则可以定义出多分类的代价敏感错误率。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>代价曲线</strong>(<em>cost curve</em>)能在非均等代价下反应出学习器的期望总体代价。代价曲线的横轴是取值为$[0,1]$的正例概率代价，纵轴是取值为$[0,1]$的归一化<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>代价。</li><li>正例概率代价<script type="math/tex; mode=display">P(+)cost=\frac{p\times cost_{01}}{p\times cost_{01}+(1-p)\times cost_{10}}</script>p是样例为正例的概率</li><li>归一化代价<script type="math/tex; mode=display">cost_{norm}=\frac{FNR\times p\times cost_{01}+FPR\times (1-p)\times cost_{10}}{p\times cost_{01}+(1-p)\times cost_{10}}</script>FPR是假正例率，$FNR=1-TPR$是假反例率</li><li>代价曲线的绘制<ol><li>设ROC曲线上的点为$(TPR,FPR)$，据此计算出FNR</li><li>在代价平面上绘制一条$(0,FPR)$到$(1,FNR)$的线段，线段下的面积即表示该条件下的期望总代价</li><li>如此将ROC曲线上的每个点转化为代价平面上的线段(ROC曲线上的每一个点对应代价平面上的一条线段)</li><li>取所有线段的下界，围成的面积即为在所有条件下学习器的期望总代价</li></ol></li></ul><p><img src="/2019/08/12/机器学习总结/代价曲线和期望总体代价.png" alt="代价曲线和期望总体代价"></p><h3 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;聚类的性能指标分为两类，一类是将聚类结果与参考模型(<em>reference model</em>)进行比较，这称为<strong>外部指标</strong>(<em>external index</em>)；另一类是直接考察聚类结果而不参考任何模型，这称为<strong>内部指标</strong>(<em>internal index</em>)。</p><h4 id="外部指标"><a href="#外部指标" class="headerlink" title="外部指标"></a>外部指标</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对数据集$D=\{x_1,x_2,\cdots,x_m\}$，聚类结果的簇划分为$C=\{C_1,C_2,\cdots,C_k\}$，参考模型的簇划分为<script type="math/tex">C^*=\{C_1^*,C_2^*,\cdots,C_s^*\}</script>，令<script type="math/tex">\boldsymbol{\lambda}</script>和<script type="math/tex">\boldsymbol{\lambda^*}</script>分别表示<script type="math/tex">C</script>和<script type="math/tex">C^*</script>对应的簇的标记向量，将样本两两配对定义：</p><script type="math/tex; mode=display">a=|SS|,\ SS=\{(\boldsymbol{x}_i\boldsymbol{x}_j)|\lambda_i=\lambda_j,\lambda_i^*=\lambda_j^*,i<j\}</script><script type="math/tex; mode=display">b=|SD|,\ SD=\{(\boldsymbol{x}_i\boldsymbol{x}_j)|\lambda_i=\lambda_j,\lambda_i^* \ne \lambda_j^*,i<j\}</script><script type="math/tex; mode=display">c=|DS|,\ DS=\{(\boldsymbol{x}_i\boldsymbol{x}_j)|\lambda_i\ne \lambda_j,\lambda_i^*=\lambda_j^*,i<j\}</script><script type="math/tex; mode=display">d=|DD|,\ DD=\{(\boldsymbol{x}_i\boldsymbol{x}_j)|\lambda_i\ne \lambda_j,\lambda_i^*\ne \lambda_j^*,i<j\}</script><p>$SS$包含了在$C$中隶属于相同簇且在<script type="math/tex">C^*</script>也隶属于相同簇的样本对,$SD$包含了在$C$中隶属于相同簇但在<script type="math/tex">C^*</script>中隶属于不同簇的样本对,$DS$包含了在$C$中隶属于不同的簇但在<script type="math/tex">C^*</script>中隶属于相同簇的样本对,$DD$包含了在$C$中隶属于不同的簇在<script type="math/tex">C^*</script>中也隶属于不同的簇的样本对。每个样本对$(\boldsymbol{x}_i,\boldsymbol{x}_j)(i&lt;j)$仅能出现在一个集合中，因此$a+b+c+d=\frac{m(m-1)}{2}$</p><ul><li>Jaccard系数(<em>Jaccard Coefficient, JC</em>)<script type="math/tex; mode=display">JC=\frac{a}{a+b+c}</script></li><li>FM指数(<em>Fowlkes and Mallows Index, FMI</em>)<script type="math/tex; mode=display">FMI=\sqrt{\frac{a}{a+b}\cdot \frac{a}{a+c}}</script></li><li>Rand指数(<em>Rand Index, RI</em>)<script type="math/tex; mode=display">RI=\frac{2(a+d)}{m(m-1)}</script>这些值的结果均在$[0,1]$，值越大越好<h4 id="内部指标"><a href="#内部指标" class="headerlink" title="内部指标"></a>内部指标</h4>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设聚类结果的簇划分为$C=\{C_1,C_2,\cdots,C_k\}$，则可定义<script type="math/tex; mode=display">avg(C) = \frac{2}{|C|(|C|-1)}\sum_{1\le i<j\le |C|}dist(\boldsymbol{x}_i,\boldsymbol{x}_j)</script><script type="math/tex; mode=display">diam(C)=max_{1\le i<j\le |C|}dist(\boldsymbol{x}_i,\boldsymbol{x}_j)</script><script type="math/tex; mode=display">d_{min}(C_i,C_j)=min_{\boldsymbol{x}_i \in C_i,\boldsymbol{x}_j \in C_j}dist(\boldsymbol{x}_i,\boldsymbol{x}_j)</script><script type="math/tex; mode=display">d_{cen}(C_i,C_j)=dist(\boldsymbol{\mu}_i,\boldsymbol{\mu}_j)</script></li></ul><ol><li>$dist(\cdot,\cdot)$用于计算两个样本之间的距离；</li><li>$\boldsymbol{\mu}$代表簇$C$的中心点$\boldsymbol{\mu}=\frac{1}{|C|}\sum_{1\le i\le |C|}\boldsymbol{x}_i$;</li><li>$avg(C)$表示簇内样本的平均距离</li><li>$diam(C)$表示簇内样本的最远距离</li><li>$d_{min}(C_i,C_j)$表示簇$C_i$和簇$C_j$两个簇之间最近样本间的距离</li><li>$d_{cen}(C_i,C_j)$表示簇$C_i$和簇$C_j$两个簇中心点间的距离</li></ol><ul><li>DB指数(<em>, Davies-Bouldin Index,DBI</em>)<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>DBI指数</strong>(戴维森堡丁指数/分类适确性指标)计算任意两类别的类内平均距离之和除以两聚类中心距离求最大值，DBI越小意味着类内距离越小同时类间距离越大。<script type="math/tex; mode=display">DBI=\frac{1}{k}\sum_{i=1}^k\max_{j\ne i }(\frac{avg(C_i)+avg(C_j)}{d_{cen}(C_i,C_j)})</script></li><li>Dunn指数(<em>Dunn Index,DI</em>)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Dunn指数</strong>(邓恩指数)计算两个簇之间最近样本间的距离(类间)除以任意簇的簇内样本的最远距离，DI越大意味着簇间距离越大同时类内距离越小。<script type="math/tex; mode=display">DI=\min_{1\le i\le k}\{\min_{j\ne i}(\frac{d_{min}(C_i,C_j)}{max_{1\le l\le k}diam(C_l)})\}</script>DBI越小越好，DI则越大越好。由于距离使用的是欧式聚集，所以两者对环状分布的聚类度量都不好。<h4 id="距离计算"><a href="#距离计算" class="headerlink" title="距离计算"></a>距离计算</h4>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>连续属性</strong>在定义域上有无穷多个可能的取值，<strong>有序属性</strong>表示属性之间有明显的远近关系(1与2的距离在数值上显然比1与3的距离近，所以表示数值的$\{1,2,3\}$就是有序属性的集合)。</li><li>闵可夫斯基距离(<em>Minkowski distance</em>)<script type="math/tex; mode=display">dist_{mk}(\boldsymbol{x}_i,\boldsymbol{x}_j)=(\sum_{u=1}^n|x_{iu}-x_{ju}|^p)^\frac{1}{p}</script></li><li>欧式距离(<em>Euclidean distance</em>)<script type="math/tex; mode=display">dist_{ed}(\boldsymbol{x}_i,\boldsymbol{x}_j)=\|\boldsymbol{x}_i-\boldsymbol{x}_j\|_2=\sqrt{(\sum_{u=1}^n|x_{iu}-x_{ju}|^2)} \tag{p=2}</script></li><li>曼哈顿距离(<em>Manhattan distance</em>)<script type="math/tex; mode=display">dist_{md}(\boldsymbol{x}_i,\boldsymbol{x}_j)=\|\boldsymbol{x}_i-\boldsymbol{x}_j\|=(\sum_{u=1}^n|x_{iu}-x_{ju}|) \tag{p=1}</script></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>离散属性</strong>在定义域上有有限多个取值，<strong>无序属性</strong>表示属性之间没有远近大小关系(如实物电脑、书、杯子之间就没法确定一定的顺序，所以{电脑、书、杯子}就是无序属性的集合)。</p><ul><li>VDM(<em>Value Difference Metric</em>)<script type="math/tex; mode=display">VDM_p(a,b)=\sum_{k=1}^p|\frac{m_{u,a,i}}{m_{u,a}}-\frac{m_{u,b,i}}{m_{u,b}}|^p</script>$m_{u,a}$表示属性$u$上取值为$a$的样本数；$m_{u,a,i}$表示在第$i$个样本簇中在属性$u$上取值为$a$的样本数；$k$表示样本簇数。此为属性$u$上两个离散值$a$和$b$之间的$VDM$距离。</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假定有$n_c$个有序属性，$n-n_c$个无序属性，则混合属性的距离计算如下：</p><script type="math/tex; mode=display">MinkovDM_p(\boldsymbol{x}_i,\boldsymbol{x}_j)=(\sum_{u=1}^{n_c}|x_{iu}-x_{ju}|^p+\sum_{u=n_c+1}^nVDM_p(x_{iu},x_{ju}))^\frac{1}{p}</script><h2 id="比较检验"><a href="#比较检验" class="headerlink" title="比较检验"></a>比较检验</h2><p>// TODO 因无法完全理解各个比较检验公式的含义，暂时不在此总结</p><h2 id="偏差和方差"><a href="#偏差和方差" class="headerlink" title="偏差和方差"></a>偏差和方差</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>偏差</strong>度量了学习器的期望预测结果与真实结果的偏离程度，刻画了学习算法本身的拟合能力；<strong>方差</strong>度量了同样大小的训练集的变动所导致的学习性能的改变，刻画了数据扰动所带来的影响；<strong>噪声</strong>表达了当前任务上任何学习算法所能达到的期望泛化误差的下界，刻画了学习问题本身的难度；<strong>泛化误差</strong>是偏差、方差和噪声之和<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup>。</p><ul><li>期望预测<script type="math/tex; mode=display">\bar{f}(\boldsymbol{x})=E_D(f(\boldsymbol{x};D))</script></li><li>偏差<script type="math/tex; mode=display">bias^2(\boldsymbol{x})=(f(\bar{\boldsymbol{x}})-y)^2</script></li><li>方差<script type="math/tex; mode=display">var(\boldsymbol{x})=E_D[(f(\boldsymbol{x};D)-\bar{f}(\boldsymbol{x}))^2]</script></li><li>噪声<script type="math/tex; mode=display">\varepsilon^2= E_D[(y_D-y)^2]</script></li><li>泛化误差(令噪声期望$E_D[y_d-y]=0$)<script type="math/tex; mode=display">\begin{aligned}E(f;D) &= E_D[(f(\boldsymbol{x};D)-y_D)^2] \\      &= E_D[(f(\boldsymbol{x};D)-\bar{f}(\boldsymbol{x})+\bar{f}(\boldsymbol{x})-y_D)^2]\\      & = E_D[(f(\boldsymbol{x};D)-\bar{f}(\boldsymbol{x}))^2] +E_D[(\bar{f}(\boldsymbol{x})-y_D)^2] + E_D[2(f(\boldsymbol{x};D)-\bar{f}(\boldsymbol{x}))(\bar{f}(\boldsymbol{x})-y_D)] \\     &=E_D[(f(\boldsymbol{x};D)-\bar{f}(\boldsymbol{x}))^2] +E_D[(\bar{f}(\boldsymbol{x})-y_D)^2]\\     &=var(\boldsymbol{x}) + E_D[(\bar{f}(\boldsymbol{x})-y+y-y_D)^2]\\     &=var(\boldsymbol{x}) +  E_D[(\bar{f}(\boldsymbol{x})-y)^2]+E_D[(y-y_D)^2]+E_D[2(\bar{f}(\boldsymbol{x})-y)(y-y_D)]\\     &=var(\boldsymbol{x})+E_D[(\bar{f}(\boldsymbol{x})-y)^2]+E_D[(y_D-y)^2] \\     &=var(\boldsymbol{x})+bias^2(\boldsymbol{x}) + \varepsilon^2\end{aligned}</script>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当算法训练不足时，数据的扰动不足以使学习器受到明显的影响，这时算法处于欠拟合状态，主要受偏差的影响；当算法训练充足之后，算法有着很强的拟合能力，当数据出现轻微变动的时候都足以使学习器发生显著变化，这时是方差起着决定性作用，如果学习器学习能力过强，将自身独有的特性作为全局特性(非全局特性被学习)，这时学习器出现过拟合。<br><img src="/2019/08/12/机器学习总结/偏差与方差.png" alt="误差和偏差"></li></ul><h3 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>学习曲线</strong>是一种可视化的性能指标，它根据训练数据和测试数据比较模型的性能。通过绘制随着数据增加的训练误差和测试误差曲线来度量模型的偏差和方差。高偏差是欠拟合的表现，其模型的学习曲线在趋于平稳之后会很靠近但是整体误差远高于期望误差；高方差是过拟合的表现，其模型的学习曲线趋于平稳后两条曲线会有明显缝隙，且测试误差高于期望误差，训练误差低于期望误差。<strong>欠拟合</strong>可通过提升模型复杂度解决、减少正则化参数、增加新的特征，而<strong>过拟合</strong>只能通过降低模型复杂度、增加数据、使用正则化方法、采用dropout等方式缓解。</p><ul><li>根据一系列训练实例中的训练和测试数据比较模型的指标性能。<ul><li>高偏差模型<br><img src="/2019/08/12/机器学习总结/高偏差模型.png" alt="高偏差模型"></li><li>高方差模型<br><img src="/2019/08/12/机器学习总结/高方差模型.png" alt="高方差模型"></li></ul></li></ul><h1 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h1><h2 id="数据标准化"><a href="#数据标准化" class="headerlink" title="数据标准化"></a>数据标准化</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>标准化</strong>是指将数据按比例缩放，让它的分布落入一个固定的区间。</p><h3 id="Min-Max标准化"><a href="#Min-Max标准化" class="headerlink" title="Min-Max标准化"></a>Min-Max标准化</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Min-Max标准化</strong>也叫离差标准化，它通过对数据进行线性变换使结果落到$[0,1]$区间，其缺点为当有新数据加入导致最大最小值变化时，所有数据均需重新计算。</p><script type="math/tex; mode=display">x_i^*=\frac{x_i-min(\boldsymbol{x})}{max(\boldsymbol{x})-min(\boldsymbol{x})}</script><h3 id="Z-score标准化"><a href="#Z-score标准化" class="headerlink" title="Z-score标准化"></a>Z-score标准化</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Z-score标准化</strong>也叫零-均值规范化，亦称标准差标准化，经过处理的数据均值为$0$，标准差为$1$。</p><script type="math/tex; mode=display">x_i^*=\frac{x_i-\bar{\boldsymbol{x}}}{\sigma}</script><p>其中$\bar{\boldsymbol{x}}$为$\boldsymbol{x}$的均值，$\sigma$为$\boldsymbol{x}$的标准差，$\sigma=\sqrt{\frac{1}{n}\sum_{i=1}^n(x_i -\bar{\boldsymbol{x}})^2}$</p><h3 id="小数定标规范法"><a href="#小数定标规范法" class="headerlink" title="小数定标规范法"></a>小数定标规范法</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>小数定标规范法</strong>通过移动小数点的位置将数据映射到区间$[-1,1]$，移动的位数由数据中绝对值的最大值确定。</p><script type="math/tex; mode=display">x_i^*=\frac{x_i}{10^k}</script><p>$k$为移动的位数</p><h3 id="离散属性处理"><a href="#离散属性处理" class="headerlink" title="离散属性处理"></a>离散属性处理</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于离散属性如果存在有序关系，则通过连续化将其转换为连续值，如高度的取值为高,中,低可以转换为${1.0,0.5,0}$；如果离散属性不存在有序关系，假设有$k$个属性值，则可以转换为$k$纬向量，如出行方式的取值为汽车,自行车,公交车可以转换为$(1,0,0)(0,1,0)(0,0,1)$</p><h2 id="缺失值"><a href="#缺失值" class="headerlink" title="缺失值"></a>缺失值</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>缺失值</strong>是指在数据集中为空的那部分数据。</p><h3 id="缺失值分类"><a href="#缺失值分类" class="headerlink" title="缺失值分类"></a>缺失值分类</h3><ul><li>不存在型空值<br><strong>不存在型空值</strong>指的是无法填入的值，即该对象在该属性上无法取值，如未婚人士的配偶姓名。</li><li>存在型空值<br><strong>存在型空值</strong>指的是对象在该属性上的值是存在的，但由于某种原因在数据集中缺失。一般而言空值是指代的存在型空值。</li><li>占位型空值<br><strong>占位型空值</strong>无法确定是不存在型空值和存在型空值，这种空值除填充空位外不代表任何其它信息。</li></ul><h3 id="处理方式"><a href="#处理方式" class="headerlink" title="处理方式"></a>处理方式</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在对缺失值进行处理之前，需要先确定这部分值缺失的原因，如果其包含有特定的意义，则定义一个默认值表示这部分数据，如果只是统计缺失或则数据不全，再分类进行讨论。</p><h4 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;删除是指的直接删除这一条存在缺失值的数据，这种方式会造成大量的资源浪费，当数据量较小时，删除数据会导致数据的信息丢失从而影响数据的客观性，当缺失值较多且呈现出非随机分布时，删除这部分数据可能导致数据发生偏离从而得出错误的结论，以下是一些使用场景</p><ul><li>类标记缺失(分类任务)</li><li>一条数据存在大量缺失值</li><li>删除的数据占数据集的比例非常小</li></ul><h4 id="补齐"><a href="#补齐" class="headerlink" title="补齐"></a>补齐</h4><ol><li>人工填写<br>当数据量不大时可以使用这种方式，这种方式产生的数据偏离较小</li><li>特殊值填充<br>使用特定的值填充空值如字符串<code>None</code>、<code>NULL</code>或者<code>0</code>，但这样可能会引入新的属性值，从而导致数据产生巨大的偏差，一般不采用</li><li>平均值填充<br>如果数据是数值型的有序数据，可以使用平均值填充；如果数据是离散数据或者数值型的无序数据则可以使用众数(即改特征出现次数最多的属性值)填充</li><li>k近邻法<br>在数据集中找到<em>k</em>条与该数据最近(一般是欧式距离)的数据，然后将<em>k</em>个值加权平均来得到缺失值的数据</li><li>就近补齐<br>在数据集中找到一条和该数据集最相似(一般而言是距离最近)的数据进行填充，这可以算是k近邻法的特例</li><li>使用所有的值<br>使用所有可能的取值进行填充，在数据量很大取值很多或缺失值很多的情况下计算代价会很大</li><li>回归<br>使用完整的数据集建立回归模型，对于包含空值的数据将已知属性代入模型中求解缺失值</li><li>期望最大化方法(EM)<br>在缺失类型为随机缺失的条件下，假设模型对于完整的样本是正确的，通过观测数据的边际分布可以对未知参数进行<a href="https://baike.baidu.com/item/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/3350286?fr=aladdin" target="_blank" rel="noopener">极大似然估计</a>。这种方式适用于有效样本的数量足够以保证ML估计值是渐近无偏的并服从正态分布。但是这种方法可能会陷入局部极值，收敛速度不快且计算复杂。</li></ol><h4 id="不处理"><a href="#不处理" class="headerlink" title="不处理"></a>不处理</h4><p>贝叶斯网络和人工神经网络可以在包含空值的数据集上进行数据挖掘</p><h2 id="异常值"><a href="#异常值" class="headerlink" title="异常值"></a>异常值</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>异常值</strong>(<em>outlier</em>)是指数据集中偏离大部分数据的数据点，也称<strong>离群点</strong>。</p><h3 id="异常值检测方法"><a href="#异常值检测方法" class="headerlink" title="异常值检测方法"></a>异常值检测方法</h3><h4 id="简单统计"><a href="#简单统计" class="headerlink" title="简单统计"></a>简单统计</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对属性值进行一个描述性的统计，并规定范围，从而查看哪些值超过了这个范围即为异常值</p><h5 id="箱线图"><a href="#箱线图" class="headerlink" title="箱线图"></a>箱线图</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>箱线图</strong>根据<strong>IQR(四分位距)</strong>来进行绘制。箱线图中的矩形表示的就是<strong>IQR</strong>，矩形的上下边界分别就是指的$Q_3$和$Q_1$，而矩形中间的一条线是<strong>中位数</strong>，上下的线段分别叫做<strong>上极限</strong>和<strong>下极限</strong>，而超出这个界限的那些点就被视为异常点。</p><ul><li>IQR<script type="math/tex; mode=display">IQR = Q_3 -Q_1</script>$Q_3$表示上四分位数即$\frac{3}{4}$分位数；$Q_1$表示下四分位数即$\frac{1}{4}$分位数</li><li>上极限<script type="math/tex; mode=display">upper = Q_3+ 1.5IQR</script></li><li>下极限<script type="math/tex; mode=display">down = Q_1 - 1.5IQR</script></li><li>箱线图<br><img src="/2019/08/12/机器学习总结/箱线图.jpeg" alt="箱线图"></li></ul><h4 id="3-sigma-原则"><a href="#3-sigma-原则" class="headerlink" title="$3\sigma$原则"></a>$3\sigma$原则</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;若数据服从<a href="https://baike.baidu.com/item/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83/829892?fr=aladdin" target="_blank" rel="noopener">正态分布</a>，则根据正态分布的定义可知数据距离平均值$3\sigma$之外的概率为$P(|x-\mu|&gt;3\sigma)\le 0.003$，这种极小概率事件被认为是不可能的，所以如果出现这种类型的样本则被认为是异常值。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设$n$维数据集合为$\vec{x_i}=(x_{i,1},x_{i,2},\cdots,x_{i,n}),i\in\{1,2,\cdots,m\}$，通过公式计算每个纬度的均值$\mu_{j}$和方差$\sigma_j,j\in\{1,2,\cdots,n\}$，然后在正太分布的假设下计算数据$\vec{x_i}$的概率$p(\vec{x})$可知其是否是异常点。</p><ul><li>均值<script type="math/tex; mode=display">\mu_j=\frac{\sum_{i=1}^mx_{i,j}}{m}</script></li><li>方差<script type="math/tex; mode=display">\sigma_j^2=\frac{\sum_{i=1}^m(x_{i,j}-\mu_{j})^2}{m}</script></li><li>$p(\vec{x})$<script type="math/tex; mode=display">p(\vec{x})=\prod_{j=1}^np(x_j;\mu_j,\sigma_j^2)=\prod_{j=1}^n\frac{1}{\sqrt{2\pi}\sigma_j}\exp(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2})</script></li><li>正态分布<br><img src="/2019/08/12/机器学习总结/正态分布.png" alt="正态分布"></li></ul><h4 id="使用距离检测多元离群点"><a href="#使用距离检测多元离群点" class="headerlink" title="使用距离检测多元离群点"></a>使用距离检测多元离群点</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当数据不服从正态分布时，通过远离平均距离多少倍的标准差来进行判定，倍数的取值由经验决定。</p><h3 id="异常值的处理"><a href="#异常值的处理" class="headerlink" title="异常值的处理"></a>异常值的处理</h3><ol><li>删除异常值</li><li>用平均数或中位数修正</li><li>采用处理缺失值的方法</li><li>取对数减少极值影响</li><li>压缩极值到上下极限</li><li>不处理</li></ol><h1 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>监督学习</strong>是指通过给定一个已知正确输出的数据集，使用该数据集训练出一个表示输入和输出之间关系的模型。监督学习的典型代表是<strong>分类</strong>(<em>classification</em>)和<strong>回归</strong>(<em>regression</em>)。</p><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>线性模型</strong>试图学习一个通过属性的线性组合来进行预测的函数，而许多非线性模型也可在线性模型的基础上通过引入层级结构和高维映射获得。线性模型的一般表达式如下:</p><script type="math/tex; mode=display">f(x)=w_1x_1+w_2x_2+w_3x_3+...+w_dx_d+b</script><p>向量形式为:</p><script type="math/tex; mode=display">f(x)=\boldsymbol{w^Tx}+b</script><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;线性模型因为其中的$\boldsymbol{w}$直观地表达了各属性在预测中的重要性，所以具有很好的<strong>可解释性</strong>。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>线性回归</strong>试图学得一个线性模型来尽可能准确地预测。</p><h3 id="性能度量-1"><a href="#性能度量-1" class="headerlink" title="性能度量"></a>性能度量</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;回归一般使用<strong>均方误差</strong>作为性能度量，其优化目标则是使均方误差最小化。</p><ul><li>均方误差最小化<script type="math/tex; mode=display">\begin{aligned}  (w^*,b^*)&=argmin_{(w,b)}\sum_{i=1}^m\Big(f(x_i)-y_i\Big)^2\\  &=argmin_{(w,b)}\sum_{i=1}^m(wx_i+b-y_i)^2\\  &=argmin_{(w,b)}\sum_{i=1}^m(y_i-wx_i-b)^2\\\end{aligned}</script><script type="math/tex">w^*</script>,<script type="math/tex">b^*</script>表示$w$和$b$的解</li></ul><h3 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于均方误差最小化的模型求解方法叫做<strong>最小二乘法</strong>。线性回归中最小二乘法试图找到一条直线使所有样本到直线上的欧式距离之和最小。求解$w$和$b$使均方误差($E_{(w,b)}=\sum_{i=1}^m(y_i-wx_i-b)^2$)最小化的过程称为线性回归模型的最小二乘<strong>参数估计</strong>(<em>parameter estimation</em>)。其求解闭式解(<em>closed-form</em>)如下：</p><ol><li>对$w$和$b$分别求导</li><li>令求导后的两式分别等于0</li></ol><h4 id="单元线性回归"><a href="#单元线性回归" class="headerlink" title="单元线性回归"></a>单元线性回归</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;单属性值的线性回归试图学习$f(x_i)=wx_i+b$,使得$f(x_i)\approx y_i$</p><ul><li>对$w$求导<script type="math/tex; mode=display">\begin{aligned}\frac{\partial E_{(w,b)}}{\partial w} &= -\sum_{i=1}^m2x_i(y_i-wx_i-b) \\&=2\sum_{i=1}^mx_i\Big(wx_i-(y_i-b)\Big)\\  &=2\Big(w\sum_{i=1}^mx_i^2 - \sum_{i=1}^m(y_i-b)x_i\Big)\\&=0\\\implies\\ w\sum_{i=1}^mx_i^2 &= \sum_{i=1}^m(y_i-b)x_i\\\implies \\w &= \frac{\sum_{i=1}^m(y_i-b)x_i}{\sum_{i=1}^mx_i^2}\end{aligned}</script></li><li>对$b$求导<script type="math/tex; mode=display">\begin{aligned}\frac{\partial E_{(w,b)}}{\partial b} &=-\sum_{i=1}^m2(y_i-wx_i-b)\\&=2\sum_{i=1}^m\Big(b-(y_i-wx_i)\Big)  \\&=2\Big(mb-\sum_{i=1}^m(y_i-wx_i)\Big) \\&=0\\\implies\\mb &= \sum_{i=1}^m(y_i-wx_i)\\\implies\\b &= \frac{\sum_{i=1}^m(y_i-wx_i)}{m}\end{aligned}</script></li><li>联立求解<script type="math/tex; mode=display">\begin{cases}  w = \frac{\sum_{i=1}^m(y_i-b)x_i}{\sum_{i=1}^mx_i^2}\\      \\  b = \frac{\sum_{i=1}^m(y_i-wx_i)}{m}\end{cases}</script>令$m\bar{y}=\sum_{i=1}^my_i$、$m\bar{x}=\sum_{i=1}^mx_i$，则可得出<script type="math/tex; mode=display">\begin{cases}  w = \frac{\sum_{i=1}^mx_iy_i-b\sum_{i=1}^mx_i}{\sum_{i=1}^mx_i^2} = \frac{\sum_{i=1}^mx_iy_i-bm\bar{x}}{\sum_{i=1}^mx_i^2} \\      \\  b = \frac{m\bar{y}-wm\bar{x}}{m} = \bar{y}-w\bar{x} \end{cases}</script>将$b$代入$w$中<script type="math/tex; mode=display">\begin{aligned}  w\sum_{i=1}^mx_i^2 &=\sum_{i=1}^mx_iy_i-(\bar{y}-w\bar{x})m\bar{x}\\  &= \sum_{i=1}^mx_iy_i-m\bar{x}\bar{y}+mw\bar{x}^2 \\  w(\sum_{i=1}^mx_i^2 -m\bar{x}^2) &= \sum_{i=1}^mx_iy_i-m\bar{x}\bar{y} \\  w\Big(\sum_{i=1}^mx_i^2-\frac{1}{m}(\sum_{i=1}^mx_i)^2\Big) &= \sum_{i=1}^mx_iy_i-\bar{x}\sum_{i=1}^my_i \\  w &= \frac{\sum_{i=1}^my_i(x_i-\bar{x})}{\sum_{i=1}^mx_i^2-\frac{1}{m}\Big(\sum_{i=1}^mx_i\Big)^2}\end{aligned}</script>最后得出的闭式解为：<script type="math/tex; mode=display">\begin{cases}  w = \frac{\sum_{i=1}^my_i(x_i-\bar{x})}{\sum_{i=1}^mx_i^2-\frac{1}{m}\Big(\sum_{i=1}^mx_i\Big)^2}\\  b = \bar{y}-w\bar{x} \end{cases}</script></li></ul><h4 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当数据集$D$中的样本不只由一个属性描述，而是由$d$个属性时，试图学得$f(\boldsymbol{x_i})=\boldsymbol{w^Tx_i}+b$,使得$f(\boldsymbol{x_i})\approx y_i$。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将$w$和$b$吸收入向量形式$\hat{w}=(w;b)$，数据集$D$表示为一个$m\times(d+1)$大小的矩阵$\boldsymbol{X}$，其中每一行对应一个样本，该行前$d$个元素对应样本的$d$个属性值，最后一个元素恒为1:</p><script type="math/tex; mode=display">\boldsymbol{X} = \left(     \begin{matrix}        x_{11} & x_{12} & \cdots & x_{1d} & 1\\        x_{21} & x_{22} & \cdots & x_{2d} & 1\\        \vdots & \vdots & \ddots & \vdots & \vdots\\        x_{m1} & x_{m2} & \cdots & x_{md} & 1    \end{matrix}    \right) = \left(    \begin{matrix}        \boldsymbol{x_1^T} & 1 \\        \boldsymbol{x_2^T} & 1 \\        \vdots & \vdots \\        \boldsymbol{x_m^T} & 1    \end{matrix}    \right)</script><p>然后将标记表示为向量形式$\boldsymbol{y} = (y_1;y_2;\cdots;y_m)$，则得到多元线性回归的均方误差最小化公式为:</p><script type="math/tex; mode=display">\boldsymbol{\hat{w}^*}=argmin_{\hat{\boldsymbol{w}}}(\boldsymbol{y}- \boldsymbol{X\hat{w}})^T(\boldsymbol{y}-\boldsymbol{X\hat{w}})</script><p>令$\boldsymbol{E_{\hat{w}}}=(\boldsymbol{y}- \boldsymbol{X\hat{w}})^T(\boldsymbol{y}-\boldsymbol{X\hat{w}})$并对$\hat{\boldsymbol{w}}$求导可得：</p><script type="math/tex; mode=display">\frac{\partial\boldsymbol{E_{\hat{w}}}}{\partial\boldsymbol{\hat{w}}}=-2\boldsymbol{X}^T(\boldsymbol{y}-\boldsymbol{X\hat{w}})=2\boldsymbol{X}^T(\boldsymbol{X\hat{w}}-\boldsymbol{y})</script><p>当$\boldsymbol{X}^T\boldsymbol{X}$为<a href="https://baike.baidu.com/item/%E6%BB%A1%E7%A7%A9%E7%9F%A9%E9%98%B5/10017113" target="_blank" rel="noopener">满秩矩阵(<em>full-rank matrix</em>)</a>或<a href="https://baike.baidu.com/item/%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5" target="_blank" rel="noopener">正定矩阵(<em>positive definite matrix</em>)</a>使导数为0可得:</p><script type="math/tex; mode=display">\begin{aligned}    2\boldsymbol{X}^T(\boldsymbol{X\hat{w}}-\boldsymbol{y}) = 0 \\    \implies     \boldsymbol{X}^T\boldsymbol{X\hat{w}}-\boldsymbol{X}^T\boldsymbol{y}=0 \\    \implies    \boldsymbol{X}^T\boldsymbol{X\hat{w}}=\boldsymbol{X}^T\boldsymbol{y}\\    \implies    \boldsymbol{\hat{w}}=(\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{X}^T\boldsymbol{y}\end{aligned}</script><p>令$\boldsymbol{\hat{x}_i}=(\boldsymbol{x_i},1)$则多元线性回归的模型为</p><script type="math/tex; mode=display">f(\boldsymbol{\hat{x}_i})=\boldsymbol{\hat{x}}_i^T(\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{X}^T\boldsymbol{y}</script><p>当属性值超过样本数量时将导致$\boldsymbol{X}$的列数多于行数，此时$\boldsymbol{X}^T\boldsymbol{X}$将不再是满秩矩阵，这将得出多个$\boldsymbol{\hat{w}}$都能使得均方误差最小化，而选择哪一个作为最终的解将由学习算法的归纳偏好<sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup>决定，常见的做法使引入<strong>正则化</strong>(<em>regularization</em>)，同时还可以通过减少特征属性(特征属性之间有强的相关关系)来使得矩阵满秩。</p><h3 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>梯度下降法</strong>通过迭代调整参数来达到最小化损失函数(这里讨论的为均方误差)的目的。其中<strong>梯度</strong>指的是利用梯度方向来最小化损失函数，而梯度方向指的是在此点上升最快的方向，也就是切线方向，只需要沿着这个方向的反方向则能迅速减小损失函数的值而在最后收敛直至稳定。切线的方向可以通过对整个损失函数求导得出，最后的梯度下降的过程如下：</p><script type="math/tex; mode=display">\text{repeat until converage}\{ \theta_j := \theta_j - \alpha\frac{\partial J(\theta_j)}{\partial\theta_j}\}</script><p>其中$J(\theta) = \frac{1}{2}\sum_{i=1}^m(h_\theta\big(x^{(i)}\big)-y^{(i)})^2$，$\alpha$为学习率，决定了每一次下降的步长，$h(x)$是假设函数为</p><script type="math/tex; mode=display">h_\theta(x)=\theta_o+\theta_1x_1+\theta_2x_2+\cdots+\theta_nx_n=\sum_{i=0}^n\theta_ix_i=\theta^Tx</script><p>梯度方向的计算：</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial J(\theta_j)}{\partial\theta_j} &=   \frac{\partial}{\partial\theta_j}\frac{1}{2}(h_\theta(x)-y)^2\\&= 2\cdot\frac{1}{2}(h_\theta(x)-y)\cdot\frac{\partial}{\partial\theta_j}(h_\theta(x)-y)\\&=(h_\theta(x)-y)\cdot\frac{\partial}{\partial\theta_j}\Big(\sum_{i=0}^n\theta_ix_i-y\Big)\\&=(h_\theta(x)-y)x_j\end{aligned}</script><ul><li>梯度下降<br><img src="/2019/08/12/机器学习总结/梯度下降.png" alt="梯度下降"><h4 id="梯度下降算法的运行过程"><a href="#梯度下降算法的运行过程" class="headerlink" title="梯度下降算法的运行过程"></a>梯度下降算法的运行过程</h4></li></ul><ol><li>$x_k=a$，沿着负梯度方向移动到$x_{k+1}=b$有<script type="math/tex; mode=display">b=a-\nabla F(a)\implies f(a)\geq f(b)</script></li><li>从$x_0$为出发点，每次沿着当前函数梯度反方向移动一定距离$\alpha k$，得到：<script type="math/tex; mode=display">x_0,x_1,x_2,\cdots,x_n</script></li><li>对应各点函数值的关系为:<script type="math/tex; mode=display">f(x_0)\geq f(x_1)\geq f(x_2)\geq \cdots\geq f(x_n)</script></li><li>当$n$足够大时，$f(x)$将收敛到局部最小值</li></ol><h3 id="最小二乘法和梯度下降对比"><a href="#最小二乘法和梯度下降对比" class="headerlink" title="最小二乘法和梯度下降对比"></a>最小二乘法和梯度下降对比</h3><div class="table-container"><table><thead><tr><th style="text-align:center">最小二乘法</th><th style="text-align:center">梯度下降</th></tr></thead><tbody><tr><td style="text-align:center">不需要选择$\alpha$</td><td style="text-align:center">需要选择$\alpha$</td></tr><tr><td style="text-align:center">不需要迭代</td><td style="text-align:center">需要多次迭代</td></tr><tr><td style="text-align:center">$O(n^3)$，需要计算$X^TX$的转置</td><td style="text-align:center">$O(kn^2)$</td></tr><tr><td style="text-align:center">当特征属性很多时计算很慢</td><td style="text-align:center">当特征属性很多时表现不错</td></tr></tbody></table></div><h2 id="对数几率回归"><a href="#对数几率回归" class="headerlink" title="对数几率回归"></a>对数几率回归</h2><h3 id="对数几率函数"><a href="#对数几率函数" class="headerlink" title="对数几率函数"></a>对数几率函数</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>对数几率函数</strong>是一种Sigmoid函数<sup id="fnref:8"><a href="#fn:8" rel="footnote">8</a></sup>，它将$z$值转化为一个接近0或1的$y$值，并且其输出值在$z=0$附近变化很陡。将线性回归的假设函数$h_\theta(x)=\theta^Tx$代入代入$z$使得$z=\theta^Tx$后即可得到对数几率回归的假设函数。</p><ul><li>对数几率函数<script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{-z}}</script></li><li>对数几率回归假设函数<script type="math/tex; mode=display">h_\theta(x)=\frac{1}{1+e^{(-\theta^Tx)}}</script>将$h_\theta(x)$视为$x$为正例的可能性，$1-h_\theta(x)$视为为反例的可能性，两者的比值$\frac{h_\theta(x)}{1-h_\theta(x)}$则被称为<strong>几率</strong>，这反映了$x$作为正例的相对可能性，对几率取对数可以得到<strong>对数几率</strong>(<em>log odds, logit</em>) $\log\frac{h_\theta(x)}{1-h_\theta(x)}$，即对数几率回归假设函数可一变化为:<script type="math/tex; mode=display">\begin{aligned}  \log\frac{h_\theta(x)}{1-h_\theta(x)} &= \log\Bigg(\frac{\frac{1}{1+e^{(-\theta^Tx)}}}{1-\frac{1}{1+e^{(-\theta^Tx)}}}\Bigg)\\  &=\log\Bigg(\frac{\frac{1}{1+e^{(-\theta^Tx)}}}{\frac{1+e^{(-\theta^Tx)}-1}{1+e^{(-\theta^Tx)}}}\Bigg) \\  &= \log\Big(\frac{1}{1+e^{(-\theta^Tx)}}\cdot \frac{1+e^{(-\theta^Tx)}}{e^{(-\theta^Tx)}}\Big) \\  & =\log \big(\frac{1}{e^{(-\theta^Tx)}}\big) \\  &= \log e^{\theta^Tx} \\  &= \theta^Tx\end{aligned}</script></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;用线性模型的预测结果去逼近真实标记的对数几率对应的模型就称为<strong>对数几率模型</strong>(<em>Llogitstic regression, logit regression</em>)，也称逻辑回归。这是一种分类的学习方法，有以下优点:</p><ol><li>可以直接对分类进行建模而无需对数据分布进行假设，避免了假设分布不准确造成的问题</li><li>除了能预测类别之外还可以的到近似概率预测，可以用于利用概率进行辅助决策的任务</li><li>对数函数是任意阶可导的凸函数，可以通过许多数值优化算法直接进行最优解求解。</li></ol><h3 id="对数似然函数"><a href="#对数似然函数" class="headerlink" title="对数似然函数"></a>对数似然函数</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;逻辑回归使用<strong>极大似然法</strong>进行参数估计。<a href="https://baike.baidu.com/item/%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0/6011241?fr=aladdin" target="_blank" rel="noopener"><strong>似然函数</strong></a>指的是在给定输出$x$时，关于参数$\theta$的似然函数$L(\theta|x)$(在数值上)等于给定参数$\theta$后变量$x$的概率$L(\theta|x)=p(X=x|\theta)$。在已经得到实验结果的情况下使用使该结果出现的可能性最大的$X$作为真$X$就是极大似然法。对似然函数取对数之后就是对数似然函数，使用对数可以在不改变函数的单调性的情况下降低指数函数的计算复杂度，提高计算效率。</p><ul><li>参数估计<br>假定：<script type="math/tex; mode=display">p(y=1|x;\theta)=h_\theta(x)</script><script type="math/tex; mode=display">p(y=0|x;\theta)=1-h_\theta(x)</script>合并后可得:<script type="math/tex; mode=display">p(y|x;\theta) = \big(h_\theta(x)\big)^y + \big(1-h_\theta(x))\big)^{(1-y)}</script>令$L(\theta)=p(\vec{y}|X;\theta)$，则：<script type="math/tex; mode=display">\begin{aligned}  L(\theta) &= \prod_{i=1}^mp(y^{(i)}|x^{(i)};\theta)\\  &=\prod_{i=1}^m\big(h_\theta(x^{(i)}\big)^{y^{(i)}}\big(1-h_\theta(x^{(i)})\big)^{(1-y^{(i)})}\end{aligned}</script>取对数得到对数似然函数:<script type="math/tex; mode=display">\begin{aligned}  l(\theta) &= \log L(\theta) \\  &= \sum_{i=1}^m\Big(y^{(i)}\log h(x^{(i)}) + (1-y^{(i)})\log \big(1-h(x^{(i)})\big)\Big)\end{aligned}</script></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;式$l(\theta)$是关于$\theta$的高阶可导连续凸函数，其同样可以使用梯度下降法求解最优解。</p><ul><li>求解<sup id="fnref:9"><a href="#fn:9" rel="footnote">9</a></sup><br>先对$l(\theta)$求导，$h_\theta(x)=g(\theta^Tx)$，$g(z) = \frac{1}{1+e^{-z}}$:<script type="math/tex; mode=display">\begin{aligned} \frac{\partial l(\theta)}{\partial\theta_j} &= \Big(y\frac{1}{g(\theta^Tx)} - (1-y)\frac{1}{1-g(\theta^Tx)}\Big)\frac{\partial}{\partial\theta_j}g(\theta^Tx) \\ &= \Big(y\frac{1}{g(\theta^Tx)} - (1-y)\frac{1}{1-g(\theta^Tx)}\Big)g(\theta^Tx)(1-g(\theta^Tx))\frac{\partial}{\partial\theta_j}\theta^Tx \\ &=\big(y(1-g(\theta^Tx))-(1-y)g(\theta^Tx)\big)x_j \\ &=(y-h_\theta(x))x_j\end{aligned}</script>最后的到参数优化过程为:<script type="math/tex; mode=display">repeat\{  \theta_j := \theta_j -\alpha\frac{\partial}{\partial \theta_j}l(\theta)  \}</script><script type="math/tex; mode=display">repeat\{  \theta_j := \theta_j - \alpha\sum_{i=1}^m\Big(y^{(i)}-h_\theta(x^{(i)})\Big)x_j^{(i)}  \}</script></li></ul><h2 id="K近邻算法-KNN"><a href="#K近邻算法-KNN" class="headerlink" title="K近邻算法(KNN)"></a>K近邻算法(KNN)</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>K近邻算法</strong>(<em>KNN</em>)采用测量不同特征值之间的距离<sup id="fnref:10"><a href="#fn:10" rel="footnote">10</a></sup>来进行分类，它通过将新数据的每个特征和样本集中数据对应的特征进行比较，然后通过算法提取样本集中特征最相似的<em>N</em>个数据的实际标签，通过计算(类别标签一般使用投票法，数值型的一般使用平均值)得出该数据的标签值。K近邻算法具有精确度高、对异常值不敏感、无数据输入假定的优点，但是其每次都要计算所有样本与新样本的距离且由于它无法得出模型，所以需要保存所有样本数据，这导致该算法具有极高的时间复杂度和空间复杂度。</p><h2 id="支持向量机-SVM"><a href="#支持向量机-SVM" class="headerlink" title="支持向量机(SVM)"></a>支持向量机(SVM)</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>支持向量机</strong>(<em>SVM</em>)是一种基于最大间隔来分隔数据的算法，具有泛化错误率低、计算开销小和结果易解释的优点，但是它对参数调节和核函数的选择敏感。</p><h3 id="硬间隔"><a href="#硬间隔" class="headerlink" title="硬间隔"></a>硬间隔</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分类学习是基于训练集在样本空间中找到一个划分超平面来将不同类别的样本分开，而SVM是找到离正负样本的距离都很大的超平面，即最大间隔。这个划分超平民啊可以被法向量$\boldsymbol{w}$和位移$b$决定，其中法向量$\boldsymbol{w}=(w_1;w_2;\cdots;w_d)$决定了超平面的方向，$b$决定了超平面与原点之间的距离。则划分超平面的公式为:</p><script type="math/tex; mode=display">\boldsymbol{w}^T\boldsymbol{x}+b=0</script><p>该公式来源如下:<br><img src="/2019/08/12/机器学习总结/点到平面距离.png" alt="点到平面距离"></p><ul><li>在$R^3$的空间里，一个平面可以由平面上一个点$P_0$以及一个垂直平面的法向量$w$确定</li><li>任意取平面上一个点$P$从原点到$P$，$P_0$做两个向量$x$,$x_0$<br>因为法向量垂直于平面，所以可得:<script type="math/tex; mode=display">\begin{aligned}  \vec{w}\cdot(\vec{x}-\vec{x_0})&=0 \\  \vec{w}\cdot\vec{x}-\vec{w}\cdot\vec{x_0}&=0\end{aligned}</script>令$b=-\vec{w}\cdot\vec{x_0}$可得:<script type="math/tex; mode=display">\vec{w}\cdot\vec{x}+b=0</script>推广到$R^n$即可得到上式。</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设超平面能将样本正确分类，即对于样本$(x_i,y_i)\in D$，若$y_i=+1$,则有$\boldsymbol{w}^T\boldsymbol{x}_i+b&gt;0$；若$y_i=-11$,则有$\boldsymbol{w}^T\boldsymbol{x}_i+b&lt;0$。令:</p><script type="math/tex; mode=display">\begin{cases}    \boldsymbol{w}^T\boldsymbol{x}_i + b \ge +1, y_i=+1\\     \boldsymbol{w}^T\boldsymbol{x}_i + b \le -1, y_i=-1\end{cases}</script><p>距离超平面最近的几个训练样本点使得上式的等号成立，这几个点被称为<strong>支持向量</strong>(<em>support vector</em>)。两个异类支持向量到超平面的距离之和称为<strong>间隔</strong>(<em>margin</em>)，可由样本空间中任意点$x$到超平面的距离公式推导出来:</p><ul><li><p>任意点到超平面的距离</p><script type="math/tex; mode=display">r=\frac{|\boldsymbol{w}^T\boldsymbol{x}+b|}{\|\boldsymbol{w}\|}</script><p>此公式可通过点到平面的距离推广</p></li><li><p>异类支持向量到超平面的距离之和</p><script type="math/tex; mode=display">\gamma=\frac{2}{\|\boldsymbol{w}\|}</script><p>2是因为支持向量取等号所以距离为1，两个之和即为2</p></li><li><p>支持向量与间隔<br><img src="/2019/08/12/机器学习总结/支持向量与间隔.png" alt="支持向量与间隔"></p></li></ul><h4 id="最优化问题"><a href="#最优化问题" class="headerlink" title="最优化问题"></a>最优化问题</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;寻找划分超平面的最大间隔(<em>maximum margin</em>)即是求解$\boldsymbol{w}$和$b$在满足约束条件的情况下$\gamma$的最大值。</p><script type="math/tex; mode=display">\begin{cases}    \max_{\boldsymbol{w},b}\frac{2}{\|\boldsymbol{w}\|} \\    \\    s.t. \ y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)\ge1 \  i=1,2,\cdots,m\end{cases}</script><p>其中最大化$\frac{2}{|\boldsymbol{w}|}$等价于最小化$\frac{1}{2}|\boldsymbol{w}|^2$，则上式等价于:</p><script type="math/tex; mode=display">\begin{cases}    \min_{\boldsymbol{w},b}\frac{1}{2}\|\boldsymbol{w}\|^2 \\    \\    s.t. \ y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)\ge1 \  i=1,2,\cdots,m\end{cases}</script><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上述问题是一个凸二次优化(<em>convex quadratic programming</em>)问题，可以通过使用拉格朗日乘子法<sup id="fnref:11"><a href="#fn:11" rel="footnote">11</a></sup>来求解其对偶问题(<em>dual problem</em>)。具体做法是对每条约束添加拉格朗日乘子$\alpha_i\ge0$得$\alpha_i(1-y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b))$，则该问题的拉格朗日函数为:</p><script type="math/tex; mode=display">l(\boldsymbol{w},b, \boldsymbol{\alpha}) = \frac{1}{2}\|\boldsymbol{w}\|^2 + \sum_{i=1}^m\alpha_i(1-y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b))</script><p>其中$\boldsymbol{\alpha}=(\alpha_1;\alpha_2;\cdots;\alpha_m)$<br>因为原问题是极小极大$\min_{\boldsymbol{w},b}\max_\boldsymbol{\alpha}l(\boldsymbol{w},b, \boldsymbol{\alpha})$，转换成对偶问题则是求极大极小$\max_\boldsymbol{\alpha}\min_{\boldsymbol{w},b}l(\boldsymbol{w},b, \boldsymbol{\alpha})$，所以求极小值先令$l(\boldsymbol{w},b, \boldsymbol{\alpha})$对$\boldsymbol{w}$和$b$的偏导分别为0，然后代入$l(\boldsymbol{w},b, \boldsymbol{\alpha})$后即可:</p><script type="math/tex; mode=display">\begin{aligned}    \frac{\partial}{\partial\boldsymbol{w}}l(\boldsymbol{w},b, \boldsymbol{\alpha}) &= \boldsymbol{w} - \sum_{i=1}^m\alpha_iy_i\boldsymbol{x}_i =0 \\    \implies \boldsymbol{w} &= \sum_{i=1}^m\alpha_iy_i\boldsymbol{x}_i\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}    \frac{\partial}{\partial b}l(\boldsymbol{w},b, \boldsymbol{\alpha}) &= \sum_{i=1}^m\alpha_iy_i=0  \\    \implies 0 &= \sum_{i=1}^m\alpha_iy_i\end{aligned}</script><p>将得到的结果代入$l(\boldsymbol{w},b, \boldsymbol{\alpha})$进行化解:</p><script type="math/tex; mode=display">\begin{aligned}    l(\boldsymbol{w},b, \boldsymbol{\alpha}) &= \frac{1}{2}\|\boldsymbol{w}\|^2 + \sum_{i=1}^m\alpha_i(1-y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)) \\    &=\frac{1}{2}\boldsymbol{w}^T\boldsymbol{w}+\sum_{i=1}\alpha_i-\boldsymbol{w}^T\sum_1^m\alpha_iy_i\boldsymbol{x}_i-b\sum_{i=1}^m\alpha_iy_i \\    &=\frac{1}{2}\boldsymbol{w}^T\sum_{i=1}^m\alpha_iy_i\boldsymbol{x}_i+\sum_{i=1}\alpha_i-\boldsymbol{w}^T\sum_1^m\alpha_iy_i\boldsymbol{x}_i-b\cdot0\\    &= \sum_{i=1}\alpha_i - \frac{1}{2}\Big(\sum_{i=1}^m\alpha_iy_i\boldsymbol{x}_i\Big)^T\sum_{i=1}^m\alpha_iy_i\boldsymbol{x}_i \\    &=\sum_{i=1}\alpha_i - \frac{1}{2}\sum_{i,j=1}^m\alpha_i\alpha_jy_iy_j\boldsymbol{x}_i^T\boldsymbol{x}_j\end{aligned}</script><p>最后得到对偶问题的解为:</p><script type="math/tex; mode=display">\begin{cases}    \max_{\boldsymbol{\alpha}}\sum_{i=1}^m\alpha_i - \frac{1}{2}\sum_{i,j=1}^m\alpha_i\alpha_jy_iy_j\boldsymbol{x}_i^T\boldsymbol{x}_j \\    \\    s.t. \sum_{i=1}^m\alpha_iy_i=0 \\    \\    \alpha_i \ge0, \ i=1,2,\cdots,m\end{cases}</script><p>解出$\boldsymbol{\alpha}$后求出$\boldsymbol{w}$和$b$即可得到模型:</p><script type="math/tex; mode=display">f(x) = \sum_{i=1}^m\alpha_iy_i\boldsymbol{x}_i^T\boldsymbol{x}+b</script><p>通过求解对偶问题，将原问题对$\boldsymbol{w}$的求解转化成对$\boldsymbol{\alpha}$的求解，将纬度从特征数量(和$\boldsymbol{x}$的属性一致)转变为样本数量，因为原问题存在不等式约束。所以求解后同样需要满足KKT(<em>Karush-Kuhn-Tucker</em>)条件:</p><script type="math/tex; mode=display">\begin{cases}    \alpha_i\ge0 \\    y_if(\boldsymbol{x}_i)-1\ge0\\    \alpha_i(y_if(\boldsymbol{x}_i)-1)=0\end{cases}</script><p>由约束条件可知对于任意训练样本$\boldsymbol{x}_i,y_i$总有$\alpha_i=0$或$y_if(\boldsymbol{x}_i)=1$;若$\alpha_i=0$则不会对$f(\boldsymbol{x})$有影响；若$\alpha_i&gt;0$，则一定有$y_if(\boldsymbol{x}_i)=1$，所对应的样本点位于最大间隔边界上是一个支持向量。所以在支持向量训练完之后大部分样本都不需要保留。</p><h3 id="软间隔"><a href="#软间隔" class="headerlink" title="软间隔"></a>软间隔</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;硬间隔假定训练样本在样本空间是线性可分的，存在一个超平面将不同类的样本完全划分开。<strong>软间隔</strong>(<em>soft margin</em>)则允许部分样本被错误分类，以此缓解强制线性可分造成的过拟合和解决线性不可分问题。软件隔允许某些样本不满足约束$y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)\ge1$，最后的优化目标将不同于硬间隔:</p><script type="math/tex; mode=display">\min_{\boldsymbol{w},b}\frac{1}{2}\|\boldsymbol{w}\|^2 + C\sum_{i=1}^ml_{0/1}(y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)-1)</script><p>其中$C&gt;0$为常数，当$C$无穷大时上式等同于$\min_{\boldsymbol{w},b}\frac{1}{2}|\boldsymbol{w}|^2$；当$C$取有限值时则表示允许一些样本不满足约束。$l_{0/1}$是0/1损失函数:</p><script type="math/tex; mode=display">l_{0/1}(z) = \left\{  \begin{array}{lr}    1 & ,\ z < 0\\    0 & ,\  其它  \end{array}\right.</script><p>$l_{0/1}$具有非凸、非连续性等不太好的数学性质使得软间隔的优化不易求解，所以使用一些<strong>替代损失</strong>(<em>surrogate loss</em>)函数<sup id="fnref:12"><a href="#fn:12" rel="footnote">12</a></sup>来代替$l_{0/1}$，这些函数是凸的连续函数且是$l_{0/1}$的上界:</p><ul><li>hinge损失<script type="math/tex; mode=display">l_{hinge}(z)=max(0, 1-z)</script></li><li>指数损失(<em>exponential loss</em>)<script type="math/tex; mode=display">l_{exp}(z)=exp(-z)</script></li><li>对率损失(<em>logistic loss</em>)<script type="math/tex; mode=display">l_{log}(z)=log(1+exp(-z))</script>最后引入<strong>松弛变量</strong>(<em>slack variables</em>)$\varepsilon_i\ge0$即可得到<strong>软间隔支持向量机</strong>，将优化目标重写为:<script type="math/tex; mode=display">\begin{cases}  \min_{\boldsymbol{w},b,\varepsilon}\frac{1}{2}\|\boldsymbol{w}\|^2+C\sum_{i=1}^m\varepsilon_i\\  \\  s.t. \ y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)\ge 1-\varepsilon_i \\  \\  \varepsilon_i\ge0,\ i=1,2,\cdots,m\end{cases}</script></li><li>软间隔<br><img src="/2019/08/12/机器学习总结/软间隔.png" alt="软间隔"></li><li>替代损失函数<br><img src="/2019/08/12/机器学习总结/替代损失函数.png" alt="替代损失函数"></li></ul><h4 id="软间隔的最优化"><a href="#软间隔的最优化" class="headerlink" title="软间隔的最优化"></a>软间隔的最优化</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对每条约束$y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)\ge 1-\varepsilon_i $添加拉格朗日乘子$\alpha_i\ge0$得$\alpha_i(1-\varepsilon_iy_i(\boldsymbol{w}^T\boldsymbol{x}_i+b))$;对每条约束$\varepsilon_i\ge0$添加拉格朗日乘子$\multimap_i$得$-\mu_i\varepsilon_i$，最后得到拉格朗日函数为:</p><script type="math/tex; mode=display">L(\boldsymbol{w},b,\boldsymbol{\alpha},\boldsymbol{\varepsilon},\boldsymbol{\mu})=\frac{1}{2}\|\boldsymbol{w}\|^2+C\sum_{i=1}^m\varepsilon_i+\sum_{i=1}^m\alpha_i(1-\varepsilon_iy_i(\boldsymbol{w}^T\boldsymbol{x}_i+b))-\sum_{i=1}^m\mu_i\varepsilon_i</script><p>令$L(\boldsymbol{w},b,\boldsymbol{\alpha},\boldsymbol{\varepsilon},\boldsymbol{\mu})$分别对$\boldsymbol{w}$、$b$、$\varepsilon_i$的偏导为零可得:</p><script type="math/tex; mode=display">\begin{aligned}    \boldsymbol{w}&=\sum_{i=1}^m\alpha_iy_i\boldsymbol{x}_i \\    0&=\sum_{i=1}^m\alpha_iy_i \\    C&=\alpha_i+\mu_i\end{aligned}</script><p>将其代入$L(\boldsymbol{w},b,\boldsymbol{\alpha},\boldsymbol{\varepsilon},\boldsymbol{\mu})$中可得对偶问题:</p><script type="math/tex; mode=display">\begin{cases}    \max_\alpha \sum_{i=1}^m\alpha_i -\frac{1}{2}\sum_{i,j=1}^m\alpha_i\alpha_jy_iy_i\boldsymbol{x}_i^T\boldsymbol{x}_j \\    \\    s.t. \ \sum_{i=1}^m\alpha_iy_i=0 \\    \\    0\le\alpha_i\le C, \ i=1,2,\cdots,m\end{cases}</script><h3 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;硬间隔解决了严格线性可分的问题，而软间隔解决了非严格线性可分的问题，这些都是在当前样本空间能够找到一个划分超平面能将训练样本正确分类，而<strong>核函数</strong>则是为了解决线性不可分问题，即在当前样本空间找不到这样一个划分超平面来划分训练样（“异或”问题），它将样本从原始空间映射到一个更高维的特征空间使得样本在这个特征空间里线性可分<sup id="fnref:13"><a href="#fn:13" rel="footnote">13</a></sup>。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;令$\phi(\boldsymbol{x})$表示将$\boldsymbol{x}$映射后的特征向量，则在特征空间中划分超平面对应的模型为:</p><script type="math/tex; mode=display">f(x)=\boldsymbol{w}^T\phi(\boldsymbol{x})+b</script><p>同理，优化目标可以写为:</p><script type="math/tex; mode=display">\begin{cases}    \min_{\boldsymbol{w},b}\frac{1}{2}\|\boldsymbol{w}\|^2 \\    \\    s.t. \ y_i\big(\boldsymbol{w}^T\phi(\boldsymbol{x}_i)+b\big)\ge1, \ i=1,2,\cdots,m\end{cases}</script><p>对偶问题为:</p><script type="math/tex; mode=display">\begin{cases}    \max_{\boldsymbol{\alpha}}\sum_{i=1}^m\alpha_i-\frac{1}{2}\sum_{i,j=1}^m\alpha_i\alpha_jy_iy_j\phi(\boldsymbol{x}_i)^T\phi(\boldsymbol{x}_j) \\    \\    s.t.\ \sum_{i=1}^m\alpha_iy_i=0, \\    \\    \alpha_i \ge0, \ i=1,2,\cdots,m\end{cases}</script><p>式中计算$\phi(\boldsymbol{x}_i)^T\phi(\boldsymbol{x}_j)$是指的样本$\boldsymbol{x}_i$和$\boldsymbol{x}_j$映射到高维特征空间之后的内积，因为映射后的空间维数可能很高（可能无穷维）而导致$\phi(\boldsymbol{x}_i)^T\phi(\boldsymbol{x}_j)$计算困难,所以设计核函数<sup id="fnref:14"><a href="#fn:14" rel="footnote">14</a></sup>如下:</p><script type="math/tex; mode=display">\kappa(\boldsymbol{x}_i,\boldsymbol{x}_j)=\langle\phi(\boldsymbol{x}_i),\phi(\boldsymbol{x}_j)\rangle=\phi(\boldsymbol{x}_i)^T\phi(\boldsymbol{x}_j)</script><p>即$\boldsymbol{x}_i$和$\boldsymbol{x}_j$的内积等于它们在原始样本空间中通过函数$\kappa(\cdot,\cdot)$计算的结果，这样就不用去计算高维特征中的内积。上面的对偶问题则可以改写为如下形式:</p><script type="math/tex; mode=display">\begin{cases}   \max_{\boldsymbol{\alpha}}\sum_{i=1}^m\alpha_i-\frac{1}{2}\sum_{i,j=1}^m\alpha_i\alpha_jy_iy_j\kappa(\boldsymbol{x}_i,\boldsymbol{x}_j)\\   \\   s.t.\ \sum_{i=1}^m\alpha_iy_i=0\\   \\   \alpha_i \ge0,\ i=1,2,\cdots,m\end{cases}</script><p>最后求解得到模型为:</p><script type="math/tex; mode=display">\begin{aligned}    f(\boldsymbol{x})&=\boldsymbol{w}^T\phi(\boldsymbol{x})+b\\    &=\sum_{i=1}^m\alpha_iy_i\phi(\boldsymbol{x})^T\phi(\boldsymbol{x})+b\\    &=\sum_{i=1}^m\alpha_iy_i\kappa(\boldsymbol{x}_i,\boldsymbol{x}_j)+b\end{aligned}</script><ul><li>常见核函数</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">名称</th><th style="text-align:center">表达式</th><th style="text-align:center">参数</th></tr></thead><tbody><tr><td style="text-align:center">线性核</td><td style="text-align:center">$\kappa(\boldsymbol{x}_i,\boldsymbol{x}_j)=\boldsymbol{x}_i^T\boldsymbol{x}_j$</td></tr><tr><td style="text-align:center">多项式核</td><td style="text-align:center">$\kappa(\boldsymbol{x}_i,\boldsymbol{x}_j)=(\boldsymbol{x}_i^T\boldsymbol{x}_j)^d$</td><td style="text-align:center">$d\ge1为多项式的次数，d=1退化为线性核$</td></tr><tr><td style="text-align:center">高斯核(RBF核)</td><td style="text-align:center">$\kappa(\boldsymbol{x}_i,\boldsymbol{x}_j)=\exp(-\frac{&#124;\boldsymbol{x}_i-\boldsymbol{x}_j&#124;^2}{2\sigma^2})$</td><td style="text-align:center">$\sigma&gt;0$为高斯核的带宽</td></tr><tr><td style="text-align:center">拉普拉斯核</td><td style="text-align:center">$\kappa(\boldsymbol{x}_i,\boldsymbol{x}_j)=\exp(-\frac{&#124;\boldsymbol{x}_i-\boldsymbol{x}_j&#124;}{\sigma})$</td><td style="text-align:center">$\sigma&gt;0$</td></tr><tr><td style="text-align:center">Sigmoid核</td><td style="text-align:center">$\kappa(\boldsymbol{x}_i,\boldsymbol{x}_j)=\tanh(\beta\boldsymbol{x}_i^T\boldsymbol{x}_j+\theta)$</td><td style="text-align:center">$\tanh$为双曲正切函数，$\beta&gt;0$,$\theta&lt;0$</td></tr></tbody></table></div><p>核函数可以相互组合形成新的核函数。</p><ul><li>异或问题<br><img src="/2019/08/12/机器学习总结/异或问题.png" alt="异或问题"></li></ul><h3 id="SMO"><a href="#SMO" class="headerlink" title="SMO"></a>SMO</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>SMO</strong>(<em>Sequential Minimal Optimization</em>)表示最小序列优化<sup id="fnref:15"><a href="#fn:15" rel="footnote">15</a></sup>，它将大优化问题分解为多个小优化问题来求解。SMO的目标是求解出一系列的$\alpha$和$b$然后计算权重向量$w$最后得到划分超平面。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因为在对偶问题中存在约束$\sum_{i=1}^m\alpha_iy_i=0$，若固定$\alpha_i$之外的其它变量则$\alpha_i$可由其它变量导出，所以SMO的基本思路为先固定$\alpha_i$之外的所有参数然后求$\alpha_i$的极值。因为改变一个$\alpha$会使得约束失效，所以SMO选择同时改变两个$\alpha$。则SMO的一般步骤为:</p><ol><li>选取一对需要更新的变量$\alpha_i$和$\alpha_j$</li><li>固定$\alpha_i$和$\alpha_j$以外的参数，求解对偶问题然后获得更新后的$\alpha_i$和$\alpha_j$</li><li>重复上面的步骤直至收敛<br>只需要选取$\alpha_i$和$\alpha_j$中有一个不满足KKT条件，目标函数就会在迭代后减小。KKT条件违背的程度越大，则变量更新后可能导致的目标函数值减幅越大。所以SMO先选取违背KKT条件程度最大的变量，第二个变量应选择一个使目标函数值减小最快的变量。SMO采用一种启发式的算法：选取的两变量所对应样本之间的间隔最大。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当仅考虑$\alpha_i$和$\alpha_j$时，约束<script type="math/tex; mode=display">\begin{cases} s.t. \sum_{i=1}^m\alpha_iy_i=0 \\ \\ \alpha_i \ge0, \ i=1,2,\cdots,m\end{cases}</script>可重写为:<script type="math/tex; mode=display">\alpha_iy_i+\alpha_jy_j=c,\ \alpha_i\ge0,\ \alpha_j\ge=0</script>其中<script type="math/tex; mode=display">c = -\sum_{k\ne i,j}\alpha_ky_k</script>是使$\sum_{i=1}^m\alpha_iy_i=0$的常数，将重写后的约束$\alpha_iy_i+\alpha_jy_j=c$代入原对偶问题可以消去变量$\alpha_j$，最后变成一个关于$\alpha_i$的单变量二次规划问题，并且只剩下一个$\alpha_i\ge0$的约束。这样的问题是具有闭式解的。</li></ol><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;偏移量$b$可以通过支持向量求解。对任意的支持向量都有$(\boldsymbol{x}_s,y_s)$都有$y_sf(\boldsymbol{x}_s)=1$，即为:</p><script type="math/tex; mode=display">y_s\Big(\sum_{i\in S}\alpha_iy_i\boldsymbol{x}_i^T\boldsymbol{x}_s+b\Big)=1</script><p>其中$S=\{i|\alpha_i&gt;0,i=1,2,\cdots,m\}$为所有支持向量的下标集。可以选取任意支持向量直接求的$b$，但现实任务中往往使用所有支持向量求解的平均值这一更具有鲁棒性的方法:</p><script type="math/tex; mode=display">b=\frac{1}{|S|}\sum_{s\in S}\Big(y_s-\sum_{i\in S}\alpha_iy_i\boldsymbol{x}_i^T\boldsymbol{x}_s\Big)</script><h1 id="不搞了"><a href="#不搞了" class="headerlink" title="不搞了"></a>不搞了</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">即有放回采样</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;">$\boldsymbol{I}$为指示函数，成立时取值为$1$</span><a href="#fnref:2" rev="footnote"> ↩</a></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">3.</span><span style="display: inline-block; vertical-align: top;">均等代价的度量方式如一般的错误率都是直接计算错误次数</span><a href="#fnref:3" rev="footnote"> ↩</a></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">4.</span><span style="display: inline-block; vertical-align: top;">归一化是指将不同范围的值映射到相同的固定范围中，常见为$[0,1]$</span><a href="#fnref:4" rev="footnote"> ↩</a></li><li id="fn:5"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">5.</span><span style="display: inline-block; vertical-align: top;">原文中为$d_{cen}(\boldsymbol{\mu}_i,\boldsymbol{\mu}_j)$，这里应该计算的是两个聚类中心之间的距离，我个人觉得依照上面定义的定义会更好理解，具体可参考<a href="https://en.wikipedia.org/wiki/Davies%E2%80%93Bouldin_index" target="_blank" rel="noopener">维基百科</a></span><a href="#fnref:5" rev="footnote"> ↩</a></li><li id="fn:6"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">6.</span><span style="display: inline-block; vertical-align: top;">这里计算的是回归算法中的偏差和方差</span><a href="#fnref:6" rev="footnote"> ↩</a></li><li id="fn:7"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">7.</span><span style="display: inline-block; vertical-align: top;">机器学习算法在学习过程中对某种类型假设的偏好称为归纳偏好(<em>inductive bias</em>)</span><a href="#fnref:7" rev="footnote"> ↩</a></li><li id="fn:8"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">8.</span><span style="display: inline-block; vertical-align: top;">Sigmoid函数指的是形似$S$的函数</span><a href="#fnref:8" rev="footnote"> ↩</a></li><li id="fn:9"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">9.</span><span style="display: inline-block; vertical-align: top;">$g'(z) = (\frac{1}{1+e^(-z)})'= \frac{e^{-z}}{(1+e^{-z})^2}$，将$g(z) = \frac{1}{1+e^{-z}}$代入简化后得$g'(z)=g(z)\big(1-g(z)\big)$</span><a href="#fnref:9" rev="footnote"> ↩</a></li><li id="fn:10"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">10.</span><span style="display: inline-block; vertical-align: top;">距离计算见<a href="http://coldjune.com/2019/08/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/#%E8%B7%9D%E7%A6%BB%E8%AE%A1%E7%AE%97">模型评估与选择-性能度量-聚类距离计算</a>,这里一般用的是欧式距离</span><a href="#fnref:10" rev="footnote"> ↩</a></li><li id="fn:11"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">11.</span><span style="display: inline-block; vertical-align: top;"><a href="https://baike.baidu.com/item/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0%E6%B3%95/8550443?fr=aladdin" target="_blank" rel="noopener">拉格朗日乘子法</a>将一个有n个变量与k个约束条件的最优化问题转换为一个有n + k个变量的方程组的极值问题，其变量不受任何约束</span><a href="#fnref:11" rev="footnote"> ↩</a></li><li id="fn:12"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">12.</span><span style="display: inline-block; vertical-align: top;">采用hinge损失则软间隔优化目标变为$\min_{\boldsymbol{w},b}\frac{1}{2}|\boldsymbol{w}|^2+C\sum_{i=1}^m\max(0,1-y_i(\boldsymbol{w}^Tx_i+b))$</span><a href="#fnref:12" rev="footnote"> ↩</a></li><li id="fn:13"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">13.</span><span style="display: inline-block; vertical-align: top;">如果原始空间是有限维则一定存在一个高维特征空间使样本可分</span><a href="#fnref:13" rev="footnote"> ↩</a></li><li id="fn:14"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">14.</span><span style="display: inline-block; vertical-align: top;">令$\chi$为输入空间，$\kappa(\cdot,\cdot)$是定义在$\chi\times\chi$上的对称函数，则$\kappa$是核函数当且仅当对于任意数据$D={\boldsymbol{x}_1,\boldsymbol{x}_2,\cdots,\boldsymbol{x}_m}$，核矩阵(<em>kernel matrix</em>)$K$是半正定的。即只要一个对称函数所对应的核矩阵是半正定的，它就能作为<a href="https://baike.baidu.com/item/%E6%A0%B8%E5%87%BD%E6%95%B0/4693132?fr=aladdin" target="_blank" rel="noopener">核函数</a>使用。</span><a href="#fnref:14" rev="footnote"> ↩</a></li><li id="fn:15"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">15.</span><span style="display: inline-block; vertical-align: top;">SMO的实现可以参考<a href="http://coldjune.com/2018/05/22/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-SVM/">支持向量机(SVM)</a>，这是根据机器学习实战写的博文。</span><a href="#fnref:15" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      对自己接触和学习到的机器学习算法相关知识点进行一个梳理和总结
    
    </summary>
    
      <category term="机器学习" scheme="http://coldjune.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://coldjune.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>House Prices: Advanced Regression Techniques(2)</title>
    <link href="http://coldjune.com/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/"/>
    <id>http://coldjune.com/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/</id>
    <published>2019-06-27T11:30:00.000Z</published>
    <updated>2019-08-06T12:02:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;书接上文，在前文中我们已经了解到机器学习需要经历的基本过程，其中占据大部分篇幅的是数据分析和数据处理的部分，模型的训练反而占比不大。这其中的原因除了因为特征工程在机器学习的整个过程中应有如此大的比重之外，还因为之前训练的模型都是一些简单模型，并不涉及到大量参数的调试。而这里使用的集成学习将会涉及到不少的参数需要调节。</p><h1 id="集成学习概述"><a href="#集成学习概述" class="headerlink" title="集成学习概述"></a>集成学习概述</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;既然已经单独将这部分内容提了出来，那么在进入正式的调参之前，我们先简要看看集成学习是个什么东西吧。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>集成学习</strong>通过构建并结合多个学习器来完成学习任务，其先产生一组“个体学习器”，再用某种策略将它们结合起来。集成的方式又分为<strong>同质集成</strong>和<strong>异质集成</strong>。<strong>同质集成</strong>只包含相同类型的个体学习器，其个体学习器也称为“基学习器”；<strong>异质集成</strong>中的个体学习器是不同类型的，其被称为“组件学习器”。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据个体学习器的生成方式集成学习又可以分为两大类，一种是串行生成的序列化方法，其个体学习器之间存在强依赖关系，代表为<strong>Boosting</strong>；另一种是同时生成的并行化方法，其个体学习器之间不存在强依赖关系，代表有<strong>Bagging</strong>和<strong>Random Forest</strong>。<strong>Boosting</strong>是一族可将弱学习器提升为强学习器的算法，它先从初始训练集训练出一个基学习器，再根据其表现调整训练样本的分布，即重新分配每个样本的权重，使表现不好的样本在下次训练时得到更多的关注，直至达到预定的训练次数，最后将所有的基学习器进行加权结合；<strong>Boosting</strong>每一次都是使用的全量数据，而<strong>Bagging</strong>却并不是，它采用有放回的采样的方式来生成训练集，每个基学习器使用不同的训练集来进行训练，有放回的采样使得同一个数据集能够被多次使用从而训练出不同的模型，最后可以通过<em>投票</em>(分类)和<em>平均</em>(回归)来结合各个基学习器的结果；<strong>Random Forest</strong>(RF)是在<strong>Bagging</strong>的基础上进一步在决策树的训练过程中引入随机属性选择,传统的决策树选择划分属性时是在当前节点的属性集合中选择一个最优属性，而在<strong>RF</strong>中是先从该结点的属性集合中随机选择一个包含<em>k</em>个属性的子集，再从子集中选择最优属性。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;集成学习还有很多细节上的东西，包括<strong>Boosting</strong>和<strong>Bagging</strong>的训练过程，基学习器预测结果的结合方式等等，在这里就不再进行一一陈述了。下面让我们进入主题——集成模型的训练吧。</p><h1 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我先创建了一个公用方法，其目的是为了画出网格搜索($GridSearch$)过程中的平均准确率和准确率的变异系数<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>。这两个分数是比较简单的用于衡量一个回归模型好坏的指标，这里将测试和训练进行了对比展示，从而对模型的泛化能力进行评估，对参数选择做出决断。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">def plot_acc_4_grid(grid_cv, param):</span><br><span class="line">        fig = plt.figure(figsize=(10, 10))</span><br><span class="line">        mean_acc = fig.add_subplot(2,1,1)</span><br><span class="line">        std_acc = fig.add_subplot(2,1,2)</span><br><span class="line">        # 训练参数个数</span><br><span class="line">        params_num = len(grid_cv.cv_results_[&apos;params&apos;])</span><br><span class="line">        x_ticks = np.arange(params_num)</span><br><span class="line">        # 把每一次的参数作为横坐标label</span><br><span class="line">        score_label = [list(grid_cv.cv_results_[&apos;params&apos;][i].values())[0] for i in range(params_num)]</span><br><span class="line">        # 平均精确度</span><br><span class="line">        mean_train_score = grid_cv.cv_results_[&apos;mean_train_score&apos;]</span><br><span class="line">        mean_test_score =  grid_cv.cv_results_[&apos;mean_test_score&apos;]</span><br><span class="line">        # 方差</span><br><span class="line">        std_train_score = grid_cv.cv_results_[&apos;std_train_score&apos;]</span><br><span class="line">        std_test_score = grid_cv.cv_results_[&apos;std_test_score&apos;]</span><br><span class="line"></span><br><span class="line">        mean_acc.plot(mean_train_score, &apos;r-o&apos;, label=&apos;mean_train_score&apos;)</span><br><span class="line">        mean_acc.plot(mean_test_score , &apos;b-o&apos;, label=&apos;mean_test_score&apos;)</span><br><span class="line">        mean_acc.set_title(&apos;mean_acc@&apos;+param, fontsize=18)</span><br><span class="line">        mean_acc.set_xticks(x_ticks)</span><br><span class="line">        mean_acc.set_xticklabels(score_label)</span><br><span class="line">        mean_acc.set_xlabel(param, fontsize=18)</span><br><span class="line">        mean_acc.set_ylabel(&apos;mean_acc&apos;, fontsize=18)</span><br><span class="line">        mean_acc.legend(loc=&apos;best&apos;, fontsize=18)</span><br><span class="line">        mean_acc.grid()</span><br><span class="line"></span><br><span class="line">        std_acc.plot(std_train_score,&apos;r-*&apos;, label=&apos;std_train_score&apos;)</span><br><span class="line">        std_acc.plot(std_test_score, &apos;b-*&apos;, label=&apos;std_test_score&apos;)</span><br><span class="line">        std_acc.set_title(&apos;std_acc@&apos;+param, fontsize=18)</span><br><span class="line">        std_acc.set_xticks(x_ticks)</span><br><span class="line">        std_acc.set_xticklabels(score_label)</span><br><span class="line">        std_acc.set_xlabel(param, fontsize=18)</span><br><span class="line">        std_acc.set_ylabel(&apos;std_acc&apos;, fontsize=18)</span><br><span class="line">        std_acc.legend(loc=&apos;best&apos;, fontsize=18)</span><br><span class="line">        std_acc.grid()</span><br><span class="line"></span><br><span class="line">        plt.subplots_adjust(hspace=0.5)</span><br></pre></td></tr></table></figure></p><h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们先来尝试一下上面提到的随机森林，这里主要关注的是影响性能的几个参数，罗列如下：</p><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;        text-align: left;        word-wrap:break-word;        word-break:break-all;        white-space:normal;        max-width:650px;        font-family:SimSun;    }    .dataframe thead th {        text-align: center;    }</style><table class="dataframe" style="margin:auto; width:100%;">    <thead>        <tr>            <th>参数</th>            <th>详情</th>        </tr>    </thead>    <tbody>        <tr>            <th>n_estimators</th>            <th>子模型的数量<br>&nbsp;&nbsp;&nbsp;&nbsp;• integer(n_estimators≥1)<br>            &nbsp;&nbsp;&nbsp;&nbsp;* 默认值为10            </th>        </tr>        <tr>            <th>max_depth</th>            <th>树的最大深度<br>            &nbsp;&nbsp;&nbsp;&nbsp;• integer(max_depth≥1)<br>            &nbsp;&nbsp;&nbsp;&nbsp;• None(树会生长到所有叶子节点都分到一个类或者某节点所代表的样本数据已小于min_samples_split)<br>            &nbsp;&nbsp;&nbsp;&nbsp;* 默认值为None            </th>        </tr>        <tr>            <th>max_features</th>            <th>在寻找最佳划分时考虑的最大特征数<br>            &nbsp;&nbsp;&nbsp;&nbsp;• integer(n_features≥max_features≥1)<br>            &nbsp;&nbsp;&nbsp;&nbsp;• float(占所有特征的百分比)<br>            &nbsp;&nbsp;&nbsp;&nbsp;• "auto"(n_features，即所有特征)<br>            &nbsp;&nbsp;&nbsp;&nbsp;• "sqrt"(max_features=sqrt(n_features)<br>            &nbsp;&nbsp;&nbsp;&nbsp;• "log2"(max_features=log2(n_features))<br>            &nbsp;&nbsp;&nbsp;&nbsp;• None(n_features，即所有特征)<br>            &nbsp;&nbsp;&nbsp;&nbsp;* 默认值为"auto"            </th>        </tr>        <tr>            <th>min_samples_split</th>            <th>内部节点分裂所需的最小样本数<br>            &nbsp;&nbsp;&nbsp;&nbsp;• integer(min_samples_split≥2)<br>            &nbsp;&nbsp;&nbsp;&nbsp;• float(ceil(min_samples_split * n_samples)，即占所有样本的百分比向下取整)<br>            &nbsp;&nbsp;&nbsp;&nbsp;* 默认值为2            </th>        </tr>        <tr>            <th>max_leaf_nodes</th>            <th>最大叶节点数<br>            &nbsp;&nbsp;&nbsp;&nbsp;• integer(max_leaf_nodes≥1)<br>            &nbsp;&nbsp;&nbsp;&nbsp;• None(不限制叶节点个数)<br>            &nbsp;&nbsp;&nbsp;&nbsp;* 默认值为None            </th>        </tr>        <tr>            <th>min_weight_fraction_leaf</th>            <th>叶节点最小样本权重总值<br>            &nbsp;&nbsp;&nbsp;&nbsp;• float(权重总值)<br>            &nbsp;&nbsp;&nbsp;&nbsp;* 默认值为0            </th>        </tr>        <tr>            <th>min_samples_leaf</th>            <th>叶节点最小样本数<br>            &nbsp;&nbsp;&nbsp;&nbsp;• integer(min_samples_leaf≥1)<br>            &nbsp;&nbsp;&nbsp;&nbsp;• float(ceil(min_samples_leaf * n_samples)，即占所有样本的百分比向下取整)<br>            &nbsp;&nbsp;&nbsp;&nbsp;* 默认值为1            </th>        </tr>        <tr>            <th>bootstrap</th>            <th>是否使用bootstrap对样本进行采样<br>            &nbsp;&nbsp;&nbsp;&nbsp;• False(所有子模型的样本一致，子模型强相关)<br>            &nbsp;&nbsp;&nbsp;&nbsp;• True(每个子模型的样本从总样本中有放回采样)<br>            &nbsp;&nbsp;&nbsp;&nbsp;* 默认值为True            </th>        </tr>        <tr>            <th>criterion</th>            <th>判断节点是否分裂的使用的计算方法<br>            &nbsp;&nbsp;&nbsp;&nbsp;• "mse"(均方误差)<br>            &nbsp;&nbsp;&nbsp;&nbsp;• "mae"(平均绝对误差)<br>            &nbsp;&nbsp;&nbsp;&nbsp;* 默认值为"mse"            </th>        </tr>    </tbody></table><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中的<code>n_estimators</code>的值一般来说是越大性能越好，泛化能力越强，是单调递增的，但随着子模型的数量增加，训练算法所消耗的资源和时间将会急剧增加，而其性能的提升也会到达瓶颈。其它数值型参数对性能的影响都呈现出有增有减的，而枚举型的例如<code>criterion</code>则需要视情况而定了，需要在实际应用时灵活调整。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们已经对需要调节的参数有了一个直观的认识，知道每个参数代表的含义。但是我们怎么来调节他们呢？在一开始的时候，我选择了一种非常笨重的方式——直接将所有参数塞进<code>GridSearchCV</code>，这导致训练花费了大量的时间。举个例子，不如设想有<em>3</em>个参数需要调节，每个参数取<em>10</em>个待定值，最后需要尝试的组合高达<strong>1000</strong>个之多，而这里的参数有<code>9</code>个，如果是更复杂的神经网络，那基本上就是望山跑死马的事了。我后知后觉得意识到了网格查找的局限性，于是我马上尝试书里提到的随机方法<code>RandomizedSearchCV</code>，并一度以为这样就能完美解决问题，但显然是我过于乐观——最后训练出的模型基本上都是过拟合的，而且参数可控性极低。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了解决这些问题，最后尝试了一种基于贪心策略的坐标下降法，即每一次只调节一个参数，然后选择最优的参数固定下来继续训练下一个参数，这可以大大减少训练所需的资源和时间——将上面的<strong>1000</strong>减少到<strong>30</strong>，只要能保证训练的模型是凸的，就能取得不错的效果。下面让我们来一探究竟吧。</p><ul><li>n_estimators</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先进行调节的是<code>n_estimators</code>这个参数，正如前文所述，这是一个使性能单调递增的参数，我们首先在粗粒度对它训练，观察训练的整体趋势。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line">rf_param = &#123;</span><br><span class="line">    &apos;n_estimators&apos;: np.arange(1, 1000, 100),</span><br><span class="line">&#125;</span><br><span class="line">rf_grid_cv = GridSearchCV(RandomForestRegressor(n_estimators=50), param_grid=rf_param,</span><br><span class="line">                         cv=3, verbose=True, n_jobs=-1)</span><br><span class="line">rf_grid_cv.fit(x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>Fitting 3 folds for each of 10 candidates, totalling 30 fits[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.8min finishedGridSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,       estimator=RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=None,           max_features=&#39;auto&#39;, max_leaf_nodes=None,           min_impurity_decrease=0.0, min_impurity_split=None,           min_samples_leaf=1, min_samples_split=2,           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,           oob_score=False, random_state=None, verbose=0, warm_start=False),       fit_params=None, iid=&#39;warn&#39;, n_jobs=-1,       param_grid={&#39;n_estimators&#39;: array([  1, 101, 201, 301, 401, 501, 601, 701, 801, 901])},       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,       scoring=None, verbose=True)</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面是这<em>10</em>个模型的最终得分情况，我们可以发现训练得分和验证得分有比较大的差距，但是两者的提升都是同步的，不曾出现此消彼长的情况；在子模型数为<em>1~101</em>时两个得分的提高最为明显，之后增加子模型数量对平均分数并未有任何贡献，可见子模型数量带来的性能提升是有瓶颈的。虽然如此，通过观察变异系数可以发现验证集的得分的离散程度还有一定幅度的减小，这意味子模型数量的增加虽然无异于提高分数，但是其使模型更加稳定。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_acc_4_grid(rf_grid_cv, &apos;n_estimators&apos;)</span><br></pre></td></tr></table></figure></p><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_60_0.png" alt="png"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大刀阔斧地调参会忽视掉许多细节，比如是否两个取值点刚好错过了可能存在于两者之间的波峰或者波谷，结果是否存在波动等。基于此我们接下来根据上面得到的返回结果确定细粒度调节的区间。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">rf_param = &#123;</span><br><span class="line">    &apos;n_estimators&apos;: np.arange(100, 200, 10),</span><br><span class="line">&#125;</span><br><span class="line">rf_grid_cv = GridSearchCV(RandomForestRegressor(n_estimators=50), param_grid=rf_param,</span><br><span class="line">                         cv=3, verbose=True, n_jobs=-1)</span><br><span class="line">rf_grid_cv.fit(x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>Fitting 3 folds for each of 10 candidates, totalling 30 fits[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   35.4s finishedGridSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,       estimator=RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=None,           max_features=&#39;auto&#39;, max_leaf_nodes=None,           min_impurity_decrease=0.0, min_impurity_split=None,           min_samples_leaf=1, min_samples_split=2,           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,           oob_score=False, random_state=None, verbose=0, warm_start=False),       fit_params=None, iid=&#39;warn&#39;, n_jobs=-1,       param_grid={&#39;n_estimators&#39;: array([100, 110, 120, 130, 140, 150, 160, 170, 180, 190])},       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,       scoring=None, verbose=True)</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;不出所料，这里的变异系数存在明显的波动，而最终得分却没什么提升，说明<code>n_estimators</code>是一个适合在粗粒度上进行调节的参数。最后我们选取验证变异系数最小的取值<em>160</em>作为模型中<code>n_estimators</code>参数的最终取值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_acc_4_grid(rf_grid_cv, &apos;n_estimators&apos;)</span><br></pre></td></tr></table></figure></p><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_62_0.png" alt="png"></p><ul><li>max_depth</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>max_depth</code>控制着每棵树的深度，随着树的深度越深，子模型的偏差降低而方差升高，当方差升高到一定程度的时候将会使泛化性能下降，也就是出现过拟合现象。如果是一颗完全二叉树，其叶节点的数目为$2^{n-1}$，则这里使用的训练集的数量只需要一颗深度为<em>10</em>的树基本就能将所有实例分布在不同的叶节点上。当然树的结构显然不会如此理想，所以现将深度的查找范围扩大到<em>100</em>进行训练。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">rf_param = &#123;</span><br><span class="line">    &apos;max_depth&apos;: np.arange(1, 100),</span><br><span class="line">&#125;</span><br><span class="line">rf_grid_cv = GridSearchCV(RandomForestRegressor(n_estimators=160), param_grid=rf_param,</span><br><span class="line">                         cv=3, verbose=True, n_jobs=-1)</span><br><span class="line">rf_grid_cv.fit(x_train, y_train)</span><br></pre></td></tr></table></figure><pre><code>Fitting 3 folds for each of 99 candidates, totalling 297 fits[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   31.3s[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.5min[Parallel(n_jobs=-1)]: Done 297 out of 297 | elapsed:  5.5min finishedGridSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,       estimator=RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=None,           max_features=&#39;auto&#39;, max_leaf_nodes=None,           min_impurity_decrease=0.0, min_impurity_split=None,           min_samples_leaf=1, min_samples_split=2,           min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=None,           oob_score=False, random_state=None, verbose=0, warm_start=False),       fit_params=None, iid=&#39;warn&#39;, n_jobs=-1,       param_grid={&#39;max_depth&#39;: array([ 1,  2, ..., 98, 99])},       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,       scoring=None, verbose=True)</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;让我们来看看这些模型的整体表现如何，通过第一张图可以清晰的看到随着深度的增加，模型在变得越来越好，但是我们并不能因此而沾沾自喜，和在训练<code>n_estimators</code>时一样，我们还要考察它的变异系数。前期随着模型得分越来越高，变异系数也在稳步下降，但是在<code>max_depth</code>增长到<em>5</em>的时候，得分的增幅明显放缓，到<em>9</em>之后更是基本保持不变了，而反观验证得分的变异系数，它也基本在同样的节点发生了逆转，在<code>max_depth</code>为<em>6</em>时达到波谷，而后便开始逐步上升，在<em>12</em>之后出现明显的波动，这说明得分开始趋于不稳定，调节这一部分取值并不会有多大好处。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_acc_4_grid(rf_grid_cv, &apos;max_depth&apos;)</span><br></pre></td></tr></table></figure></p><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_65_0.png" alt="png"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;到这里我们已经能够基本得到我们想要的取值了，但在确定这个参数之前，为了更准确地估计，我把参数调节的范围缩小到了<em>1~20</em>，希望这能带来更清楚的认识。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">rf_param = &#123;</span><br><span class="line">    &apos;max_depth&apos;: np.arange(1, 20),</span><br><span class="line">&#125;</span><br><span class="line">rf_grid_cv = GridSearchCV(RandomForestRegressor(n_estimators=160), param_grid=rf_param,</span><br><span class="line">                         cv=3, verbose=True, n_jobs=-1)</span><br><span class="line">rf_grid_cv.fit(x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>Fitting 3 folds for each of 19 candidates, totalling 57 fits[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   28.9s[Parallel(n_jobs=-1)]: Done  57 out of  57 | elapsed:   44.3s finishedGridSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,       estimator=RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=None,           max_features=&#39;auto&#39;, max_leaf_nodes=None,           min_impurity_decrease=0.0, min_impurity_split=None,           min_samples_leaf=1, min_samples_split=2,           min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=None,           oob_score=False, random_state=None, verbose=0, warm_start=False),       fit_params=None, iid=&#39;warn&#39;, n_jobs=-1,       param_grid={&#39;max_depth&#39;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,       18, 19])},       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,       scoring=None, verbose=True)</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在我们可以看到上面产生极具变化的那一部分的局部放大版了，这时候可以清除地看到验证得分的变异系数发生转变是在<code>max_depth</code>为<em>5</em>的时候，在为<em>12</em>的时候开始出现波动。至于取什么值，我们依然遵循前面的原则，分数尽可能高，而变异系数尽可能低，当然并不是说取对应的分数高和编译系数最低的，因为可能存在变异系数在低谷时得分并不高的情况。最后经过考虑之后暂时选择了<code>max_depth</code>为<em>5</em>。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_acc_4_grid(rf_grid_cv, &apos;max_depth&apos;)</span><br></pre></td></tr></table></figure></p><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_67_0.png" alt="png"></p><ul><li>max_features</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>max_features</code>决定了算法在分裂节点时需要考虑的最大特征数，其可以通过内置的枚举值通过计算取值也可以通过直接设置数值取值。因为这里的特征数量并不是很多，加上$OneHot$向量后一共有345个，所以我采用了设置数值的方式，这样既能够清晰地看到不同取值对模型的影响，又方便确定具体数值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">rf_param = &#123;</span><br><span class="line">    &apos;max_features&apos;: np.arange(1, 345, 10)</span><br><span class="line">&#125;</span><br><span class="line">rf_grid_cv = GridSearchCV(RandomForestRegressor(n_estimators=160, max_depth=5),</span><br><span class="line">                          param_grid=rf_param, cv=3, verbose=True, n_jobs=-1)</span><br><span class="line">rf_grid_cv.fit(x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>Fitting 3 folds for each of 35 candidates, totalling 105 fits[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.3s[Parallel(n_jobs=-1)]: Done 105 out of 105 | elapsed:   26.2s finishedGridSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,       estimator=RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=5,           max_features=&#39;auto&#39;, max_leaf_nodes=None,           min_impurity_decrease=0.0, min_impurity_split=None,           min_samples_leaf=1, min_samples_split=2,           min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=None,           oob_score=False, random_state=None, verbose=0, warm_start=False),       fit_params=None, iid=&#39;warn&#39;, n_jobs=-1,       param_grid={&#39;max_features&#39;: array([  1,  11,  21,  31,  41,  51,  61,  71,  81,  91, 101, 111, 121,       131, 141, 151, 161, 171, 181, 191, 201, 211, 221, 231, 241, 251,       261, 271, 281, 291, 301, 311, 321, 331, 341])},       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,       scoring=None, verbose=True)</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我想这幅图应该是目前为止最直观最简单的一副图了，其趋势非常明显——得分不断上升，变异系数不断下降。由此可知，只要<code>max_features</code>设置为最大值就可以了。甚至还可以在特征工程中人工增加一些特征来提升模型复杂度，充分发挥<code>max_features</code>带来的性能提升。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_acc_4_grid(rf_grid_cv, &apos;max_features&apos;)</span><br></pre></td></tr></table></figure></p><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_70_0.png" alt="png"></p><ul><li>min_samples_split</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>min_samples_split</code>同样是一个影响模型偏差/方差的参数，它限定了一个节点分裂所需的最小样本数，其值越大模型越简单，偏差越大方差越小，而调节这个参数就是为了在这之间做一个权衡。<code>min_samples_split</code>参数最小取值为<em>2</em>，基于和训练<code>max_depth</code>时一样的原因，这里将取值限定在<em>2~100</em>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">rf_param = &#123;</span><br><span class="line">    &apos;min_samples_split&apos;: np.arange(2,100, 10),</span><br><span class="line">&#125;</span><br><span class="line">rf_grid_cv = GridSearchCV(RandomForestRegressor(n_estimators=160, max_depth=5, max_features=&apos;auto&apos;),</span><br><span class="line">                          param_grid=rf_param, cv=3, verbose=True, n_jobs=-1)</span><br><span class="line">rf_grid_cv.fit(x_train, y_train)</span><br></pre></td></tr></table></figure><pre><code>Fitting 3 folds for each of 10 candidates, totalling 30 fits[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   14.2s finishedGridSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,       estimator=RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=5,           max_features=&#39;auto&#39;, max_leaf_nodes=None,           min_impurity_decrease=0.0, min_impurity_split=None,           min_samples_leaf=1, min_samples_split=2,           min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=None,           oob_score=False, random_state=None, verbose=0, warm_start=False),       fit_params=None, iid=&#39;warn&#39;, n_jobs=-1,       param_grid={&#39;min_samples_split&#39;: array([ 2, 12, 22, 32, 42, 52, 62, 72, 82, 92])},       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,       scoring=None, verbose=True)</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这幅图有一个有趣的地方，虽然得分在不断地下降，但是变异系数存在一个低谷，如果训练到此为止，似乎有理由去选择这个值，因为其有不差的评分和相对较低的变异系数。但事实真的如此吗？<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_acc_4_grid(rf_grid_cv, &apos;min_samples_split&apos;)</span><br></pre></td></tr></table></figure></p><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_73_0.png" alt="png"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了验证上面的假设，我们将取值范围集中在低谷附近，同时将它的步长从<em>10</em>降低到<em>1</em>，让我们来看看训练效果如何。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">rf_param = &#123;</span><br><span class="line">    &apos;min_samples_split&apos;: np.arange(2,22),</span><br><span class="line">&#125;</span><br><span class="line">rf_grid_cv = GridSearchCV(RandomForestRegressor(n_estimators=160, max_depth=5, max_features=&apos;auto&apos;),</span><br><span class="line">                          param_grid=rf_param, cv=3, verbose=True, n_jobs=-1)</span><br><span class="line">rf_grid_cv.fit(x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>Fitting 3 folds for each of 20 candidates, totalling 60 fits[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   21.7s[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   28.4s finishedGridSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,       estimator=RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=5,           max_features=&#39;auto&#39;, max_leaf_nodes=None,           min_impurity_decrease=0.0, min_impurity_split=None,           min_samples_leaf=1, min_samples_split=2,           min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=None,           oob_score=False, random_state=None, verbose=0, warm_start=False),       fit_params=None, iid=&#39;warn&#39;, n_jobs=-1,       param_grid={&#39;min_samples_split&#39;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,       19, 20, 21])},       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,       scoring=None, verbose=True)</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;没错，上面解释过的现象又再次出现了，这里的波谷并不是全局的波谷，可以明显地发现其振荡的现象，但其总体趋势是在升高。因此可以得出结论，<code>min_samples_split</code>在这里并不适合调节，只需要将其设置为默认值就行了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_acc_4_grid(rf_grid_cv, &apos;min_samples_split&apos;)</span><br></pre></td></tr></table></figure></p><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_75_0.png" alt="png"></p><ul><li>max_leaf_nodes</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>max_leaf_nodes</code>规定了最大叶节点数，与<code>min_samples_split</code>相反， <code>max_leaf_nodes</code>越大模型越复杂，方差越高。甚至可以不限制它的数量，任由其生长，基于此，我们这里选用一个较大的范围去观察它的整体趋势，然后再如同前面一样在细粒度上去进行调节。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">rf_param = &#123;</span><br><span class="line">    &apos;max_leaf_nodes&apos;: np.arange(2, 1000, 10)</span><br><span class="line">&#125;</span><br><span class="line">rf_grid_cv = GridSearchCV(RandomForestRegressor(n_estimators=160, max_depth=5, max_features=&apos;auto&apos;,</span><br><span class="line">                                               min_samples_split=2),  </span><br><span class="line">                          param_grid=rf_param, cv=3, verbose=True, n_jobs=-1)</span><br><span class="line">rf_grid_cv.fit(x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>Fitting 3 folds for each of 100 candidates, totalling 300 fits[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   25.9s[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.0min[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.0min finishedGridSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,       estimator=RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=5,           max_features=&#39;auto&#39;, max_leaf_nodes=None,           min_impurity_decrease=0.0, min_impurity_split=None,           min_samples_leaf=1, min_samples_split=2,           min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=None,           oob_score=False, random_state=None, verbose=0, warm_start=False),       fit_params=None, iid=&#39;warn&#39;, n_jobs=-1,       param_grid={&#39;max_leaf_nodes&#39;: array([  2,  12, ..., 982, 992])},       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,       scoring=None, verbose=True)</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;和前面大多数参数的表现一样，这里也是在取值较小时似乎就已经达到了比较不错的效果，后面的取值对结果也没有提升，反而徒增资源的消耗。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_acc_4_grid(rf_grid_cv, &apos;max_leaf_nodes&apos;)</span><br></pre></td></tr></table></figure></p><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_78_0.png" alt="png"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;依葫芦画瓢地，我们缩小参数返回进行细粒度的调参，可以发现其在取值为<em>22</em>时表现已趋于稳定。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">rf_param = &#123;</span><br><span class="line">    &apos;max_leaf_nodes&apos;: np.arange(2, 200, 10)</span><br><span class="line">&#125;</span><br><span class="line">rf_grid_cv = GridSearchCV(RandomForestRegressor(n_estimators=160, max_depth=5, max_features=&apos;auto&apos;,</span><br><span class="line">                                               min_samples_split=2),  </span><br><span class="line">                          param_grid=rf_param, cv=3, verbose=True, n_jobs=-1)</span><br><span class="line">rf_grid_cv.fit(x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>Fitting 3 folds for each of 20 candidates, totalling 60 fits[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   26.0s[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   35.6s finishedGridSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,       estimator=RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=5,           max_features=&#39;auto&#39;, max_leaf_nodes=None,           min_impurity_decrease=0.0, min_impurity_split=None,           min_samples_leaf=1, min_samples_split=2,           min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=None,           oob_score=False, random_state=None, verbose=0, warm_start=False),       fit_params=None, iid=&#39;warn&#39;, n_jobs=-1,       param_grid={&#39;max_leaf_nodes&#39;: array([  2,  12,  22,  32,  42,  52,  62,  72,  82,  92, 102, 112, 122,       132, 142, 152, 162, 172, 182, 192])},       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,       scoring=None, verbose=True)</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_acc_4_grid(rf_grid_cv, &apos;max_leaf_nodes&apos;)</span><br></pre></td></tr></table></figure><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_80_0.png" alt="png"></p><ul><li>min_weight_fraction_leaf</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;叶节点最小权重总值限制了叶子节点所有样本权重的最小值，如果小于这个值，则会和其他叶子节点一起被剪枝，提高模型偏差，降低方差。如果样本的分布存在偏斜或者有较多的缺失值可以考虑引入权重。由于之前已经在特征工程中处理了相应的问题，所以这里的调参对提升模型不会有什么作用，但是并不妨碍我们一窥究竟。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">rf_param = &#123;</span><br><span class="line">    &apos;min_weight_fraction_leaf&apos;: np.linspace(0, 0.5, 10)</span><br><span class="line">&#125;</span><br><span class="line">rf_grid_cv = GridSearchCV(RandomForestRegressor(n_estimators=160, max_depth=5, max_features=&apos;auto&apos;,</span><br><span class="line">                                               min_samples_split=2, max_leaf_nodes=22 ),</span><br><span class="line">                          param_grid=rf_param, cv=3, verbose=True, n_jobs=-1)</span><br><span class="line">rf_grid_cv.fit(x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>Fitting 3 folds for each of 10 candidates, totalling 30 fits[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    7.9s finishedGridSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,       estimator=RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=5,           max_features=&#39;auto&#39;, max_leaf_nodes=22,           min_impurity_decrease=0.0, min_impurity_split=None,           min_samples_leaf=1, min_samples_split=2,           min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=None,           oob_score=False, random_state=None, verbose=0, warm_start=False),       fit_params=None, iid=&#39;warn&#39;, n_jobs=-1,       param_grid={&#39;min_weight_fraction_leaf&#39;: array([0.     , 0.05556, 0.11111, 0.16667, 0.22222, 0.27778, 0.33333,       0.38889, 0.44444, 0.5    ])},       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,       scoring=None, verbose=True)</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我想这是这篇文章到此为止第二个如此直观的图了，那么我便不在做过多的解释，直接确定取值了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_acc_4_grid(rf_grid_cv, &apos;min_weight_fraction_leaf&apos;)</span><br></pre></td></tr></table></figure></p><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_83_0.png" alt="png"></p><ul><li>min_samples_leaf</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>min_samples_leaf</code>是我们训练的最后一个关于子模型结构的参数了，它表示叶节点的最小样本树。如果返回前面去看我们已经训练过的参数，会发现一个和它非常相似的参数，就是<code>min_samples_split</code>，这两个参树可以说是直接限定定了叶节点样本个数的范围。下面让我们仿照<code>min_samples_split</code>的训练过程对<code>min_samples_leaf</code>的取值进行设定。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">rf_param = &#123;</span><br><span class="line">    &apos;min_samples_leaf&apos;: np.arange(1, 100, 10)</span><br><span class="line">&#125;</span><br><span class="line">rf_grid_cv = GridSearchCV(RandomForestRegressor(n_estimators=160, max_depth=5, max_features=&apos;auto&apos;,</span><br><span class="line">                                               min_samples_split=2, max_leaf_nodes=22, min_weight_fraction_leaf=0 ),</span><br><span class="line">                          param_grid=rf_param, cv=3, verbose=True, n_jobs=-1)</span><br><span class="line">rf_grid_cv.fit(x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>Fitting 3 folds for each of 10 candidates, totalling 30 fits[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   13.5s finishedGridSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,       estimator=RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=5,           max_features=&#39;auto&#39;, max_leaf_nodes=22,           min_impurity_decrease=0.0, min_impurity_split=None,           min_samples_leaf=1, min_samples_split=2,           min_weight_fraction_leaf=0, n_estimators=160, n_jobs=None,           oob_score=False, random_state=None, verbose=0, warm_start=False),       fit_params=None, iid=&#39;warn&#39;, n_jobs=-1,       param_grid={&#39;min_samples_leaf&#39;: array([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])},       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,       scoring=None, verbose=True)</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图所示，虽然在较粗粒度的层面上进行调参，但是其总体趋势确实非常明显，所以这里便不再多做赘述，直接将值取为<em>1</em>。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_acc_4_grid(rf_grid_cv, &apos;min_samples_leaf&apos;)</span><br></pre></td></tr></table></figure></p><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_86_0.png" alt="png"></p><ul><li>bootstrap</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;到目前为止，我们已经通过以上的步骤训练完了直接影响子模型结构的参数(除了<code>n_estimators</code>)，现在我们稍微站高一点，尝试一下对<code>booststrap</code>这个参数取不同的值，看看最后的效果如何。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>bootstrap</code>决定了是否对样本进行抽样，也就是说它对训练使用什么哪些样本起着至关重要的作用。一般而言，使用子采样会降低子模型之间的关联度，降低最终模型的方差，这也是<strong>bagging</strong>的做法。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">rf_param = &#123;</span><br><span class="line">    &apos;bootstrap&apos;: [True, False]</span><br><span class="line">&#125;</span><br><span class="line">rf_grid_cv = GridSearchCV(RandomForestRegressor(n_estimators=160, max_depth=5, max_features=&apos;auto&apos;,</span><br><span class="line">                           min_samples_split=2, max_leaf_nodes=22, min_weight_fraction_leaf=0,</span><br><span class="line">                          min_samples_leaf=1),</span><br><span class="line">                          param_grid=rf_param, cv=3, verbose=True, n_jobs=-1)</span><br><span class="line">rf_grid_cv.fit(x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>Fitting 3 folds for each of 2 candidates, totalling 6 fits[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    4.4s remaining:    0.0s[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    4.4s finishedGridSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,       estimator=RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=5,           max_features=&#39;auto&#39;, max_leaf_nodes=22,           min_impurity_decrease=0.0, min_impurity_split=None,           min_samples_leaf=1, min_samples_split=2,           min_weight_fraction_leaf=0, n_estimators=160, n_jobs=None,           oob_score=False, random_state=None, verbose=0, warm_start=False),       fit_params=None, iid=&#39;warn&#39;, n_jobs=-1,       param_grid={&#39;bootstrap&#39;: [True, False]}, pre_dispatch=&#39;2*n_jobs&#39;,       refit=True, return_train_score=&#39;warn&#39;, scoring=None, verbose=True)</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;经过验证，在这里展现出的结果也确实如此。那么我很有什么理由不使用默认值呢。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_acc_4_grid(rf_grid_cv, &apos;bootstrap&apos;)</span><br></pre></td></tr></table></figure></p><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_89_0.png" alt="png"></p><ul><li>criterion</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在<strong>scikit-learn</strong>的<em>0.18</em>版中，<code>mae</code>作为新的计算方法被添加进来，以前都是使用<code>mse</code>来做为判断是否分裂节点的计算方法。既然如此我们也来尝试一下吧。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">rf_param = &#123;</span><br><span class="line">    &apos;criterion&apos;: [&apos;mse&apos;, &apos;mae&apos;]</span><br><span class="line">&#125;</span><br><span class="line">rf_grid_cv = GridSearchCV(RandomForestRegressor(n_estimators=160, max_depth=5, max_features=&apos;auto&apos;,</span><br><span class="line">                           min_samples_split=2, max_leaf_nodes=22, min_weight_fraction_leaf=0,</span><br><span class="line">                          min_samples_leaf=1, bootstrap=True),</span><br><span class="line">                          param_grid=rf_param, cv=3, verbose=True, n_jobs=-1)</span><br><span class="line">rf_grid_cv.fit(x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>Fitting 3 folds for each of 2 candidates, totalling 6 fits[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   59.7s remaining:    0.0s[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   59.7s finishedGridSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,       estimator=RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=5,           max_features=&#39;auto&#39;, max_leaf_nodes=22,           min_impurity_decrease=0.0, min_impurity_split=None,           min_samples_leaf=1, min_samples_split=2,           min_weight_fraction_leaf=0, n_estimators=160, n_jobs=None,           oob_score=False, random_state=None, verbose=0, warm_start=False),       fit_params=None, iid=&#39;warn&#39;, n_jobs=-1,       param_grid={&#39;criterion&#39;: [&#39;mse&#39;, &#39;mae&#39;]}, pre_dispatch=&#39;2*n_jobs&#39;,       refit=True, return_train_score=&#39;warn&#39;, scoring=None, verbose=True)</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_acc_4_grid(rf_grid_cv, &apos;criterion&apos;)</span><br></pre></td></tr></table></figure><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_92_0.png" alt="png"></p><ul><li>RandomForestRegressor</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;经过繁琐的步骤，我们终于可以着手训练一个完整的随机森林模型了。将上面的参数一一对应，直接使用训练数据划分验证测试。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rf = RandomForestRegressor(n_estimators=160, max_depth=5, max_features=&apos;auto&apos;,</span><br><span class="line">                           min_samples_split=2, max_leaf_nodes=22, min_weight_fraction_leaf=0,</span><br><span class="line">                          min_samples_leaf=1, bootstrap=True)</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rf_pred = cross_val_predict(rf, x_train, y_train,</span><br><span class="line">                                 verbose=True, n_jobs=-1, cv=3)</span><br><span class="line">mse = mean_squared_error(y_train, rf_pred)</span><br><span class="line">np.sqrt(mse)</span><br></pre></td></tr></table></figure><pre><code>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.7s finished0.16115609724602975</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;就这样，我们最后得到了一个自己亲手调试的集成模型。对这最后的成果我们可以做一个简要的分析。首先相比之前我多次尝试训练的随机森林，它有着一个极大的改变，那就是它的训练曲线不再是一条接近<em>1</em>的水平线了，good job！！！这说明通过调参已经有效的缓解了严重的过拟合现象；其次，我们也可以发现一些问题，模型似乎仍然存在一定程度的过拟合(两条线靠得并不太近)，同时模型的准确度似乎有着明显的下降。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_learning_curve(rf, x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[learning_curve] Training set sizes: [ 131  426  721 1016 1312][Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   20.1s finished</code></pre><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_96_3.png" alt="png"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然最后的模型看起来并不是很完美的解决方案，但这至少可以作为一个里程碑，它证明了贪心策略的可行性的同时也产出了一个完整的集成模型。</p><h2 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>梯度提升树</strong>是一种<em>Boosting</em>方法，每个子模型拟合的是上一个子模型的预测结果与真实结果的残差，即先训练一个弱分类器，然后用这个弱分类器去预测数据集，得到的预测结果和真实的结果取差，然后将得到的残差作为数据集新的预测目标，下一个分类器再去拟合这个残差，如此反复，最后将所有的弱分类器加权求和得到最终分类器，所以说梯度提升树是一种基于加法模型的算法。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GBDT通常采用高偏差低方差的基函数，一般是<em>CART Tree(分类回归树)</em>。因为是基于树的集成模型，那么它同样涉及到树的生成问题，例如深度、叶子节点个数、分隔所需最小样本树等等。基于此，对这部分参数的训练可以直接仿照<em>Random Forest</em>的训练过程，所以便不再占用大量的篇幅去描述。</p><ul><li>subsample</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;相比于随机森林，GBDT多训练了一个叫做<code>subsample</code>的参数，这个参数的中文名叫做子采样率，它表示每一次训练弱分类器所使用的样本比例，如果$\lt 1.0$表示使用随机梯度提升，能降低方差提高偏差，有效防止过拟合的发生。下面让我们看看它的训练效果。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们将值限定在一个极小数与<em>1</em>之间，然后取了<em>100</em>个值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">gbdt_param = &#123;</span><br><span class="line">    &apos;subsample&apos;: np.linspace(1e-7, 1, 100),</span><br><span class="line">&#125;</span><br><span class="line">gbdt_grid_cv = GridSearchCV(GradientBoostingRegressor(n_estimators=23, max_depth=8, max_features=&apos;auto&apos;,</span><br><span class="line">                                                      min_samples_split=2, max_leaf_nodes=12, min_weight_fraction_leaf=0,</span><br><span class="line">                                                     min_samples_leaf=1),</span><br><span class="line">                            param_grid=gbdt_param, verbose=True, cv=3, n_jobs=-1)</span><br><span class="line">gbdt_grid_cv.fit(x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>Fitting 3 folds for each of 100 candidates, totalling 300 fits[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    8.1s[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed:   29.4s[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   39.7s finishedGridSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,       estimator=GradientBoostingRegressor(alpha=0.9, criterion=&#39;friedman_mse&#39;, init=None,             learning_rate=0.1, loss=&#39;ls&#39;, max_depth=8,             max_features=&#39;auto&#39;, max_leaf_nodes=12,             min_impurity_decrease=0.0, min_impurity_split=None,             min_samples_leaf=1, min_sampl...       subsample=1.0, tol=0.0001, validation_fraction=0.1, verbose=0,             warm_start=False),       fit_params=None, iid=&#39;warn&#39;, n_jobs=-1,       param_grid={&#39;subsample&#39;: array([1.00000e-07, 1.01011e-02, ..., 9.89899e-01, 1.00000e+00])},       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,       scoring=None, verbose=True)</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们可以发现随着<code>subsample</code>的取值越大，得分总体呈上升趋势并趋于平稳，变异系数整体呈下降趋势，然后开始震荡。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_acc_4_grid(gbdt_grid_cv, &apos;subsample&apos;)</span><br></pre></td></tr></table></figure></p><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_129_0.png" alt="png"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;同理，让我们把目光集中在急速下降的地方，放大它的内部表现。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">gbdt_param = &#123;</span><br><span class="line">    &apos;subsample&apos;: np.linspace(1e-7,2.22222e-01, 100),</span><br><span class="line">&#125;</span><br><span class="line">gbdt_grid_cv = GridSearchCV(GradientBoostingRegressor(n_estimators=23, max_depth=8, max_features=&apos;auto&apos;,</span><br><span class="line">                                                      min_samples_split=2, max_leaf_nodes=12, min_weight_fraction_leaf=0,</span><br><span class="line">                                                     min_samples_leaf=1),</span><br><span class="line">                            param_grid=gbdt_param, verbose=True, cv=3, n_jobs=-1)</span><br><span class="line">gbdt_grid_cv.fit(x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>Fitting 3 folds for each of 100 candidates, totalling 300 fits[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:    9.1s[Parallel(n_jobs=-1)]: Done 286 tasks      | elapsed:   24.6s[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   25.8s finishedGridSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,       estimator=GradientBoostingRegressor(alpha=0.9, criterion=&#39;friedman_mse&#39;, init=None,             learning_rate=0.1, loss=&#39;ls&#39;, max_depth=8,             max_features=&#39;auto&#39;, max_leaf_nodes=12,             min_impurity_decrease=0.0, min_impurity_split=None,             min_samples_leaf=1, min_sampl...       subsample=1.0, tol=0.0001, validation_fraction=0.1, verbose=0,             warm_start=False),       fit_params=None, iid=&#39;warn&#39;, n_jobs=-1,       param_grid={&#39;subsample&#39;: array([1.00000e-07, 2.24477e-03, ..., 2.19977e-01, 2.22222e-01])},       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,       scoring=None, verbose=True)</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;和上面的趋势几乎如出一辙。这同样说明该参数不太适合在过小的粒度上进行调节。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_acc_4_grid(gbdt_grid_cv, &apos;subsample&apos;)</span><br></pre></td></tr></table></figure></p><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_131_0.png" alt="png"></p><ul><li>GBDT<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;没错，我们又得到了一个集成模型，现在让我们再看看这个模型的表现。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gbdt = GradientBoostingRegressor(n_estimators=23, max_depth=8, max_features=&apos;auto&apos;,</span><br><span class="line">                                                      min_samples_split=2, max_leaf_nodes=12, min_weight_fraction_leaf=0,</span><br><span class="line">                                                     min_samples_leaf=1, subsample=1)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gbdt_pred = cross_val_predict(gbdt, x_train, y_train)</span><br><span class="line">mse = mean_squared_error(y_train, gbdt_pred)</span><br><span class="line">np.sqrt(mse)</span><br></pre></td></tr></table></figure><pre><code>0.1558966244053635</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_learning_curve(gbdt, x_train, y_train)</span><br></pre></td></tr></table></figure><pre><code>[learning_curve] Training set sizes: [ 131  426  721 1016 1312][Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    8.1s finished</code></pre><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_134_2.png" alt="png"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;相比于随机森林而言，它的均方误差变小了,同时准确率也有所提高。</p><h3 id="GBDT历史版本"><a href="#GBDT历史版本" class="headerlink" title="GBDT历史版本"></a>GBDT历史版本</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;同时，这里将之前使用<code>RandomizedSearchCV</code>的版本罗列了出来，可以发现两者的巨大差异，虽然该版本的均方误差更低，但是其明显的过拟合现象就说明这不是一个好的模型了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import GradientBoostingRegressor</span><br><span class="line">from sklearn.model_selection import RandomizedSearchCV</span><br><span class="line"></span><br><span class="line"># gbdt_param = &#123;</span><br><span class="line">#     &apos;n_estimators&apos;: np.arange(1000, 5000, 100),</span><br><span class="line">#     &apos;max_depth&apos;: np.arange(2, 10),</span><br><span class="line">#     &apos;subsample&apos;: np.linspace(0.1, 1, 20),</span><br><span class="line">#     &apos;max_features&apos;:[&apos;auto&apos;, &apos;sqrt&apos;, &apos;log2&apos;]</span><br><span class="line"># &#125;</span><br><span class="line"></span><br><span class="line"># gbdt_grid_cv = RandomizedSearchCV(GradientBoostingRegressor(n_estimators=100), param_distributions=gbdt_param, n_jobs=-1,</span><br><span class="line">#                                  verbose=True, random_state=42, cv=3)</span><br><span class="line"># gbdt_grid_cv.fit(x_train, y_train)</span><br><span class="line">gbdt = GradientBoostingRegressor(alpha=0.9, criterion=&apos;friedman_mse&apos;, init=None,</span><br><span class="line">             learning_rate=0.1, loss=&apos;ls&apos;, max_depth=4,</span><br><span class="line">             max_features=&apos;auto&apos;, max_leaf_nodes=None,</span><br><span class="line">             min_impurity_decrease=0.0, min_impurity_split=None,</span><br><span class="line">             min_samples_leaf=1, min_samples_split=2,</span><br><span class="line">             min_weight_fraction_leaf=0.0, n_estimators=3900,</span><br><span class="line">             n_iter_no_change=None, presort=&apos;auto&apos;, random_state=None,</span><br><span class="line">             subsample=0.5736842105263158, tol=0.0001,</span><br><span class="line">             validation_fraction=0.1, verbose=0, warm_start=False)</span><br><span class="line">gbdt.fit(x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>GradientBoostingRegressor(alpha=0.9, criterion=&#39;friedman_mse&#39;, init=None,             learning_rate=0.1, loss=&#39;ls&#39;, max_depth=4,             max_features=&#39;auto&#39;, max_leaf_nodes=None,             min_impurity_decrease=0.0, min_impurity_split=None,             min_samples_leaf=1, min_samples_split=2,             min_weight_fraction_leaf=0.0, n_estimators=3900,             n_iter_no_change=None, presort=&#39;auto&#39;, random_state=None,             subsample=0.5736842105263158, tol=0.0001,             validation_fraction=0.1, verbose=0, warm_start=False)</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># gbdt_grid_cv.best_estimator_</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># gbdt_grid_cv.best_score_</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import cross_val_predict</span><br><span class="line">from sklearn.metrics import mean_squared_error</span><br><span class="line"># gbdt = gbdt_grid_cv.best_estimator_</span><br><span class="line">gbdt_pred = cross_val_predict(gbdt, x_train, y_train,</span><br><span class="line">                             verbose=True, n_jobs=-1, cv=5)</span><br><span class="line">mse = mean_squared_error(y_train, gbdt_pred)</span><br><span class="line">np.sqrt(mse)</span><br></pre></td></tr></table></figure><pre><code>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   58.5s finished0.12245307114524771</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_learning_curve(gbdt, x_train, y_train)</span><br></pre></td></tr></table></figure><pre><code>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[learning_curve] Training set sizes: [ 131  426  721 1016 1312][Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  4.5min finished</code></pre><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_139_3.png" alt="png"></p><h2 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在，我们已经使用相同的方式训练了两个集成模型。另外，我还尝试了一些其他模型，比如这里的<a href="https://xgboost.readthedocs.io/en/latest/" target="_blank" rel="noopener"><strong>XGBoost</strong></a>。如果我们还按照上面的行文方式，那么就会变成记流水账了。既然训练方法和过程都已经熟悉，那么这里便直接给出训练后的结果，转而简单介绍一下XGBoost的原理。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<em>XGBoost</em>是在<em>GBDT</em>的基础上改进而来的一种<em>Boosting</em>算法，虽然是<em>Boosting</em>，但是其可以通过使用特征上的并行计算提升训练效率。它在训练之前会对数据进行排序，然后保存为<em>block</em>结构以便在后序地迭代中使用。同样因为该结构的存在，在节点分裂需要计算每个特征值的增益的时候，就可以多线程地进行。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<em>XGBoost</em>相比与<em>GBDT</em>还在代价函数中还加入了正则化方法用于控制模型的复杂度，正则化通过降低模型的方差达到防止过拟合的目的。<em>XGBoost</em>不仅仅只是使用<em>CART</em>（<code>booster=&#39;gbtree&#39;</code>）作为基分类器,还同时引入了线性分类器（<code>booster=&#39;gblinear&#39;</code>）,当使用线性分类器时就如同带有<em>l1</em>或<em>l2</em>正则的逻辑斯蒂回归（分类）和线性回归（回归）。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;除此之外，<em>XGBoost</em>还支持列抽样、自动学习缺失值的分裂方向等。<em>XGBoost</em>是一个非常优秀的模型，我这里只是大概做了一个梳理，想要完全掌握这个算法我实在是还差得很远。具体的内容可以查看<a href="https://xgboost.readthedocs.io/en/latest/tutorials/model.html" target="_blank" rel="noopener">官方文档</a>，也可以去翻看相关论文进行更深度的学习。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">xg = XGBRegressor(objective=&apos;reg:squarederror&apos;, booster=&apos;gbtree&apos;, n_estimators=470,</span><br><span class="line">                                       max_depth=2, reg_lambda=0, reg_alpha=0.08163, colsample_bylevel=0.06122,</span><br><span class="line">                                      colsample_bynode=0, colsample_bytree=1, min_child_weight=1)</span><br><span class="line">xg_pred = cross_val_predict(xg, x_train, y_train,</span><br><span class="line">                             verbose=True, n_jobs=-1, cv=5)</span><br><span class="line">mse = mean_squared_error(y_train, xg_pred)</span><br><span class="line">np.sqrt(mse)</span><br></pre></td></tr></table></figure></p><pre><code>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.1s finished0.1472574980184566</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最后我们来看看<em>XGBoost</em>模型的表现情况，可以发现它比之前的<em>GBDT</em>在结果上有不小的提升，两条曲线非常接近，也没有严重的过拟合问题，可以说是一个不错的结果了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_learning_curve(xg, x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>[learning_curve] Training set sizes: [ 131  426  721 1016 1312][Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.1min finished</code></pre><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_175_2.png" alt="png"></p><h2 id="stack"><a href="#stack" class="headerlink" title="stack"></a>stack</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在文章的开头我们对集成学习做了一个概述，其中省略了如何将子模型结果进行结合的方法，现在便对其做一个补充。在对具体的结合策略进行表述之前，先来说说使用结合策略可以带来哪些好处：</p><ol><li>因为目标的假设空间很大，可能有多个假设在训练集上达到相同的性能，因此结合多个学习器可以减小单个学习器因误选而导致泛化性能不佳的风险</li><li>由于局部极小值的存在，而单个学习器在有的局部极小值对应的泛化性能很差，多次训练学习器并对结果进行结合可以降低陷入糟糕局部极小值的风险</li><li>目标的真实假设空间可能不在当前算法所考虑的假设空间中，多个学习器可以将相应的假设空间扩大从而摒除单个学习器无效的情况</li></ol><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;综上所述，结合策略的使用可以提高泛化性能，扩大相应的假设空间，使得模型的整体效果变得更好。下面就让我们看看有哪些具体的策略吧。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先最容易想到的便是针对回归的<strong>平均法</strong>和针对分类的<strong>投票法</strong>。其中平均法又分为简单平均和加权平均。所谓简单平均就是求所有学习器的总平均值，加权平均就是对每一个分类器分配一个权重($\sum ^{T}_{i=1}w_i = 1$)再求和，而简单平均是加权平均权重为$\frac{1}{T}$的特例。投票法与平均法类似，分为绝对多数投票法、相对多数投票法和加权投票法，其中加权投票法和加权平均法类似，只是一个取的是加权后的计数最大值作为最终标记而另一个取的是平均值作为预测结果。绝对多数投票法和相对多数投票法可以说是兄弟了，它们都会通过标记计数大小来预测结果，但是绝对多数取的是预测过半的标记，如果没有则可以拒绝预测，而相对多数投票法就是少数服从多数的完美诠释，即取数量最多的标记作为预测结果，如果绝对多数投票法不允许拒绝预测，要求必须有一个预测值，那么它将退化为相对多数投票法。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;除此之外，还有一种更为强大的结合策略就是<strong>学习法</strong>。学习法通过额外的学习器(次级学习器)来结合基学习器(初级学习器)的预测结果。其中的典型代表就是下面使用的<strong>Stacking</strong><sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>，其一般步骤如下：</p><ol><li>从数据集训练出基学习器</li><li>使用初级学习器生成新的数据集，新数据集中的特征为初级学习器的输出，标记不变</li><li>在新的数据集上使用次级学习器训练</li></ol><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;学习法在使用过程中为了降低过拟合的风险，在训练初级学习器时使用交叉验证的方式，通过训练初级学习器时未使用的数据来生成新的数据集。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面是<em>Stacking</em>的一个<a href="https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard" target="_blank" rel="noopener">实现版本</a>，其实我一开始也并没有太懂为什么要这样处理，直到我回过头再去审视这段代码，才有了一定的体会。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们首先来看一下它的构造。在初始化阶段(<code>__init__</code>)我们传入了<code>base_models</code>作为初级学习器，<code>final_models</code>作为次级学习器，即用<code>base_models</code>生成数据，<code>final_model</code>做最后的预测，<code>n_folds</code>表示交叉验证中使用的折数。</p><ul><li><code>fit</code><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这里<code>fit</code>不再只是单纯地去训练模型了，它还包括了生成数据集的步骤。前两行代码首先使用<code>base_models</code>生成了一个空列表用于存储训练使用的<em>model</em>，使用<code>clone</code>函数是因为对象传递进来是引用，如果直接在上面进行操作会影响外部的模型，所以要创建一个备份用于该类内使用。接下来便是创建交叉验证的划分折数，然后根据初级学习器的数量创建一个大小为(n, n_models)<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>的<code>numpy</code>数组用于存储新的数据集。第一层<code>for</code>循环遍历初级学习器，第二层<code>循环</code>使用交叉验证训练初级学习器，并保存每一折的训练后的模型，然后使用初级学习器对为参与训练的数据进行预测，最后使用预测值填充上面的<code>numpy</code>数组对应的位置。在数据生成之后，再用这些数据去训练次级学习器。</li><li><code>predict</code><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;预测阶段同样需要做一些预处理，顺序地从保存模型的列表中取出对应的模型列表(即对应模型每一折的训练成果)，然后计算该类模型预测的平均值，最后将所有的模型预测结合起来作为最后预测需要的数据，然后再调用次级学习器进行预测。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone</span><br><span class="line">from sklearn.model_selection import KFold</span><br><span class="line"></span><br><span class="line">class StackModel(BaseEstimator, TransformerMixin, RegressorMixin):</span><br><span class="line">    def __init__(self, base_models, final_model, n_folds=5):</span><br><span class="line">        self.base_models = base_models</span><br><span class="line">        self.final_model = final_model</span><br><span class="line">        self.n_folds = n_folds</span><br><span class="line"></span><br><span class="line">    def fit(self, X, y):</span><br><span class="line">        self.base_models_ = [list() for i in self.base_models]</span><br><span class="line">        self.final_model_ = clone(self.final_model)</span><br><span class="line">        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=42)</span><br><span class="line"></span><br><span class="line">        out_predictions = np.zeros((X.shape[0], len(self.base_models)))</span><br><span class="line">        for i, model in enumerate(self.base_models):</span><br><span class="line">            for train_index, holdout_index in kfold.split(X, y):</span><br><span class="line">                instance = clone(model)</span><br><span class="line">                self.base_models_[i].append(instance)</span><br><span class="line">                instance.fit(X[train_index], y[train_index])</span><br><span class="line">                y_pred = instance.predict(X[holdout_index])</span><br><span class="line">                out_predictions[holdout_index, i] = y_pred</span><br><span class="line"></span><br><span class="line">        self.final_model_.fit(out_predictions, y)</span><br><span class="line">        return self</span><br><span class="line"></span><br><span class="line">    def predict(self, X):</span><br><span class="line">        final_feature = np.column_stack([</span><br><span class="line">            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)</span><br><span class="line">            for base_models in self.base_models_</span><br><span class="line">        ])</span><br><span class="line">        return self.final_model_.predict(final_feature)</span><br></pre></td></tr></table></figure></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们已经证实在简单模型中<code>Lasso</code>在该数据集上的表现更好，同时由于<em>Stacking</em>用多响应线性回归作为次级学习算法效果会比较好，所以这里选用该模型作为次级学习器。其它的初级学习器为我们之前使用或调参之后的模型。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.linear_model import  Lasso, ElasticNet</span><br><span class="line">from sklearn.kernel_ridge import KernelRidge</span><br><span class="line">from sklearn.ensemble import GradientBoostingRegressor</span><br><span class="line"></span><br><span class="line">ridge = KernelRidge(degree=2, alpha=0.05, kernel=&apos;polynomial&apos;)</span><br><span class="line">lasso = Lasso(alpha=0.0005)</span><br><span class="line">en = ElasticNet(max_iter=5000, selection=&apos;random&apos;)</span><br><span class="line">gbdt = GradientBoostingRegressor(n_estimators=49, max_depth=5, max_features=&apos;auto&apos;,</span><br><span class="line">                                                      min_samples_split=2, max_leaf_nodes=7, min_weight_fraction_leaf=0,</span><br><span class="line">                                                     min_samples_leaf=1, subsample=1)</span><br><span class="line"></span><br><span class="line">stack_models = StackModel(base_models=(ridge, gbdt, en), final_model=lasso)</span><br><span class="line">stack_models.fit(x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>StackModel(base_models=(KernelRidge(alpha=0.05, coef0=1, degree=2, gamma=None, kernel=&#39;polynomial&#39;,      kernel_params=None), GradientBoostingRegressor(alpha=0.9, criterion=&#39;friedman_mse&#39;, init=None,             learning_rate=0.1, loss=&#39;ls&#39;, max_depth=5,             max_features=&#39;auto&#39;, max_leaf_nodes=7,  ...False, precompute=False,      random_state=None, selection=&#39;random&#39;, tol=0.0001, warm_start=False)),      final_model=Lasso(alpha=0.0005, copy_X=True, fit_intercept=True, max_iter=1000,   normalize=False, positive=False, precompute=False, random_state=None,   selection=&#39;cyclic&#39;, tol=0.0001, warm_start=False),      n_folds=5)</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;显而易见的，使用<em>Stacking</em>之后的均方误差更小，而其得分也达到了<em>90%</em>以上，可以说相当于之前的集成模型或者单一模型有着飞跃性的提升。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import mean_squared_error</span><br><span class="line">from sklearn.model_selection import cross_val_predict</span><br><span class="line">stack_pred = stack_models.predict(x_train)</span><br><span class="line">mse = mean_squared_error(stack_pred, y_train)</span><br><span class="line">np.sqrt(mse)</span><br></pre></td></tr></table></figure></p><pre><code>0.08064604349182854</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_learning_curve(stack_models, x_train, y_train)</span><br></pre></td></tr></table></figure><pre><code>[learning_curve] Training set sizes: [ 131  426  721 1016 1312][Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   49.9s finished</code></pre><p><img src="/2019/06/27/House-Prices-Advanced-Regression-Techniques-2/Predict%20House%20Prices_186_2.png" alt="png"></p><h1 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;终于到了验证成果的时候了，在做预测之前，我们先加载需要预测的数据，并使用与处理训练数据相同的规则对数据进行特征处理。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">test = pd.read_csv(&apos;house_price/test.csv&apos;)</span><br><span class="line">index = np.array(test[[&apos;Id&apos;]])[:,0]</span><br><span class="line">test = test.set_index([&apos;Id&apos;])</span><br><span class="line">x_test = full_pipeline.transform(test)</span><br></pre></td></tr></table></figure></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一如既往地，训练模型、数据预测，结合，最后将预测结果按照指定的格式输出到文件。这里需要稍微说一下的是结合策略，因为在上面的模型中，<em>XGBoost</em>应该是除了<em>Stacking</em>之外的表现最好的模型，所以在这里将这两者的结果进行加权平均，得出最后的预测值。这里的比例是随机选取的，当然也可以通过构建新的模型来训练这个比重，这里便不再多做赘述。最后还有一个需要注意的地方，那就是对模型预测的结果还取了指数，这是因为在之前分析训练集时为了解决目标值分布偏移的问题而对其进行了取对数操作，这使得所有的预测结果其实都是以此为基准的，为了得到真实的结果那么自然需要进行还原。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">stack_models.fit(x_train, y_train)</span><br><span class="line">stack_pre =  stack_models.predict(x_test)</span><br><span class="line">xg.fit(x_train, y_train)</span><br><span class="line">xg_pre = xg.predict(x_test)</span><br><span class="line">ensemble_pred = stack_pre*0.8 + xg_pre*0.2</span><br><span class="line">pred_df = pd.DataFrame(&#123;&apos;Id&apos;:index,</span><br><span class="line">                       &apos;SalePrice&apos;:np.expm1(ensemble_pred)&#125;)</span><br><span class="line">pred_df.to_csv(&apos;./house_price/prediction.csv&apos;, index=&apos;&apos;)</span><br></pre></td></tr></table></figure></p><h1 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;转眼之间两个月已经过去了，总算是把内容都呈现了出来。虽然说两篇文章没有什么实质性的内容，但对我而言已经是一个良好的总结了。在这两个月多月里，我基本上是坚持每天码字。有时候写到不懂的地方就需要花费大量的时间去查资料，这导致最后行文可能只有一两行。特别是最后这一段时间，工作繁忙而没有时间做一个很好的梳理并保持之前的连续性。虽然有诸多困难，但好在功夫不负有心人，也算是圆满完成了当时定下的目标，这点让我倍感欣慰。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这个过程中，我查阅了大量的资料，从书本到网络博客，参考了很多牛人的思想。其中有两本书可以说是我整个实践过程中的基石，其中一本是周志华老师的《机器学习》，它丰富和完善了我的理论知识，另一本是之前提到的 Aurélien Géron的《Hands-On Machine Learning with Scikit-Learn &amp; TensorFlow》，它教会我如何去使用<strong>Scikit-Learn</strong>。在此我衷心地感谢在这个过程中给我提供帮助的书和博客的作者。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最后便是接下来的一些规划了，这已经算是一个实战项目了，但由于基础理论知识的相对薄弱，导致在训练过程中对各个参数的意义一知半解。我接下来打算对我接触到的所有基础内容做一个概览似的总结，方便后序查漏补缺。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;感谢您的阅读！！！</p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">又称离散系数，这里是标准差系数，其反应的是单位均值上的各指标观测值的离散程度</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;">本身是一种集成学习方法，这里作为一种特殊的结合策略</span><a href="#fnref:2" rev="footnote"> ↩</a></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">3.</span><span style="display: inline-block; vertical-align: top;"><em>n</em>为样本数量，<em>n_models</em>为初级学习器个数</span><a href="#fnref:3" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      接上一篇，主要记录集成模型的训练过程
    
    </summary>
    
      <category term="机器学习" scheme="http://coldjune.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="kaggle" scheme="http://coldjune.com/tags/kaggle/"/>
    
  </entry>
  
  <entry>
    <title>House-Prices-Advanced-Regression-Techniques-1</title>
    <link href="http://coldjune.com/2019/05/25/House-Prices-Advanced-Regression-Techniques-1/"/>
    <id>http://coldjune.com/2019/05/25/House-Prices-Advanced-Regression-Techniques-1/</id>
    <published>2019-05-25T00:57:50.000Z</published>
    <updated>2019-07-20T08:01:52.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我真正接触Kaggle是在做《Hands-On Machine Learning with Scikit-Learn and TensorFlow》的一道练习题的时候，那道练习题使用的数据是Kaggle上一个分类数据集——<a href="https://www.kaggle.com/c/titanic" target="_blank" rel="noopener">Titanic: Machine Learning from Disaster</a>，当我登录这个页面的时候后发现这是一个非常热门的项目，其参与团队(个人)已经达到了11223个，这对我这样一个初来乍到的人是一个不小的冲击，抱着决定在这个平台试一试的心态我开始寻找适合我的项目。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques" target="_blank" rel="noopener">House-Prices-Advanced-Regression-Techniques</a>是Kaggle上的一个知识性竞赛，作为一个回归问题，它提供了适量的数据以及特征供学习者使用；而作为机器学习的入门项目它帮助了很多人完成了从0到1的过程，现在上面有4746个团队(个人)提交了自己的预测结果。我作为一名学习者，也通过自己的努力在上面获得了自己的分数——<em>0.12702</em>，这是使用<code>KernelRidge</code>实现的模型进行预测的结果，这并不算一个很好的评分，大概排在1757名左右(前40%)，但对我来说确实一个很大的进步，这标示着从无到有的过程。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kaggle对于数据初学者来说确实是一个非常适合的平台，kaggler们都不吝啬自己的知识，发布着自己的kernel，表述自己的想法，借此帮助每一个需要帮助的社区成员。能完成这个项目对我来说意义非凡，在这里我特别感谢kaggle上的两位kaggler以及他们的对自己项目的无私奉献，他们分别是<a href="https://www.kaggle.com/pmarcelino" target="_blank" rel="noopener">@Pedro Marcelino</a>和他的kenel——<a href="https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python" target="_blank" rel="noopener">Comprehensive data exploration with Python</a>,他对数据的分析以及把控让现在的我难以望其项背，给了我非常大的启发；以及<a href="https://www.kaggle.com/serigne" target="_blank" rel="noopener">@Serigne</a>和他的kernel——<a href="https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard" target="_blank" rel="noopener">Stacked Regressions : Top 4% on LeaderBoard</a>,他同样用了<a href="https://www.kaggle.com/pmarcelino" target="_blank" rel="noopener">@Pedro Marcelino</a>的数据分析方法，但是他在数据分析的基础上增加了模型的训练以及分析过程，帮助我学会把控自己的模型。再次对他们表示真挚的感谢。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然这个项目的准确程度还可以有很大的提升，但就我现在的能力而言我决定让它暂且休息一下，好回头看看，总结总结得失。</p><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在我个人的学习过程中，对于机器学习的理解一直都是觉得算法有多么多么重要，但当我真正着手去做的时候，发现事实其实与我想象中的大相径庭。不可否认，算法是构建模型的关键步骤，是不可逾越的一道关隘，但是其对最终模型的起到的作用其实并没有想象中的那么重要。这不经让我想到微软发布的那个关于数据和算法对模型影响的论文——<a href="http://static.googleusercontent.com/media/research.google.com/fr//pubs/archive/35179.pdf" target="_blank" rel="noopener">The Unreasonable Effectiveness of Data</a>，这篇论文说明了当数据量达到一定程度时，算法的优劣将被摒弃，颇有一些殊途同归的意思。而按我的理解，当数据的质量达到一定程度时，算法的优劣差异也会被一定程度上的减弱。我想这也是那么多前辈强调特征工程重要性的原因。</p><h2 id="数据篇"><a href="#数据篇" class="headerlink" title="数据篇"></a>数据篇</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;当我们拿到一份数据的时侯不是将它直接塞入算法，让算法产出一个模型，而应该是先对数据有一个全局的insight，了解数据的组成成分，包括以下几点：</p><ol><li>目标<br>&nbsp;&nbsp;&nbsp;&nbsp;即分类任务或者回归任务，观察需要预测的目标的分布，可以借用<code>seaborn</code>库进行可视化</li><li>特征值<br>&nbsp;&nbsp;&nbsp;&nbsp;即实例的属性，确定属性值是离散的类别标签还是连续的数值型数据，对不同类型的数据需要进行不同的处理</li><li>异常值<br>&nbsp;&nbsp;&nbsp;&nbsp;不是所有的数据分布都是合理的，在数据集中可能存在部分数据的分布超过一定的阈值，这部分数据被称作异常值或者离群点，对异常值的处理需要非常谨慎，这部分数据对模型的好坏起着非常关键的作用。</li><li>空值<br>&nbsp;&nbsp;&nbsp;&nbsp;空值一般是指那种数据集中缺失的值，这部分值可能代表数据的特性，如表示某种特征，也可能只是单纯的缺失值。如果是单纯的值缺失，数值类型可以使用中位数进行填充，而类别标签可以用当前特征表示某种类别数量最多的类别值填充；而如果是表示某种特征，则可以使用<code>None</code>填充类别标签，用<code>0</code>填充数值特征，表示该缺失类别<h3 id="观测"><a href="#观测" class="headerlink" title="观测"></a>观测</h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kaggle有一个非常友好的地方，那就是在每一个项目里面都有关于这个数据集的描述，这个项目的描述文件可以在<a href="https://github.com/coldJune/machineLearning/blob/master/kaggle/house_price/data_description.txt" target="_blank" rel="noopener">data_description.txt</a>中看到。结合描述文件和一些python代码可以对数据有一个比较清晰的认知，了解特征的特性、取值和分布，了解目标的特性以及特征和目标之间的直接关系，下面的代码用表的方式直观地展现了数据的一些特性。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入相关数据包</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sbn</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ignore_warn</span><span class="params">(*args, **kwargs)</span>:</span></span><br><span class="line">    <span class="comment"># 忽略警告输出</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">warnings.warn = ignore_warn</span><br><span class="line"><span class="comment"># 设置最大显示列数</span></span><br><span class="line">pd.set_option(<span class="string">"display.max_columns"</span>,<span class="number">500</span>)</span><br><span class="line"><span class="comment"># 导入数据</span></span><br><span class="line">data = pd.read_csv(<span class="string">'./house_price/train.csv'</span>)</span><br><span class="line"><span class="comment">#展示数据的前5行</span></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure></li></ol><div style="overflow:scroll;"><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Id</th>      <th>MSSubClass</th>      <th>MSZoning</th>      <th>LotFrontage</th>      <th>LotArea</th>      <th>Street</th>      <th>Alley</th>      <th>LotShape</th>      <th>LandContour</th>      <th>Utilities</th>      <th>LotConfig</th>      <th>LandSlope</th>      <th>Neighborhood</th>      <th>Condition1</th>      <th>Condition2</th>      <th>BldgType</th>      <th>HouseStyle</th>      <th>OverallQual</th>      <th>OverallCond</th>      <th>YearBuilt</th>      <th>YearRemodAdd</th>      <th>RoofStyle</th>      <th>RoofMatl</th>      <th>Exterior1st</th>      <th>Exterior2nd</th>      <th>MasVnrType</th>      <th>MasVnrArea</th>      <th>ExterQual</th>      <th>ExterCond</th>      <th>Foundation</th>      <th>BsmtQual</th>      <th>BsmtCond</th>      <th>BsmtExposure</th>      <th>BsmtFinType1</th>      <th>BsmtFinSF1</th>      <th>BsmtFinType2</th>      <th>BsmtFinSF2</th>      <th>BsmtUnfSF</th>      <th>TotalBsmtSF</th>      <th>Heating</th>      <th>HeatingQC</th>      <th>CentralAir</th>      <th>Electrical</th>      <th>1stFlrSF</th>      <th>2ndFlrSF</th>      <th>LowQualFinSF</th>      <th>GrLivArea</th>      <th>BsmtFullBath</th>      <th>BsmtHalfBath</th>      <th>FullBath</th>      <th>HalfBath</th>      <th>BedroomAbvGr</th>      <th>KitchenAbvGr</th>      <th>KitchenQual</th>      <th>TotRmsAbvGrd</th>      <th>Functional</th>      <th>Fireplaces</th>      <th>FireplaceQu</th>      <th>GarageType</th>      <th>GarageYrBlt</th>      <th>GarageFinish</th>      <th>GarageCars</th>      <th>GarageArea</th>      <th>GarageQual</th>      <th>GarageCond</th>      <th>PavedDrive</th>      <th>WoodDeckSF</th>      <th>OpenPorchSF</th>      <th>EnclosedPorch</th>      <th>3SsnPorch</th>      <th>ScreenPorch</th>      <th>PoolArea</th>      <th>PoolQC</th>      <th>Fence</th>      <th>MiscFeature</th>      <th>MiscVal</th>      <th>MoSold</th>      <th>YrSold</th>      <th>SaleType</th>      <th>SaleCondition</th>      <th>SalePrice</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>60</td>      <td>RL</td>      <td>65.0</td>      <td>8450</td>      <td>Pave</td>      <td>NaN</td>      <td>Reg</td>      <td>Lvl</td>      <td>AllPub</td>      <td>Inside</td>      <td>Gtl</td>      <td>CollgCr</td>      <td>Norm</td>      <td>Norm</td>      <td>1Fam</td>      <td>2Story</td>      <td>7</td>      <td>5</td>      <td>2003</td>      <td>2003</td>      <td>Gable</td>      <td>CompShg</td>      <td>VinylSd</td>      <td>VinylSd</td>      <td>BrkFace</td>      <td>196.0</td>      <td>Gd</td>      <td>TA</td>      <td>PConc</td>      <td>Gd</td>      <td>TA</td>      <td>No</td>      <td>GLQ</td>      <td>706</td>      <td>Unf</td>      <td>0</td>      <td>150</td>      <td>856</td>      <td>GasA</td>      <td>Ex</td>      <td>Y</td>      <td>SBrkr</td>      <td>856</td>      <td>854</td>      <td>0</td>      <td>1710</td>      <td>1</td>      <td>0</td>      <td>2</td>      <td>1</td>      <td>3</td>      <td>1</td>      <td>Gd</td>      <td>8</td>      <td>Typ</td>      <td>0</td>      <td>NaN</td>      <td>Attchd</td>      <td>2003.0</td>      <td>RFn</td>      <td>2</td>      <td>548</td>      <td>TA</td>      <td>TA</td>      <td>Y</td>      <td>0</td>      <td>61</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0</td>      <td>2</td>      <td>2008</td>      <td>WD</td>      <td>Normal</td>      <td>208500</td>    </tr>    <tr>      <th>1</th>      <td>2</td>      <td>20</td>      <td>RL</td>      <td>80.0</td>      <td>9600</td>      <td>Pave</td>      <td>NaN</td>      <td>Reg</td>      <td>Lvl</td>      <td>AllPub</td>      <td>FR2</td>      <td>Gtl</td>      <td>Veenker</td>      <td>Feedr</td>      <td>Norm</td>      <td>1Fam</td>      <td>1Story</td>      <td>6</td>      <td>8</td>      <td>1976</td>      <td>1976</td>      <td>Gable</td>      <td>CompShg</td>      <td>MetalSd</td>      <td>MetalSd</td>      <td>None</td>      <td>0.0</td>      <td>TA</td>      <td>TA</td>      <td>CBlock</td>      <td>Gd</td>      <td>TA</td>      <td>Gd</td>      <td>ALQ</td>      <td>978</td>      <td>Unf</td>      <td>0</td>      <td>284</td>      <td>1262</td>      <td>GasA</td>      <td>Ex</td>      <td>Y</td>      <td>SBrkr</td>      <td>1262</td>      <td>0</td>      <td>0</td>      <td>1262</td>      <td>0</td>      <td>1</td>      <td>2</td>      <td>0</td>      <td>3</td>      <td>1</td>      <td>TA</td>      <td>6</td>      <td>Typ</td>      <td>1</td>      <td>TA</td>      <td>Attchd</td>      <td>1976.0</td>      <td>RFn</td>      <td>2</td>      <td>460</td>      <td>TA</td>      <td>TA</td>      <td>Y</td>      <td>298</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0</td>      <td>5</td>      <td>2007</td>      <td>WD</td>      <td>Normal</td>      <td>181500</td>    </tr>    <tr>      <th>2</th>      <td>3</td>      <td>60</td>      <td>RL</td>      <td>68.0</td>      <td>11250</td>      <td>Pave</td>      <td>NaN</td>      <td>IR1</td>      <td>Lvl</td>      <td>AllPub</td>      <td>Inside</td>      <td>Gtl</td>      <td>CollgCr</td>      <td>Norm</td>      <td>Norm</td>      <td>1Fam</td>      <td>2Story</td>      <td>7</td>      <td>5</td>      <td>2001</td>      <td>2002</td>      <td>Gable</td>      <td>CompShg</td>      <td>VinylSd</td>      <td>VinylSd</td>      <td>BrkFace</td>      <td>162.0</td>      <td>Gd</td>      <td>TA</td>      <td>PConc</td>      <td>Gd</td>      <td>TA</td>      <td>Mn</td>      <td>GLQ</td>      <td>486</td>      <td>Unf</td>      <td>0</td>      <td>434</td>      <td>920</td>      <td>GasA</td>      <td>Ex</td>      <td>Y</td>      <td>SBrkr</td>      <td>920</td>      <td>866</td>      <td>0</td>      <td>1786</td>      <td>1</td>      <td>0</td>      <td>2</td>      <td>1</td>      <td>3</td>      <td>1</td>      <td>Gd</td>      <td>6</td>      <td>Typ</td>      <td>1</td>      <td>TA</td>      <td>Attchd</td>      <td>2001.0</td>      <td>RFn</td>      <td>2</td>      <td>608</td>      <td>TA</td>      <td>TA</td>      <td>Y</td>      <td>0</td>      <td>42</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0</td>      <td>9</td>      <td>2008</td>      <td>WD</td>      <td>Normal</td>      <td>223500</td>    </tr>    <tr>      <th>3</th>      <td>4</td>      <td>70</td>      <td>RL</td>      <td>60.0</td>      <td>9550</td>      <td>Pave</td>      <td>NaN</td>      <td>IR1</td>      <td>Lvl</td>      <td>AllPub</td>      <td>Corner</td>      <td>Gtl</td>      <td>Crawfor</td>      <td>Norm</td>      <td>Norm</td>      <td>1Fam</td>      <td>2Story</td>      <td>7</td>      <td>5</td>      <td>1915</td>      <td>1970</td>      <td>Gable</td>      <td>CompShg</td>      <td>Wd Sdng</td>      <td>Wd Shng</td>      <td>None</td>      <td>0.0</td>      <td>TA</td>      <td>TA</td>      <td>BrkTil</td>      <td>TA</td>      <td>Gd</td>      <td>No</td>      <td>ALQ</td>      <td>216</td>      <td>Unf</td>      <td>0</td>      <td>540</td>      <td>756</td>      <td>GasA</td>      <td>Gd</td>      <td>Y</td>      <td>SBrkr</td>      <td>961</td>      <td>756</td>      <td>0</td>      <td>1717</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>3</td>      <td>1</td>      <td>Gd</td>      <td>7</td>      <td>Typ</td>      <td>1</td>      <td>Gd</td>      <td>Detchd</td>      <td>1998.0</td>      <td>Unf</td>      <td>3</td>      <td>642</td>      <td>TA</td>      <td>TA</td>      <td>Y</td>      <td>0</td>      <td>35</td>      <td>272</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0</td>      <td>2</td>      <td>2006</td>      <td>WD</td>      <td>Abnorml</td>      <td>140000</td>    </tr>    <tr>      <th>4</th>      <td>5</td>      <td>60</td>      <td>RL</td>      <td>84.0</td>      <td>14260</td>      <td>Pave</td>      <td>NaN</td>      <td>IR1</td>      <td>Lvl</td>      <td>AllPub</td>      <td>FR2</td>      <td>Gtl</td>      <td>NoRidge</td>      <td>Norm</td>      <td>Norm</td>      <td>1Fam</td>      <td>2Story</td>      <td>8</td>      <td>5</td>      <td>2000</td>      <td>2000</td>      <td>Gable</td>      <td>CompShg</td>      <td>VinylSd</td>      <td>VinylSd</td>      <td>BrkFace</td>      <td>350.0</td>      <td>Gd</td>      <td>TA</td>      <td>PConc</td>      <td>Gd</td>      <td>TA</td>      <td>Av</td>      <td>GLQ</td>      <td>655</td>      <td>Unf</td>      <td>0</td>      <td>490</td>      <td>1145</td>      <td>GasA</td>      <td>Ex</td>      <td>Y</td>      <td>SBrkr</td>      <td>1145</td>      <td>1053</td>      <td>0</td>      <td>2198</td>      <td>1</td>      <td>0</td>      <td>2</td>      <td>1</td>      <td>4</td>      <td>1</td>      <td>Gd</td>      <td>9</td>      <td>Typ</td>      <td>1</td>      <td>TA</td>      <td>Attchd</td>      <td>2000.0</td>      <td>RFn</td>      <td>3</td>      <td>836</td>      <td>TA</td>      <td>TA</td>      <td>Y</td>      <td>192</td>      <td>84</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0</td>      <td>12</td>      <td>2008</td>      <td>WD</td>      <td>Normal</td>      <td>250000</td>    </tr>  </tbody></table></div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上表将所有的特征列都展示了出来，通过和描述文件结合，可以大概知道特征存在数值和类别两种不同形式的数据。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但仅有这些明显是不够的，在远距离观察之后，让我们走近一点，细细品一品这些有趣的数据。在接近它之前，还有一点点额外的工作需要做。我们知道在用<code>pandas</code>导入数据的时候，<code>DataFrame</code>会自动为我们创建<code>index</code>,而通过对数据的遥望，我们发现数据集中有一个叫<code>Id</code>的特征列是按照有序递增的方式排列的，这个特征列在描述文件中并没有提及，由此我们可以相信这是一个与数据集分布无关的列，只是每个实例的唯一标志——当然，得出这个结论其实不需要这么复杂的分析，因为它是显而易见的。因此，我们可以放弃自动生成的<code>index</code>而使用<code>Id</code>作为新的<code>index</code>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = data.set_index([<span class="string">'Id'</span>])</span><br></pre></td></tr></table></figure></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在，可以说是万事具备只欠东风了。是时候深入了解我们的数据了。我想没有什么能比图片更具有表现力了吧，现在就让我们来通过图来观察它。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数值型的特征有一个类别特征不具备的好处，它可以直接和目标值绘制出相关性，而接下来的代码就是做这件事的。我们首先将数值型的特征筛选出来，然后分别和<code>SalePrice</code>进行关联，<code>SalePrice</code>作为<code>Y</code>轴是因变量，特征值作为<code>X</code>轴是自变量<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">24</span>, <span class="number">36</span>))</span><br><span class="line">count = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> data[data.columns[data.dtypes != <span class="string">'object'</span>]]:</span><br><span class="line">    ax = fig.add_subplot(<span class="number">8</span>,<span class="number">5</span>, count)</span><br><span class="line">    ax.scatter(y=data[<span class="string">'SalePrice'</span>], x=data[x])</span><br><span class="line">    ax.set_xlabel(x, fontsize=<span class="number">13</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">'SalePrice'</span>, fontsize=<span class="number">13</span>)</span><br><span class="line">    ax.set_title(x)</span><br><span class="line">    count += <span class="number">1</span></span><br><span class="line">plt.subplots_adjust(hspace=<span class="number">0.9</span>, bottom=<span class="number">0.1</span>, wspace=<span class="number">0.4</span>)</span><br></pre></td></tr></table></figure></p><p><img src="/2019/05/25/House-Prices-Advanced-Regression-Techniques-1/Predict%20House%20Prices_5_0.png" alt="png"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过这些图，可以看出一些特征和目标有比较明显的线性关系，例如<code>TotalBsmtSF</code>、<code>1stFlrSF</code>和<code>2ndFlrSF</code>等，在进行特征值处理的时候就可以在这些数据上做些文章。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然，除了数据的相关性以外，还可以看出数据的一些其它情况，例如离群点。从下面的代码中可以看出我将大部分的离群点都做过处理，但是在这里我把它注释掉了。至于原因，当然是因为这么处理之后模型训练并不理想，这是因为在训练集中虽然可以删除所有的异常值，让数据看起来非常完美，让模型的训练准确率变得很高，但是这样做是没有意义的，因为这将导致在测试的时候效果变得很差，对于测试的数据，我们总不能也将这些异常值删去不做预测吧，就像在业务场景中我们不可能抛弃一部分看起来不太合理但实际存在的客户一样，所以后面采用了其它方式处理训练集和测试集的离群点.至于保留这部分注释，也是为了保留这个思考过程。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在众多删除异常值的代码中，唯独有一行并没有删去。这一行删除的数据是<code>[0, 3]</code>这张图的那两个异常点，是参考<a href="https://www.kaggle.com/pmarcelino" target="_blank" rel="noopener">@Pedro Marcelino</a>的<a href="https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python" target="_blank" rel="noopener">kenel</a>后选择保留的。刚开始保留的时候我其实并不太清楚为何<a href="https://www.kaggle.com/pmarcelino" target="_blank" rel="noopener">@Pedro Marcelino</a>独独要删去这两个离群点而对其它的视而不见，后来我阅读关于这个特征的描述——<em>Above grade (ground) living area square feet</em>以及后面的相关性矩阵发现这个特征和大多数的面积特征都有关系(毕竟它表示地上生活面积)，并且在去掉这两个离群点之后重新画了图，看到其它面积的离群点也一起消失了。这无疑证明了<a href="https://www.kaggle.com/pmarcelino" target="_blank" rel="noopener">@Pedro Marcelino</a>这种处理方式的合理性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># data.drop(data[data['LotFrontage'] &gt; 300].index, inplace=True)</span></span><br><span class="line"><span class="comment"># data.drop(data[data['LotArea'] &gt; 100000].index, inplace=True)</span></span><br><span class="line"><span class="comment"># data.drop(data[data['MasVnrArea'] &gt; 1500].index, inplace=True)</span></span><br><span class="line">data.drop(data[(data[<span class="string">'GrLivArea'</span>] &gt; <span class="number">4000</span>) &amp; (data[<span class="string">'SalePrice'</span>]&lt;<span class="number">300000</span>)].index, inplace=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># data.drop(data[data['BsmtFullBath'] == 3].index, inplace=True)</span></span><br><span class="line"><span class="comment"># data.drop(data[data['EnclosedPorch'] &gt; 400].index, inplace=True)</span></span><br><span class="line"><span class="comment"># data.drop(data[data['PoolArea'] &gt; 200].index, inplace=True)</span></span><br><span class="line"><span class="comment"># data.drop(data[data['MiscVal'] &gt; 5000].index, inplace=True)</span></span><br><span class="line"><span class="comment"># fig = plt.figure(figsize=(24, 36))</span></span><br><span class="line"><span class="comment"># count = 1</span></span><br><span class="line"><span class="comment"># for x in data[data.columns[data.dtypes != 'object']]:</span></span><br><span class="line"><span class="comment">#     ax = fig.add_subplot(8,5, count)</span></span><br><span class="line"><span class="comment">#     ax.scatter(y=data['SalePrice'], x=data[x])</span></span><br><span class="line"><span class="comment">#     ax.set_xlabel(x, fontsize=13)</span></span><br><span class="line"><span class="comment">#     ax.set_ylabel('SalePrice', fontsize=13)</span></span><br><span class="line"><span class="comment">#     ax.set_title(x)</span></span><br><span class="line"><span class="comment">#     count += 1</span></span><br><span class="line"><span class="comment"># plt.subplots_adjust(hspace=0.9, bottom=0.1, wspace=0.4)</span></span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;处理完了明显的异常点之后，换个方向，看看我们的目标值。我们知道线性模型往往最简单的回归模型，而根据<a href="https://baike.baidu.com/item/%E5%A5%A5%E5%8D%A1%E5%A7%86%E5%89%83%E5%88%80%E5%8E%9F%E7%90%86/10900565?fr=aladdin" target="_blank" rel="noopener">奥卡姆剃刀原理</a>，当两个模型拥有一致的性能的时候，选取相对简单的那个。适用线性模型的数据往往具有<a href="https://baike.baidu.com/item/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83/829892?fr=aladdin" target="_blank" rel="noopener">正态分布</a>的特性，为了明白线性模型是否适用于当前数据集，我们可以通过查看目标值是否满足这一特性。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过调用<code>seaborn</code>库的<code>distplot</code>函数，能够很简单明了的发现数据存在比较明显的偏斜。为了让数据分布更加符合正态分布，可以尝试对其进行取对数操作，因为取对数并不会影响数据的相对关系，并且可以减弱数据的<a href="https://baike.baidu.com/item/%E5%BC%82%E6%96%B9%E5%B7%AE%E6%80%A7/3206526?fromtitle=%E5%BC%82%E6%96%B9%E5%B7%AE&amp;fromid=17503121&amp;fr=aladdin" target="_blank" rel="noopener">异方差</a>。通过下方的第二张图可以发现，在进行对数操作之后的数据图形更加符合正态分布。</p><ul><li>原始<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看售价分布</span></span><br><span class="line">sbn.distplot(data[<span class="string">'SalePrice'</span>])</span><br></pre></td></tr></table></figure></li></ul><p><img src="/2019/05/25/House-Prices-Advanced-Regression-Techniques-1/Predict%20House%20Prices_7_1.png" alt="png"></p><ul><li>取对数<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbn.distplot(np.log1p(data[<span class="string">'SalePrice'</span>]))</span><br></pre></td></tr></table></figure></li></ul><p><img src="/2019/05/25/House-Prices-Advanced-Regression-Techniques-1/Predict%20House%20Prices_8_1.png" alt="png"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在，我们对数据集已经有了一个大概的了解，包括特征值和目标值，并知道了需要对目标值做相应的处理(上面的取对数操作)，是时候将目标值取出来放在旁边了。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用<code>DataFrame</code>提供的切片操作，将数据的特征和目标划分开并分别定义为<code>x_train</code>(特征)和<code>y_train</code>(目标)。在完成这个步骤之后，通过<code>info()</code>函数查看特征值的类型和数量关系，明确哪类特征有多少缺失值，方便后序处理。当我看见特征列中有部分数据存在大量缺失的时候，如<code>PoolQC</code>、<code>Fence</code>等，第一反应是直接删除这些数据，当然这种方式是欠考虑的；正如前文所述，在处理缺失值的时候我们应该考虑它是否代表该特征的部分特性以便做特殊处理。(后面未被删去的注释代码体现了这一思考过程)。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_train, y_train = data.loc[:,:<span class="string">'SaleCondition'</span>], np.log1p(data[<span class="string">'SalePrice'</span>]).get_values()</span><br><span class="line">x_train.info()</span><br></pre></td></tr></table></figure></p><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;Int64Index: 1458 entries, 1 to 1460Data columns (total 79 columns):MSSubClass       1458 non-null int64MSZoning         1458 non-null objectLotFrontage      1199 non-null float64LotArea          1458 non-null int64Street           1458 non-null objectAlley            91 non-null objectLotShape         1458 non-null objectLandContour      1458 non-null objectUtilities        1458 non-null objectLotConfig        1458 non-null objectLandSlope        1458 non-null objectNeighborhood     1458 non-null objectCondition1       1458 non-null objectCondition2       1458 non-null objectBldgType         1458 non-null objectHouseStyle       1458 non-null objectOverallQual      1458 non-null int64OverallCond      1458 non-null int64YearBuilt        1458 non-null int64YearRemodAdd     1458 non-null int64RoofStyle        1458 non-null objectRoofMatl         1458 non-null objectExterior1st      1458 non-null objectExterior2nd      1458 non-null objectMasVnrType       1450 non-null objectMasVnrArea       1450 non-null float64ExterQual        1458 non-null objectExterCond        1458 non-null objectFoundation       1458 non-null objectBsmtQual         1421 non-null objectBsmtCond         1421 non-null objectBsmtExposure     1420 non-null objectBsmtFinType1     1421 non-null objectBsmtFinSF1       1458 non-null int64BsmtFinType2     1420 non-null objectBsmtFinSF2       1458 non-null int64BsmtUnfSF        1458 non-null int64TotalBsmtSF      1458 non-null int64Heating          1458 non-null objectHeatingQC        1458 non-null objectCentralAir       1458 non-null objectElectrical       1457 non-null object1stFlrSF         1458 non-null int642ndFlrSF         1458 non-null int64LowQualFinSF     1458 non-null int64GrLivArea        1458 non-null int64BsmtFullBath     1458 non-null int64BsmtHalfBath     1458 non-null int64FullBath         1458 non-null int64HalfBath         1458 non-null int64BedroomAbvGr     1458 non-null int64KitchenAbvGr     1458 non-null int64KitchenQual      1458 non-null objectTotRmsAbvGrd     1458 non-null int64Functional       1458 non-null objectFireplaces       1458 non-null int64FireplaceQu      768 non-null objectGarageType       1377 non-null objectGarageYrBlt      1377 non-null float64GarageFinish     1377 non-null objectGarageCars       1458 non-null int64GarageArea       1458 non-null int64GarageQual       1377 non-null objectGarageCond       1377 non-null objectPavedDrive       1458 non-null objectWoodDeckSF       1458 non-null int64OpenPorchSF      1458 non-null int64EnclosedPorch    1458 non-null int643SsnPorch        1458 non-null int64ScreenPorch      1458 non-null int64PoolArea         1458 non-null int64PoolQC           6 non-null objectFence            281 non-null objectMiscFeature      54 non-null objectMiscVal          1458 non-null int64MoSold           1458 non-null int64YrSold           1458 non-null int64SaleType         1458 non-null objectSaleCondition    1458 non-null objectdtypes: float64(3), int64(33), object(43)memory usage: 911.2+ KB</code></pre><h2 id="数据分类"><a href="#数据分类" class="headerlink" title="数据分类"></a>数据分类</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;全局的审视已经告一段落了，是时候关注一些局部的细节了。正如前文已经提到的，特征一般分为两类，而现在就是要对两类数据分开讨论了。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这里，我们将会分别讨论数值型和类别型特征，包括数据分布，数值特征、数量关系等。</p><h3 id="数值型数据"><a href="#数值型数据" class="headerlink" title="数值型数据"></a>数值型数据</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在之前的分析中，我们已经其实已经对数值型的数据有一个大概的了解了，现在我们需要进行具体的数值分析。数值型的数据有很多的指标可以进行分析，通过平均数、中位数、分位数、总数、标准差等可以得到不少有用的信息。而这些指标可以使用<code>describe</code>方法直接求的，下面便是计算之后的结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_train.describe()</span><br></pre></td></tr></table></figure></p><div style="overflow:scroll;"><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>MSSubClass</th>      <th>LotFrontage</th>      <th>LotArea</th>      <th>OverallQual</th>      <th>OverallCond</th>      <th>YearBuilt</th>      <th>YearRemodAdd</th>      <th>MasVnrArea</th>      <th>BsmtFinSF1</th>      <th>BsmtFinSF2</th>      <th>BsmtUnfSF</th>      <th>TotalBsmtSF</th>      <th>1stFlrSF</th>      <th>2ndFlrSF</th>      <th>LowQualFinSF</th>      <th>GrLivArea</th>      <th>BsmtFullBath</th>      <th>BsmtHalfBath</th>      <th>FullBath</th>      <th>HalfBath</th>      <th>BedroomAbvGr</th>      <th>KitchenAbvGr</th>      <th>TotRmsAbvGrd</th>      <th>Fireplaces</th>      <th>GarageYrBlt</th>      <th>GarageCars</th>      <th>GarageArea</th>      <th>WoodDeckSF</th>      <th>OpenPorchSF</th>      <th>EnclosedPorch</th>      <th>3SsnPorch</th>      <th>ScreenPorch</th>      <th>PoolArea</th>      <th>MiscVal</th>      <th>MoSold</th>      <th>YrSold</th>    </tr>  </thead>  <tbody>    <tr>      <th>count</th>      <td>1458.000000</td>      <td>1199.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1450.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.00000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1377.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>      <td>1458.000000</td>    </tr>    <tr>      <th>mean</th>      <td>56.893004</td>      <td>69.797331</td>      <td>10459.936900</td>      <td>6.093964</td>      <td>5.576132</td>      <td>1971.218107</td>      <td>1984.834019</td>      <td>102.753793</td>      <td>438.827160</td>      <td>46.613169</td>      <td>567.096708</td>      <td>1052.537037</td>      <td>1158.851166</td>      <td>345.762003</td>      <td>5.852538</td>      <td>1510.465706</td>      <td>0.423868</td>      <td>0.057613</td>      <td>1.563786</td>      <td>0.38203</td>      <td>2.866255</td>      <td>1.046639</td>      <td>6.510974</td>      <td>0.611111</td>      <td>1978.464052</td>      <td>1.766118</td>      <td>472.050069</td>      <td>94.084362</td>      <td>46.245542</td>      <td>21.984225</td>      <td>3.414266</td>      <td>15.081619</td>      <td>2.433471</td>      <td>43.548697</td>      <td>6.323045</td>      <td>2007.816187</td>    </tr>    <tr>      <th>std</th>      <td>42.329437</td>      <td>23.203458</td>      <td>9859.198156</td>      <td>1.376369</td>      <td>1.113359</td>      <td>30.193754</td>      <td>20.641760</td>      <td>179.442156</td>      <td>432.969094</td>      <td>161.420729</td>      <td>442.087187</td>      <td>414.982320</td>      <td>372.039498</td>      <td>435.423924</td>      <td>48.655960</td>      <td>507.878508</td>      <td>0.517404</td>      <td>0.238907</td>      <td>0.549891</td>      <td>0.50271</td>      <td>0.816323</td>      <td>0.220483</td>      <td>1.615880</td>      <td>0.641988</td>      <td>24.682879</td>      <td>0.747104</td>      <td>212.239248</td>      <td>125.350021</td>      <td>65.312932</td>      <td>61.155666</td>      <td>29.337173</td>      <td>55.792877</td>      <td>38.209947</td>      <td>496.460799</td>      <td>2.700167</td>      <td>1.328826</td>    </tr>    <tr>      <th>min</th>      <td>20.000000</td>      <td>21.000000</td>      <td>1300.000000</td>      <td>1.000000</td>      <td>1.000000</td>      <td>1872.000000</td>      <td>1950.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>334.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>334.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.00000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>2.000000</td>      <td>0.000000</td>      <td>1900.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>1.000000</td>      <td>2006.000000</td>    </tr>    <tr>      <th>25%</th>      <td>20.000000</td>      <td>59.000000</td>      <td>7544.500000</td>      <td>5.000000</td>      <td>5.000000</td>      <td>1954.000000</td>      <td>1967.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>223.000000</td>      <td>795.250000</td>      <td>882.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>1128.500000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>1.000000</td>      <td>0.00000</td>      <td>2.000000</td>      <td>1.000000</td>      <td>5.000000</td>      <td>0.000000</td>      <td>1961.000000</td>      <td>1.000000</td>      <td>331.500000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>5.000000</td>      <td>2007.000000</td>    </tr>    <tr>      <th>50%</th>      <td>50.000000</td>      <td>69.000000</td>      <td>9475.000000</td>      <td>6.000000</td>      <td>5.000000</td>      <td>1972.500000</td>      <td>1994.000000</td>      <td>0.000000</td>      <td>382.000000</td>      <td>0.000000</td>      <td>477.500000</td>      <td>991.000000</td>      <td>1086.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>1461.500000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>2.000000</td>      <td>0.00000</td>      <td>3.000000</td>      <td>1.000000</td>      <td>6.000000</td>      <td>1.000000</td>      <td>1980.000000</td>      <td>2.000000</td>      <td>479.500000</td>      <td>0.000000</td>      <td>24.500000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>6.000000</td>      <td>2008.000000</td>    </tr>    <tr>      <th>75%</th>      <td>70.000000</td>      <td>80.000000</td>      <td>11600.000000</td>      <td>7.000000</td>      <td>6.000000</td>      <td>2000.000000</td>      <td>2004.000000</td>      <td>164.750000</td>      <td>711.000000</td>      <td>0.000000</td>      <td>808.000000</td>      <td>1296.750000</td>      <td>1390.750000</td>      <td>728.000000</td>      <td>0.000000</td>      <td>1776.000000</td>      <td>1.000000</td>      <td>0.000000</td>      <td>2.000000</td>      <td>1.00000</td>      <td>3.000000</td>      <td>1.000000</td>      <td>7.000000</td>      <td>1.000000</td>      <td>2002.000000</td>      <td>2.000000</td>      <td>576.000000</td>      <td>168.000000</td>      <td>68.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>8.000000</td>      <td>2009.000000</td>    </tr>    <tr>      <th>max</th>      <td>190.000000</td>      <td>313.000000</td>      <td>215245.000000</td>      <td>10.000000</td>      <td>9.000000</td>      <td>2010.000000</td>      <td>2010.000000</td>      <td>1600.000000</td>      <td>2188.000000</td>      <td>1474.000000</td>      <td>2336.000000</td>      <td>3206.000000</td>      <td>3228.000000</td>      <td>2065.000000</td>      <td>572.000000</td>      <td>4476.000000</td>      <td>3.000000</td>      <td>2.000000</td>      <td>3.000000</td>      <td>2.00000</td>      <td>8.000000</td>      <td>3.000000</td>      <td>14.000000</td>      <td>3.000000</td>      <td>2010.000000</td>      <td>4.000000</td>      <td>1390.000000</td>      <td>857.000000</td>      <td>547.000000</td>      <td>552.000000</td>      <td>508.000000</td>      <td>480.000000</td>      <td>738.000000</td>      <td>15500.000000</td>      <td>12.000000</td>      <td>2010.000000</td>    </tr>  </tbody></table></div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过<strong>count</strong>行可以比上面的全局更直观地看到哪些数据存在缺失，哪些没有；<strong>mean</strong>可以知道相应特征的平均值；<strong>std</strong>是指的标准差；<strong>min</strong>和<strong>max</strong>分别表示最小值和最大值；剩下对应的行是相对应的分位数。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过最大最小值可以得到数据的分布区间，比如<code>LotArea</code>的最大值为   <em>215245</em>而最小值为<em>1300</em>而<code>Fireplaces</code>最大值为<em>3</em>最小值为<em>0</em>。不同的区间会导致模型的性能不佳，所以需要进行标准化。标准化的方法有很多，有<strong>Min-Max标准化</strong><sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>和<strong>Z-score标准化</strong>，而这里用的是<code>StandardScaler</code>提供的<strong>Z-score标准化</strong>:</p><script type="math/tex; mode=display">z = \frac{x - u}{s}</script><ul><li>z: 标准化后的值</li><li>x: 原始值</li><li>u: 对应特征列的平均值</li><li>s: 对应特征列的标准差</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上述的的标准化已经基本使用到了除了分位数的所有指标，那么分位数又有什么用呢？先让我们画出箱线图吧。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">24</span>, <span class="number">24</span>))</span><br><span class="line">count = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> x_train[x_train.columns[x_train.dtypes != <span class="string">'object'</span>]]:</span><br><span class="line">    ax = fig.add_subplot(<span class="number">8</span>,<span class="number">5</span>, count)</span><br><span class="line">    ax.boxplot(x_train[x])</span><br><span class="line">    ax.set_title(x)</span><br><span class="line">    count += <span class="number">1</span></span><br></pre></td></tr></table></figure></p><p><img src="/2019/05/25/House-Prices-Advanced-Regression-Techniques-1/Predict%20House%20Prices_12_1.png" alt="png"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上面的图就是是所有数值型特征的箱线图，我想你也看到了这些图基本上都具有一箱三线多点的特征。提到箱线图就不得不说一下它的依据了，它是根据计算<strong>IQR(四分位距)</strong>来绘制的，这里先列出它的计算公式：</p><script type="math/tex; mode=display">IQR = Q_3 -Q_1</script><ul><li>$Q_3$表示上四分位数即$\frac{3}{4}$分位数</li><li>$Q_1$表示下四分位数即$\frac{1}{4}$分位数</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;箱线图中的矩形表示的就是<strong>IQR</strong>，矩形的上下边界分别就是指的$Q_3$和$Q_1$，而矩形中间的一条线是<strong>中位数</strong>；上下的线段分别叫做上极限和下极限，而超出这个界限的那些点就被视为异常点，下面是上下极限的计算方法：</p><ul><li>上极限$upper = Q_3+ 1.5IQR$</li><li>下极限$down = Q_1 - 1.5IQR$<br>下面是我在网上找的一张关于箱线图的详解<br><img src="/2019/05/25/House-Prices-Advanced-Regression-Techniques-1/箱线图.jpeg" alt="png"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;箱线图可以比较直观的观察数据的分布，知道其是否出现异常值，有多少异常值，数据是否偏斜等。通过上面的图，可以发现几乎每个特征都存在异常值，还有部分数据存在严重的偏斜。对于异常值，我们有多种处理方式：</li></ul><ol><li>删除异常值</li><li>用平均数或中位数修正</li><li>采用处理缺失值的方法</li><li>取对数减少极值影响</li><li>压缩极值到上下极限</li><li>不处理</li></ol><p>可以根据不同情况选取上述方式。而偏斜的数据我们之前其实已经做过处理，便是使用自然对数。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们已经通过箱线图观测到了异常值，也发现部分数据存在偏斜，那么接下来使用直方图来观察数据，明晰具体数据都存在怎样的偏斜。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_train.hist(figsize=(<span class="number">24</span>, <span class="number">24</span>))</span><br></pre></td></tr></table></figure></p><p><img src="/2019/05/25/House-Prices-Advanced-Regression-Techniques-1/Predict%20House%20Prices_13_1.png" alt="png"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过上图我们可以看到部分数据具有明显的正态分布，比如<code>OverallQual</code>、<code>TotRmsAbvGrd</code>，再结合箱线图发现他们的中位数缺失是靠近数据的中点的，这样的数据除了标准化就不用进行太多处理；但是像<code>BsmtUnfSF</code>和<code>2ndFlrSF</code>等就存在数据偏斜的问题，这部分数据除了需要进行归一化，可能还需要进行取对数平滑等操作来降低其可能带来的误差；除了上述的分布以外，我们还可以看到诸如<code>YrSold</code>的均匀分布和<code>3SsnPorch</code>这样的比较极端的分布，对于均匀分布我们不需要做太多处理，而对于那些比较极端分布可以根据数据的数量关系和对目标的影响来决定是否保留或做其它处理。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;之前我们使用散点图观察了数值型特征和目标之间的相关性并且排除了两个异常点，现在我们需要了解的是特征之间的相关性。关于相关性我们依然可以沿用散点图来进行观测，但是这里一共有<strong>36</strong>个特征，如果要绘制出两两之间的散点图，那么一共需要绘制<strong>1260</strong>张图，这是非常不利于观察和总结的。因此我们这里摒弃了这种方式，而是使用<code>seaborn</code>的<code>heatmap</code>方法来绘制出相关性矩阵的热力图。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">24</span>, <span class="number">24</span>))</span><br><span class="line">sbn.heatmap(x_train.corr(), linewidths=<span class="number">0.5</span>, annot=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure></p><p><img src="/2019/05/25/House-Prices-Advanced-Regression-Techniques-1/Predict%20House%20Prices_15_1.png" alt="png"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过上图我们可以看到有部分特征具有很高的相关性，比如<code>YearBuilt</code>和<code>GarageYrBlt``TotRmsAbvGrd</code>和<code>GrLiveArea</code>等。对于相关性高的数据，我们可以采用整合数据为新的特征列、留一去一等方式，这需要根据实际情况来决定。但是相关性矩阵有一个缺点就是其只能表示线性相关，而不能体现其它相关性，如多项式、指数等，但是往往线性相关就已经能能够说明问题。对于诸如多项式之类的可以在训练中使用核技巧(<em>如果必要</em>)来弥补这部分缺陷。</p><h3 id="非数值型数据"><a href="#非数值型数据" class="headerlink" title="非数值型数据"></a>非数值型数据</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如你所见，数值型特征有很多分析方法，通过图表可以对数据有很清晰的认知，同时基于认识可以规划出相应的处理方式。说完了数值型特征，那么就要处理非数值型的特征了。虽然非数值型的数据没有那么多分析方法，但是其复杂度却并不少，同样需要考虑异常值、数据分布等。下面先让我们看看数据的分布。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">24</span>, <span class="number">48</span>))</span><br><span class="line">count = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> x_train.columns[x_train.dtypes == <span class="string">'object'</span>]:</span><br><span class="line">    ax = fig.add_subplot(<span class="number">15</span>, <span class="number">3</span>, count)</span><br><span class="line">    temp_feature = x_train[x].value_counts()</span><br><span class="line">    feature_bar = ax.bar(range(temp_feature.shape[<span class="number">0</span>]), temp_feature.values,  align=<span class="string">'center'</span>)</span><br><span class="line">    ax.set_xticks(np.arange(temp_feature.shape[<span class="number">0</span>]))</span><br><span class="line">    <span class="keyword">if</span> temp_feature.shape[<span class="number">0</span>] &gt; <span class="number">10</span>:</span><br><span class="line">        indexs = [index[<span class="number">-2</span>:] <span class="keyword">for</span> index <span class="keyword">in</span> temp_feature.index]</span><br><span class="line">        ax.set_xticklabels(indexs)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ax.set_xticklabels(temp_feature.index)</span><br><span class="line">    <span class="keyword">for</span> bar <span class="keyword">in</span> feature_bar:</span><br><span class="line">        height = bar.get_height()</span><br><span class="line">        ax.text(bar.get_x()+bar.get_width()/<span class="number">2</span><span class="number">-0.1</span>, <span class="number">1.1</span>*height, str(height))</span><br><span class="line"><span class="comment">#     ax.set_ylim(0, 1.2 * temp_feature.values[0])</span></span><br><span class="line">    ax.set_title(x+<span class="string">'('</span>+str(np.sum(temp_feature))+<span class="string">')'</span>)</span><br><span class="line">    count+=<span class="number">1</span></span><br><span class="line">    </span><br><span class="line">plt.subplots_adjust(hspace=<span class="number">0.9</span>, bottom=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure></p><p><img src="/2019/05/25/House-Prices-Advanced-Regression-Techniques-1/Predict%20House%20Prices_18_0.png" alt="png"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;柱状图以每个特征的取值为横坐标，相应取值的数量为纵坐标，可以比较清晰地看到数据的数量关系。其中<code>Utilities</code>中共有1457条取值为<code>AllPub</code>的数据，1条取值为<code>NoSeWa</code>的数据，对训练并不会有什么帮助，因此可以删去这个特征。而其它的特征虽然也存在明显的偏斜，但是为了保证训练出来的模型不至于过拟合，还是应该适当保留这些特征而不应为了使数据完美而删去这部分特征。</p><h2 id="处理数据"><a href="#处理数据" class="headerlink" title="处理数据"></a>处理数据</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于数据的分析已经告一段落，接下来需要做的是结合之前的分析确定数据的处理方式了。这里使用创建<strong>Transformers</strong>类的方式来统筹数据处理，让我们依此来看下面类的作用：</p><ol><li><code>FeaturePreProcessing</code><br>这个类用于对所有的特征进行预处理，主要是转换数据的类别，因为有些数据虽然是数值类型，但是其表示的意义是一种类别关系，如果把其当成数字特征就隐含了大小关系，而这种特征是没有这种关系的，就会使模型进度下降，所以需要将这类数据的类型从<code>float</code>或<code>int</code>转换为<code>str</code>。同时，这里添加了使用<code>TotalBsmtSF</code>、<code>1stFlrSF</code>和<code>2ndFlrSF</code>添加了一个<code>TotalSF</code>组合特征，这是因为通过描述文件提供的信息可以得知这三个特征包含了一个的所有楼层建面信息。</li><li><code>FeatureSelect</code><br><code>FeatureSelect</code>类的作用比较简单，其目的只是单纯地为了分离数值型特征和非数值型特征以便后面分别进行处理。</li><li><code>NumericalImputer</code><br>对于数值型的数据，在之前进行处理的时候一开始是直接使用<code>sklearn</code>的<code>SimpleImputer</code>进行处理的，但后来比对描述文件，发现对空值不能这么一概而论，所以增加了这个类用于处理特定的数值特征空值(<em>用0填充</em>)</li><li><p><code>StringImputer</code><br>犹如分析时一样，处理完了数值型的特征便是处理非数值型的了。非数值型的特征缺失值有两种处理方式，第一种是根据描述文件表述的意思将<code>NA</code>替换为<code>None</code>，第二种是根据频率最高的填充。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> learning_curve</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeaturePreProcessing</span><span class="params">(BaseEstimator, TransformerMixin)</span>:</span></span><br><span class="line">    <span class="string">"""预处理所有特征"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        X[<span class="string">'MSSubClass'</span>] = X[<span class="string">'MSSubClass'</span>].astype(<span class="string">'str'</span>)</span><br><span class="line">        X[<span class="string">'YrSold'</span>] = X[<span class="string">'YrSold'</span>].astype(<span class="string">'str'</span>)</span><br><span class="line">        X[<span class="string">'MoSold'</span>] = X[<span class="string">'MoSold'</span>].astype(<span class="string">'str'</span>)</span><br><span class="line">        X[<span class="string">'OverallQual'</span>] = X[<span class="string">'OverallQual'</span>].astype(<span class="string">'str'</span>)</span><br><span class="line">        X[<span class="string">'OverallCond'</span>] = X[<span class="string">'OverallCond'</span>].astype(<span class="string">'str'</span>)</span><br><span class="line">        X[<span class="string">'TotalSF'</span>] = X[<span class="string">'TotalBsmtSF'</span>] + X[<span class="string">'1stFlrSF'</span>] + X[<span class="string">'2ndFlrSF'</span>]</span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeatureSelect</span><span class="params">(BaseEstimator, TransformerMixin)</span>:</span></span><br><span class="line">    <span class="string">"""特征选取"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, obj=True)</span>:</span></span><br><span class="line">        self.obj = obj</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> X[X.columns[X.dtypes == <span class="string">'object'</span>]] <span class="keyword">if</span> self.obj <span class="keyword">else</span> X[X.columns[X.dtypes != <span class="string">'object'</span>]]</span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NumericalImputer</span><span class="params">(BaseEstimator, TransformerMixin)</span>:</span></span><br><span class="line">    <span class="string">"""数值型特征填充空值"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        self.attributes = [<span class="string">'BsmtFinSF1'</span>, <span class="string">'BsmtFinSF2'</span>, <span class="string">'BsmtUnfSF'</span>, <span class="string">'TotalBsmtSF'</span>, <span class="string">'BsmtFullBath'</span>, <span class="string">'BsmtHalfBath'</span>, </span><br><span class="line">                           <span class="string">'Fireplaces'</span>, </span><br><span class="line">                           <span class="string">'MasVnrArea'</span>,</span><br><span class="line">                           <span class="string">'GarageCars'</span>, <span class="string">'GarageArea'</span>, <span class="string">'GarageYrBlt'</span>]</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> attribute <span class="keyword">in</span> self.attributes:</span><br><span class="line">            X[attribute].fillna(<span class="number">0.0</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">        <span class="comment"># 添加总面积特征</span></span><br><span class="line">        <span class="comment"># X['TotalSF'] = X['TotalBsmtSF'] + X['1stFlrSF'] + X['2ndFlrSF']</span></span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StringImputer</span><span class="params">(BaseEstimator, TransformerMixin)</span>:</span></span><br><span class="line">    <span class="string">"""填充String类型的空值"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        self.most_frequent_ = pd.Series([X[c].value_counts().index[<span class="number">0</span>] <span class="keyword">for</span> c <span class="keyword">in</span> X],</span><br><span class="line">                        index=X.columns)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Alley: Type of alley access to property</span></span><br><span class="line"><span class="string">           Grvl Gravel</span></span><br><span class="line"><span class="string">           Pave Paved</span></span><br><span class="line"><span class="string">           NA  No alley access</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        X[<span class="string">'Alley'</span>].fillna(<span class="string">'None'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        MasVnrType: Masonry veneer type</span></span><br><span class="line"><span class="string">           BrkCmn   Brick Common</span></span><br><span class="line"><span class="string">           BrkFace  Brick Face</span></span><br><span class="line"><span class="string">           CBlock   Cinder Block</span></span><br><span class="line"><span class="string">           None None</span></span><br><span class="line"><span class="string">           Stone    Stone</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        X[<span class="string">'MasVnrType'</span>].fillna(<span class="string">'None'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        BsmtCond: Evaluates the general condition of the basement</span></span><br><span class="line"><span class="string">           Ex   Excellent</span></span><br><span class="line"><span class="string">           Gd   Good</span></span><br><span class="line"><span class="string">           TA   Typical - slight dampness allowed</span></span><br><span class="line"><span class="string">           Fa   Fair - dampness or some cracking or settling</span></span><br><span class="line"><span class="string">           Po   Poor - Severe cracking, settling, or wetness</span></span><br><span class="line"><span class="string">           NA   No Basement</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        X[<span class="string">'BsmtCond'</span>].fillna(<span class="string">'None'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        BsmtExposure: Refers to walkout or garden level walls</span></span><br><span class="line"><span class="string">           Gd   Good Exposure</span></span><br><span class="line"><span class="string">           Av   Average Exposure (split levels or foyers typically score average or above)  </span></span><br><span class="line"><span class="string">           Mn   Mimimum Exposure</span></span><br><span class="line"><span class="string">           No   No Exposure</span></span><br><span class="line"><span class="string">           NA   No Basement</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        X[<span class="string">'BsmtExposure'</span>].fillna(<span class="string">'None'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        BsmtFinType1: Rating of basement finished area</span></span><br><span class="line"><span class="string">           GLQ  Good Living Quarters</span></span><br><span class="line"><span class="string">           ALQ  Average Living Quarters</span></span><br><span class="line"><span class="string">           BLQ  Below Average Living Quarters   </span></span><br><span class="line"><span class="string">           Rec  Average Rec Room</span></span><br><span class="line"><span class="string">           LwQ  Low Quality</span></span><br><span class="line"><span class="string">           Unf  Unfinshed</span></span><br><span class="line"><span class="string">           NA   No Basement</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        X[<span class="string">'BsmtFinType1'</span>].fillna(<span class="string">'None'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        BsmtFinType2: Rating of basement finished area (if multiple types)</span></span><br><span class="line"><span class="string">           GLQ  Good Living Quarters</span></span><br><span class="line"><span class="string">           ALQ  Average Living Quarters</span></span><br><span class="line"><span class="string">           BLQ  Below Average Living Quarters   </span></span><br><span class="line"><span class="string">           Rec  Average Rec Room</span></span><br><span class="line"><span class="string">           LwQ  Low Quality</span></span><br><span class="line"><span class="string">           Unf  Unfinshed</span></span><br><span class="line"><span class="string">           NA   No Basement</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        X[<span class="string">'BsmtFinType2'</span>].fillna(<span class="string">'None'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        FireplaceQu: Fireplace quality</span></span><br><span class="line"><span class="string">           Ex   Excellent - Exceptional Masonry Fireplace</span></span><br><span class="line"><span class="string">           Gd   Good - Masonry Fireplace in main level</span></span><br><span class="line"><span class="string">           TA   Average - Prefabricated Fireplace in main living area or Masonry Fireplace in basement</span></span><br><span class="line"><span class="string">           Fa   Fair - Prefabricated Fireplace in basement</span></span><br><span class="line"><span class="string">           Po   Poor - Ben Franklin Stove</span></span><br><span class="line"><span class="string">           NA   No Fireplace</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        X[<span class="string">'FireplaceQu'</span>].fillna(<span class="string">'None'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        GarageType: Garage location</span></span><br><span class="line"><span class="string">           2Types   More than one type of garage</span></span><br><span class="line"><span class="string">           Attchd   Attached to home</span></span><br><span class="line"><span class="string">           Basment  Basement Garage</span></span><br><span class="line"><span class="string">           BuiltIn  Built-In (Garage part of house - typically has room above garage)</span></span><br><span class="line"><span class="string">           CarPort  Car Port</span></span><br><span class="line"><span class="string">           Detchd   Detached from home</span></span><br><span class="line"><span class="string">           NA   No Garage</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        X[<span class="string">'GarageType'</span>].fillna(<span class="string">'None'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        GarageFinish: Interior finish of the garage</span></span><br><span class="line"><span class="string">           Fin  Finished</span></span><br><span class="line"><span class="string">           RFn  Rough Finished  </span></span><br><span class="line"><span class="string">           Unf  Unfinished</span></span><br><span class="line"><span class="string">           NA   No Garage</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        X[<span class="string">'GarageFinish'</span>].fillna(<span class="string">'None'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        GarageQual: Garage quality</span></span><br><span class="line"><span class="string">           Ex   Excellent</span></span><br><span class="line"><span class="string">           Gd   Good</span></span><br><span class="line"><span class="string">           TA   Typical/Average</span></span><br><span class="line"><span class="string">           Fa   Fair</span></span><br><span class="line"><span class="string">           Po   Poor</span></span><br><span class="line"><span class="string">           NA   No Garage</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        X[<span class="string">'GarageQual'</span>].fillna(<span class="string">'None'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        GarageCond: Garage condition</span></span><br><span class="line"><span class="string">           Ex   Excellent</span></span><br><span class="line"><span class="string">           Gd   Good</span></span><br><span class="line"><span class="string">           TA   Typical/Average</span></span><br><span class="line"><span class="string">           Fa   Fair</span></span><br><span class="line"><span class="string">           Po   Poor</span></span><br><span class="line"><span class="string">           NA   No Garage</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        X[<span class="string">'GarageCond'</span>].fillna(<span class="string">'None'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment">#         X['GarageYrBlt'].fillna('None', inplace=True)</span></span><br><span class="line">        <span class="string">"""  </span></span><br><span class="line"><span class="string">        PoolQC: Pool quality</span></span><br><span class="line"><span class="string">           Ex Excellent</span></span><br><span class="line"><span class="string">           Gd Good</span></span><br><span class="line"><span class="string">           TA Average/Typical</span></span><br><span class="line"><span class="string">           Fa Fair</span></span><br><span class="line"><span class="string">           NA No Pool</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        X[<span class="string">'PoolQC'</span>].fillna(<span class="string">'None'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Fence: Fence quality</span></span><br><span class="line"><span class="string">           GdPrv  Good Privacy</span></span><br><span class="line"><span class="string">           MnPrv  Minimum Privacy</span></span><br><span class="line"><span class="string">           GdWo  Good Wood</span></span><br><span class="line"><span class="string">           MnWw Minimum Wood/Wire</span></span><br><span class="line"><span class="string">           NA No Fence</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        X[<span class="string">'Fence'</span>].fillna(<span class="string">'None'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        MiscFeature: Miscellaneous feature not covered in other categories</span></span><br><span class="line"><span class="string">           Elev Elevator</span></span><br><span class="line"><span class="string">           Gar2 2nd Garage (if not described in garage section)</span></span><br><span class="line"><span class="string">           Othr Other</span></span><br><span class="line"><span class="string">           Shed Shed (over 100 SF)</span></span><br><span class="line"><span class="string">           TenC Tennis Court</span></span><br><span class="line"><span class="string">           NA None</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        X[<span class="string">'MiscFeature'</span>].fillna(<span class="string">'None'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">        <span class="keyword">return</span> X.fillna(self.most_frequent_)</span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DropFeature</span><span class="params">(BaseEstimator, TransformerMixin)</span>:</span></span><br><span class="line">    <span class="string">"""删除部分特征"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, features)</span>:</span></span><br><span class="line">        self.features = features</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> X.drop(self.features, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RemoveOutlier</span><span class="params">(BaseEstimator, TransformerMixin)</span>:</span></span><br><span class="line">    <span class="string">"""处理异常值"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        q1 = X.quantile(<span class="number">0.25</span>)</span><br><span class="line">        q3 = X.quantile(<span class="number">0.75</span>)</span><br><span class="line">        iqr = q3 - q1</span><br><span class="line">        self.upper = q3 + <span class="number">1.5</span> * iqr</span><br><span class="line">        self.down = q1 - <span class="number">1.5</span> * iqr</span><br><span class="line">        self.median = X.median()</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        X.where(X &lt;= self.upper, self.upper, axis=<span class="number">1</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">        X.where(X &gt;= self.down, self.down, axis=<span class="number">1</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment">#         X['MiscVal'].where(X['MiscVal'] &lt;= 5000, 5000, inplace=True)</span></span><br><span class="line"><span class="comment">#         X['LotFrontage'].where(X['LotFrontage'] &lt;= 300, 300, inplace=True)</span></span><br><span class="line"><span class="comment">#         X['LotArea'].where(X['LotArea'] &lt;= 100000, 100000, inplace=True )</span></span><br><span class="line"><span class="comment">#         X['MasVnrArea'].where(X['MasVnrArea'] &lt;= 1500, 1500, inplace=True)</span></span><br><span class="line"><span class="comment">#         X['GrLivArea'].where(X['GrLivArea'] &lt;= 4000, 4000, inplace=True)</span></span><br><span class="line"><span class="comment">#         X['EnclosedPorch'].where(X['EnclosedPorch'] &lt;= 400, 400, inplace=True)</span></span><br><span class="line"><span class="comment">#         X['MiscVal'].where(X['MiscVal'] &lt;= 5000, 5000, inplace=True)</span></span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_learning_curve</span><span class="params">(model, X, y)</span>:</span></span><br><span class="line">    train_size, train_scores, test_scores = learning_curve(model, X, y, </span><br><span class="line">                                                           n_jobs=<span class="number">-1</span>, verbose=<span class="keyword">True</span>, cv=<span class="number">10</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">    train_scores_mean = np.mean(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">    train_scores_std = np.std(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">    test_scores_mean = np.mean(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">    test_scores_std = np.std(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">    plt.grid()</span><br><span class="line"></span><br><span class="line">    plt.fill_between(train_size, train_scores_mean - train_scores_std,</span><br><span class="line">                    train_scores_mean + train_scores_std, alpha=<span class="number">0.1</span>,</span><br><span class="line">                    color=<span class="string">'r'</span>)</span><br><span class="line">    plt.fill_between(train_size, test_scores_mean - test_scores_std,</span><br><span class="line">                    test_scores_mean + test_scores_std, alpha=<span class="number">0.1</span>,</span><br><span class="line">                    color=<span class="string">'b'</span>)</span><br><span class="line">    plt.plot(train_size, train_scores_mean, <span class="string">'r-'</span>, label=<span class="string">'train'</span>)</span><br><span class="line">    plt.plot(train_size, test_scores_mean, <span class="string">'b--'</span>,label=<span class="string">'val'</span>)</span><br><span class="line">    plt.ylim(<span class="number">0.5</span>, <span class="number">1.05</span>)</span><br><span class="line">    plt.yticks( np.linspace(<span class="number">0.5</span>, <span class="number">1</span>, <span class="number">11</span>))</span><br><span class="line">    plt.xlabel(<span class="string">'Train Size'</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'acc'</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">'lower right'</span>)</span><br></pre></td></tr></table></figure></li><li><p><code>DropFeature</code><br>在进行数据分析的时候，我们有提到特征删除的情况，这个类就是为了处理这种情况，将筛选出需要删除的特征列作为它的处理对象，最后返回去除对应特征的特征</p></li><li><code>RemoveOutlier</code><br>正如整个代码所呈现的，该类中存在大量被注释的代码，这些就是前文所提到的删除异常值的尝试，但由于其不理想的效果，最后替换为根据<strong>IQR</strong>来处理异常值，即将界限外的值统一压缩到界限上。</li><li><code>plot_learning_curve</code><br>最后的是一个公用方法，其采用的是<code>sklearn.model_selection</code>的<code>learning_curve</code>方法计算出测试分数和训练分数，并根据这两个值画出对应的学习曲线，用这个曲线可以直观地评估模型的优劣，以便对模型做进一步分析。<br><br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;之前提到数据的处理是通过创建相应的<strong>Transformers</strong>来完成的，而为什么需要这么做却没有进行说明。<strong>Transformers</strong>的作用主要是对数据集进行处理和转换，具体的可以查看<em><a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html#sklearn.base.TransformerMixin" target="_blank" rel="noopener">sklearn</a></em>的官方文档。<strong>Transformers</strong>可以统一训练集、测试集乃至最后的预测数据处理方式，而不用单独对每一个数据集建立重复的处理代码，这显著地提高了代码的复用性；同时<strong>Transformers</strong>可以与<code>Pipeline</code>有效结合在一起，将整个数据处理简化成一个管道顺序进行，从而使数据处理更加简洁易懂。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> FeatureUnion</span><br><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"></span><br><span class="line">all_pipeline = Pipeline([</span><br><span class="line">    (<span class="string">'featurePre'</span>, FeaturePreProcessing())</span><br><span class="line">])</span><br><span class="line">numeric_pipeline = Pipeline([</span><br><span class="line"><span class="comment">#         ('drop', DropFeature(['PoolQC','YearBuilt', 'TotRmsAbvGrd', '1stFlrSF'])),</span></span><br><span class="line">        (<span class="string">'selector'</span>, FeatureSelect(<span class="keyword">False</span>)),</span><br><span class="line">        (<span class="string">'impute1'</span>, NumericalImputer()),</span><br><span class="line"><span class="comment">#         ('outlier', RemoveOutlier()),</span></span><br><span class="line">        (<span class="string">'impute'</span>, SimpleImputer(strategy=<span class="string">'median'</span>)),</span><br><span class="line">        (<span class="string">'standard'</span>, StandardScaler())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">cat_pipeline = Pipeline([</span><br><span class="line">        (<span class="string">'drop'</span>, DropFeature([ <span class="string">'Utilities'</span>])),</span><br><span class="line">        (<span class="string">'selector'</span>, FeatureSelect()),</span><br><span class="line">        (<span class="string">'impute'</span>, StringImputer()),</span><br><span class="line">        (<span class="string">'oneHot'</span>, OneHotEncoder(sparse=<span class="keyword">False</span>, handle_unknown=<span class="string">'ignore'</span>))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">full_pipeline = Pipeline([</span><br><span class="line">    (<span class="string">'all_pipeline'</span>, all_pipeline),</span><br><span class="line">    (<span class="string">'featureunion'</span>,FeatureUnion([</span><br><span class="line">        (<span class="string">'numeric_pipeline'</span>, numeric_pipeline),</span><br><span class="line">        (<span class="string">'cat_pipeline'</span>, cat_pipeline)]))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">x_train = full_pipeline.fit_transform(x_train)</span><br></pre></td></tr></table></figure></li></ol><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上面的代码便是使用<code>Pipeline</code>对不同特征进行不同的处理，其中我们创建的自不必多说，我们需要重点解释的是<code>sklearn.preprocessing</code>中导入的<code>StandardScaler</code>和<code>OneHotEncoder</code>以及<code>sklearn.impute</code>的<code>SimpleImputer</code>。</p><ol><li><code>StandardScaler</code><br><code>StandardScaler</code>是一个用于标准化的<strong>Transformer</strong>，其使用的是我们前面提到的<strong>Z-score标准化</strong></li><li><code>OneHotEncoder</code><br>在讨论分数值型特征的时候我们只看了数据的分布情况，而没有谈到对数据的处理方式。其实对于非数值型的特征一般分为两类，一种是将有明显大小关系的的特征转化为数值类特征，而另一种就是<code>OneHotEncoder</code>做的——将特征转化为<strong>OneHot</strong>向量。<strong>OneHot</strong>向量可以摒弃数值类数据的相关性，而只是单纯地作为不相关的类别进行使用。</li><li><code>SimpleImputer</code><br>和我们自己创建的<code>StringImputer</code>功能类似，只不过其是为了填充剩下(除<code>NumericalImputer</code>处理之外的)的数值类型特征，这里使用中位数<code>median</code>作为填充策略。</li></ol><h1 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;到目前为止我们已经花了大量的时间去分析处理数据，希望这些工作没有让你忘记我们一开始的目的——训练模型，之前所有的特征工程都是为了在最后能得到一个最优化模型，让我们能够使用这个模型预测未知的数据集。下面我将我进行过尝试的模型全部罗列了出来，让我们来一一地解读它们吧。</p><h2 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在使用随机梯度下降算法之前，我最先训练的是基于最小二乘法<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>的<code>LinearRegression</code>，但是其效果实在是差强人意，而<strong>sklearn</strong>提供的<code>LinearRegression</code>是基于最简单的最小二乘——<code>scipy.linalg.lstsq</code>——实现的，没有什么可以调节的参数来使模型具有更好的性能，因此我便想到使用<code>SGDRegressor</code>来替换。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_predict</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> RandomizedSearchCV</span><br><span class="line"><span class="comment"># lr_pipline = Pipeline([</span></span><br><span class="line"><span class="comment">#       ('poly', PolynomialFeatures(degree=2)),</span></span><br><span class="line"><span class="comment">#     ('lr', SGDRegressor(alpha=0.001, eta0=0.01,penalty='None', learning_rate='constant'))</span></span><br><span class="line"><span class="comment"># ])</span></span><br><span class="line"><span class="comment"># lr_pipline.fit(x_train, y_train)</span></span><br><span class="line"><span class="comment"># lr_pred = cross_val_predict(lr_pipline, x_train, y_train, </span></span><br><span class="line"><span class="comment">#                             verbose=True, n_jobs=-1, cv=3)</span></span><br><span class="line"><span class="comment"># lr_mse = mean_squared_error(lr_pred, y_train)</span></span><br><span class="line"><span class="comment"># np.sqrt(lr_mse)</span></span><br><span class="line">sgd = SGDRegressor(loss=<span class="string">'huber'</span>, early_stopping=<span class="keyword">True</span>, max_iter=<span class="number">5000</span>)</span><br><span class="line">sgd_grid_params = &#123;</span><br><span class="line">    <span class="string">'penalty'</span>: [<span class="string">'None'</span>, <span class="string">'l1'</span>, <span class="string">'l2'</span>, <span class="string">'elasticnet'</span>],</span><br><span class="line">    <span class="string">'alpha'</span>: np.linspace(<span class="number">1e-3</span>, <span class="number">0.01</span>),</span><br><span class="line">    <span class="string">'l1_ratio'</span>: np.linspace(<span class="number">0</span>, <span class="number">1</span>),</span><br><span class="line">    <span class="string">'learning_rate'</span>: [<span class="string">'constant'</span>, <span class="string">'optimal'</span>, <span class="string">'invscaling'</span>, <span class="string">'adaptive'</span>],</span><br><span class="line">    <span class="string">'eta0'</span>: np.linspace(<span class="number">1e-3</span>, <span class="number">1</span>),</span><br><span class="line">    <span class="string">'power_t'</span>: np.linspace(<span class="number">1e-3</span>, <span class="number">1</span>),</span><br><span class="line">    <span class="string">'epsilon'</span>: np.linspace(<span class="number">1e-3</span>, <span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line">sgd_rnd_cv = RandomizedSearchCV(sgd, param_distributions=sgd_grid_params, cv=<span class="number">5</span>, </span><br><span class="line">                                verbose=<span class="keyword">True</span>, n_jobs=<span class="number">-1</span>)</span><br><span class="line">sgd_rnd_cv.fit(x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>Fitting 5 folds for each of 10 candidates, totalling 50 fits[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.4min[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  4.2min finishedRandomizedSearchCV(cv=5, error_score=&#39;raise-deprecating&#39;,          estimator=SGDRegressor(alpha=0.0001, average=False, early_stopping=True, epsilon=0.1,       eta0=0.01, fit_intercept=True, l1_ratio=0.15,       learning_rate=&#39;invscaling&#39;, loss=&#39;huber&#39;, max_iter=5000,       n_iter=None, n_iter_no_change=5, penalty=&#39;l2&#39;, power_t=0.25,       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,       verbose=0, warm_start=False),          fit_params=None, iid=&#39;warn&#39;, n_iter=10, n_jobs=-1,          param_distributions={&#39;penalty&#39;: [&#39;None&#39;, &#39;l1&#39;, &#39;l2&#39;, &#39;elasticnet&#39;], &#39;alpha&#39;: array([0.001  , 0.00118, 0.00137, 0.00155, 0.00173, 0.00192, 0.0021 ,       0.00229, 0.00247, 0.00265, 0.00284, 0.00302, 0.0032 , 0.00339,       0.00357, 0.00376, 0.00394, 0.00412, 0.00431, 0.00449, 0.00467,       0.0048...51, 0.8369 ,       0.85729, 0.87767, 0.89806, 0.91845, 0.93884, 0.95922, 0.97961,       1.     ])},          pre_dispatch=&#39;2*n_jobs&#39;, random_state=None, refit=True,          return_train_score=&#39;warn&#39;, scoring=None, verbose=True)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sgd_rnd_cv.best_score_</span><br></pre></td></tr></table></figure><pre><code>0.9010049934685431</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sgd_rnd_cv.best_estimator_</span><br></pre></td></tr></table></figure><pre><code>SGDRegressor(alpha=0.0017346938775510204, average=False, early_stopping=True,       epsilon=0.6941836734693878, eta0=0.1437142857142857,       fit_intercept=True, l1_ratio=0.5510204081632653,       learning_rate=&#39;optimal&#39;, loss=&#39;huber&#39;, max_iter=5000, n_iter=None,       n_iter_no_change=5, penalty=&#39;l1&#39;, power_t=0.5922448979591837,       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,       verbose=0, warm_start=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sgd_pred = cross_val_predict(sgd_rnd_cv.best_estimator_, x_train, y_train, </span><br><span class="line">                            verbose=<span class="keyword">True</span>, n_jobs=<span class="number">-1</span>, cv=<span class="number">3</span>)</span><br><span class="line">sgd_mse = mean_squared_error(sgd_pred, y_train)</span><br><span class="line">np.sqrt(sgd_mse)</span><br></pre></td></tr></table></figure><pre><code>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   20.7s finished0.12857487720273592</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>SGDRegressor</code>使用随机梯度下降来最小化损失函数，它拥有多种参数可供调节，具体可以参考<a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor" target="_blank" rel="noopener">官方文档</a>。在我直接使用<code>SGDRegressor</code>默认参数进行训练的时候，发现误差非常大，后来加了各种参数，使用<code>RandomizedSearchCV</code>来进行参数搜索之后依然没有降低这种误差；直到我增加<code>max_iter</code>这一参数，才使得学习曲线逼近并趋近于<em>0.9</em>，这让我意识到之前之所以会出现这种量级的误差可能是训练数据集过小，导致结果无法收敛，而在<a href="https://scikit-learn.org/stable/modules/sgd.html#regression" target="_blank" rel="noopener">文档</a>中也确实明确说明了随机梯度下降适用于实例数量大于$10^4$的数据集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_learning_curve(sgd_rnd_cv.best_estimator_, x_train, y_train)</span><br></pre></td></tr></table></figure><pre><code>[learning_curve] Training set sizes: [ 131  426  721 1016 1312][Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  3.2min finished</code></pre><p><img src="/2019/05/25/House-Prices-Advanced-Regression-Techniques-1/Predict%20House%20Prices_30_2.png" alt="png"></p><h3 id="比对线性回归"><a href="#比对线性回归" class="headerlink" title="比对线性回归"></a>比对线性回归</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;之前提到<code>LinearRegression</code>是我尝试的第一个训练算法，但由于其不太好的表现效果被我弃置不顾，在我训练完<code>SGDRegressor</code>之后我又对<code>LinearRegression</code>进行了一些不同的尝试，比如这里将线性模型通过<code>PolynomialFeatures</code>将其变成一个二次型的多项式模型，这样的改变取得还算不错的成绩，只是其学习曲线反应出了它的明显缺陷，比如过拟合、验证结果波动等。这说明只是简单地使用多项式模型还是有不小的瑕疵的。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_predict</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line">lr_pipline = Pipeline([</span><br><span class="line">    (<span class="string">'poly'</span>, PolynomialFeatures(degree=<span class="number">2</span>)),</span><br><span class="line">    (<span class="string">'lr'</span>, LinearRegression())</span><br><span class="line">])</span><br><span class="line">lr_pipline.fit(x_train, y_train)</span><br><span class="line">lr_pred = cross_val_predict(lr_pipline, x_train, y_train, </span><br><span class="line">                            verbose=<span class="keyword">True</span>, n_jobs=<span class="number">-1</span>, cv=<span class="number">3</span>)</span><br><span class="line">lr_mse = mean_squared_error(lr_pred, y_train)</span><br><span class="line">np.sqrt(lr_mse)</span><br></pre></td></tr></table></figure></p><pre><code>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   52.8s finished0.14167592407063873</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_learning_curve(lr_pipline, x_train, y_train)</span><br></pre></td></tr></table></figure><pre><code>[learning_curve] Training set sizes: [ 131  426  721 1016 1312][Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 12.8min finished</code></pre><p><img src="/2019/05/25/House-Prices-Advanced-Regression-Techniques-1/Predict%20House%20Prices_33_2.png" alt="png"></p><h2 id="岭回归"><a href="#岭回归" class="headerlink" title="岭回归"></a>岭回归</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;既然说到最小二乘法，就不得不提一下它的变体了。最小二乘法通过最小化均方误差来最小化损失函数，而它的变体体现在使用不同的正则化方法。岭回归便是使用二范数<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>来进行正则化(即<strong>l2正则</strong>)：</p><script type="math/tex; mode=display">\min_{w} || X w - y||_2^2 + \alpha ||w||_2^2</script><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过选取不同的$\alpha$来对系数做不同的限制$w$，当$\alpha$足够小时，会使得一些作用不大的系数变得非常小但又不会为0，这即减小了过拟合的风险又保证了模型的复杂性，不至于损失过多的特征。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里选用的是<code>sklearn.kernel_ridge</code>的<code>KernelRidge</code>，该种实现使用到了核技巧<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>来使数据线性可分。由于前面的线性回归中使用多项式回归取得了一定的效果，所以这里选用了<strong>二次的多项式核</strong>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.kernel_ridge <span class="keyword">import</span> KernelRidge</span><br><span class="line"></span><br><span class="line">ridge = KernelRidge(degree=<span class="number">2</span>, alpha=<span class="number">0.05</span>, kernel=<span class="string">'polynomial'</span>)</span><br><span class="line">ridge_pred = cross_val_predict(ridge, x_train, y_train, </span><br><span class="line">                               cv=<span class="number">3</span>, verbose=<span class="keyword">True</span>, n_jobs=<span class="number">-1</span>)</span><br><span class="line">ridge_mse = mean_squared_error(y_train, ridge_pred)</span><br><span class="line">np.sqrt(ridge_mse)</span><br></pre></td></tr></table></figure></p><pre><code>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.5s finished0.11650866851364311</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面便是岭回归的学习曲线，我们可以发现其表现效果远好于上面的线性回归，就准确度而言也高于自己调试的随机梯度下降，但是也可以发现它的训练曲线和验证曲线相比梯度下降来说有一定间隙，可以判定其存在一定程度的过拟合。解决过拟合的方法有很多，比如增加数据量，降低模型复杂度等。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_learning_curve(ridge, x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[learning_curve] Training set sizes: [ 131  426  721 1016 1312][Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.3s finished</code></pre><p><img src="/2019/05/25/House-Prices-Advanced-Regression-Techniques-1/Predict%20House%20Prices_29_3.png" alt="png"></p><h2 id="LASSO回归"><a href="#LASSO回归" class="headerlink" title="LASSO回归"></a>LASSO回归</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;既然讨论了使用<strong>l2正则</strong>的<em>Ridge</em>，又怎么能忘了使用<strong>l1</strong>正则的<em>Lasso</em>呢。<em>Lasso和</em>Ridge*唯一不同的地方是它使用了一范数来代替而范数也就是使用绝对值来代替平方：</p><script type="math/tex; mode=display">\min_{w} { \frac{1}{2n_{\text{samples}}} ||X w - y||_2 ^ 2 + \alpha ||w||_1}</script><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>l1正则</strong>在训练过程中会使得相关的系数择一保留，这使得最后的系数保留了大量的0而产生一个稀疏向量，这能有效地减少特征，降低纬度。虽然这能有效缓解过拟合的问题，但是也可能造成精度丧失，而使得模型的泛化能力不足的情况。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line">lasso = Lasso(alpha=<span class="number">0.0005</span>)</span><br><span class="line">lasso_pred = cross_val_predict(lasso, x_train, y_train, </span><br><span class="line">                               cv=<span class="number">3</span>, verbose=<span class="keyword">True</span>, n_jobs=<span class="number">-1</span>)</span><br><span class="line">lasso_mse = mean_squared_error(lasso_pred, y_train)</span><br><span class="line">np.sqrt(lasso_mse)</span><br></pre></td></tr></table></figure><pre><code>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.2s finished0.1165640368257087</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们已经对<em>Lasso</em>的原理做了一个简单的介绍，下面来看看它的效果如何。在上面的代码中我们只设置了<code>alpha</code>这个关键参数，这个参数起的作用和<em>Ridge</em>中一样，在此便不在多做赘述。<em>Lasso</em>和<em>Ridge</em>最后的结果似乎非常接近，但是就模型复杂度而言<em>Ridge</em>不仅保留了所有的系数，同时还使用了核技巧将模型转化为二次型多项式，而<em>Lasso</em>完全没有任何其它的操作，根据奥卡姆剃刀原理，如果就两者中选择似乎应该优先选择<em>Lasso</em>。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们再看看学习曲线，<em>Lasso</em>和<em>Ridge</em>的学习曲线表现出的准确度和上面的均方误差一样都很接近，但是也可以明显地看到<em>Lasso</em>训练和验证两条线更为靠近，这有理由让我们相信它已经优化了<em>Ridge</em>的过拟合问题。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_learning_curve(lasso, x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[learning_curve] Training set sizes: [ 131  426  721 1016 1312][Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.5s finished</code></pre><p><img src="/2019/05/25/House-Prices-Advanced-Regression-Techniques-1/Predict%20House%20Prices_33_3.png" alt="png"></p><h2 id="Elastic-Net"><a href="#Elastic-Net" class="headerlink" title="Elastic Net"></a>Elastic Net</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>l1</strong>和<strong>l2</strong>我们都已经单独进行训练和分析，并且发现两种方式都能取得不错的效果，既然如此，何不将两种方式结合起来试试呢。<strong>Elastic Net</strong>就是将两者结合起来的产物，其公式如下：</p><script type="math/tex; mode=display">\min_{w} { \frac{1}{2n_{\text{samples}}} ||X w - y||_2 ^ 2 + \alpha \rho ||w||_1 + \frac{\alpha(1-\rho)}{2} ||w||_2 ^ 2}</script><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中$\rho$用于控制<strong>l1</strong>和<strong>l2</strong>的权衡，这样的方式使得训练过程中如果有多个相关性很高的系数会可能保留多个而不是像<strong>Lasso</strong>那样随机选取一个，同时也能拥有<strong>Ridge</strong>在应对数据旋转时的稳定性。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> ElasticNet</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_predict</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line">en = ElasticNet(max_iter=<span class="number">5000</span>, selection=<span class="string">'random'</span>)</span><br><span class="line">en_param = &#123;</span><br><span class="line">    <span class="string">'l1_ratio'</span>: np.linspace(<span class="number">0.01</span>, <span class="number">1</span>, <span class="number">11</span>),</span><br><span class="line">    <span class="string">'alpha'</span>: np.linspace(<span class="number">0.0005</span>, <span class="number">0.1</span>,<span class="number">11</span>)</span><br><span class="line">&#125;</span><br><span class="line">en_grid_cv = GridSearchCV(en, param_grid=en_param, verbose=<span class="keyword">True</span>, </span><br><span class="line">                                cv=<span class="number">5</span>, n_jobs=<span class="number">-1</span>)</span><br><span class="line">en_grid_cv.fit(x_train, y_train)</span><br><span class="line"><span class="comment"># en = ElasticNet(alpha=0.0005, copy_X=True, fit_intercept=True,</span></span><br><span class="line"><span class="comment">#       l1_ratio=0.3, max_iter=1000, normalize=False, positive=False,</span></span><br><span class="line"><span class="comment">#       precompute=False, random_state=None, selection='cyclic', tol=0.0001,</span></span><br><span class="line"><span class="comment">#       warm_start=False)</span></span><br><span class="line"><span class="comment"># en.fit(x_train, y_train)</span></span><br></pre></td></tr></table></figure></p><pre><code>Fitting 5 folds for each of 121 candidates, totalling 605 fits[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.3s[Parallel(n_jobs=-1)]: Done 500 tasks      | elapsed:   19.2s[Parallel(n_jobs=-1)]: Done 605 out of 605 | elapsed:   19.9s finishedGridSearchCV(cv=5, error_score=&#39;raise-deprecating&#39;,       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,      max_iter=5000, normalize=False, positive=False, precompute=False,      random_state=None, selection=&#39;random&#39;, tol=0.0001, warm_start=False),       fit_params=None, iid=&#39;warn&#39;, n_jobs=-1,       param_grid={&#39;l1_ratio&#39;: array([0.01 , 0.109, 0.208, 0.307, 0.406, 0.505, 0.604, 0.703, 0.802,       0.901, 1.   ]), &#39;alpha&#39;: array([0.0005 , 0.01045, 0.0204 , 0.03035, 0.0403 , 0.05025, 0.0602 ,       0.07015, 0.0801 , 0.09005, 0.1    ])},       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,       scoring=None, verbose=True)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">en = en_grid_cv.best_estimator_</span><br><span class="line">en_grid_cv.best_estimator_</span><br></pre></td></tr></table></figure><pre><code>ElasticNet(alpha=0.0005, copy_X=True, fit_intercept=True, l1_ratio=1.0,      max_iter=5000, normalize=False, positive=False, precompute=False,      random_state=None, selection=&#39;random&#39;, tol=0.0001, warm_start=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># en_grid_cv.best_score_</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">en_pred = cross_val_predict(en, x_train, y_train, </span><br><span class="line">                            verbose=<span class="keyword">True</span>, n_jobs=<span class="number">-1</span>, cv=<span class="number">3</span>)</span><br><span class="line">mse = mean_squared_error(y_train, en_pred)</span><br><span class="line">np.sqrt(mse)</span><br></pre></td></tr></table></figure><pre><code>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished0.11655822747866447</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然上面说了<strong>Elastic Net</strong>的优点，但是在针对这个数据集的时候其最后得出的模型却与预期背道而驰。它最后选择的<code>l1_ration</code>也就是$\rho$为1，这也就意味着这个模型完全没有使用<strong>l2</strong>，而是只使用了<strong>l1</strong>，最后退化成了<strong>Lasso</strong>。从最后的均方误差和学习曲线也可以看出其和<strong>Lasso</strong>非常接近。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_learning_curve(en, x_train, y_train)</span><br></pre></td></tr></table></figure></p><pre><code>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.[learning_curve] Training set sizes: [ 131  426  721 1016 1312][Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.8s finished</code></pre><p><img src="/2019/05/25/House-Prices-Advanced-Regression-Techniques-1/Predict%20House%20Prices_47_3.png" alt="png"></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;说是小结，其实是对突然决定分篇的一个阐述。因为后面的模型都是集成模型，但是在训练时都有明显的过拟合问题，因此我又尝试重新训练这些模型，而最后当然是以失败告终了。在不停地尝试，搜索最佳参数的过程中，我突然意识到或许我只是在碰运气，而没有具体地去分析这些参数对模型最后的影响，所以失败是不言而喻的。基于此，我决定先写到这儿，待我将剩下的模型都一一分析透彻之后再单开一篇专门来专门叙述。</p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">$z = \frac{m - min}{max - min}$</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;">$\min_{w} || X w - y||_2^2$</span><a href="#fnref:2" rev="footnote"> ↩</a></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">3.</span><span style="display: inline-block; vertical-align: top;">空间上两个向量矩阵的直线距离</span><a href="#fnref:3" rev="footnote"> ↩</a></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">4.</span><span style="display: inline-block; vertical-align: top;">将低维空间的数据通过核函数映射到高维空间</span><a href="#fnref:4" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      这是我第一个真正意义上完成的机器学习项目
    
    </summary>
    
      <category term="机器学习" scheme="http://coldjune.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="kaggle" scheme="http://coldjune.com/tags/kaggle/"/>
    
  </entry>
  
  <entry>
    <title>Reinforcement Learning</title>
    <link href="http://coldjune.com/2019/01/08/Reinforcement-Learning/"/>
    <id>http://coldjune.com/2019/01/08/Reinforcement-Learning/</id>
    <published>2019-01-08T01:10:31.000Z</published>
    <updated>2019-05-17T14:32:54.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引入OpenAI-gym"><a href="#引入OpenAI-gym" class="headerlink" title="引入OpenAI gym"></a>引入OpenAI gym</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">%matplotlib nbagg</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.animation <span class="keyword">as</span> animation</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gym</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env = gym.make(<span class="string">"MsPacman-v0"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">obs = env.reset()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">obs.shape</span><br></pre></td></tr></table></figure><pre><code>(210, 160, 3)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = env.render(mode=<span class="string">"rgb_array"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">4</span>))</span><br><span class="line">plt.imshow(img)</span><br><span class="line">plt.axis(<span class="string">"off"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>&lt;IPython.core.display.Javascript object&gt;</code></pre><p><img src="data:image/png;base64,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" width="498.88890210493145"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(img == obs).all()</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_environment</span><span class="params">(env, figsize=<span class="params">(<span class="number">5</span>, <span class="number">4</span>)</span>)</span>:</span></span><br><span class="line">    plt.close()</span><br><span class="line">    plt.figure(figsize=figsize)</span><br><span class="line">    img = env.render(mode=<span class="string">"rgb_array"</span>)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    plt.axis(<span class="string">"off"</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env.action_space</span><br></pre></td></tr></table></figure><pre><code>Discrete(9)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">env.reset()</span><br><span class="line">plot_environment(env)</span><br></pre></td></tr></table></figure><pre><code>&lt;IPython.core.display.Javascript object&gt;</code></pre><p><img src="data:image/png;base64,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" width="498.88890210493145"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">110</span>):</span><br><span class="line">    env.step(<span class="number">3</span>) <span class="comment">#left</span></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">40</span>):</span><br><span class="line">    env.step(<span class="number">8</span>) <span class="comment">#lower-left</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_environment(env)</span><br></pre></td></tr></table></figure><pre><code>&lt;IPython.core.display.Javascript object&gt;</code></pre><p><img src="data:image/png;base64,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" width="498.88890210493145"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">obs, reward, done, info = env.step(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#observation告诉代理环境是什么样的</span></span><br><span class="line">obs.shape <span class="comment">#210*160RGB图像</span></span><br></pre></td></tr></table></figure><pre><code>(210, 160, 3)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#最后一步的得分</span></span><br><span class="line">reward</span><br></pre></td></tr></table></figure><pre><code>10.0</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#游戏结束 done=True</span></span><br><span class="line">done</span><br></pre></td></tr></table></figure><pre><code>False</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#额外信息</span></span><br><span class="line">info</span><br></pre></td></tr></table></figure><pre><code>{&#39;ale.lives&#39;: 3}</code></pre><h2 id="随机游玩"><a href="#随机游玩" class="headerlink" title="随机游玩"></a>随机游玩</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">frames = []</span><br><span class="line"></span><br><span class="line">n_max_steps = <span class="number">1000</span></span><br><span class="line">n_change_steps = <span class="number">10</span></span><br><span class="line">obs = env.reset()</span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(n_max_steps):</span><br><span class="line">    img = env.render(mode=<span class="string">"rgb_array"</span>)</span><br><span class="line">    frames.append(img)</span><br><span class="line">    <span class="keyword">if</span> step % n_change_steps == <span class="number">0</span>:</span><br><span class="line">        action = env.action_space.sample()</span><br><span class="line">    obs, reward, done, info = env.step(action)</span><br><span class="line">    <span class="keyword">if</span> done:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_scene</span><span class="params">(num, frames, patch)</span>:</span></span><br><span class="line">    patch.set_data(frames[num])</span><br><span class="line">    <span class="keyword">return</span> patch</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_animation</span><span class="params">(frames, repeat=False, interval=<span class="number">40</span>)</span>:</span></span><br><span class="line">    plt.close()</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    patch = plt.imshow(frames[<span class="number">0</span>])</span><br><span class="line">    plt.axis(<span class="string">"off"</span>)</span><br><span class="line">    <span class="keyword">return</span> animation.FuncAnimation(fig, update_scene, fargs=(frames, patch),</span><br><span class="line">                                  frames=len(frames), repeat=repeat, interval=interval)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">video = plot_animation(frames)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>&lt;IPython.core.display.Javascript object&gt;</code></pre><p><img src="data:image/png;base64,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" width="638.888905813665"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env.close()</span><br></pre></td></tr></table></figure><h2 id="Cart-Pole"><a href="#Cart-Pole" class="headerlink" title="Cart-Pole"></a>Cart-Pole</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">env = gym.make(<span class="string">"CartPole-v0"</span>)</span><br><span class="line">obs = env.reset()</span><br><span class="line">obs</span><br></pre></td></tr></table></figure><pre><code>array([ 0.01760912,  0.02315423,  0.03459495, -0.03431416])</code></pre><h3 id="修复渲染问题"><a href="#修复渲染问题" class="headerlink" title="修复渲染问题"></a>修复渲染问题</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageDraw</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> pyglet.gl <span class="keyword">import</span> gl_info</span><br><span class="line">    openai_cart_pole_rendering = <span class="keyword">True</span></span><br><span class="line"><span class="keyword">except</span> Exception:</span><br><span class="line">    openai_cart_pole_rendering = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">render_cart_pole</span><span class="params">(env, obs)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> openai_cart_pole_rendering:</span><br><span class="line">        <span class="keyword">return</span> env.render(mode=<span class="string">"rgb_array"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        img_w = <span class="number">600</span></span><br><span class="line">        img_h = <span class="number">400</span></span><br><span class="line">        cart_w = img_w // <span class="number">12</span></span><br><span class="line">        cart_h = img_h // <span class="number">15</span></span><br><span class="line">        pole_len = img_h // <span class="number">3.5</span></span><br><span class="line">        pole_w = img_w // <span class="number">80</span> + <span class="number">1</span></span><br><span class="line">        x_width = <span class="number">2</span></span><br><span class="line">        max_ang = <span class="number">0.2</span></span><br><span class="line">        bg_col = (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>)</span><br><span class="line">        cart_col = <span class="number">0x000000</span></span><br><span class="line">        pole_col = <span class="number">0x669acc</span></span><br><span class="line"></span><br><span class="line">        pos, vel, ang, ang_vel = obs</span><br><span class="line">        img = Image.new(<span class="string">'RGB'</span>, (img_w, img_h), bg_col)</span><br><span class="line">        draw = ImageDraw.Draw(img)</span><br><span class="line">        cart_x = pos * img_w // x_width + img_w // x_width</span><br><span class="line">        cart_y = img_h * <span class="number">95</span> // <span class="number">100</span></span><br><span class="line">        top_pole_x = cart_x + pole_len // <span class="number">2</span> - pole_len * np.cos(ang)</span><br><span class="line">        top_pole_y = cart_y - cart_h // <span class="number">2</span> - pole_len * np.cos(ang)</span><br><span class="line">        draw.line((<span class="number">0</span>, cart_y, img_w, cart_y), fill=<span class="number">0</span>)</span><br><span class="line">        draw.rectangle((cart_x - cart_w // <span class="number">2</span>, cart_y - cart_h // <span class="number">2</span>,</span><br><span class="line">                        cart_x + cart_w // <span class="number">2</span>, cart_y + cart_h // <span class="number">2</span>), fill=cart_col)</span><br><span class="line">        draw.line((cart_x, cart_y - cart_h // <span class="number">2</span>, top_pole_x, top_pole_y),</span><br><span class="line">                 fill=pole_col, width=pole_w)</span><br><span class="line">        <span class="keyword">return</span> np.array(img)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_cart_pole</span><span class="params">(env, obs)</span>:</span></span><br><span class="line">    plt.close()</span><br><span class="line">    img = render_cart_pole(env, obs)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    plt.axis(<span class="string">"off"</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_cart_pole(env, obs)</span><br></pre></td></tr></table></figure><pre><code>&lt;IPython.core.display.Javascript object&gt;</code></pre><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAj8AAAGvCAYAAAC0IrTpAAAYeUlEQVR4Xu3c3ZEbRxKFUdGMtUMyY+2g3KAbpB0yQ2vHmjEKUT8RQ4mYSTS6Ubfu2ecCUHmyHr5Ykvrw8vLy8oP/ESBAgAABAgRKBD6In5JNG5MAAQIECBD4KiB+PAQCBAgQIECgSkD8VK3bsAQIECBAgID48QYIECBAgACBKgHxU7VuwxIgQIAAAQLixxsgQIAAAQIEqgTET9W6DUuAAAECBAiIH2+AAAECBAgQqBIQP1XrNiwBAgQIECAgfrwBAgQIECBAoEpA/FSt27AECBAgQICA+PEGCBAgQIAAgSoB8VO1bsMSIECAAAEC4scbIECAAAECBKoExE/Vug1LgAABAgQIiB9vgAABAgQIEKgSED9V6zYsAQIECBAgIH68AQIECBAgQKBKQPxUrduwBAgQIECAgPjxBggQIECAAIEqAfFTtW7DEiBAgAABAuLHGyBAgAABAgSqBMRP1boNS4AAAQIECIgfb4AAAQIECBCoEhA/Ves2LAECBAgQICB+vAECBAgQIECgSkD8VK3bsAQIECBAgID48QYIECBAgACBKgHxU7VuwxIgQIAAAQLixxsgQIAAAQIEqgTET9W6DUuAAAECBAiIH2+AAAECBAgQqBIQP1XrNiwBAgQIECAgfrwBAgQIECBAoEpA/FSt27AECBAgQICA+PEGCBAgQIAAgSoB8VO1bsMSIECAAAEC4scbIECAAAECBKoExE/Vug1LgAABAgQIiB9vgAABAgQIEKgSED9V6zYsAQIECBAgIH68AQIECBAgQKBKQPxUrduwBAgQIECAgPjxBggQIECAAIEqAfFTtW7DEiBAgAABAuLHGyBAgAABAgSqBMRP1boNS4AAAQIECIgfb4AAAQIECBCoEhA/Ves2LAECBAgQICB+vAECBAgQIECgSkD8VK3bsAQIECBAgID48QYIECBAgACBKgHxU7VuwxIgQIAAAQLixxsgQIAAAQIEqgTET9W6DUuAAAECBAiIH2+AAAECBAgQqBIQP1XrNiwBAgQIECAgfrwBAgQIECBAoEpA/FSt27AECBAgQICA+PEGCBAgQIAAgSoB8VO1bsMSIECAAAEC4scbIECAAAECBKoExE/Vug1LgAABAgQIiB9vgAABAgQIEKgSED9V6zYsAQIECBAgIH68AQIECBAgQKBKQPxUrduwBAgQIECAgPjxBggQIECAAIEqAfFTtW7DEiBAgAABAuLHGyBAgAABAgSqBMRP1boNS4AAAQIECIgfb4AAAQIECBCoEhA/Ves2LAECBAgQICB+vAECBAgQIECgSkD8VK3bsAQIECBAgID48QYIECBAgACBKgHxU7VuwxIgQIAAAQLixxsgQIAAAQIEqgTET9W6DUuAAAECBAiIH2+AAAECBAgQqBIQP1XrNiwBAgQIECAgfrwBAgQIECBAoEpA/FSt27AECBAgQICA+PEGCBAgQIAAgSoB8VO1bsMSIECAAAEC4scbIECAAAECBKoExE/Vug1LgAABAgQIiB9vgAABAgQIEKgSED9V6zYsAQIECBAgIH68AQIECBAgQKBKQPxUrduwBAgQIECAgPjxBggQIECAAIEqAfFTtW7DEiBAgAABAuLHGyBAgAABAgSqBMRP1boNS4AAAQIECIgfb4AAAQIECBCoEhA/Ves2LAECBAgQICB+vAECBAgQIECgSkD8VK3bsAQIECBAgID48QYIECBAgACBKgHxU7VuwxIgQIAAAQLixxsgQIAAAQIEqgTET9W6DUuAAAECBAiIH2+AAAECBAgQqBIQP1XrNiwBAgQIECAgfrwBAgQIECBAoEpA/FSt27AECBAgQICA+PEGCBAgQIAAgSoB8VO1bsMSIECAAAEC4scbIECAAAECBKoExE/Vug1LgAABAgQIiB9vgAABAgQIEKgSED9V6zYsAQIECBAgIH68AQIECBAgQKBKQPxUrduwBAgQIECAgPjxBggQIECAAIEqAfFTtW7DEiBAgAABAuLHGyBAgAABAgSqBMRP1boNS4AAAQIECIgfb4AAAQIECBCoEhA/Ves2LAECBAgQICB+vAECBAgQIECgSkD8VK3bsAQIECBAgID48QYIECBAgACBKgHxU7VuwxIgQIAAAQLixxsgQIAAAQIEqgTET9W6DUuAAAECBAiIH2+AAAECBAgQqBIQP1XrNiwBAgQIECAgfrwBAgQIECBAoEpA/FSt27AECBAgQICA+PEGCBAgQIAAgSoB8VO1bsMSIECAAAEC4scbIECAAAECBKoExE/Vug1LgAABAgQIiB9vgAABAgQIEKgSED9V6zYsAQIECBAgIH68AQIECBAgQKBKQPxUrduwBAgQIECAgPjxBggQIECAAIEqAfFTtW7DEiBAgAABAuLHGyBAgAABAgSqBMRP1boNS4AAAQIECIgfb4AAAQIECBCoEhA/Ves2LAECBAgQICB+vAECBAgQIECgSkD8VK3bsAQIECBAgID48QYIECBAgACBKgHxU7VuwxIgQIAAAQLixxsgQIAAAQIEqgTET9W6DUuAAAECBAiIH2+AAAECBAgQqBIQP1XrNiwBAgQIECAgfrwBAgQIECBAoEpA/FSt27AECBAgQICA+PEGCBAgQIAAgSoB8VO1bsMSIECAAAEC4scbIECAAAECBKoExE/Vug1LgAABAgQIiB9vgAABAgQIEKgSED9V6zYsAQIECBAgIH68AQIECBAgQKBKQPxUrduwBAgQIECAgPjxBggQIECAAIEqAfFTtW7DEiBAgAABAuLHGyBAgAABAgSqBMRP1boNS4AAAQIECIgfb4AAAQIECBCoEhA/Ves2LAECBAgQICB+vAECBAgQIECgSkD8VK3bsAQIECBAgID48QYIECBAgACBKgHxU7VuwxIgQIAAAQLixxsgQIAAAQIEqgTET9W6DUuAAAECBAiIH2+AAAECBAgQqBIQP1XrNiwBAgQIECAgfrwBAgQIECBAoEpA/FSt27AECBAgQICA+PEGCBAgQIAAgSoB8VO1bsMSIECAAAEC4scbIECAAAECBKoExE/Vug1LgAABAgQIiB9vgAABAgQIEKgSED9V6zYsAQIECBAgIH68AQIECBAgQKBKQPxUrduwBAgQIECAgPjxBggQIECAAIEqAfFTtW7DEiBAgAABAuLHGyBAgAABAgSqBMRP1boNS4AAAQIECIgfb4AAAQIECBCoEhA/Ves2LAECBAgQICB+vAECBAgQIECgSkD8VK3bsAQIECBAgID48QYIEFhW4H9ffv56tx8/fl72ji5GgECegPjJ25kbE6gR+Ct+vjewKKp5CgYl8FAB8fNQTl9GgMAjBcTPIzV9FwECfwmIH2+BAIFlBcTPsqtxMQLRAuInen0uT2BvAfGz935NR+BZAuLnWfJ+lwCBNwXEz5tEDhAgcIeA+LkDzUcIELhGQPxc4+xXCLQJiJ+2jZuXQJCA+AlalqsSCBIQP0HLclUCbQLip23j5iVwjYD4ucbZrxAgcIeA+LkDzUcIEHhTQPy8SeQAAQLPEhA/z5L3uwT2FhA/e+/XdASiBcRP9PpcnsCyAuJn2dW4GAEC4scbIEDgDAHxc4aq7yRA4CEC4uchjL6EAIFvBMSPJ0GAwLIC4mfZ1bgYgWgB8RO9PpcnsLeA+Nl7v6Yj8CwB8fMseb9LgMCbAuLnTSIHCBC4Q0D83IHmIwQIXCMgfq5x9isE2gTET9vGzUsgSED8BC3LVQkECYifoGW5KoEmAeHTtG2zErhWQPxc6+3XCBB4p4D4eSeUYwQIjAXEz5jMBwgQuEJA/Fyh7DcIdAqIn869m5rA8gLiZ/kVuSCBWAHxE7s6Fyewt4D42Xu/piPwTAHx80x9v02AwHcFxI/HQYDAWQLi5yxZ30uAwCEB8XOIz4cJELghIH48DwIElhQQP0uuxaUIbCEgfrZYoyEI7CcgfvbbqYkIrCIgflbZhHsQIPBKQPx4EAQInCUgfs6S9b0ECBwSED+H+HyYAIEbAuLH8yBAYEkB8bPkWlyKwBYC4meLNRqCwH4C4me/nZqIwCoC4meVTbgHAQKvBMSPB0GAwFkC4ucsWd9LgMAhAfFziM+HCRC4ISB+PA8CBJYUED9LrsWlCGwhIH62WKMhCOwnIH7226mJCKwiIH5W2YR7ECDwSkD8eBAECJwlIH7OkvW9BAgcEhA/h/h8mACBGwLix/MgQGBJAfGz5FpcisAWAuJnizUagsB+AuJnv52aiMAqAuJnlU24BwECrwRuxc+PHz/TIkCAwN0C4uduOh8kQOBMAfFzpq7vJtAtIH669296AssKiJ9lV+NiBOIFxE/8Cg1AYE8B8bPnXk1FYAUB8bPCFtyBAIF/CIgfj4IAgbMExM9Zsr6XAIFDAuLnEJ8PEyBwQ0D8eB4ECCwpIH6WXItLEdhCQPxssUZDENhPQPzst1MTEVhFQPyssgn3IEDglYD48SAIEDhLQPycJet7CRA4JCB+DvH5MAECNwTEj+dBgMCSAuJnybW4FIEtBMTPFms0BIH9BMTPfjs1EYFVBMTPKptwDwIEXgmIHw+CAIGzBMTPWbK+lwCBQwLi5xCfDxMgcENA/HgeBAgsKSB+llyLSxHYQkD8bLFGQxDYT0D87LdTExFYRUD8rLIJ9yBA4JWA+PEgCBA4S0D8nCXrewkQOCQgfg7x+TABAjcExI/nQYDAkgLiZ8m1uBSBLQTEzxZrNASB/QTEz347NRGBVQTEzyqbcA8CBF4JiB8PggCBswTEz1myvpcAgUMC4ucQnw8TIHBDQPx4HgQILCcgfJZbiQsR2EpA/Gy1TsMQ2ENA/OyxR1MQWFVA/Ky6GfciUCwgfoqXb3QCFwiInwuQ/QQBAjMB8TPzcpoAgZmA+Jl5OU2AwAUC4ucCZD9BoFhA/BQv3+gEVhUQP6tuxr0I7CEgfvbYoykIbCUgfrZap2EILCcgfpZbiQsRICB+vAECBM4UED9n6vpuAgTuEhA/d7H5EAEC7xQQP++EcowAgesExM911n6JQKOA+GncupkJLC4gfhZfkOsRCBcQP+ELdH0COwqInx23aiYC6wiIn3V24SYECPwpIH48BQIEzhQQP2fq+m4CBO4SED93sfkQAQLvFBA/74RyjACB6wTEz3XWfolAo4D4ady6mQksLiB+Fl+Q6xEIFxA/4Qt0fQI7CoifHbdqJgLrCIifdXbhJgQI/CkgfjwFAgTOFBA/Z+r6bgIE7hIQP3ex+RABAu8UED/vhHKMAIHrBMTPddZ+iUCjgPhp3LqZCSwuIH4WX5DrEQgXED/hC3R9AjsKiJ8dt2omAusIiJ91duEmBLYR+PDhw92z/Pr5483P/vTzl7u/++Xl5e7P+iABAvsIiJ99dmkSAssIiJ9lVuEiBAj8i4D48SwIEHi4gPh5OKkvJEDggQLi54GYvooAgT8EjsbPL///9z/6+u9/vvzgj728MgIEjgqIn6OCPk+AwD8Ezoqf33/o06ef7hb3d37upvNBAlsJiJ+t1mkYAmsIHImfT59+vTmE+Fljx25BIFlA/CRvz90JLCogfhZdjGsRIPBVQPx4CAQIPFzgSPz8/k/dv/d3fvyx18NX5QsJVAqIn8q1G5rAuQJnxY+/8Hzu3nw7gRYB8dOyaXMSuFDgSPx8e81v/6OH/rXXhYv0UwQ2FRA/my7WWASeKfDI+HnkHP611yM1fReBXAHxk7s7NyewrID4WXY1LkaAgL/w7A0QIHCGgPg5Q9V3EiDwKAH/z8+jJH0PAQJ/C4gfj4EAgZUFxM/K23E3AqEC4id0ca5NoERA/JQs2pgErhQQP1dq+y0CBKYC4mcq5jwBAm8KiJ83iRwgQOCJAuLnifh+msCuAuJn182ai8AeAuJnjz2agsBSAuJnqXW4DAEC3wiIH0+CAIGHC4ifh5P6QgIEHiggfh6I6asIEPhDQPx4CQQIrCwgflbejrsRCBUQP6GLc20CJQLip2TRxiRwpYD4uVLbbxEgMBUQP1Mx5wkQIECAAIFoAfETvT6XJ0CAAAECBKYC4mcq5jwBAgQIECAQLSB+otfn8gQIECBAgMBUQPxMxZwnQIAAAQIEogXET/T6XJ4AAQIECBCYCoifqZjzBAgQIECAQLSA+Ilen8sTIECAAAECUwHxMxVzngABAgQIEIgWED/R63N5AgQIECBAYCogfqZizhMgQIAAAQLRAuInen0uT4AAAQIECEwFxM9UzHkCBAgQIEAgWkD8RK/P5QkQIECAAIGpgPiZijlPgAABAgQIRAuIn+j1uTwBAgQIECAwFRA/UzHnCRAgQIAAgWgB8RO9PpcnQIAAAQIEpgLiZyrmPAECBAgQIBAtIH6i1+fyBAgQIECAwFRA/EzFnCdAgAABAgSiBcRP9PpcngABAgQIEJgKiJ+pmPMECBAgQIBAtID4iV6fyxMgQIAAAQJTAfEzFXOeAAECBAgQiBYQP9Hrc3kCBAgQIEBgKiB+pmLOEyBAgAABAtEC4id6fS5PgAABAgQITAXEz1TMeQIECBAgQCBaQPxEr8/lCRAgQIAAgamA+JmKOU+AAAECBAhEC4if6PW5PAECBAgQIDAVED9TMecJECBAgACBaAHxE70+lydAgAABAgSmAuJnKuY8AQIECBAgEC0gfqLX5/IECBAgQIDAVED8TMWcJ0CAAAECBKIFxE/0+lyeAAECBAgQmAqIn6mY8wQIECBAgEC0gPiJXp/LEyBAgAABAlMB8TMVc54AAQIECBCIFhA/0etzeQIECBAgQGAqIH6mYs4TIECAAAEC0QLiJ3p9Lk+AAAECBAhMBcTPVMx5AgQIECBAIFpA/ESvz+UJECBAgACBqYD4mYo5T4AAAQIECEQLiJ/o9bk8AQIECBAgMBUQP1Mx5wkQIECAAIFoAfETvT6XJ0CAAAECBKYC4mcq5jwBAgQIECAQLSB+otfn8gQIECBAgMBUQPxMxZwnQIAAAQIEogXET/T6XJ4AAQIECBCYCoifqZjzBAgQIECAQLSA+Ilen8sTIECAAAECUwHxMxVzngABAgQIEIgWED/R63N5AgQIECBAYCogfqZizhMgQIAAAQLRAuInen0uT4AAAQIECEwFxM9UzHkCBAgQIEAgWkD8RK/P5QkQIECAAIGpgPiZijlPgAABAgQIRAuIn+j1uTwBAgQIECAwFRA/UzHnCRAgQIAAgWgB8RO9PpcnQIAAAQIEpgLiZyrmPAECBAgQIBAtIH6i1+fyBAgQIECAwFRA/EzFnCdAgAABAgSiBcRP9PpcngABAgQIEJgKiJ+pmPMECBAgQIBAtID4iV6fyxMgQIAAAQJTAfEzFXOeAAECBAgQiBYQP9Hrc3kCBAgQIEBgKiB+pmLOEyBAgAABAtEC4id6fS5PgAABAgQITAXEz1TMeQIECBAgQCBaQPxEr8/lCRAgQIAAgamA+JmKOU+AAAECBAhEC4if6PW5PAECBAgQIDAVED9TMecJECBAgACBaAHxE70+lydAgAABAgSmAuJnKuY8AQIECBAgEC0gfqLX5/IECBAgQIDAVED8TMWcJ0CAAAECBKIFxE/0+lyeAAECBAgQmAqIn6mY8wQIECBAgEC0gPiJXp/LEyBAgAABAlMB8TMVc54AAQIECBCIFhA/0etzeQIECBAgQGAqIH6mYs4TIECAAAEC0QLiJ3p9Lk+AAAECBAhMBcTPVMx5AgQIECBAIFpA/ESvz+UJECBAgACBqYD4mYo5T4AAAQIECEQLiJ/o9bk8AQIECBAgMBUQP1Mx5wkQIECAAIFoAfETvT6XJ0CAAAECBKYC4mcq5jwBAgQIECAQLSB+otfn8gQIECBAgMBUQPxMxZwnQIAAAQIEogXET/T6XJ4AAQIECBCYCoifqZjzBAgQIECAQLSA+Ilen8sTIECAAAECUwHxMxVzngABAgQIEIgWED/R63N5AgQIECBAYCogfqZizhMgQIAAAQLRAuInen0uT4AAAQIECEwFxM9UzHkCBAgQIEAgWkD8RK/P5QkQIECAAIGpgPiZijlPgAABAgQIRAuIn+j1uTwBAgQIECAwFRA/UzHnCRAgQIAAgWgB8RO9PpcnQIAAAQIEpgLiZyrmPAECBAgQIBAtIH6i1+fyBAgQIECAwFRA/EzFnCdAgAABAgSiBcRP9PpcngABAgQIEJgKiJ+pmPMECBAgQIBAtID4iV6fyxMgQIAAAQJTAfEzFXOeAAECBAgQiBYQP9Hrc3kCBAgQIEBgKiB+pmLOEyBAgAABAtEC4id6fS5PgAABAgQITAXEz1TMeQIECBAgQCBaQPxEr8/lCRAgQIAAgamA+JmKOU+AAAECBAhEC4if6PW5PAECBAgQIDAV+A3IhCBsB+SVEwAAAABJRU5ErkJggg==" width="638.888905813665"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env.action_space</span><br></pre></td></tr></table></figure><pre><code>Discrete(2)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">obs = env.reset()</span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    obs, reward, done, info = env.step(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">if</span> done:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.close()</span><br><span class="line">img = render_cart_pole(env, obs)</span><br><span class="line">plt.imshow(img)</span><br><span class="line">plt.axis(<span class="string">"off"</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;IPython.core.display.Javascript object&gt;</code></pre><p><img src="data:image/png;base64,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" width="638.888905813665"></p><pre><code>(-0.5, 599.5, 399.5, -0.5)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img.shape</span><br></pre></td></tr></table></figure><pre><code>(400, 600, 3)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">obs = env.reset()</span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    obs, reward, done, info = env.step(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> done:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_cart_pole(env, obs)</span><br></pre></td></tr></table></figure><pre><code>&lt;IPython.core.display.Javascript object&gt;</code></pre><p><img src="data:image/png;base64,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" width="638.888905813665"></p><h3 id="硬编码策略"><a href="#硬编码策略" class="headerlink" title="硬编码策略"></a>硬编码策略</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">frames = []</span><br><span class="line"></span><br><span class="line">n_max_steps = <span class="number">1000</span></span><br><span class="line">n_change_steps = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">obs = env.reset()</span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(n_max_steps):</span><br><span class="line">    img = render_cart_pole(env, obs)</span><br><span class="line">    frames.append(img)</span><br><span class="line"></span><br><span class="line">    position, velocity, angle, angular_velocity = obs</span><br><span class="line">    <span class="keyword">if</span> angle &lt; <span class="number">0</span>:</span><br><span class="line">        action = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        action = <span class="number">1</span></span><br><span class="line">    obs, reward, done, info = env.step(action)</span><br><span class="line">    <span class="keyword">if</span> done:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">video = plot_animation(frames)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>&lt;IPython.core.display.Javascript object&gt;</code></pre><p><img src="data:image/png;base64,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" width="638.888905813665"></p><h2 id="神经网络策略"><a href="#神经网络策略" class="headerlink" title="神经网络策略"></a>神经网络策略</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">4</span></span><br><span class="line">n_hidden = <span class="number">4</span></span><br><span class="line">n_outputs = <span class="number">1</span></span><br><span class="line">initializer = tf.variance_scaling_initializer()</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, n_inputs])</span><br><span class="line">hidden = tf.layers.dense(X, n_hidden, activation=tf.nn.elu,</span><br><span class="line">                        kernel_initializer=initializer)</span><br><span class="line">outputs = tf.layers.dense(hidden, n_outputs, activation=tf.nn.sigmoid,</span><br><span class="line">                         kernel_initializer=initializer)</span><br><span class="line"></span><br><span class="line">p_left_and_right = tf.concat(axis=<span class="number">1</span>, values=[outputs, <span class="number">1</span> - outputs])</span><br><span class="line">action = tf.multinomial(tf.log(p_left_and_right), num_samples=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">n_max_steps = <span class="number">1000</span></span><br><span class="line">frames = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    obs = env.reset()</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(n_max_steps):</span><br><span class="line">        img = render_cart_pole(env, obs)</span><br><span class="line">        frames.append(img)</span><br><span class="line">        action_val = action.eval(feed_dict=&#123;X: obs.reshape(<span class="number">1</span>, n_inputs)&#125;)</span><br><span class="line">        obs, reward, done, info = env.step(action_val[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">env.close()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">video = plot_animation(frames)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>&lt;IPython.core.display.Javascript object&gt;</code></pre><p><img src="data:image/png;base64,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" width="638.888905813665"></p><h3 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reset_graph</span><span class="params">(seed=<span class="number">42</span>)</span>:</span></span><br><span class="line">    tf.reset_default_graph()</span><br><span class="line">    tf.set_random_seed(seed)</span><br><span class="line">    np.random.seed(seed)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">4</span></span><br><span class="line">n_hidden = <span class="number">4</span></span><br><span class="line">n_outputs = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line">initializer = tf.variance_scaling_initializer()</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, n_inputs])</span><br><span class="line">y = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, n_outputs])</span><br><span class="line"></span><br><span class="line">hidden = tf.layers.dense(X, n_hidden, activation=tf.nn.elu,</span><br><span class="line">                        kernel_initializer=initializer)</span><br><span class="line">logits = tf.layers.dense(hidden, n_outputs)</span><br><span class="line">outputs = tf.nn.sigmoid(logits)</span><br><span class="line">p_left_and_right = tf.concat(axis=<span class="number">1</span>, values=[outputs, <span class="number">1</span> - outputs])</span><br><span class="line">action = tf.multinomial(tf.log(p_left_and_right), num_samples=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate)</span><br><span class="line">training_op = optimizer.minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">n_environments = <span class="number">10</span></span><br><span class="line">n_iterations = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">envs = [gym.make(<span class="string">"CartPole-v0"</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(n_environments)]</span><br><span class="line">observations = [env.reset() <span class="keyword">for</span> env <span class="keyword">in</span> envs]</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_iterations):</span><br><span class="line">        target_probas = np.array([([<span class="number">1.</span>] <span class="keyword">if</span> obs[<span class="number">2</span>] &lt; <span class="number">0</span>  <span class="keyword">else</span> [<span class="number">0.</span>])</span><br><span class="line">                                 <span class="keyword">for</span> obs <span class="keyword">in</span> observations])</span><br><span class="line">        action_val, _ = sess.run([action, training_op],</span><br><span class="line">                                 feed_dict=&#123;X: np.array(observations), y: target_probas&#125;)</span><br><span class="line">        <span class="keyword">for</span> env_index, env <span class="keyword">in</span> enumerate(envs):</span><br><span class="line">            obs, reward, done, info = env.step(action_val[env_index][<span class="number">0</span>])</span><br><span class="line">            observations[env_index] = obs <span class="keyword">if</span> <span class="keyword">not</span> done <span class="keyword">else</span> env.reset()</span><br><span class="line">    saver.save(sess, <span class="string">"reinforce/my_policy_net_basic.ckpt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> env <span class="keyword">in</span> envs:</span><br><span class="line">    env.close()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">render_policy_net</span><span class="params">(model_path, action, X, n_max_steps = <span class="number">1000</span>)</span>:</span></span><br><span class="line">    frames = []</span><br><span class="line">    env = gym.make(<span class="string">"CartPole-v0"</span>)</span><br><span class="line">    obs = env.reset()</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        saver.restore(sess, model_path)</span><br><span class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> range(n_max_steps):</span><br><span class="line">            img = render_cart_pole(env, obs)</span><br><span class="line">            frames.append(img)</span><br><span class="line">            action_val  = action.eval(feed_dict=&#123;X: obs.reshape(<span class="number">1</span>, n_inputs)&#125;)</span><br><span class="line">            obs, reward, done, info = env.step(action_val[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">            <span class="keyword">if</span> done:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    env.close()</span><br><span class="line">    <span class="keyword">return</span> frames</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">frames = render_policy_net(<span class="string">"reinforce/my_policy_net_basic.ckpt"</span>, action, X)</span><br><span class="line">video = plot_animation(frames)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from reinforce/my_policy_net_basic.ckpt&lt;IPython.core.display.Javascript object&gt;</code></pre><p><img src="data:image/png;base64,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" width="638.888905813665"></p><h1 id="Policy-Gradients"><a href="#Policy-Gradients" class="headerlink" title="Policy Gradients"></a>Policy Gradients</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">4</span></span><br><span class="line">n_hidden = <span class="number">4</span></span><br><span class="line">n_outputs = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line">initializer = tf.variance_scaling_initializer()</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, n_inputs])</span><br><span class="line"></span><br><span class="line">hidden = tf.layers.dense(X, n_hidden, activation=tf.nn.elu, kernel_initializer=initializer)</span><br><span class="line">logits = tf.layers.dense(hidden, n_outputs)</span><br><span class="line">outputs = tf.nn.sigmoid(logits)</span><br><span class="line">p_left_and_right = tf.concat(axis=<span class="number">1</span>, values=[outputs, <span class="number">1</span> - outputs])</span><br><span class="line">action = tf.multinomial(tf.log(p_left_and_right), num_samples=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">y = <span class="number">1.</span> - tf.to_float(action)</span><br><span class="line">cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate)</span><br><span class="line">grads_and_vars = optimizer.compute_gradients(cross_entropy)</span><br><span class="line">gradients = [grad <span class="keyword">for</span> grad, variable <span class="keyword">in</span> grads_and_vars]</span><br><span class="line">gradient_plachholders = []</span><br><span class="line">grads_and_vars_feed = []</span><br><span class="line"><span class="keyword">for</span> grad, variable <span class="keyword">in</span> grads_and_vars:</span><br><span class="line">    gradient_plachholder = tf.placeholder(tf.float32, shape=grad.get_shape())</span><br><span class="line">    gradient_plachholders.append(gradient_plachholder)</span><br><span class="line">    grads_and_vars_feed.append((gradient_plachholder, variable))</span><br><span class="line"></span><br><span class="line">training_op = optimizer.apply_gradients(grads_and_vars_feed)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discount_rewards</span><span class="params">(rewards, discount_rate)</span>:</span></span><br><span class="line">    discount_rewards = np.zeros(len(rewards))</span><br><span class="line">    cumulative_rewards = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> reversed(range(len(rewards))):</span><br><span class="line">        cumulative_rewards = rewards[step] + cumulative_rewards * discount_rate</span><br><span class="line">        discount_rewards[step] = cumulative_rewards</span><br><span class="line">    <span class="keyword">return</span> discount_rewards</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discount_and_normalize_rewards</span><span class="params">(all_rewards, discount_rate)</span>:</span></span><br><span class="line">    all_discounted_rewards = [discount_rewards(rewards, discount_rate)</span><br><span class="line">                              <span class="keyword">for</span> rewards <span class="keyword">in</span> all_rewards]</span><br><span class="line">    flat_rewards = np.concatenate(all_discounted_rewards)</span><br><span class="line">    reward_mean = flat_rewards.mean()</span><br><span class="line">    reward_std = flat_rewards.std()</span><br><span class="line">    <span class="keyword">return</span> [(discounted_rewards - reward_mean)/reward_std</span><br><span class="line">            <span class="keyword">for</span> discounted_rewards <span class="keyword">in</span> all_discounted_rewards]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">discount_rewards([<span class="number">10</span>, <span class="number">0</span>, <span class="number">-50</span>], discount_rate=<span class="number">0.8</span>)</span><br></pre></td></tr></table></figure><pre><code>array([-22., -40., -50.])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">discount_and_normalize_rewards([[<span class="number">10</span>, <span class="number">0</span>, <span class="number">-50</span>],[<span class="number">10</span>, <span class="number">20</span>]], discount_rate=<span class="number">0.8</span>)</span><br></pre></td></tr></table></figure><pre><code>[array([-0.28435071, -0.86597718, -1.18910299]), array([1.26665318, 1.0727777 ])]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">env = gym.make(<span class="string">"CartPole-v0"</span>)</span><br><span class="line"></span><br><span class="line">n_games_per_update = <span class="number">10</span></span><br><span class="line">n_max_steps = <span class="number">1000</span></span><br><span class="line">n_iterations = <span class="number">250</span></span><br><span class="line">save_iterations = <span class="number">10</span></span><br><span class="line">discount_rate = <span class="number">0.95</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_iterations):</span><br><span class="line">        print(<span class="string">"\rIteration:&#123;&#125;"</span>.format(iteration), end =<span class="string">""</span>)</span><br><span class="line">        all_rewards = []</span><br><span class="line">        all_gradients = []</span><br><span class="line">        <span class="keyword">for</span> game <span class="keyword">in</span> range(n_games_per_update):</span><br><span class="line">            current_rewards = []</span><br><span class="line">            current_gradients = []</span><br><span class="line">            obs = env.reset()</span><br><span class="line">            <span class="keyword">for</span> step <span class="keyword">in</span> range(n_max_steps):</span><br><span class="line">                action_val, gradients_val = sess.run([action, gradients],</span><br><span class="line">                                                    feed_dict=&#123;X: obs.reshape(<span class="number">1</span>, n_inputs)&#125;)</span><br><span class="line">                obs, reward, done, info = env.step(action_val[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">                current_rewards.append(reward)</span><br><span class="line">                current_gradients.append(gradients_val)</span><br><span class="line">                <span class="keyword">if</span> done:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            all_rewards.append(current_rewards)</span><br><span class="line">            all_gradients.append(current_gradients)</span><br><span class="line"></span><br><span class="line">        all_rewards = discount_and_normalize_rewards(all_rewards, discount_rate=discount_rate)</span><br><span class="line">        feed_dict = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> var_index, gradient_plachholder <span class="keyword">in</span> enumerate(gradient_plachholders):</span><br><span class="line">            mean_gradients = np.mean([reward * all_gradients[game_index][step][var_index]</span><br><span class="line">                                     <span class="keyword">for</span> game_index,rewards <span class="keyword">in</span> enumerate(all_rewards)</span><br><span class="line">                                     <span class="keyword">for</span> step, reward <span class="keyword">in</span> enumerate(rewards)], axis=<span class="number">0</span>)</span><br><span class="line">            feed_dict[gradient_plachholder] = mean_gradients</span><br><span class="line">        sess.run(training_op, feed_dict=feed_dict)</span><br><span class="line">        <span class="keyword">if</span> iteration % save_iterations == <span class="number">0</span>:</span><br><span class="line">            saver.save(sess, <span class="string">"reinforce/nmy_policy_net_pg.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>Iteration:249</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env.close()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">frames = render_policy_net(<span class="string">"reinforce/nmy_policy_net_pg.ckpt"</span>, action, X, n_max_steps=<span class="number">1000</span>)</span><br><span class="line">video = plot_animation(frames)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from reinforce/nmy_policy_net_pg.ckpt&lt;IPython.core.display.Javascript object&gt;</code></pre><p><img src="data:image/png;base64,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" width="638.888905813665"></p><h1 id="马尔科夫链-Markov-Chains"><a href="#马尔科夫链-Markov-Chains" class="headerlink" title="马尔科夫链(Markov Chains)"></a>马尔科夫链(Markov Chains)</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">trainsition_probabilities = [</span><br><span class="line">        [<span class="number">0.7</span>, <span class="number">0.2</span>, <span class="number">0.0</span>, <span class="number">0.1</span>],  <span class="comment"># from s0 to s0, s1, s2, s3</span></span><br><span class="line">        [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.9</span>, <span class="number">0.1</span>],  <span class="comment"># from s1 to ...</span></span><br><span class="line">        [<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>],  <span class="comment"># from s2 to ...</span></span><br><span class="line">        [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>],  <span class="comment"># from s3 to ...</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">n_max_steps = <span class="number">50</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_sequence</span><span class="params">(start_state=<span class="number">0</span>)</span>:</span></span><br><span class="line">    current_state = start_state</span><br><span class="line">    print(<span class="string">"States:"</span>, end=<span class="string">" "</span>)</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(n_max_steps):</span><br><span class="line">        print(current_state, end=<span class="string">" "</span>)</span><br><span class="line">        <span class="keyword">if</span> current_state == <span class="number">3</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        current_state = np.random.choice(range(<span class="number">4</span>), p=trainsition_probabilities[current_state])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">"..."</span>, end=<span class="string">""</span>)</span><br><span class="line">    print()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    print_sequence()</span><br></pre></td></tr></table></figure><pre><code>States: 0 0 3States: 0 1 2 1 2 1 2 1 2 1 3States: 0 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 3States: 0 3States: 0 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 3States: 0 1 3States: 0 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 ...States: 0 0 3States: 0 0 0 1 2 1 2 1 3States: 0 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 3</code></pre><h2 id="马尔科夫决策过程-MDP"><a href="#马尔科夫决策过程-MDP" class="headerlink" title="马尔科夫决策过程(MDP)"></a>马尔科夫决策过程(MDP)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">transition_probabilities = [</span><br><span class="line">        [[<span class="number">0.7</span>, <span class="number">0.3</span>, <span class="number">0.0</span>], [<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>], [<span class="number">0.8</span>, <span class="number">0.2</span>, <span class="number">0.0</span>]], <span class="comment"># in s0, if action a0 then proba 0.7 to state s0 and 0.3 to state s1, etc.</span></span><br><span class="line">        [[<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>], <span class="keyword">None</span>, [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>]],</span><br><span class="line">        [<span class="keyword">None</span>, [<span class="number">0.8</span>, <span class="number">0.1</span>, <span class="number">0.1</span>], <span class="keyword">None</span>],</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">rewards = [</span><br><span class="line">        [[+<span class="number">10</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]],</span><br><span class="line">        [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">-50</span>]],</span><br><span class="line">        [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [+<span class="number">40</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]],</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">possible_actions = [[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">2</span>], [<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">policy_fire</span><span class="params">(state)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>][state]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">policy_random</span><span class="params">(state)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.random.choice(possible_actions[state])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">policy_safe</span><span class="params">(state)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>][state]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MDPEnvironment</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, start_state=<span class="number">0</span>)</span>:</span></span><br><span class="line">        self.start_state=start_state</span><br><span class="line">        self.reset()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.total_rewards = <span class="number">0</span></span><br><span class="line">        self.state = self.start_state</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self, action)</span>:</span></span><br><span class="line">        next_state = np.random.choice(range(<span class="number">3</span>), p=transition_probabilities[self.state][action])</span><br><span class="line">        reward = rewards[self.state][action][next_state]</span><br><span class="line">        self.state = next_state</span><br><span class="line">        self.total_rewards += reward</span><br><span class="line">        <span class="keyword">return</span> self.state, reward</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_episode</span><span class="params">(policy, n_steps, start_state=<span class="number">0</span>, display=True)</span>:</span></span><br><span class="line">    env = MDPEnvironment()</span><br><span class="line">    <span class="keyword">if</span> display:</span><br><span class="line">        print(<span class="string">"States(+rewards:)"</span>, end=<span class="string">" "</span>)</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(n_steps):</span><br><span class="line">        <span class="keyword">if</span> display:</span><br><span class="line">            <span class="keyword">if</span> step == <span class="number">10</span>:</span><br><span class="line">                print(<span class="string">"..."</span>, end=<span class="string">" "</span>)</span><br><span class="line">            <span class="keyword">elif</span> step &lt; <span class="number">10</span>:</span><br><span class="line">                print(env.state, end=<span class="string">" "</span>)</span><br><span class="line">        action = policy(env.state)</span><br><span class="line">        state, reward = env.step(action)</span><br><span class="line">        <span class="keyword">if</span> display <span class="keyword">and</span> step &lt; <span class="number">10</span>:</span><br><span class="line">            <span class="keyword">if</span> reward:</span><br><span class="line">                print(<span class="string">"(&#123;&#125;)"</span>.format(reward), end=<span class="string">" "</span>)</span><br><span class="line">    <span class="keyword">if</span> display:</span><br><span class="line">        print(<span class="string">"Total rewards="</span>, env.total_rewards)</span><br><span class="line">    <span class="keyword">return</span> env.total_rewards</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> policy <span class="keyword">in</span> (policy_fire, policy_random, policy_safe):</span><br><span class="line">    all_totals = []</span><br><span class="line">    print(policy.__name__)</span><br><span class="line">    <span class="keyword">for</span> episode <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">        all_totals.append(run_episode(policy, n_steps=<span class="number">100</span>, display=(episode&lt;<span class="number">5</span>)))</span><br><span class="line">    print(<span class="string">"Summary:mean=&#123;:.1f&#125;, std=&#123;:.1f&#125;, min=&#123;&#125;, max&#123;&#125;"</span>.format(</span><br><span class="line">        np.mean(all_totals), np.std(all_totals), np.min(all_totals), np.max(all_totals)</span><br><span class="line">    ))</span><br><span class="line">    print()</span><br></pre></td></tr></table></figure><pre><code>policy_fireStates(+rewards:) 0 (10) 0 (10) 0 1 (-50) 2 2 2 (40) 0 (10) 0 (10) 0 (10) ... Total rewards= 210States(+rewards:) 0 1 (-50) 2 (40) 0 (10) 0 (10) 0 1 (-50) 2 2 (40) 0 (10) ... Total rewards= 70States(+rewards:) 0 (10) 0 1 (-50) 2 (40) 0 (10) 0 (10) 0 (10) 0 (10) 0 (10) 0 (10) ... Total rewards= 70States(+rewards:) 0 1 (-50) 2 1 (-50) 2 (40) 0 (10) 0 1 (-50) 2 (40) 0 ... Total rewards= -10States(+rewards:) 0 1 (-50) 2 (40) 0 (10) 0 (10) 0 1 (-50) 2 (40) 0 (10) 0 (10) ... Total rewards= 290Summary:mean=121.1, std=129.3, min=-330, max470policy_randomStates(+rewards:) 0 1 (-50) 2 1 (-50) 2 (40) 0 1 (-50) 2 2 (40) 0 ... Total rewards= -60States(+rewards:) 0 (10) 0 0 0 0 0 (10) 0 0 0 (10) 0 ... Total rewards= -30States(+rewards:) 0 1 1 (-50) 2 (40) 0 0 1 1 1 1 ... Total rewards= 10States(+rewards:) 0 (10) 0 (10) 0 0 0 0 1 (-50) 2 (40) 0 0 ... Total rewards= 0States(+rewards:) 0 0 (10) 0 1 (-50) 2 (40) 0 0 0 0 (10) 0 (10) ... Total rewards= 40Summary:mean=-22.1, std=88.2, min=-380, max200policy_safeStates(+rewards:) 0 1 1 1 1 1 1 1 1 1 ... Total rewards= 0States(+rewards:) 0 1 1 1 1 1 1 1 1 1 ... Total rewards= 0States(+rewards:) 0 (10) 0 (10) 0 (10) 0 1 1 1 1 1 1 ... Total rewards= 30States(+rewards:) 0 (10) 0 1 1 1 1 1 1 1 1 ... Total rewards= 10States(+rewards:) 0 1 1 1 1 1 1 1 1 1 ... Total rewards= 0Summary:mean=22.3, std=26.2, min=0, max170</code></pre><h1 id="Q-Learning"><a href="#Q-Learning" class="headerlink" title="Q-Learning"></a>Q-Learning</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">n_states = <span class="number">3</span></span><br><span class="line">n_actions = <span class="number">3</span></span><br><span class="line">n_steps = <span class="number">20000</span></span><br><span class="line">alpha = <span class="number">0.01</span></span><br><span class="line">gamma = <span class="number">0.99</span></span><br><span class="line">exploration_policy = policy_random</span><br><span class="line">q_values = np.full((n_states, n_actions), -np.inf)</span><br><span class="line"><span class="keyword">for</span> state, actions <span class="keyword">in</span> enumerate(possible_actions):</span><br><span class="line">    q_values[state][actions]=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">env = MDPEnvironment()</span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(n_steps):</span><br><span class="line">    action = exploration_policy(env.state)</span><br><span class="line">    state = env.state</span><br><span class="line">    next_state, reward = env.step(action)</span><br><span class="line">    next_value = np.max(q_values[next_state])</span><br><span class="line">    q_values[state, action] = (<span class="number">1</span>-alpha)*q_values[state, action] + alpha*(reward + gamma * next_value)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">optimal_policy</span><span class="params">(state)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.argmax(q_values[state])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">q_values</span><br></pre></td></tr></table></figure><pre><code>array([[39.13508139, 38.88079412, 35.23025716],       [18.9117071 ,        -inf, 20.54567816],       [       -inf, 72.53192111,        -inf]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">all_totals = []</span><br><span class="line"><span class="keyword">for</span> episode <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    all_totals.append(run_episode(optimal_policy, n_steps=<span class="number">100</span>, display=(episode&lt;<span class="number">5</span>)))</span><br><span class="line">print(<span class="string">"Summary:mean=&#123;:.1f&#125;, std=&#123;:.1f&#125;, min=&#123;&#125;, max&#123;&#125;"</span>.format(</span><br><span class="line">        np.mean(all_totals), np.std(all_totals), np.min(all_totals), np.max(all_totals)</span><br><span class="line">    ))</span><br><span class="line">print()</span><br></pre></td></tr></table></figure><pre><code>States(+rewards:) 0 (10) 0 (10) 0 1 (-50) 2 (40) 0 (10) 0 1 (-50) 2 (40) 0 (10) ... Total rewards= 230States(+rewards:) 0 (10) 0 (10) 0 (10) 0 1 (-50) 2 2 1 (-50) 2 (40) 0 (10) ... Total rewards= 90States(+rewards:) 0 1 (-50) 2 (40) 0 (10) 0 (10) 0 (10) 0 (10) 0 (10) 0 (10) 0 (10) ... Total rewards= 170States(+rewards:) 0 1 (-50) 2 (40) 0 (10) 0 (10) 0 (10) 0 (10) 0 (10) 0 (10) 0 (10) ... Total rewards= 220States(+rewards:) 0 1 (-50) 2 (40) 0 (10) 0 1 (-50) 2 (40) 0 (10) 0 (10) 0 (10) ... Total rewards= -50Summary:mean=125.6, std=127.4, min=-290, max500</code></pre><h1 id="使用DQN算法"><a href="#使用DQN算法" class="headerlink" title="使用DQN算法"></a>使用DQN算法</h1><h2 id="创建MsPacman"><a href="#创建MsPacman" class="headerlink" title="创建MsPacman"></a>创建MsPacman</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">env = gym.make(<span class="string">"MsPacman-v0"</span>)</span><br><span class="line">obs = env.reset()</span><br><span class="line">obs.shape</span><br></pre></td></tr></table></figure><pre><code>(210, 160, 3)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env.action_space</span><br></pre></td></tr></table></figure><pre><code>Discrete(9)</code></pre><h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mspacman_color = <span class="number">210</span> + <span class="number">164</span> + <span class="number">74</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess_observation</span><span class="params">(obs)</span>:</span></span><br><span class="line">    img = obs[<span class="number">1</span>:<span class="number">176</span>:<span class="number">2</span>, ::<span class="number">2</span>]</span><br><span class="line">    img = img.sum(axis=<span class="number">2</span>)</span><br><span class="line">    img[img==mspacman_color] = <span class="number">0</span></span><br><span class="line">    img = (img // <span class="number">3</span> - <span class="number">128</span>).astype(np.int8)</span><br><span class="line">    <span class="keyword">return</span> img.reshape(<span class="number">88</span>, <span class="number">80</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">img = preprocess_observation(obs)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">11</span>, <span class="number">7</span>))</span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line">plt.title(<span class="string">"Original observation (160*210 RGB)"</span>)</span><br><span class="line">plt.imshow(obs)</span><br><span class="line">plt.axis(<span class="string">"off"</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line">plt.title(<span class="string">"Preprocessed observation (88*80 greyscale)"</span>)</span><br><span class="line">plt.imshow(img.reshape(<span class="number">88</span>, <span class="number">80</span>), interpolation=<span class="string">"nearest"</span>, cmap=<span class="string">"gray"</span>)</span><br><span class="line">plt.axis(<span class="string">"off"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>&lt;IPython.core.display.Javascript object&gt;</code></pre><p><img src="data:image/png;base64,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" width="1098.8889179995037"></p><h2 id="创建DQN"><a href="#创建DQN" class="headerlink" title="创建DQN"></a>创建DQN</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">input_height = <span class="number">88</span></span><br><span class="line">input_width = <span class="number">80</span></span><br><span class="line">input_channels = <span class="number">1</span></span><br><span class="line">conv_n_maps = [<span class="number">32</span>, <span class="number">64</span>, <span class="number">64</span>]</span><br><span class="line">conv_kernel_sizes = [(<span class="number">8</span>, <span class="number">8</span>), (<span class="number">4</span>, <span class="number">4</span>), (<span class="number">3</span>, <span class="number">3</span>)]</span><br><span class="line">conv_strides = [<span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">conv_paddings = [<span class="string">"SAME"</span>] * <span class="number">3</span></span><br><span class="line">conv_activation = [tf.nn.relu] * <span class="number">3</span></span><br><span class="line">n_hidden_in = <span class="number">64</span> * <span class="number">11</span> * <span class="number">10</span></span><br><span class="line">n_hidden = <span class="number">512</span></span><br><span class="line">hidden_activation = tf.nn.relu</span><br><span class="line">n_outputs = env.action_space.n</span><br><span class="line">initializer = tf.variance_scaling_initializer()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">q_network</span><span class="params">(X_state, name)</span>:</span></span><br><span class="line">    prev_layer = X_state / <span class="number">128.0</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(name) <span class="keyword">as</span> scope:</span><br><span class="line">        <span class="keyword">for</span> n_maps, kernel_size, strides, padding, activation <span class="keyword">in</span> zip(</span><br><span class="line">            conv_n_maps, conv_kernel_sizes, conv_strides, conv_paddings, conv_activation</span><br><span class="line">        ):</span><br><span class="line">            prev_layer = tf.layers.conv2d(prev_layer, filters=n_maps, kernel_size=kernel_size,</span><br><span class="line">                                         strides=strides, padding=padding, activation=activation,</span><br><span class="line">                                          kernel_initializer=initializer)</span><br><span class="line">        last_conv_layers_flat = tf.reshape(prev_layer, shape=[<span class="number">-1</span>, n_hidden_in])</span><br><span class="line">        hidden = tf.layers.dense(last_conv_layers_flat, n_hidden,</span><br><span class="line">                                    activation=hidden_activation,</span><br><span class="line">                                    kernel_initializer=initializer)</span><br><span class="line">        outputs = tf.layers.dense(hidden, n_outputs, kernel_initializer=initializer)</span><br><span class="line">    trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)</span><br><span class="line">    trainable_vars_by_name = &#123;var.name[len(scope.name):]: var</span><br><span class="line">                                 <span class="keyword">for</span> var <span class="keyword">in</span> trainable_vars&#125;</span><br><span class="line">    <span class="keyword">return</span> outputs, trainable_vars_by_name</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X_state = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, input_height, input_width, input_channels])</span><br><span class="line">online_q_values, online_vars = q_network(X_state, name=<span class="string">"q_networks/online"</span>)</span><br><span class="line">target_q_values, target_vars = q_network(X_state, name=<span class="string">"q_networks/target"</span>)</span><br><span class="line"></span><br><span class="line">copy_ops = [target_var.assign(online_vars[var_name])</span><br><span class="line">           <span class="keyword">for</span> var_name, target_var <span class="keyword">in</span> target_vars.items()]</span><br><span class="line">copy_online_to_target = tf.group(*copy_ops)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">online_vars</span><br></pre></td></tr></table></figure><pre><code>{&#39;/conv2d/bias:0&#39;: &lt;tf.Variable &#39;q_networks/online/conv2d/bias:0&#39; shape=(32,) dtype=float32_ref&gt;, &#39;/conv2d/kernel:0&#39;: &lt;tf.Variable &#39;q_networks/online/conv2d/kernel:0&#39; shape=(8, 8, 1, 32) dtype=float32_ref&gt;, &#39;/conv2d_1/bias:0&#39;: &lt;tf.Variable &#39;q_networks/online/conv2d_1/bias:0&#39; shape=(64,) dtype=float32_ref&gt;, &#39;/conv2d_1/kernel:0&#39;: &lt;tf.Variable &#39;q_networks/online/conv2d_1/kernel:0&#39; shape=(4, 4, 32, 64) dtype=float32_ref&gt;, &#39;/conv2d_2/bias:0&#39;: &lt;tf.Variable &#39;q_networks/online/conv2d_2/bias:0&#39; shape=(64,) dtype=float32_ref&gt;, &#39;/conv2d_2/kernel:0&#39;: &lt;tf.Variable &#39;q_networks/online/conv2d_2/kernel:0&#39; shape=(3, 3, 64, 64) dtype=float32_ref&gt;, &#39;/dense/bias:0&#39;: &lt;tf.Variable &#39;q_networks/online/dense/bias:0&#39; shape=(512,) dtype=float32_ref&gt;, &#39;/dense/kernel:0&#39;: &lt;tf.Variable &#39;q_networks/online/dense/kernel:0&#39; shape=(7040, 512) dtype=float32_ref&gt;, &#39;/dense_1/bias:0&#39;: &lt;tf.Variable &#39;q_networks/online/dense_1/bias:0&#39; shape=(9,) dtype=float32_ref&gt;, &#39;/dense_1/kernel:0&#39;: &lt;tf.Variable &#39;q_networks/online/dense_1/kernel:0&#39; shape=(512, 9) dtype=float32_ref&gt;}</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line">momentum = <span class="number">0.95</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"train"</span>):</span><br><span class="line">    X_action  = tf.placeholder(tf.int32, shape=[<span class="keyword">None</span>])</span><br><span class="line">    y = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">1</span>])</span><br><span class="line">    q_value = tf.reduce_sum(online_q_values * tf.one_hot(X_action, n_outputs), axis=<span class="number">1</span>, keepdims=<span class="keyword">True</span>)</span><br><span class="line">    error = tf.abs(y -q_value)</span><br><span class="line">    clipped_error = tf.clip_by_value(error, <span class="number">0.0</span>, <span class="number">1.0</span>)</span><br><span class="line">    linear_error = <span class="number">2</span> * (error - clipped_error)</span><br><span class="line">    loss = tf.reduce_mean(tf.square(clipped_error) + learning_rate)</span><br><span class="line"></span><br><span class="line">    global_step = tf.Variable(<span class="number">0</span>, trainable=<span class="keyword">False</span>, name=<span class="string">"global_step"</span>)</span><br><span class="line">    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=<span class="keyword">True</span>)</span><br><span class="line">    training_op = optimizer.minimize(loss, global_step=global_step)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReplayMemory</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, maxlen)</span>:</span></span><br><span class="line">        self.maxlen = maxlen</span><br><span class="line">        self.buf = np.empty(shape=maxlen, dtype=np.object)</span><br><span class="line">        self.index = <span class="number">0</span></span><br><span class="line">        self.length = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">append</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        self.buf[self.index] = data</span><br><span class="line">        self.length = min(self.length + <span class="number">1</span>, self.maxlen)</span><br><span class="line">        self.index = (self.index + <span class="number">1</span>) % self.maxlen</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(self, batch_size, with_replacement=True)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> with_replacement:</span><br><span class="line">            indices = np.random.randint(self.length, size=batch_size)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            indices = np.random.randint(self.length)[:batch_size]</span><br><span class="line">        <span class="keyword">return</span> self.buf[indices]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">replay_memory_size = <span class="number">500000</span></span><br><span class="line">replay_memory = ReplayMemory(replay_memory_size)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_memories</span><span class="params">(batch_size)</span>:</span></span><br><span class="line">    cols = [[], [], [], [], []]</span><br><span class="line">    <span class="keyword">for</span> memory <span class="keyword">in</span> replay_memory.sample(batch_size):</span><br><span class="line">        <span class="keyword">for</span> col, value <span class="keyword">in</span> zip(cols, memory):</span><br><span class="line">            col.append(value)</span><br><span class="line">    cols = [np.array(col) <span class="keyword">for</span> col <span class="keyword">in</span> cols]</span><br><span class="line">    <span class="keyword">return</span> cols[<span class="number">0</span>], cols[<span class="number">1</span>], cols[<span class="number">2</span>].reshape(<span class="number">-1</span>, <span class="number">1</span>), cols[<span class="number">3</span>], cols[<span class="number">4</span>].reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">eps_min = <span class="number">0.1</span></span><br><span class="line">eps_max = <span class="number">1.0</span></span><br><span class="line">eps_decay_steps = <span class="number">2000000</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">epsilon_greedy</span><span class="params">(q_values, step)</span>:</span></span><br><span class="line">    epsilon = max(eps_min, eps_max - (eps_max-eps_min) * step/eps_decay_steps)</span><br><span class="line">    <span class="keyword">if</span> np.random.rand() &lt; epsilon:</span><br><span class="line">        <span class="keyword">return</span> np.random.randint(n_outputs)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> np.argmax(q_values)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">n_steps = <span class="number">4000000</span></span><br><span class="line">training_start = <span class="number">10000</span></span><br><span class="line">training_interval = <span class="number">4</span></span><br><span class="line">save_steps = <span class="number">1000</span></span><br><span class="line">copy_steps = <span class="number">10000</span></span><br><span class="line">discount_rate = <span class="number">0.99</span></span><br><span class="line">skip_start = <span class="number">90</span></span><br><span class="line">batch_size = <span class="number">50</span></span><br><span class="line">iteration = <span class="number">0</span></span><br><span class="line">checkpoint_path = <span class="string">"reinforce/dqn/my_dqn.ckpt"</span></span><br><span class="line">done = <span class="keyword">True</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">loss_val = np.infty</span><br><span class="line">game_length = <span class="number">0</span></span><br><span class="line">total_max_q = <span class="number">0</span></span><br><span class="line">mean_max_q = <span class="number">0.0</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="keyword">if</span> os.path.isfile(checkpoint_path + <span class="string">".index"</span>):</span><br><span class="line">        saver.restore(sess, checkpoint_path)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        init.run()</span><br><span class="line">        copy_online_to_target.run()</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        step = global_step.eval()</span><br><span class="line">        <span class="keyword">if</span> step &gt;= n_steps:</span><br><span class="line">            brea;</span><br><span class="line">        iteration += <span class="number">1</span></span><br><span class="line">        print(<span class="string">"\rIteration &#123;&#125;\tTraining step &#123;&#125;/&#123;&#125; (&#123;:.1f&#125;)%\tLoss &#123;:5f&#125;\tMean Max-Q &#123;:5f&#125;  "</span>.format(</span><br><span class="line">            iteration, step, n_steps, step * <span class="number">100</span> / n_steps, loss_val, mean_max_q</span><br><span class="line">        ), end=<span class="string">""</span>)</span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            obs = env.reset()</span><br><span class="line">            <span class="keyword">for</span> skip <span class="keyword">in</span> range(skip_start):</span><br><span class="line">                obs, reward, done, info = env.step(<span class="number">0</span>)</span><br><span class="line">            state = preprocess_observation(obs)</span><br><span class="line"></span><br><span class="line">        q_values = online_q_values.eval(feed_dict=&#123;X_state: [state]&#125;)</span><br><span class="line">        action = epsilon_greedy(q_values, step)</span><br><span class="line"></span><br><span class="line">        obs, reward, done, info = env.step(action)</span><br><span class="line">        next_state = preprocess_observation(obs)</span><br><span class="line"></span><br><span class="line">        replay_memory.append((state, action, reward, next_state, <span class="number">1.0</span> - done))</span><br><span class="line">        state = next_state</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        total_max_q += q_values.max()</span><br><span class="line">        game_length += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            mean_max_q = total_max_q / game_length</span><br><span class="line">            total_max_q = <span class="number">0.0</span></span><br><span class="line">            game_length = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> iteration &lt; training_start <span class="keyword">or</span> iteration % training_interval != <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        X_state_val, X_action_val, rewards, X_next_state_val, continues = (sample_memories(batch_size))</span><br><span class="line">        next_q_values = target_q_values.eval(feed_dict=&#123;X_state: X_next_state_val&#125;)</span><br><span class="line">        max_next_q_values = np.max(next_q_values, axis=<span class="number">1</span>, keepdims=<span class="keyword">True</span>)</span><br><span class="line">        y_val = rewards + continues * discount_rate * max_next_q_values</span><br><span class="line"></span><br><span class="line">        _, loss_val = sess.run([training_op, loss],</span><br><span class="line">                              feed_dict=&#123;X_state: X_state_val, X_action: X_action_val, y: y_val&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> step % copy_steps == <span class="number">0</span>:</span><br><span class="line">            copy_online_to_target.run()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> step % save_steps == <span class="number">0</span>:</span><br><span class="line">            saver.save(sess, checkpoint_path)</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from reinforce/dqn/my_dqn.ckptIteration 47872    Training step 8408/4000000 (0.2)%    Loss 0.001121    Mean Max-Q 0.096694  </code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">frames = []</span><br><span class="line">n_max_steps = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, checkpoint_path)</span><br><span class="line">    obs = env.reset()</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(n_max_steps):</span><br><span class="line">        state = preprocess_observation(obs)</span><br><span class="line"></span><br><span class="line">        q_values = online_q_values.eval(feed_dict=&#123;X_state: [state]&#125;)</span><br><span class="line">        action = np.argmax(q_values)</span><br><span class="line"></span><br><span class="line">        obs, reward, done, info = env.step(action)</span><br><span class="line"></span><br><span class="line">        img = env.render(mode=<span class="string">"rgb_array"</span>)</span><br><span class="line">        frames.append(img)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from reinforce/dqn/my_dqn.ckpt</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_animation(frames)</span><br></pre></td></tr></table></figure><pre><code>&lt;IPython.core.display.Javascript object&gt;</code></pre><p><img src="data:image/png;base64,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" width="638.888905813665"></p><pre><code>&lt;matplotlib.animation.FuncAnimation at 0x1d45d850320&gt;</code></pre><hr><p><a href="https://github.com/coldJune/machineLearning/blob/master/handson-ml/Reinforcement%20Learning.ipynb" target="_blank" rel="noopener">源文件</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;引入OpenAI-gym&quot;&gt;&lt;a href=&quot;#引入OpenAI-gym&quot; class=&quot;headerlink&quot; title=&quot;引入OpenAI gym&quot;&gt;&lt;/a&gt;引入OpenAI gym&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;
      
    
    </summary>
    
      <category term="机器学习" scheme="http://coldjune.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow" scheme="http://coldjune.com/tags/tensorflow/"/>
    
      <category term="Hands-On Machine Learning with Scikit-Learn and TensorFlow" scheme="http://coldjune.com/tags/Hands-On-Machine-Learning-with-Scikit-Learn-and-TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>Autoencoder</title>
    <link href="http://coldjune.com/2019/01/03/Autoencoder/"/>
    <id>http://coldjune.com/2019/01/03/Autoencoder/</id>
    <published>2019-01-03T01:20:16.000Z</published>
    <updated>2019-05-17T14:32:54.000Z</updated>
    
    <content type="html"><![CDATA[<hr><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reset_graph</span><span class="params">(seed=<span class="number">42</span>)</span>:</span></span><br><span class="line">    tf.reset_default_graph()</span><br><span class="line">    tf.set_random_seed(seed)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_image</span><span class="params">(image, shape=[<span class="number">28</span>, <span class="number">28</span>])</span>:</span></span><br><span class="line">    plt.imshow(image.reshape(shape), cmap=<span class="string">"Greys"</span>, interpolation=<span class="string">"nearest"</span>)</span><br><span class="line">    plt.axis(<span class="string">"off"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plt_multiple_images</span><span class="params">(images, n_rows, n_cols, pad=<span class="number">2</span>)</span>:</span></span><br><span class="line">    images = images - images.min()</span><br><span class="line">    w, h = images.shape[<span class="number">1</span>:]</span><br><span class="line">    image = np.zeros(((w+pad)*n_rows+pad, (h+pad)*n_cols+pad))</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(n_rows):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(n_cols):</span><br><span class="line">            image[(y*(h+pad)+pad):(y*(h+pad)+pad+h), (x*(w+pad)+pad):(x*(w+pad)+pad+w)]=images[y*n_cols+x]</span><br><span class="line">        plt.imshow(image, cmap=<span class="string">"Greys"</span>, interpolation=<span class="string">"nearest"</span>)</span><br><span class="line">        plt.axis(<span class="string">"off"</span>)</span><br></pre></td></tr></table></figure><h1 id="使用线性Autoencoder进行主成分分析-PCA"><a href="#使用线性Autoencoder进行主成分分析-PCA" class="headerlink" title="使用线性Autoencoder进行主成分分析(PCA)"></a>使用线性Autoencoder进行主成分分析(PCA)</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy.random <span class="keyword">as</span> rnd</span><br><span class="line"></span><br><span class="line">rnd.seed(<span class="number">4</span>)</span><br><span class="line">m = <span class="number">200</span></span><br><span class="line">w1, w2 = <span class="number">0.1</span>, <span class="number">0.3</span></span><br><span class="line">noise = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">angles = rnd.rand(m) * <span class="number">3</span> * np.pi / <span class="number">2</span> - <span class="number">0.5</span></span><br><span class="line">data = np.empty((m, <span class="number">3</span>))</span><br><span class="line">data[:, <span class="number">0</span>] = np.cos(angles) + np.sin(angles)/<span class="number">2</span> + noise * rnd.randn(m) / <span class="number">2</span></span><br><span class="line">data[:, <span class="number">1</span>] = np.sin(angles) * <span class="number">0.7</span> + noise * rnd.randn(m) / <span class="number">2</span></span><br><span class="line">data[:, <span class="number">2</span>] = data[:, <span class="number">0</span>] * w1 + data[:, <span class="number">1</span>] * w2 + noise * rnd.randn(m)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train = scaler.fit_transform(data[:<span class="number">100</span>])</span><br><span class="line">X_test = scaler.transform(data[<span class="number">100</span>:])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">3</span></span><br><span class="line">n_hidden = <span class="number">2</span></span><br><span class="line">n_outputs = n_inputs</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, n_inputs])</span><br><span class="line">hidden = tf.layers.dense(X, n_hidden)</span><br><span class="line">outputs = tf.layers.dense(hidden, n_outputs)</span><br><span class="line"></span><br><span class="line">reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))</span><br><span class="line"></span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate)</span><br><span class="line">training_op = optimizer.minimize(reconstruction_loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">n_iterations = <span class="number">1000</span></span><br><span class="line">codings = hidden</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_iterations):</span><br><span class="line">        training_op.run(feed_dict=&#123;X: X_train&#125;)</span><br><span class="line">        coding_val = codings.eval(feed_dict=&#123;X: X_test&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">4</span>,<span class="number">3</span>))</span><br><span class="line">plt.plot(coding_val[:, <span class="number">0</span>], coding_val[:, <span class="number">1</span>], <span class="string">"b."</span>)</span><br><span class="line">plt.xlabel(<span class="string">"$z_1$"</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.ylabel(<span class="string">"$z_2$"</span>, fontsize=<span class="number">18</span>, rotation=<span class="number">0</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2019/01/03/Autoencoder/Autoencoder_7_0.png" alt="png"></p><h1 id="Stacked-Autoencoders"><a href="#Stacked-Autoencoders" class="headerlink" title="Stacked Autoencoders"></a>Stacked Autoencoders</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist  = input_data.read_data_sets(<span class="string">"tmp/data/"</span>)</span><br></pre></td></tr></table></figure><pre><code>WARNING:tensorflow:From &lt;ipython-input-7-39eecf39f555&gt;:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.Instructions for updating:Please use alternatives such as official/mnist/dataset.py from tensorflow/models.WARNING:tensorflow:From e:\python\python36\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.Instructions for updating:Please write your own downloading logic.WARNING:tensorflow:From e:\python\python36\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.Instructions for updating:Please use tf.data to implement this functionality.Extracting tmp/data/train-images-idx3-ubyte.gzWARNING:tensorflow:From e:\python\python36\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.Instructions for updating:Please use tf.data to implement this functionality.Extracting tmp/data/train-labels-idx1-ubyte.gzExtracting tmp/data/t10k-images-idx3-ubyte.gzExtracting tmp/data/t10k-labels-idx1-ubyte.gzWARNING:tensorflow:From e:\python\python36\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.Instructions for updating:Please use alternatives such as official/mnist/dataset.py from tensorflow/models.</code></pre><h2 id="一次性训练所有层"><a href="#一次性训练所有层" class="headerlink" title="一次性训练所有层"></a>一次性训练所有层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line">n_hidden2 = <span class="number">150</span></span><br><span class="line">n_hidden3 = n_hidden1</span><br><span class="line">n_outputs = n_inputs</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">l2_reg = <span class="number">0.0001</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, n_inputs])</span><br><span class="line"></span><br><span class="line">he_init = tf.contrib.layers.variance_scaling_initializer()</span><br><span class="line">l2_regularizer = tf.contrib.layers.l2_regularizer(l2_reg)</span><br><span class="line"></span><br><span class="line">my_dense_layer = partial(tf.layers.dense,</span><br><span class="line">                        activation=tf.nn.elu,</span><br><span class="line">                        kernel_initializer=he_init,</span><br><span class="line">                        kernel_regularizer=l2_regularizer)</span><br><span class="line"></span><br><span class="line">hidden1 = my_dense_layer(X, n_hidden1)</span><br><span class="line">hidden2 = my_dense_layer(hidden1, n_hidden2)</span><br><span class="line">hidden3 = my_dense_layer(hidden2, n_hidden3)</span><br><span class="line">outputs = my_dense_layer(hidden3, n_outputs, activation=<span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line">reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))</span><br><span class="line"></span><br><span class="line">reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)</span><br><span class="line">loss = tf.add_n([reconstruction_loss] + reg_losses)</span><br><span class="line"></span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">5</span></span><br><span class="line">batch_size = <span class="number">150</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        n_batches = mnist.train.num_examples // batch_size</span><br><span class="line">        <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_batches):</span><br><span class="line">            print(<span class="string">"\r&#123;&#125;%"</span>.format(<span class="number">100</span> * iteration // n_batches), end=<span class="string">""</span>)</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line">            X_batch, y_batch = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch&#125;)</span><br><span class="line">        loss_train = reconstruction_loss.eval(feed_dict=&#123;X: X_batch&#125;)</span><br><span class="line">        sys.stdout.flush()</span><br><span class="line">        print(<span class="string">"\r&#123;&#125;"</span>.format(epoch), <span class="string">"Train MSE:"</span>, loss_train)</span><br><span class="line">        saver.save(sess, <span class="string">"autoencoder/my_model_all_layers.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>0 Train MSE: 0.0203023071 Train MSE: 0.0116431662 Train MSE: 0.0102257813 Train MSE: 0.0098999464 Train MSE: 0.010377405</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_reconstruction_digits</span><span class="params">(X, outputs, model_path=None, n_test_digits=<span class="number">2</span>)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="keyword">if</span> model_path:</span><br><span class="line">            saver.restore(sess, model_path)</span><br><span class="line">        X_test = mnist.test.images[:n_test_digits]</span><br><span class="line">        outputs_val = outputs.eval(feed_dict=&#123;X: X_test&#125;)</span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">3</span> * n_test_digits))</span><br><span class="line">    <span class="keyword">for</span> digit_index <span class="keyword">in</span> range(n_test_digits):</span><br><span class="line">        plt.subplot(n_test_digits, <span class="number">2</span>, digit_index * <span class="number">2</span> + <span class="number">1</span>)</span><br><span class="line">        plot_image(X_test[digit_index])</span><br><span class="line">        plt.subplot(n_test_digits, <span class="number">2</span>, digit_index * <span class="number">2</span> + <span class="number">2</span>)</span><br><span class="line">        plot_image(outputs_val[digit_index])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show_reconstruction_digits(X, outputs, <span class="string">"autoencoder/my_model_all_layers.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from autoencoder/my_model_all_layers.ckpt</code></pre><p><img src="/2019/01/03/Autoencoder/Autoencoder_14_1.png" alt="png"></p><h2 id="调整权重"><a href="#调整权重" class="headerlink" title="调整权重"></a>调整权重</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line">n_hidden2 = <span class="number">150</span></span><br><span class="line">n_hidden3 = n_hidden1</span><br><span class="line">n_outputs = n_inputs</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">l2_reg = <span class="number">0.0005</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">activation = tf.nn.elu</span><br><span class="line">regularizer = tf.contrib.layers.l2_regularizer(l2_reg)</span><br><span class="line">initializer = tf.contrib.layers.variance_scaling_initializer()</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, n_inputs])</span><br><span class="line"></span><br><span class="line">weights1_init = initializer([n_inputs, n_hidden1])</span><br><span class="line">weights2_init = initializer([n_hidden1, n_hidden2])</span><br><span class="line"></span><br><span class="line">weights1 = tf.Variable(weights1_init, dtype=tf.float32, name=<span class="string">"weights1"</span>)</span><br><span class="line">weights2 = tf.Variable(weights2_init, dtype=tf.float32, name=<span class="string">"weights2"</span>)</span><br><span class="line">weights3 = tf.transpose(weights2, name=<span class="string">"weights3"</span>)</span><br><span class="line">weights4 = tf.transpose(weights1, name=<span class="string">"weights4"</span>)</span><br><span class="line"></span><br><span class="line">biases1 = tf.Variable(tf.zeros(n_hidden1), name=<span class="string">"biases1"</span>)</span><br><span class="line">biases2 = tf.Variable(tf.zeros(n_hidden2), name=<span class="string">"biases2"</span>)</span><br><span class="line">biases3 = tf.Variable(tf.zeros(n_hidden3), name=<span class="string">"biases3"</span>)</span><br><span class="line">biases4 = tf.Variable(tf.zeros(n_outputs), name=<span class="string">"biases4"</span>)</span><br><span class="line"></span><br><span class="line">hidden1 = activation(tf.matmul(X, weights1) + biases1)</span><br><span class="line">hidden2 = activation(tf.matmul(hidden1, weights2) + biases2)</span><br><span class="line">hidden3 = activation(tf.matmul(hidden2, weights3) + biases3)</span><br><span class="line">outputs = tf.matmul(hidden3, weights4) + biases4</span><br><span class="line"></span><br><span class="line">reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))</span><br><span class="line">reg_loss = regularizer(weights1) + regularizer(weights2)</span><br><span class="line">loss = reconstruction_loss + reg_loss</span><br><span class="line"></span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">5</span></span><br><span class="line">batch_size = <span class="number">150</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        n_batches = mnist.train.num_examples // batch_size</span><br><span class="line">        <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_batches):</span><br><span class="line">            print(<span class="string">"\r&#123;&#125;%"</span>.format(<span class="number">100</span> * iteration // n_batches), end=<span class="string">""</span>)</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line">            X_batch, y_batch = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch&#125;)</span><br><span class="line">        loss_train = reconstruction_loss.eval(feed_dict=&#123;X: X_batch&#125;)</span><br><span class="line">        sys.stdout.flush()</span><br><span class="line">        print(<span class="string">"\r&#123;&#125;"</span>.format(epoch), <span class="string">"Train MSE:"</span>, loss_train)</span><br><span class="line">        saver.save(sess, <span class="string">"autoencoder/my_model_tying_weights.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>0 Train MSE: 0.0150668421 Train MSE: 0.0164885612 Train MSE: 0.0173758033 Train MSE: 0.0168782274 Train MSE: 0.015587644</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show_reconstruction_digits(X, outputs, <span class="string">"autoencoder/my_model_tying_weights.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from autoencoder/my_model_tying_weights.ckpt</code></pre><p><img src="/2019/01/03/Autoencoder/Autoencoder_20_1.png" alt="png"></p><h2 id="Training-one-Autoencoder-at-a-time-in-multiple-graphs"><a href="#Training-one-Autoencoder-at-a-time-in-multiple-graphs" class="headerlink" title="Training one Autoencoder at a time in multiple graphs"></a>Training one Autoencoder at a time in multiple graphs</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_autoencoder</span><span class="params">(X_train, n_neurons, n_epochs, batch_size,</span></span></span><br><span class="line"><span class="function"><span class="params">                     learning_rate=<span class="number">0.01</span>, l2_reg=<span class="number">0.0005</span>, seed=<span class="number">42</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                     hidden_activation=tf.nn.elu,</span></span></span><br><span class="line"><span class="function"><span class="params">                     output_activation=tf.nn.elu)</span>:</span></span><br><span class="line">    graph = tf.Graph()</span><br><span class="line">    <span class="keyword">with</span> graph.as_default():</span><br><span class="line">        tf.set_random_seed(seed)</span><br><span class="line"></span><br><span class="line">        n_inputs = X_train.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        X = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, n_inputs])</span><br><span class="line"></span><br><span class="line">        my_dense_layer = partial(</span><br><span class="line">            tf.layers.dense,</span><br><span class="line">            kernel_initializer=tf.contrib.layers.variance_scaling_initializer(),</span><br><span class="line">            kernel_regularizer=tf.contrib.layers.l2_regularizer(l2_reg)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        hidden = my_dense_layer(X, n_neurons, activation=hidden_activation, name=<span class="string">"hidden"</span>)</span><br><span class="line">        outputs = my_dense_layer(hidden, n_inputs, activation=output_activation, name=<span class="string">"outputs"</span>)</span><br><span class="line"></span><br><span class="line">        reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))</span><br><span class="line"></span><br><span class="line">        reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)</span><br><span class="line">        loss = tf.add_n([reconstruction_loss] + reg_losses)</span><br><span class="line"></span><br><span class="line">        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">        training_op = optimizer.minimize(loss)</span><br><span class="line">        init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">            init.run()</span><br><span class="line">            <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">                n_batches = len(X_train) // batch_size</span><br><span class="line">                <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_batches):</span><br><span class="line">                    print(<span class="string">"\r&#123;&#125;%"</span>.format(<span class="number">100</span> * iteration // n_batches), end=<span class="string">""</span>)</span><br><span class="line">                    sys.stdout.flush()</span><br><span class="line">                    indices = rnd.permutation(len(X_train))[:batch_size]</span><br><span class="line">                    X_batch = X_train[indices]</span><br><span class="line">                    sess.run(training_op, feed_dict=&#123;X: X_batch&#125;)</span><br><span class="line">                loss_train = reconstruction_loss.eval(feed_dict=&#123;X: X_batch&#125;)</span><br><span class="line">                sys.stdout.flush()</span><br><span class="line">                print(<span class="string">"\r&#123;&#125;"</span>.format(epoch), <span class="string">"Train MSE:"</span>, loss_train)</span><br><span class="line">            params = dict([(var.name, var.eval())</span><br><span class="line">                           <span class="keyword">for</span> var <span class="keyword">in</span> tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)])</span><br><span class="line">            hidden_val = hidden.eval(feed_dict=&#123;X: X_train&#125;)</span><br><span class="line">            <span class="keyword">return</span> hidden_val, params[<span class="string">"hidden/kernel:0"</span>],params[<span class="string">"hidden/bias:0"</span>], params[<span class="string">"outputs/kernel:0"</span>], params[<span class="string">"outputs/bias:0"</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hidden_output, W1, b1, W4, b4 = train_autoencoder(mnist.train.images,</span><br><span class="line">                                                  n_neurons=<span class="number">300</span>, n_epochs=<span class="number">4</span>,</span><br><span class="line">                                                  batch_size=<span class="number">150</span>, output_activation=<span class="keyword">None</span>)</span><br><span class="line">_, W2,b2, W3, b3 = train_autoencoder(hidden_output, n_neurons=<span class="number">150</span>,</span><br><span class="line">                                     n_epochs=<span class="number">4</span>, batch_size=<span class="number">150</span>)</span><br></pre></td></tr></table></figure><pre><code>0 Train MSE: 0.0185177381 Train MSE: 0.01868262 Train MSE: 0.0184676263 %Train MSE: 0.0192316230 Train MSE: 0.00423610861 Train MSE: 0.00483268032 Train MSE: 0.0046687483 Train MSE: 0.0044039097</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, n_inputs])</span><br><span class="line">hidden1 = tf.nn.elu(tf.matmul(X, W1) + b1)</span><br><span class="line">hidden2 = tf.nn.elu(tf.matmul(hidden1, W2) + b2)</span><br><span class="line">hidden3 = tf.nn.elu(tf.matmul(hidden2, W3) + b3)</span><br><span class="line">outputs = tf.matmul(hidden3, W4) + b4</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show_reconstruction_digits(X, outputs)</span><br></pre></td></tr></table></figure><p><img src="/2019/01/03/Autoencoder/Autoencoder_26_0.png" alt="png"></p><h2 id="Training-one-Autoencoder-at-a-time-in-a-single-graph"><a href="#Training-one-Autoencoder-at-a-time-in-a-single-graph" class="headerlink" title="Training one Autoencoder at a time in a single graph"></a>Training one Autoencoder at a time in a single graph</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line">n_hidden2 = <span class="number">150</span></span><br><span class="line">n_hidden3 = n_hidden1</span><br><span class="line">n_outputs = n_inputs</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">l2_reg = <span class="number">0.0001</span></span><br><span class="line"></span><br><span class="line">activation = tf.nn.elu</span><br><span class="line">regularizer = tf.contrib.layers.l2_regularizer(l2_reg)</span><br><span class="line">initializer = tf.contrib.layers.variance_scaling_initializer()</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, n_inputs])</span><br><span class="line"></span><br><span class="line">weights1_init = initializer([n_inputs, n_hidden1])</span><br><span class="line">weights2_init = initializer([n_hidden1, n_hidden2])</span><br><span class="line">weights3_init = initializer([n_hidden2, n_hidden3])</span><br><span class="line">weights4_init = initializer([n_hidden3, n_outputs])</span><br><span class="line"></span><br><span class="line">weights1 = tf.Variable(weights1_init, dtype=tf.float32, name=<span class="string">"weights1"</span>)</span><br><span class="line">weights2 = tf.Variable(weights2_init, dtype=tf.float32, name=<span class="string">"weigths2"</span>)</span><br><span class="line">weights3 = tf.Variable(weights3_init, dtype=tf.float32, name=<span class="string">"weights3"</span>)</span><br><span class="line">weights4 = tf.Variable(weights4_init, dtype=tf.float32, name=<span class="string">"weights4"</span>)</span><br><span class="line"></span><br><span class="line">biases1 = tf.Variable(tf.zeros(n_hidden1), name=<span class="string">"biases1"</span>)</span><br><span class="line">biases2 = tf.Variable(tf.zeros(n_hidden2), name=<span class="string">"biases2"</span>)</span><br><span class="line">biases3 = tf.Variable(tf.zeros(n_hidden3), name=<span class="string">"biases3"</span>)</span><br><span class="line">biases4 = tf.Variable(tf.zeros(n_outputs), name=<span class="string">"biases4"</span>)</span><br><span class="line"></span><br><span class="line">hidden1 = activation(tf.matmul(X, weights1) + biases1)</span><br><span class="line">hidden2 = activation(tf.matmul(hidden1, weights2) + biases2)</span><br><span class="line">hidden3 = activation(tf.matmul(hidden2, weights3) + biases3)</span><br><span class="line">outputs = tf.matmul(hidden3, weights4) + biases4</span><br><span class="line"></span><br><span class="line">reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"phase1"</span>):</span><br><span class="line">    phasel_outputs = tf.matmul(hidden1, weights4) + biases4</span><br><span class="line">    phase1_reconstruction_loss = tf.reduce_mean(tf.square(phasel_outputs - X))</span><br><span class="line">    phase1_reg_loss = regularizer(weights1) + regularizer(weights4)</span><br><span class="line">    phase1_loss = phase1_reconstruction_loss + phase1_reg_loss</span><br><span class="line">    phase1_training_op = optimizer.minimize(phase1_loss)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"phase2"</span>):</span><br><span class="line">    phase2_reconstruction_loss = tf.reduce_mean(tf.square(hidden3 - hidden1))</span><br><span class="line">    phase2_reg_loss = regularizer(weights2) + regularizer(weights3)</span><br><span class="line">    phase2_loss = phase2_reconstruction_loss + phase2_reg_loss</span><br><span class="line">    train_vars = [weights2, biases2, weights3, biases3]</span><br><span class="line">    phase2_training_op = optimizer.minimize(phase2_loss, var_list=train_vars)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">training_ops = [phase1_training_op, phase2_training_op]</span><br><span class="line">reconstruction_loesses = [phase1_reconstruction_loss, phase2_reconstruction_loss]</span><br><span class="line">n_epochs = [<span class="number">4</span>, <span class="number">4</span>]</span><br><span class="line">batch_sizes = [<span class="number">150</span>, <span class="number">150</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> phase <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">        print(<span class="string">"Training phase #&#123;&#125;"</span>.format(phase + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs[phase]):</span><br><span class="line">            n_batches = mnist.train.num_examples // batch_sizes[phase]</span><br><span class="line">            <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_batches):</span><br><span class="line">                print(<span class="string">"\r&#123;&#125;%"</span>.format(<span class="number">100</span> * iteration // n_batches), end=<span class="string">""</span>)</span><br><span class="line">                sys.stdout.flush()</span><br><span class="line">                X_batch, y_batch = mnist.train.next_batch(batch_sizes[phase])</span><br><span class="line">                sess.run(training_ops[phase],feed_dict=&#123;X: X_batch&#125;)</span><br><span class="line">            loss_train = reconstruction_loesses[phase].eval(feed_dict=&#123;X: X_batch&#125;)</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line">            print(<span class="string">"\r&#123;&#125;"</span>.format(epoch), <span class="string">"Training MSE:"</span>, loss_train)</span><br><span class="line">            saver.save(sess, <span class="string">"autoencoder/my_model_one_at_a_time.ckpt"</span>)</span><br><span class="line">    loss_test = reconstruction_loss.eval(feed_dict=&#123;X: mnist.test.images&#125;)</span><br><span class="line">    print(<span class="string">"Test MSE:"</span>, loss_test)</span><br></pre></td></tr></table></figure><pre><code>Training phase #10 Training MSE: 0.00740683821 Training MSE: 0.00782875252 Training MSE: 0.0077280593 Training MSE: 0.0074089756Training phase #20 Training MSE: 0.32578231 Training MSE: 0.005739542 Training MSE: 0.002941841739% Training MSE: 0.0024437662Test MSE: 0.009793411</code></pre><h2 id="缓存冻结的层输出"><a href="#缓存冻结的层输出" class="headerlink" title="缓存冻结的层输出"></a>缓存冻结的层输出</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">training_ops = [phase1_training_op, phase2_training_op]</span><br><span class="line">reconstruction_loesses = [phase1_reconstruction_loss, phase2_reconstruction_loss]</span><br><span class="line">n_epochs = [<span class="number">4</span>, <span class="number">4</span>]</span><br><span class="line">batch_sizes = [<span class="number">150</span>, <span class="number">150</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> phase <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">        print(<span class="string">"Training phase #&#123;&#125;"</span>.format(phase + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">if</span> phase == <span class="number">1</span>:</span><br><span class="line">            hidden1_cache = hidden1.eval(feed_dict=&#123;X: mnist.train.images&#125;)</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs[phase]):</span><br><span class="line">            n_batches = mnist.train.num_examples // batch_sizes[phase]</span><br><span class="line">            <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_batches):</span><br><span class="line">                print(<span class="string">"\r&#123;&#125;%"</span>.format(<span class="number">100</span> * iteration // n_batches), end=<span class="string">""</span>)</span><br><span class="line">                sys.stdout.flush()</span><br><span class="line">                <span class="keyword">if</span> phase == <span class="number">1</span>:</span><br><span class="line">                    indices = rnd.permutation(mnist.train.num_examples)</span><br><span class="line">                    hidden1_batch = hidden1_cache[indices[:batch_sizes[phase]]]</span><br><span class="line">                    feed_dict = &#123;hidden1: hidden1_batch&#125;</span><br><span class="line">                    sess.run(training_ops[phase], feed_dict=feed_dict)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    X_batch, y_batch = mnist.train.next_batch(batch_sizes[phase])</span><br><span class="line">                    feed_dict = &#123;X: X_batch&#125;</span><br><span class="line">                    sess.run(training_ops[phase], feed_dict=feed_dict)</span><br><span class="line">            loss_train = reconstruction_loesses[phase].eval(feed_dict=feed_dict)</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line">            print(<span class="string">"\r&#123;&#125;"</span>.format(epoch), <span class="string">"Train MSE:"</span>, loss_train)</span><br><span class="line">            saver.save(sess, <span class="string">"autoencoder/my_mode_cache_frozen.ckpt"</span>)</span><br><span class="line">        loss_test = reconstruction_loss.eval(feed_dict=&#123;X: mnist.test.images&#125;)</span><br><span class="line">        print(<span class="string">"Test MSE:"</span>, loss_test)</span><br></pre></td></tr></table></figure><pre><code>Training phase #10 Train MSE: 0.0075382271 Train MSE: 0.0077546322 Train MSE: 0.0073436433 Train MSE: 0.007837738Test MSE: 0.10728952Training phase #20 Train MSE: 0.168840931 Train MSE: 0.00448831262 Train MSE: 0.00248084523 Train MSE: 0.0020300867Test MSE: 0.009770555</code></pre><h2 id="可视化重构"><a href="#可视化重构" class="headerlink" title="可视化重构"></a>可视化重构</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">n_test_digits = <span class="number">2</span></span><br><span class="line">X_test = mnist.test.images[:n_test_digits]</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, <span class="string">"autoencoder/my_model_one_at_a_time.ckpt"</span>)</span><br><span class="line">    outputs_val = outputs.eval(feed_dict=&#123;X: X_test&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> digit_index <span class="keyword">in</span> range(n_test_digits):</span><br><span class="line">    plt.subplot(n_test_digits, <span class="number">2</span>, digit_index * <span class="number">2</span> + <span class="number">1</span>)</span><br><span class="line">    plot_image(X_test[digit_index])</span><br><span class="line">    plt.subplot(n_test_digits, <span class="number">2</span>, digit_index * <span class="number">2</span> + <span class="number">2</span>)</span><br><span class="line">    plot_image(outputs_val[digit_index])</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from autoencoder/my_model_one_at_a_time.ckpt</code></pre><p><img src="/2019/01/03/Autoencoder/Autoencoder_35_1.png" alt="png"></p><h2 id="可视化另外的特征"><a href="#可视化另外的特征" class="headerlink" title="可视化另外的特征"></a>可视化另外的特征</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, <span class="string">"autoencoder/my_model_one_at_a_time.ckpt"</span>)</span><br><span class="line">    weights_val = weights1.eval()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">5</span>, i + <span class="number">1</span>)</span><br><span class="line">    plot_image(weights_val.T[i])</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from autoencoder/my_model_one_at_a_time.ckpt</code></pre><p><img src="/2019/01/03/Autoencoder/Autoencoder_37_1.png" alt="png"></p><h2 id="非监督的预训练"><a href="#非监督的预训练" class="headerlink" title="非监督的预训练"></a>非监督的预训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line">n_hidden2 = <span class="number">150</span></span><br><span class="line">n_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">l2_reg = <span class="number">0.0005</span></span><br><span class="line"></span><br><span class="line">activation = tf.nn.elu</span><br><span class="line">regularizer = tf.contrib.layers.l2_regularizer(l2_reg)</span><br><span class="line">initializer = tf.contrib.layers.variance_scaling_initializer()</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, n_inputs])</span><br><span class="line">y = tf.placeholder(tf.int32, shape=[<span class="keyword">None</span>])</span><br><span class="line"></span><br><span class="line">weights1_init = initializer([n_inputs, n_hidden1])</span><br><span class="line">weights2_init = initializer([n_hidden1, n_hidden2])</span><br><span class="line">weights3_init = initializer([n_hidden2, n_hidden3])</span><br><span class="line"></span><br><span class="line">weights1 = tf.Variable(weights1_init, dtype=tf.float32, name=<span class="string">"weights1"</span>)</span><br><span class="line">weights2 = tf.Variable(weights2_init, dtype=tf.float32, name=<span class="string">"weights2"</span>)</span><br><span class="line">weights3 = tf.Variable(weights3_init, dtype=tf.float32, name=<span class="string">"weights3"</span>)</span><br><span class="line"></span><br><span class="line">biases1 = tf.Variable(tf.zeros(n_hidden1), name=<span class="string">"biases1"</span>)</span><br><span class="line">biases2 = tf.Variable(tf.zeros(n_hidden2), name=<span class="string">"biases2"</span>)</span><br><span class="line">biases3 = tf.Variable(tf.zeros(n_hidden3), name=<span class="string">"biases3"</span>)</span><br><span class="line"></span><br><span class="line">hidden1 = activation(tf.matmul(X, weights1) + biases1)</span><br><span class="line">hidden2 = activation(tf.matmul(hidden1, weights2) + biases2)</span><br><span class="line">logits = tf.matmul(hidden2, weights3) + biases3</span><br><span class="line"></span><br><span class="line">cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">reg_loss = regularizer(weights1) + regularizer(weights2) + regularizer(weights3)</span><br><span class="line">loss = cross_entropy + reg_loss</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate)</span><br><span class="line">training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">correct = tf.nn.in_top_k(logits, y, <span class="number">1</span>)</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">pretrain_saver = tf.train.Saver([weights1, weights2, biases1, biases2])</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">4</span></span><br><span class="line">batch_size = <span class="number">150</span></span><br><span class="line">n_labeled_instance = <span class="number">20000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        n_batches = n_labeled_instance // batch_size</span><br><span class="line">        <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_batches):</span><br><span class="line">            print(<span class="string">"\r&#123;&#125;%"</span>.format(<span class="number">100</span> * iteration // n_batches), end=<span class="string">""</span>)</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line">            indices = rnd.permutation(n_labeled_instance)[:batch_size]</span><br><span class="line">            X_batch, y_batch = mnist.train.images[indices], mnist.train.labels[indices]</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        accuracy_val = accuracy.eval(feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        sys.stdout.flush()</span><br><span class="line">        print(<span class="string">"\r&#123;&#125;"</span>.format(epoch), <span class="string">"Traing accuracy:"</span>, accuracy_val, end=<span class="string">""</span>)</span><br><span class="line">        saver.save(sess, <span class="string">"autoencoder/my_model_supervised.ckpt"</span>)</span><br><span class="line">        accuracy_val = accuracy.eval(feed_dict=&#123;X: mnist.test.images, y: mnist.test.labels&#125;)</span><br><span class="line">        print(<span class="string">"Test accuracy:"</span>, accuracy_val)</span><br></pre></td></tr></table></figure><pre><code>0 Traing accuracy: 0.94Test accuracy: 0.92471 Traing accuracy: 0.97333336Test accuracy: 0.93282 Traing accuracy: 0.9866667Test accuracy: 0.94063 Traing accuracy: 0.98Test accuracy: 0.9423</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">4</span></span><br><span class="line">batch_size = <span class="number">150</span></span><br><span class="line">n_labeled_instance = <span class="number">2000</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    pretrain_saver.restore(sess, <span class="string">"autoencoder/my_model_supervised.ckpt"</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        n_batches = n_labeled_instance // batch_size</span><br><span class="line">        <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_batches):</span><br><span class="line">            print(<span class="string">"\r&#123;&#125;%"</span>.format(<span class="number">100</span> * iteration // n_batches), end=<span class="string">""</span>)</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line">            indices = rnd.permutation(n_labeled_instance)[:batch_size]</span><br><span class="line">            X_batch, y_batch = mnist.train.images[indices], mnist.train.labels[indices]</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        accuracy_val = accuracy.eval(feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        sys.stdout.flush()</span><br><span class="line">        print(<span class="string">"\r&#123;&#125;"</span>.format(epoch), <span class="string">"Traing accuracy:"</span>, accuracy_val, end=<span class="string">""</span>)</span><br><span class="line">        saver.save(sess, <span class="string">"autoencoder/my_model_supervised.ckpt"</span>)</span><br><span class="line">        accuracy_val = accuracy.eval(feed_dict=&#123;X: mnist.test.images, y: mnist.test.labels&#125;)</span><br><span class="line">        print(<span class="string">"Test accuracy:"</span>, accuracy_val)</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from autoencoder/my_model_supervised.ckpt0 Traing accuracy: 0.9533333Test accuracy: 0.88571 Traing accuracy: 0.9866667Test accuracy: 0.9292 Traing accuracy: 1.0Test accuracy: 0.9363 Traing accuracy: 1.0Test accuracy: 0.9339</code></pre><h1 id="Denoising-Autoencoders"><a href="#Denoising-Autoencoders" class="headerlink" title="Denoising Autoencoders"></a>Denoising Autoencoders</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line">n_hidden2 = <span class="number">150</span></span><br><span class="line">n_hidden3 = n_hidden1</span><br><span class="line">n_outputs = n_inputs</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">noise_level = <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, n_inputs])</span><br><span class="line">X_noisy = X + noise_level * tf.random_normal(tf.shape(X))</span><br><span class="line"></span><br><span class="line">hidden1 = tf.layers.dense(X_noisy, n_hidden1, activation=tf.nn.elu,</span><br><span class="line">                         name=<span class="string">"hidden1"</span>)</span><br><span class="line">hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.elu,</span><br><span class="line">                         name=<span class="string">"hidden2"</span>)</span><br><span class="line">hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.elu,</span><br><span class="line">                         name=<span class="string">"hidden3"</span>)</span><br><span class="line">outputs = tf.layers.dense(hidden3, n_outputs, name=<span class="string">"outputs"</span>)</span><br><span class="line"></span><br><span class="line">reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate)</span><br><span class="line">training_op = optimizer.minimize(reconstruction_loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">150</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        n_batches = mnist.train.num_examples // batch_size</span><br><span class="line">        <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_batches):</span><br><span class="line">            print(<span class="string">"\r&#123;&#125;%"</span>.format(<span class="number">100</span> * iteration // n_batches), end=<span class="string">""</span>)</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line">            X_batch, y_batch = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch&#125;)</span><br><span class="line">        loss_train = reconstruction_loss.eval(feed_dict=&#123;X: X_batch&#125;)</span><br><span class="line">        sys.stdout.flush()</span><br><span class="line">        print(<span class="string">"\r&#123;&#125;"</span>.format(epoch), <span class="string">"Train MSE:"</span>, loss_train)</span><br><span class="line">        saver.save(sess, <span class="string">"autoencoder/my_model_stacked_denosing_gaussian.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>0 Train MSE: 0.0441556951 Train MSE: 0.0414786042 Train MSE: 0.04023053 Train MSE: 0.038675444 Train MSE: 0.0367054645 Train MSE: 0.0354459026 Train MSE: 0.035014537 Train MSE: 0.036786438 Train MSE: 0.27451529 Train MSE: 0.09069635</code></pre><h2 id="使用dropout"><a href="#使用dropout" class="headerlink" title="使用dropout"></a>使用dropout</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line">n_hidden2 = <span class="number">150</span></span><br><span class="line">n_hidden3 = n_hidden1</span><br><span class="line">n_outputs = n_inputs</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">dropout_rate = <span class="number">0.3</span></span><br><span class="line"></span><br><span class="line">training = tf.placeholder_with_default(<span class="keyword">False</span>, shape=(), name=<span class="string">"training"</span>)</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_inputs])</span><br><span class="line">X_drop = tf.layers.dropout(X, dropout_rate, training=training)</span><br><span class="line"></span><br><span class="line">hidden1 = tf.layers.dense(X_drop, n_hidden1, activation=tf.nn.relu,</span><br><span class="line">                         name=<span class="string">"hidden1"</span>)</span><br><span class="line">hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,</span><br><span class="line">                         name=<span class="string">"hidden2"</span>)</span><br><span class="line">hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu,</span><br><span class="line">                         name=<span class="string">"hidden3"</span>)</span><br><span class="line">outputs = tf.layers.dense(hidden3, n_outputs, name=<span class="string">"outputs"</span>)</span><br><span class="line"></span><br><span class="line">reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">training_op = optimizer.minimize(reconstruction_loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">150</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        n_batches = mnist.train.num_examples // batch_size</span><br><span class="line">        <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_batches):</span><br><span class="line">            print(<span class="string">"\r&#123;&#125;%"</span>.format(<span class="number">100</span> * iteration // n_batches), end=<span class="string">""</span>)</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line">            X_batch, y_batch  = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, training:<span class="keyword">True</span>&#125;)</span><br><span class="line">        loss_train = reconstruction_loss.eval(feed_dict=&#123;X: X_batch&#125;)</span><br><span class="line">        sys.stdout.flush()</span><br><span class="line">        print(<span class="string">"\r&#123;&#125;"</span>.format(epoch), <span class="string">"Train MSE:"</span>, loss_train)</span><br><span class="line">        saver.save(sess, <span class="string">"autoencoder/my_model_stacked_denoising_dropout.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>0 Train MSE: 0.0323652851 Train MSE: 0.0280171732 Train MSE: 0.0270888773 Train MSE: 0.0272952044 Train MSE: 0.0248700275 Train MSE: 0.0264654236 Train MSE: 0.0251754847 Train MSE: 0.0268614668 Train MSE: 0.0237117659 Train MSE: 0.026963389</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show_reconstruction_digits(X, outputs, <span class="string">"autoencoder/my_model_stacked_denoising_dropout.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from autoencoder/my_model_stacked_denoising_dropout.ckpt</code></pre><p><img src="/2019/01/03/Autoencoder/Autoencoder_52_1.png" alt="png"></p><h1 id="Sparse-Autoencoder"><a href="#Sparse-Autoencoder" class="headerlink" title="Sparse Autoencoder"></a>Sparse Autoencoder</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">p = <span class="number">0.1</span></span><br><span class="line">q = np.linspace(<span class="number">0.001</span>, <span class="number">0.999</span>, <span class="number">500</span>)</span><br><span class="line">kl_div = p * np.log(p / q) + (<span class="number">1</span> - p) * np.log((<span class="number">1</span>-p) / (<span class="number">1</span> - q))</span><br><span class="line">mse = (p - q) ** <span class="number">2</span></span><br><span class="line">plt.plot([p, p], [<span class="number">0</span>, <span class="number">0.3</span>], <span class="string">"k:"</span>)</span><br><span class="line">plt.text(<span class="number">0.05</span>, <span class="number">0.32</span>, <span class="string">"Target\nsparsity"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.plot(q, kl_div, <span class="string">"b-"</span>, label=<span class="string">"KL divergence"</span>)</span><br><span class="line">plt.plot(q, mse, <span class="string">"r--"</span>, label=<span class="string">"MSE"</span>)</span><br><span class="line">plt.legend(loc=<span class="string">"upper left"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Actual sparsity"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Cost"</span>, rotation=<span class="number">0</span>)</span><br><span class="line">plt.axis([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0.95</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2019/01/03/Autoencoder/Autoencoder_54_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">1000</span></span><br><span class="line">n_outputs = n_inputs</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kl_divergence</span><span class="params">(p, q)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> p * tf.log(p / q) + (<span class="number">1</span> - p) * tf.log((<span class="number">1</span> - p) / (<span class="number">1</span> - q))</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">sparsity_target = <span class="number">0.1</span></span><br><span class="line">sparsity_weight = <span class="number">0.2</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, n_inputs])</span><br><span class="line"></span><br><span class="line">hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.sigmoid)</span><br><span class="line">outputs = tf.layers.dense(hidden1, n_outputs)</span><br><span class="line"></span><br><span class="line">hidden1_mean = tf.reduce_mean(hidden1, axis=<span class="number">0</span>)</span><br><span class="line">sparsity_loss = tf.reduce_sum(kl_divergence(sparsity_target, hidden1_mean))</span><br><span class="line">reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))</span><br><span class="line">loss = reconstruction_loss + sparsity_weight * sparsity_loss</span><br><span class="line"></span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate)</span><br><span class="line">training_op = optimizer.minimize(loss)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">30</span></span><br><span class="line">batch_size = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        n_batches = mnist.train.num_examples // batch_size</span><br><span class="line">        <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_batches):</span><br><span class="line">            print(<span class="string">"\r&#123;&#125;%"</span>.format(<span class="number">100</span> * iteration // n_batches), end=<span class="string">""</span>)</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line">            X_batch, y_batch = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch&#125;)</span><br><span class="line">        reconstruction_loss_val, sparsity_loss_val, loss_val = sess.run(</span><br><span class="line">            [reconstruction_loss, sparsity_loss, loss],</span><br><span class="line">            feed_dict=&#123;X: X_batch&#125;</span><br><span class="line">        )</span><br><span class="line">        sys.stdout.flush()</span><br><span class="line">        print(<span class="string">"\r&#123;&#125;"</span>.format(epoch), <span class="string">"Train MSE:"</span>, reconstruction_loss_val,</span><br><span class="line">              <span class="string">"\t Sparsity loss:"</span>, sparsity_loss_val,</span><br><span class="line">              <span class="string">"\tTotal loss:"</span>, loss_val)</span><br><span class="line">        saver.save(sess, <span class="string">"autoencoder/my_model_sparse.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>0 Train MSE: 0.13597836      Sparsity loss: 0.34833914     Total loss: 0.205646191 Train MSE: 0.05859924      Sparsity loss: 0.010568377     Total loss: 0.0607129152 Train MSE: 0.05301216      Sparsity loss: 0.0274893     Total loss: 0.058510023 Train MSE: 0.048152912      Sparsity loss: 0.02638663     Total loss: 0.0534302374 Train MSE: 0.04519025      Sparsity loss: 0.028350491     Total loss: 0.0508603455 Train MSE: 0.043140396      Sparsity loss: 0.015900817     Total loss: 0.046320566 Train MSE: 0.03955833      Sparsity loss: 0.06444825     Total loss: 0.052447987 Train MSE: 0.035567418      Sparsity loss: 0.03933688     Total loss: 0.0434347958 Train MSE: 0.032602772      Sparsity loss: 0.049595118     Total loss: 0.0425217979 Train MSE: 0.029823603      Sparsity loss: 0.08126265     Total loss: 0.04607613410 Train MSE: 0.027128985      Sparsity loss: 0.010442203     Total loss: 0.02921742611 Train MSE: 0.025444714      Sparsity loss: 0.16434407     Total loss: 0.05831352612 Train MSE: 0.02411371      Sparsity loss: 0.27343276     Total loss: 0.0788002613 Train MSE: 0.02250252      Sparsity loss: 0.6099131     Total loss: 0.1444851514 Train MSE: 0.02092416      Sparsity loss: 0.070890054     Total loss: 0.0351021715 Train MSE: 0.020057669      Sparsity loss: 0.08326996     Total loss: 0.03671166316 Train MSE: 0.019493314      Sparsity loss: 0.09606047     Total loss: 0.0387054117 Train MSE: 0.018581435      Sparsity loss: 0.055874564     Total loss: 0.02975634918 Train MSE: 0.017862516      Sparsity loss: 0.18050222     Total loss: 0.0539629619 Train MSE: 0.017116258      Sparsity loss: 0.2812312     Total loss: 0.073362520 Train MSE: 0.015459475      Sparsity loss: 0.10458441     Total loss: 0.03637635721 Train MSE: 0.015748186      Sparsity loss: 0.18440554     Total loss: 0.05262929222 Train MSE: 0.016706262      Sparsity loss: 0.23294647     Total loss: 0.0632955623 Train MSE: 0.01546143      Sparsity loss: 0.08982499     Total loss: 0.03342642624 Train MSE: 0.015510442      Sparsity loss: 0.050992575     Total loss: 0.02570895725 Train MSE: 0.01604331      Sparsity loss: 0.3630172     Total loss: 0.08864675526 Train MSE: 0.014945716      Sparsity loss: 0.13651599     Total loss: 0.04224891227 Train MSE: 0.014371737      Sparsity loss: 0.08159548     Total loss: 0.03069083428 Train MSE: 0.013957049      Sparsity loss: 0.042383395     Total loss: 0.02243372829 Train MSE: 0.014041565      Sparsity loss: 0.11076699     Total loss: 0.036194965</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show_reconstruction_digits(X, outputs,  <span class="string">"autoencoder/my_model_sparse.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from autoencoder/my_model_sparse.ckpt</code></pre><p><img src="/2019/01/03/Autoencoder/Autoencoder_59_1.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.sigmoid)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">logits = tf.layers.dense(hidden1, n_outputs)</span><br><span class="line">outputs = tf.nn.sigmoid(logits)</span><br><span class="line"></span><br><span class="line">xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=X, logits=logits)</span><br><span class="line">reconstruction_loss = tf.reduce_mean(xentropy)</span><br></pre></td></tr></table></figure><h1 id="Variational-Autoencoder"><a href="#Variational-Autoencoder" class="headerlink" title="Variational Autoencoder"></a>Variational Autoencoder</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">500</span></span><br><span class="line">n_hidden2 = <span class="number">500</span></span><br><span class="line">n_hidden3 = <span class="number">20</span></span><br><span class="line">n_hidden4 = n_hidden2</span><br><span class="line">n_hidden5 = n_hidden1</span><br><span class="line">n_outputs = n_inputs</span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line">initializer = tf.contrib.layers.variance_scaling_initializer()</span><br><span class="line"></span><br><span class="line">my_dense_layer = partial(</span><br><span class="line">    tf.layers.dense,</span><br><span class="line">    activation=tf.nn.elu,</span><br><span class="line">    kernel_initializer=initializer</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_inputs])</span><br><span class="line">hidden1 = my_dense_layer(X, n_hidden1)</span><br><span class="line">hidden2 = my_dense_layer(hidden1, n_hidden2)</span><br><span class="line"></span><br><span class="line">hidden3_mean = my_dense_layer(hidden2, n_hidden3, activation=<span class="keyword">None</span>)</span><br><span class="line">hidden3_sigma = my_dense_layer(hidden2, n_hidden3, activation=<span class="keyword">None</span>)</span><br><span class="line">noise = tf.random_normal(tf.shape(hidden3_sigma), dtype=tf.float32)</span><br><span class="line">hidden3 = hidden3_mean + hidden3_sigma * noise</span><br><span class="line"></span><br><span class="line">hidden4 = my_dense_layer(hidden3, n_hidden4)</span><br><span class="line">hidden5 = my_dense_layer(hidden4, n_hidden5)</span><br><span class="line">logits = my_dense_layer(hidden5, n_outputs, activation=<span class="keyword">None</span>)</span><br><span class="line">outputs = tf.sigmoid(logits)</span><br><span class="line"></span><br><span class="line">xentropy =tf.nn.sigmoid_cross_entropy_with_logits(labels=X, logits=logits)</span><br><span class="line">reconstruction_loss = tf.reduce_sum(xentropy)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">eps = <span class="number">1e-10</span></span><br><span class="line"></span><br><span class="line">latent_loss = <span class="number">0.5</span> * tf.reduce_sum(</span><br><span class="line">    tf.square(hidden3_sigma) + tf.square(hidden3_mean)</span><br><span class="line">    - <span class="number">1</span> - tf.log(eps + tf.square(hidden3_sigma))</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">loss = reconstruction_loss + latent_loss</span><br><span class="line"></span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">30</span></span><br><span class="line">batch_size = <span class="number">150</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        n_batches = mnist.train.num_examples // batch_size</span><br><span class="line">        <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_batches):</span><br><span class="line">            print(<span class="string">"\r&#123;&#125;%"</span>.format(<span class="number">100</span> * iteration // n_batches), end=<span class="string">""</span>)</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line">            X_batch, y_batch = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch&#125;)</span><br><span class="line">        loss_val, reconstruction_loss_val, latent_loss_val = sess.run(</span><br><span class="line">            [loss, reconstruction_loss, latent_loss],</span><br><span class="line">            feed_dict=&#123;X: X_batch&#125;</span><br><span class="line">        )</span><br><span class="line">        sys.stdout.flush()</span><br><span class="line">        print(<span class="string">"\r&#123;&#125;"</span>.format(epoch), <span class="string">"Train total loss:"</span>, loss_val,</span><br><span class="line">             <span class="string">"\tReconstruction loss:"</span>, reconstruction_loss_val,</span><br><span class="line">             <span class="string">"\tLatent loss:"</span>, latent_loss_val)</span><br><span class="line">        saver.save(sess, <span class="string">"autoencoder/my_mode_variational.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>0 Train total loss: 28618.115     Reconstruction loss: 24168.121     Latent loss: 4449.99461 Train total loss: 30913.555     Reconstruction loss: 24000.023     Latent loss: 6913.53032 Train total loss: 29388.672     Reconstruction loss: 23002.838     Latent loss: 6385.8343 Train total loss: 24904.79     Reconstruction loss: 21492.559     Latent loss: 3412.22954 Train total loss: 23107.95     Reconstruction loss: 19479.098     Latent loss: 3628.85165 Train total loss: 20817.688     Reconstruction loss: 18077.043     Latent loss: 2740.64556 Train total loss: 18226.535     Reconstruction loss: 15215.681     Latent loss: 3010.8557 Train total loss: 18172.998     Reconstruction loss: 15165.561     Latent loss: 3007.4388 Train total loss: 16930.88     Reconstruction loss: 13802.411     Latent loss: 3128.47059 Train total loss: 16704.396     Reconstruction loss: 13389.804     Latent loss: 3314.593310 Train total loss: 16542.025     Reconstruction loss: 13393.953     Latent loss: 3148.071811 Train total loss: 16166.852     Reconstruction loss: 12910.099     Latent loss: 3256.75312 Train total loss: 16105.586     Reconstruction loss: 12837.162     Latent loss: 3268.423313 Train total loss: 16308.055     Reconstruction loss: 12895.441     Latent loss: 3412.613314 Train total loss: 16188.68     Reconstruction loss: 12905.858     Latent loss: 3282.821515 Train total loss: 15944.889     Reconstruction loss: 12597.764     Latent loss: 3347.124516 Train total loss: 16157.871     Reconstruction loss: 12752.218     Latent loss: 3405.652817 Train total loss: 16119.484     Reconstruction loss: 12944.701     Latent loss: 3174.783218 Train total loss: 16498.84     Reconstruction loss: 13098.1875     Latent loss: 3400.652319 Train total loss: 16263.916     Reconstruction loss: 12844.331     Latent loss: 3419.584720 Train total loss: 15123.937     Reconstruction loss: 11745.332     Latent loss: 3378.604521 Train total loss: 15629.256     Reconstruction loss: 12185.464     Latent loss: 3443.791522 Train total loss: 15720.427     Reconstruction loss: 12303.7295     Latent loss: 3416.697323 Train total loss: 16194.514     Reconstruction loss: 12576.848     Latent loss: 3617.665524 Train total loss: 33406.54     Reconstruction loss: 21884.143     Latent loss: 11522.395525 Train total loss: 31271.346     Reconstruction loss: 24857.89     Latent loss: 6413.455626 Train total loss: 27312.076     Reconstruction loss: 23121.59     Latent loss: 4190.48627 Train total loss: 32417.924     Reconstruction loss: 23142.03     Latent loss: 9275.89528 Train total loss: 19135.332     Reconstruction loss: 15877.373     Latent loss: 3257.959729 Train total loss: 17062.746     Reconstruction loss: 13949.103     Latent loss: 3113.644</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">500</span></span><br><span class="line">n_hidden2 = <span class="number">500</span></span><br><span class="line">n_hidden3 = <span class="number">20</span></span><br><span class="line">n_hidden4 = n_hidden2</span><br><span class="line">n_hidden5 = n_hidden1</span><br><span class="line">n_outputs = n_inputs</span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line">initializer = tf.contrib.layers.variance_scaling_initializer()</span><br><span class="line">my_dense_layer = partial(</span><br><span class="line">    tf.layers.dense,</span><br><span class="line">    activation=tf.nn.elu,</span><br><span class="line">    kernel_initializer=initializer</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_inputs])</span><br><span class="line">hidden1 = my_dense_layer(X, n_hidden1)</span><br><span class="line">hidden2 = my_dense_layer(hidden1, n_hidden2)</span><br><span class="line">hidden3_mean = my_dense_layer(hidden2, n_hidden3, activation=<span class="keyword">None</span>)</span><br><span class="line">hidden3_gamma = my_dense_layer(hidden2, n_hidden3, activation=<span class="keyword">None</span>)</span><br><span class="line">noise = tf.random_normal(tf.shape(hidden3_gamma), dtype=tf.float32)</span><br><span class="line">hidden3 = hidden3_mean + tf.exp(<span class="number">0.5</span> * hidden3_gamma) * noise</span><br><span class="line">hidden4 = my_dense_layer(hidden3, n_hidden4)</span><br><span class="line">hidden5 = my_dense_layer(hidden4, n_hidden5)</span><br><span class="line">logits = my_dense_layer(hidden5, n_outputs, activation=<span class="keyword">None</span>)</span><br><span class="line">outputs = tf.sigmoid(logits)</span><br><span class="line"></span><br><span class="line">xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=X, logits=logits)</span><br><span class="line">reconstruction_loss = tf.reduce_sum(xentropy)</span><br><span class="line">latent_loss = <span class="number">0.5</span> * tf.reduce_sum(</span><br><span class="line">    tf.exp(hidden3_gamma) + tf.square(hidden3_mean) - <span class="number">1</span> - hidden3_gamma</span><br><span class="line">)</span><br><span class="line">loss = reconstruction_loss + latent_loss</span><br><span class="line"></span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><h2 id="生成数字"><a href="#生成数字" class="headerlink" title="生成数字"></a>生成数字</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">n_digits = <span class="number">60</span></span><br><span class="line">n_epochs = <span class="number">50</span></span><br><span class="line">batch_size = <span class="number">150</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        n_batches = mnist.train.num_examples // batch_size</span><br><span class="line">        <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_batches):</span><br><span class="line">            print(<span class="string">"\r&#123;&#125;%"</span>.format(<span class="number">100</span> * iteration // n_batches), end=<span class="string">""</span>)</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line">            X_batch, y_batch = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch&#125;)</span><br><span class="line">        loss_val, reconstruction_loss_val, latent_loss_val = sess.run(</span><br><span class="line">            [loss, reconstruction_loss, latent_loss],</span><br><span class="line">            feed_dict=&#123;X: X_batch&#125;</span><br><span class="line">        )</span><br><span class="line">        sys.stdout.flush()</span><br><span class="line">        print(<span class="string">"\r&#123;&#125;"</span>.format(epoch), <span class="string">"Train total loss:"</span>, loss_val,</span><br><span class="line">             <span class="string">"\tReconstruction loss:"</span>, reconstruction_loss_val,</span><br><span class="line">             <span class="string">"\tLatent loss:"</span>, latent_loss_val)</span><br><span class="line">        saver.save(sess, <span class="string">"autoencoder/my_mode_variational.ckpt"</span>)</span><br><span class="line"></span><br><span class="line">    codings_rnd = np.random.normal(size=[n_digits, n_hidden3])</span><br><span class="line">    outputs_val = outputs.eval(feed_dict=&#123;hidden3: codings_rnd&#125;)</span><br></pre></td></tr></table></figure><pre><code>0 Train total loss: 17901.604     Reconstruction loss: 14327.854     Latent loss: 3573.751 Train total loss: 17533.953     Reconstruction loss: 13797.998     Latent loss: 3735.95562 Train total loss: 17169.412     Reconstruction loss: 13212.218     Latent loss: 3957.19483 Train total loss: 16717.809     Reconstruction loss: 12906.914     Latent loss: 3810.8954 Train total loss: 16044.961     Reconstruction loss: 12291.742     Latent loss: 3753.21835 Train total loss: 15961.359     Reconstruction loss: 12190.328     Latent loss: 3771.0316 Train total loss: 15915.147     Reconstruction loss: 12045.509     Latent loss: 3869.63877 Train total loss: 16101.495     Reconstruction loss: 12314.455     Latent loss: 3787.048 Train total loss: 16155.182     Reconstruction loss: 12248.786     Latent loss: 3906.3959 Train total loss: 15280.502     Reconstruction loss: 11493.895     Latent loss: 3786.607210 Train total loss: 15289.568     Reconstruction loss: 11527.297     Latent loss: 3762.27211 Train total loss: 15314.567     Reconstruction loss: 11661.371     Latent loss: 3653.196512 Train total loss: 16085.252     Reconstruction loss: 12162.346     Latent loss: 3922.905813 Train total loss: 15621.995     Reconstruction loss: 11872.033     Latent loss: 3749.961714 Train total loss: 15449.285     Reconstruction loss: 11592.572     Latent loss: 3856.712415 Train total loss: 15287.921     Reconstruction loss: 11499.002     Latent loss: 3788.919216 Train total loss: 15538.403     Reconstruction loss: 11705.019     Latent loss: 3833.384817 Train total loss: 15225.552     Reconstruction loss: 11402.747     Latent loss: 3822.804718 Train total loss: 15403.612     Reconstruction loss: 11579.656     Latent loss: 3823.95619 Train total loss: 15133.092     Reconstruction loss: 11382.73     Latent loss: 3750.36120 Train total loss: 14997.918     Reconstruction loss: 11217.044     Latent loss: 3780.873821 Train total loss: 14820.831     Reconstruction loss: 11080.611     Latent loss: 3740.2222 Train total loss: 15386.146     Reconstruction loss: 11490.824     Latent loss: 3895.321823 Train total loss: 15093.336     Reconstruction loss: 11351.523     Latent loss: 3741.81324 Train total loss: 14981.201     Reconstruction loss: 11242.91     Latent loss: 3738.290525 Train total loss: 15472.315     Reconstruction loss: 11591.695     Latent loss: 3880.6226 Train total loss: 15147.291     Reconstruction loss: 11353.133     Latent loss: 3794.157727 Train total loss: 14945.247     Reconstruction loss: 11207.519     Latent loss: 3737.728528 Train total loss: 15122.988     Reconstruction loss: 11392.824     Latent loss: 3730.163629 Train total loss: 14832.348     Reconstruction loss: 11220.064     Latent loss: 3612.283430 Train total loss: 14930.701     Reconstruction loss: 11258.225     Latent loss: 3672.476631 Train total loss: 14597.051     Reconstruction loss: 10906.106     Latent loss: 3690.94432 Train total loss: 14825.398     Reconstruction loss: 11091.76     Latent loss: 3733.638433 Train total loss: 15294.322     Reconstruction loss: 11642.213     Latent loss: 3652.109434 Train total loss: 15126.83     Reconstruction loss: 11404.553     Latent loss: 3722.277835 Train total loss: 15034.021     Reconstruction loss: 11319.728     Latent loss: 3714.294436 Train total loss: 14350.993     Reconstruction loss: 10798.258     Latent loss: 3552.73537 Train total loss: 14759.768     Reconstruction loss: 11103.823     Latent loss: 3655.943838 Train total loss: 14463.07     Reconstruction loss: 10842.15     Latent loss: 3620.9239 Train total loss: 15347.902     Reconstruction loss: 11575.847     Latent loss: 3772.055440 Train total loss: 14960.492     Reconstruction loss: 11185.019     Latent loss: 3775.473141 Train total loss: 14601.76     Reconstruction loss: 10891.197     Latent loss: 3710.56342 Train total loss: 15046.1045     Reconstruction loss: 11385.711     Latent loss: 3660.393643 Train total loss: 15596.535     Reconstruction loss: 11777.922     Latent loss: 3818.613844 Train total loss: 15113.572     Reconstruction loss: 11316.323     Latent loss: 3797.24945 Train total loss: 14451.59     Reconstruction loss: 10892.8955     Latent loss: 3558.694646 Train total loss: 14933.413     Reconstruction loss: 11258.839     Latent loss: 3674.574547 Train total loss: 15393.2705     Reconstruction loss: 11576.03     Latent loss: 3817.240248 Train total loss: 15296.997     Reconstruction loss: 11525.246     Latent loss: 3771.75149 Train total loss: 14890.031     Reconstruction loss: 11069.418     Latent loss: 3820.6135</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">50</span>))</span><br><span class="line"><span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_digits):</span><br><span class="line">    plt.subplot(n_digits, <span class="number">10</span>, iteration + <span class="number">1</span>)</span><br><span class="line">    plot_image(outputs_val[iteration])</span><br></pre></td></tr></table></figure><p><img src="/2019/01/03/Autoencoder/Autoencoder_70_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">latent_loss = <span class="number">0.5</span> * tf.reduce_sum(tf.exp(hidden3_gamma) + tf.square(hidden3_mean) - <span class="number">1</span> - hidden3_gamma )</span><br></pre></td></tr></table></figure><h1 id="Encode-amp-Decode"><a href="#Encode-amp-Decode" class="headerlink" title="Encode &amp; Decode"></a>Encode &amp; Decode</h1><h2 id="Encode"><a href="#Encode" class="headerlink" title="Encode"></a>Encode</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">n_digits = <span class="number">3</span></span><br><span class="line">X_test, y_test = mnist.train.next_batch(batch_size)</span><br><span class="line">codings = hidden3</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, <span class="string">"autoencoder/my_mode_variational.ckpt"</span>)</span><br><span class="line">    codings_val = codings.eval(feed_dict=&#123;X: X_test&#125;)</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from autoencoder/my_mode_variational.ckpt</code></pre><h2 id="Decode"><a href="#Decode" class="headerlink" title="Decode"></a>Decode</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, <span class="string">"autoencoder/my_mode_variational.ckpt"</span>)</span><br><span class="line">    outputs_val = outputs.eval(feed_dict=&#123;codings: codings_val&#125;)</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from autoencoder/my_mode_variational.ckpt</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">2.5</span> * n_digits))</span><br><span class="line"><span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_digits):</span><br><span class="line">    plt.subplot(n_digits, <span class="number">2</span>, <span class="number">1</span> + <span class="number">2</span> * iteration )</span><br><span class="line">    plot_image(X_test[iteration])</span><br><span class="line">    plt.subplot(n_digits, <span class="number">2</span>, <span class="number">2</span> + <span class="number">2</span> * iteration)</span><br><span class="line">    plot_image(outputs_val[iteration])</span><br></pre></td></tr></table></figure><p><img src="/2019/01/03/Autoencoder/Autoencoder_77_0.png" alt="png"></p><h2 id="Interpolate-digits"><a href="#Interpolate-digits" class="headerlink" title="Interpolate digits"></a>Interpolate digits</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">n_iterations  = <span class="number">3</span></span><br><span class="line">n_digits = <span class="number">6</span></span><br><span class="line">codings_rnd = np.random.normal(size=[n_digits, n_hidden3])</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, <span class="string">"autoencoder/my_mode_variational.ckpt"</span>)</span><br><span class="line">    target_codings = np.roll(codings_rnd, <span class="number">-1</span>, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_iterations + <span class="number">1</span>):</span><br><span class="line">        codings_interpolate = codings_rnd + (target_codings - codings_rnd) * iteration / n_iterations</span><br><span class="line">        outputs_val = outputs.eval(feed_dict=&#123;codings: codings_interpolate&#125;)</span><br><span class="line">        plt.figure(figsize=(<span class="number">11</span>, <span class="number">1.5</span>*n_iterations))</span><br><span class="line">        <span class="keyword">for</span> digit_index <span class="keyword">in</span> range(n_digits):</span><br><span class="line">            plt.subplot(<span class="number">1</span>, n_digits, digit_index + <span class="number">1</span>)</span><br><span class="line">            plot_image(outputs_val[digit_index])</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from autoencoder/my_mode_variational.ckpt</code></pre><p><img src="/2019/01/03/Autoencoder/Autoencoder_79_1.png" alt="png"></p><p><img src="/2019/01/03/Autoencoder/Autoencoder_79_2.png" alt="png"></p><p><img src="/2019/01/03/Autoencoder/Autoencoder_79_3.png" alt="png"></p><p><img src="/2019/01/03/Autoencoder/Autoencoder_79_4.png" alt="png"></p><hr><p><a href="https://github.com/coldJune/machineLearning/blob/master/handson-ml/Autoencoder.ipynb" target="_blank" rel="noopener">源文件</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;hr&gt;
&lt;h1 id=&quot;准备&quot;&gt;&lt;a href=&quot;#准备&quot; class=&quot;headerlink&quot; title=&quot;准备&quot;&gt;&lt;/a&gt;准备&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;
      
    
    </summary>
    
      <category term="机器学习" scheme="http://coldjune.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow" scheme="http://coldjune.com/tags/tensorflow/"/>
    
      <category term="Hands-On Machine Learning with Scikit-Learn and TensorFlow" scheme="http://coldjune.com/tags/Hands-On-Machine-Learning-with-Scikit-Learn-and-TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>Recurrent Neural Networks</title>
    <link href="http://coldjune.com/2018/12/28/Recurrent-Neural-Networks/"/>
    <id>http://coldjune.com/2018/12/28/Recurrent-Neural-Networks/</id>
    <published>2018-12-28T07:43:28.000Z</published>
    <updated>2019-05-17T14:32:54.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reset_graph</span><span class="params">(seed=<span class="number">42</span>)</span>:</span></span><br><span class="line">    tf.reset_default_graph()</span><br><span class="line">    tf.set_random_seed(seed)</span><br><span class="line">    np.random.seed(seed)</span><br></pre></td></tr></table></figure><h1 id="RNN基础"><a href="#RNN基础" class="headerlink" title="RNN基础"></a>RNN基础</h1><h2 id="手动实现RNN"><a href="#手动实现RNN" class="headerlink" title="手动实现RNN"></a>手动实现RNN</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">3</span></span><br><span class="line">n_neurons = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">X0 = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_inputs])</span><br><span class="line">X1 = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_inputs])</span><br><span class="line"></span><br><span class="line">Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons], dtype=tf.float32))</span><br><span class="line">Wy = tf.Variable(tf.random_normal(shape=[n_neurons, n_neurons], dtype=tf.float32))</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">1</span>, n_neurons], dtype=tf.float32))</span><br><span class="line"></span><br><span class="line">Y0 = tf.tanh(tf.matmul(X0, Wx) + b)</span><br><span class="line">Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">X0_batch = np.array([</span><br><span class="line">    [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">    [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">    [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">    [<span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">])<span class="comment"># t=0</span></span><br><span class="line">X1_batch = np.array([</span><br><span class="line">    [<span class="number">9</span>, <span class="number">8</span>, <span class="number">7</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span>],</span><br><span class="line">    [<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">])<span class="comment"># t=1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict=&#123;X0: X0_batch, X1: X1_batch&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(Y0_val)</span><br></pre></td></tr></table></figure><pre><code>[[-0.0664006   0.9625767   0.68105793  0.7091854  -0.898216  ] [ 0.9977755  -0.719789   -0.9965761   0.9673924  -0.9998972 ] [ 0.99999774 -0.99898803 -0.9999989   0.9967762  -0.9999999 ] [ 1.         -1.         -1.         -0.99818915  0.9995087 ]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(Y1_val)</span><br></pre></td></tr></table></figure><pre><code>[[ 1.         -1.         -1.          0.4020025  -0.9999998 ] [-0.12210419  0.62805265  0.9671843  -0.9937122  -0.2583937 ] [ 0.9999983  -0.9999994  -0.9999975  -0.85943305 -0.9999881 ] [ 0.99928284 -0.99999815 -0.9999058   0.9857963  -0.92205757]]</code></pre><h2 id="使用static-rnn"><a href="#使用static-rnn" class="headerlink" title="使用static_rnn()"></a>使用static_rnn()</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">n_inputs = <span class="number">3</span></span><br><span class="line">n_neurons = <span class="number">5</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">X0 = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_inputs])</span><br><span class="line">X1 = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_inputs])</span><br><span class="line"></span><br><span class="line">basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)</span><br><span class="line">out_put_seqs, states = tf.nn.static_rnn(basic_cell, [X0, X1], dtype=tf.float32)</span><br><span class="line">Y0, Y1 = out_put_seqs</span><br></pre></td></tr></table></figure><pre><code>WARNING:tensorflow:From &lt;ipython-input-7-64acfd881dc3&gt;:6: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.Instructions for updating:This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">X0_batch = np.array([</span><br><span class="line">    [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">    [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">    [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">    [<span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">])<span class="comment"># t=0</span></span><br><span class="line">X1_batch = np.array([</span><br><span class="line">    [<span class="number">9</span>, <span class="number">8</span>, <span class="number">7</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span>],</span><br><span class="line">    [<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">])<span class="comment"># t=1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict=&#123;X0: X0_batch, X1: X1_batch&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Y0_val</span><br></pre></td></tr></table></figure><pre><code>array([[ 0.30741334, -0.32884315, -0.6542847 , -0.9385059 ,  0.52089024],       [ 0.99122757, -0.9542541 , -0.7518079 , -0.9995208 ,  0.9820235 ],       [ 0.9999268 , -0.99783254, -0.8247353 , -0.9999963 ,  0.99947774],       [ 0.996771  , -0.68750614,  0.8419969 ,  0.9303911 ,  0.8120684 ]],      dtype=float32)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Y1_val</span><br></pre></td></tr></table></figure><pre><code>array([[ 0.99998885, -0.99976057, -0.0667929 , -0.9999803 ,  0.99982214],       [-0.6524943 , -0.51520866, -0.37968948, -0.5922594 , -0.08968379],       [ 0.99862397, -0.99715203, -0.03308626, -0.9991566 ,  0.9932902 ],       [ 0.99681675, -0.9598194 ,  0.39660627, -0.8307606 ,  0.79671973]],      dtype=float32)</code></pre><h2 id="打包序列"><a href="#打包序列" class="headerlink" title="打包序列"></a>打包序列</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">n_steps = <span class="number">2</span></span><br><span class="line">n_inputs = <span class="number">3</span></span><br><span class="line">n_neurons = <span class="number">5</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_steps, n_inputs])</span><br><span class="line">X_seqs = tf.unstack(tf.transpose(X, perm=[<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>]))</span><br><span class="line"></span><br><span class="line">basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)</span><br><span class="line">out_put_seqs, states = tf.nn.static_rnn(basic_cell, X_seqs, dtype=tf.float32)</span><br><span class="line">outputs = tf.transpose(tf.stack(out_put_seqs), perm=[<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">X_batch = np.array([</span><br><span class="line">    [[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">9</span>, <span class="number">8</span>, <span class="number">7</span>]],</span><br><span class="line">    [[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]],</span><br><span class="line">    [[<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span>]],</span><br><span class="line">    [[<span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>], [<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]],</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    outputs_val = outputs.eval(feed_dict=&#123;X: X_batch&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(outputs_val)</span><br></pre></td></tr></table></figure><pre><code>[[[-0.45652324 -0.68064123  0.40938237  0.63104504 -0.45732826]  [-0.9428799  -0.9998869   0.94055814  0.9999985  -0.9999997 ]] [[-0.8001535  -0.9921827   0.7817797   0.9971032  -0.9964609 ]  [-0.637116    0.11300927  0.5798437   0.4310559  -0.6371699 ]] [[-0.93605185 -0.9998379   0.9308867   0.9999815  -0.99998295]  [-0.9165386  -0.9945604   0.896054    0.99987197 -0.9999751 ]] [[ 0.9927369  -0.9981933  -0.55543643  0.9989031  -0.9953323 ]  [-0.02746338 -0.73191994  0.7827872   0.9525682  -0.9781773 ]]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(np.transpose(outputs_val, axes=[<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>])[<span class="number">1</span>])</span><br></pre></td></tr></table></figure><pre><code>[[-0.9428799  -0.9998869   0.94055814  0.9999985  -0.9999997 ] [-0.637116    0.11300927  0.5798437   0.4310559  -0.6371699 ] [-0.9165386  -0.9945604   0.896054    0.99987197 -0.9999751 ] [-0.02746338 -0.73191994  0.7827872   0.9525682  -0.9781773 ]]</code></pre><h2 id="使用dynamic-rnn"><a href="#使用dynamic-rnn" class="headerlink" title="使用dynamic_rnn()"></a>使用dynamic_rnn()</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">n_steps = <span class="number">2</span></span><br><span class="line">n_inputs = <span class="number">3</span></span><br><span class="line">n_neurons = <span class="number">5</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_steps, n_inputs])</span><br><span class="line"></span><br><span class="line">basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)</span><br><span class="line">outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">X_batch = np.array([</span><br><span class="line">    [[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">9</span>, <span class="number">8</span>, <span class="number">7</span>]],</span><br><span class="line">    [[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]],</span><br><span class="line">    [[<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span>]],</span><br><span class="line">    [[<span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>], [<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]],</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    outputs_val = outputs.eval(feed_dict=&#123;X: X_batch&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(outputs_val)</span><br></pre></td></tr></table></figure><pre><code>[[[-0.85115266  0.87358344  0.5802911   0.8954789  -0.0557505 ]  [-0.999996    0.99999577  0.9981815   1.          0.37679607]] [[-0.9983293   0.9992038   0.98071456  0.999985    0.25192663]  [-0.7081804  -0.0772338  -0.85227895  0.5845349  -0.78780943]] [[-0.9999827   0.99999535  0.9992863   1.          0.5159072 ]  [-0.9993956   0.9984095   0.83422637  0.99999976 -0.47325212]] [[ 0.87888587  0.07356028  0.97216916  0.9998546  -0.7351168 ]  [-0.9134514   0.3600957   0.7624866   0.99817705  0.80142   ]]]</code></pre><h2 id="设置序列长度"><a href="#设置序列长度" class="headerlink" title="设置序列长度"></a>设置序列长度</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">n_steps = <span class="number">2</span></span><br><span class="line">n_inputs = <span class="number">3</span></span><br><span class="line">n_neurons = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_steps, n_inputs])</span><br><span class="line">basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">seq_length = tf.placeholder(tf.int32, [<span class="keyword">None</span>])</span><br><span class="line">outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32, sequence_length=seq_length)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X_batch = np.array([</span><br><span class="line">    [[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">9</span>, <span class="number">8</span>, <span class="number">7</span>]],</span><br><span class="line">    [[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]],</span><br><span class="line">    [[<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span>]],</span><br><span class="line">    [[<span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>], [<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]],</span><br><span class="line">])</span><br><span class="line">seq_length_batch = np.array([<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    outputs_val, states_val = sess.run(</span><br><span class="line">        [outputs, states], feed_dict=&#123;X: X_batch, seq_length: seq_length_batch&#125;</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(outputs_val)</span><br></pre></td></tr></table></figure><pre><code>[[[-0.9123188   0.16516446  0.5548655  -0.39159346  0.20846416]  [-1.          0.956726    0.99831694  0.99970174  0.96518576]] [[-0.9998612   0.6702289   0.9723653   0.6631046   0.74457586]  [ 0.          0.          0.          0.          0.        ]] [[-0.99999976  0.8967997   0.9986295   0.9647514   0.93662   ]  [-0.9999526   0.9681953   0.96002865  0.98706263  0.85459226]] [[-0.96435434  0.99501586 -0.36150697  0.9983378   0.999497  ]  [-0.9613586   0.9568762   0.7132288   0.97729224 -0.0958299 ]]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(states_val)</span><br></pre></td></tr></table></figure><pre><code>[[-1.          0.956726    0.99831694  0.99970174  0.96518576] [-0.9998612   0.6702289   0.9723653   0.6631046   0.74457586] [-0.9999526   0.9681953   0.96002865  0.98706263  0.85459226] [-0.9613586   0.9568762   0.7132288   0.97729224 -0.0958299 ]]</code></pre><h2 id="训练序列分类器"><a href="#训练序列分类器" class="headerlink" title="训练序列分类器"></a>训练序列分类器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_steps = <span class="number">28</span></span><br><span class="line">n_inputs = <span class="number">28</span></span><br><span class="line">n_neurons = <span class="number">150</span></span><br><span class="line">n_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_steps, n_inputs])</span><br><span class="line">y = tf.placeholder(tf.int32, [<span class="keyword">None</span>])</span><br><span class="line"></span><br><span class="line">basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)</span><br><span class="line">outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">logits = tf.layers.dense(states, n_outputs)</span><br><span class="line">xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line"></span><br><span class="line">loss = tf.reduce_mean(xentropy)</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">training_op = optimizer.minimize(loss)</span><br><span class="line">correct = tf.nn.in_top_k(logits, y, <span class="number">1</span>)</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()</span><br><span class="line">X_train = X_train.astype(np.float32).reshape(<span class="number">-1</span>, <span class="number">28</span>*<span class="number">28</span>) / <span class="number">255.0</span></span><br><span class="line">X_test = X_test.astype(np.float32).reshape(<span class="number">-1</span>, <span class="number">28</span>*<span class="number">28</span>) / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">y_train = y_train.astype(np.int32)</span><br><span class="line">y_test = y_test.astype(np.int32)</span><br><span class="line"></span><br><span class="line">X_valid, X_train = X_train[:<span class="number">5000</span>], X_train[<span class="number">5000</span>:]</span><br><span class="line">y_valid, y_train = y_train[:<span class="number">5000</span>], y_train[<span class="number">5000</span>:]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shuffle_batch</span><span class="params">(X, y, batch_size)</span>:</span></span><br><span class="line">    rnd_idx = np.random.permutation(len(X))</span><br><span class="line">    n_batches = len(X) // batch_size</span><br><span class="line">    <span class="keyword">for</span> batch_idx <span class="keyword">in</span> np.array_split(rnd_idx, n_batches):</span><br><span class="line">        X_batch, y_batch = X[batch_idx], y[batch_idx]</span><br><span class="line">        <span class="keyword">yield</span> X_batch, y_batch</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_test = X_test.reshape((<span class="number">-1</span>, n_steps, n_inputs))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">30</span></span><br><span class="line">batch_size = <span class="number">150</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> shuffle_batch(X_train, y_train, batch_size):</span><br><span class="line">            X_batch = X_batch.reshape(<span class="number">-1</span>, n_steps, n_inputs)</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        acc_batch = accuracy.eval(feed_dict=&#123;X: X_batch, y:y_batch&#125;)</span><br><span class="line">        acc_test = accuracy.eval(feed_dict=&#123;X: X_test, y: y_test&#125;)</span><br><span class="line">        print(epoch, <span class="string">"Last batch accuracy:"</span>, acc_batch, <span class="string">"Test accuracy:"</span>, acc_test)</span><br></pre></td></tr></table></figure><pre><code>0 Last batch accuracy: 0.9533333 Test accuracy: 0.92881 Last batch accuracy: 0.96 Test accuracy: 0.94712 Last batch accuracy: 0.96 Test accuracy: 0.94993 Last batch accuracy: 0.96 Test accuracy: 0.95634 Last batch accuracy: 0.98 Test accuracy: 0.96775 Last batch accuracy: 0.93333334 Test accuracy: 0.96516 Last batch accuracy: 0.98 Test accuracy: 0.96857 Last batch accuracy: 0.96666664 Test accuracy: 0.96788 Last batch accuracy: 0.97333336 Test accuracy: 0.96939 Last batch accuracy: 0.99333334 Test accuracy: 0.971410 Last batch accuracy: 0.98 Test accuracy: 0.975211 Last batch accuracy: 0.9866667 Test accuracy: 0.974312 Last batch accuracy: 0.94666666 Test accuracy: 0.971613 Last batch accuracy: 0.97333336 Test accuracy: 0.965814 Last batch accuracy: 1.0 Test accuracy: 0.977215 Last batch accuracy: 0.98 Test accuracy: 0.97416 Last batch accuracy: 0.99333334 Test accuracy: 0.977917 Last batch accuracy: 0.9866667 Test accuracy: 0.977518 Last batch accuracy: 0.9866667 Test accuracy: 0.971319 Last batch accuracy: 0.98 Test accuracy: 0.972420 Last batch accuracy: 0.9866667 Test accuracy: 0.970221 Last batch accuracy: 0.98 Test accuracy: 0.975822 Last batch accuracy: 0.98 Test accuracy: 0.978223 Last batch accuracy: 0.99333334 Test accuracy: 0.977824 Last batch accuracy: 0.9866667 Test accuracy: 0.974525 Last batch accuracy: 0.9866667 Test accuracy: 0.974126 Last batch accuracy: 0.9866667 Test accuracy: 0.978427 Last batch accuracy: 1.0 Test accuracy: 0.980828 Last batch accuracy: 0.99333334 Test accuracy: 0.978729 Last batch accuracy: 0.98 Test accuracy: 0.9813</code></pre><h2 id="多层RNN"><a href="#多层RNN" class="headerlink" title="多层RNN"></a>多层RNN</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line">n_steps = <span class="number">28</span></span><br><span class="line">n_inputs = <span class="number">28</span></span><br><span class="line">n_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_steps, n_inputs])</span><br><span class="line">y = tf.placeholder(tf.int32, [<span class="keyword">None</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">n_neurons = <span class="number">100</span></span><br><span class="line">n_layers = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">layers = [tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons,</span><br><span class="line">                                     activation=tf.nn.relu)</span><br><span class="line">         <span class="keyword">for</span> layer <span class="keyword">in</span> range(n_layers)]</span><br><span class="line">multi_layer_cell = tf.nn.rnn_cell.MultiRNNCell(layers)</span><br><span class="line">outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">states_concat = tf.concat(axis=<span class="number">1</span>, values=states)</span><br><span class="line">logits = tf.layers.dense(states_concat, n_outputs)</span><br><span class="line">xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">loss = tf.reduce_mean(xentropy)</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">training_op = optimizer.minimize(loss)</span><br><span class="line">correct = tf.nn.in_top_k(logits, y, <span class="number">1</span>)</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">150</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> shuffle_batch(X_train, y_train, batch_size):</span><br><span class="line">            X_batch = X_batch.reshape((<span class="number">-1</span>, n_steps, n_inputs))</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        acc_batch = accuracy.eval(feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        acc_test = accuracy.eval(feed_dict=&#123;X: X_test, y: y_test&#125;)</span><br><span class="line">        print(epoch, <span class="string">"Last batch accuracy:"</span>, acc_batch, <span class="string">"Test accuracy:"</span>, acc_test)</span><br><span class="line">file_writer = tf.summary.FileWriter(<span class="string">'rnn/multiRNN'</span>, tf.get_default_graph())</span><br></pre></td></tr></table></figure><pre><code>0 Last batch accuracy: 0.94 Test accuracy: 0.93181 Last batch accuracy: 0.96 Test accuracy: 0.95632 Last batch accuracy: 0.96 Test accuracy: 0.97093 Last batch accuracy: 0.9866667 Test accuracy: 0.97014 Last batch accuracy: 0.9866667 Test accuracy: 0.97735 Last batch accuracy: 0.9533333 Test accuracy: 0.97476 Last batch accuracy: 0.99333334 Test accuracy: 0.97637 Last batch accuracy: 0.9866667 Test accuracy: 0.98048 Last batch accuracy: 0.98 Test accuracy: 0.97559 Last batch accuracy: 0.96666664 Test accuracy: 0.9804</code></pre><h2 id="时间序列"><a href="#时间序列" class="headerlink" title="时间序列"></a>时间序列</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">t_min, t_max = <span class="number">0</span>, <span class="number">30</span></span><br><span class="line">resolution = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">time_series</span><span class="params">(t)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> t * np.sin(t) / <span class="number">3</span> + <span class="number">2</span> * np.sin(t*<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">next_batch</span><span class="params">(batch_size, n_steps)</span>:</span></span><br><span class="line">    t0 = np.random.rand(batch_size, <span class="number">1</span>) * (t_max - t_min - n_steps * resolution)</span><br><span class="line">    Ts = t0 + np.arange(<span class="number">0</span>, n_steps + <span class="number">1</span>) * resolution</span><br><span class="line">    ys = time_series(Ts)</span><br><span class="line">    <span class="keyword">return</span> ys[:, :<span class="number">-1</span>].reshape(<span class="number">-1</span>, n_steps, <span class="number">1</span>), ys[:, <span class="number">1</span>:].reshape(<span class="number">-1</span>, n_steps, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">t = np.linspace(t_min, t_max, int((t_max - t_min) / resolution))</span><br><span class="line"></span><br><span class="line">n_steps = <span class="number">20</span></span><br><span class="line">t_instance = np.linspace(<span class="number">12.2</span>, <span class="number">12.2</span> + resolution * (n_steps + <span class="number">1</span>), n_steps + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">11</span>, <span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line">plt.title(<span class="string">"A time series (generated)"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.plot(t, time_series(t), label=<span class="string">r"$ t. \sin(t)/3 + 2 . \sin(5t)$"</span>)</span><br><span class="line">plt.plot(t_instance[:<span class="number">-1</span>], time_series(t_instance[:<span class="number">-1</span>]),</span><br><span class="line">                                      <span class="string">"b-"</span>, linewidth=<span class="number">3</span>, label=<span class="string">"A training instance"</span>)</span><br><span class="line">plt.legend(loc=<span class="string">"lower left"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.axis([<span class="number">0</span>, <span class="number">30</span>, <span class="number">-17</span>, <span class="number">13</span>])</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Value"</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line">plt.title(<span class="string">"A training instance"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.plot(t_instance[:<span class="number">-1</span>], time_series(t_instance[:<span class="number">-1</span>]), <span class="string">"bo"</span>, markersize=<span class="number">10</span>, label=<span class="string">"instance"</span>)</span><br><span class="line">plt.plot(t_instance[<span class="number">1</span>:], time_series(t_instance[<span class="number">1</span>:]), <span class="string">"w*"</span>, markersize=<span class="number">10</span>, label=<span class="string">"target"</span>)</span><br><span class="line">plt.legend(loc=<span class="string">"upper left"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/28/Recurrent-Neural-Networks/Recurrent%20Neural%20Networks_49_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_batch, y_batch = next_batch(<span class="number">1</span>, n_steps)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.c_[X_batch[<span class="number">0</span>], y_batch[<span class="number">0</span>]]</span><br></pre></td></tr></table></figure><pre><code>array([[ 1.38452097,  2.05081182],       [ 2.05081182,  2.29742291],       [ 2.29742291,  2.0465599 ],       [ 2.0465599 ,  1.34009916],       [ 1.34009916,  0.32948704],       [ 0.32948704, -0.76115235],       [-0.76115235, -1.68967022],       [-1.68967022, -2.25492776],       [-2.25492776, -2.34576159],       [-2.34576159, -1.96789418],       [-1.96789418, -1.24220428],       [-1.24220428, -0.37478448],       [-0.37478448,  0.39387907],       [ 0.39387907,  0.84815766],       [ 0.84815766,  0.85045064],       [ 0.85045064,  0.3752526 ],       [ 0.3752526 , -0.48422846],       [-0.48422846, -1.53852738],       [-1.53852738, -2.54795941],       [-2.54795941, -3.28097239]])</code></pre><h3 id="使用OutputProjectionWrapper"><a href="#使用OutputProjectionWrapper" class="headerlink" title="使用OutputProjectionWrapper"></a>使用OutputProjectionWrapper</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_steps = <span class="number">20</span></span><br><span class="line">n_inputs = <span class="number">1</span></span><br><span class="line">n_neurons = <span class="number">100</span></span><br><span class="line">n_outputs = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_steps, n_inputs])</span><br><span class="line">y = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_steps, n_outputs])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cell = tf.contrib.rnn.OutputProjectionWrapper(</span><br><span class="line">    tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu),</span><br><span class="line">    output_size=n_outputs</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line">loss = tf.reduce_mean(tf.square(outputs -y))</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">n_iterations = <span class="number">1500</span></span><br><span class="line">batch_size = <span class="number">50</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_iterations):</span><br><span class="line">        X_batch, y_batch = next_batch(batch_size, n_steps)</span><br><span class="line">        sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        <span class="keyword">if</span> iteration % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            mse = loss.eval(feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">            print(iteration, <span class="string">"\tMSE:"</span>, mse)</span><br><span class="line"></span><br><span class="line">    saver.save(sess, <span class="string">"rnn/my_time_series_model"</span>)</span><br></pre></td></tr></table></figure><pre><code>0     MSE: 11.967254100     MSE: 0.525841200     MSE: 0.1495599300     MSE: 0.07279411400     MSE: 0.06158535500     MSE: 0.05938873600     MSE: 0.05470166700     MSE: 0.047849063800     MSE: 0.05107608900     MSE: 0.0472091961000     MSE: 0.0470583141100     MSE: 0.0478314651200     MSE: 0.040830411300     MSE: 0.0470868051400     MSE: 0.041784383</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, <span class="string">"rnn/my_time_series_model"</span>)</span><br><span class="line"></span><br><span class="line">    X_new = time_series(np.array(t_instance[:<span class="number">-1</span>].reshape(<span class="number">-1</span>, n_steps, n_inputs)))</span><br><span class="line">    y_pred = sess.run(outputs, feed_dict=&#123;X: X_new&#125;)</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from rnn/my_time_series_model</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred</span><br></pre></td></tr></table></figure><pre><code>array([[[-3.407753 ],        [-2.4575484],        [-1.1029298],        [ 0.7815629],        [ 2.2002175],        [ 3.126768 ],        [ 3.4037762],        [ 3.3489153],        [ 2.8798013],        [ 2.2659323],        [ 1.6447463],        [ 1.5210768],        [ 1.8972012],        [ 2.7159088],        [ 3.8894904],        [ 5.140914 ],        [ 6.142068 ],        [ 6.666671 ],        [ 6.6410103],        [ 6.0725527]]], dtype=float32)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">"Testing the model"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.plot(t_instance[:<span class="number">-1</span>], time_series(t_instance[:<span class="number">-1</span>]),</span><br><span class="line">         <span class="string">"bo"</span>, markersize=<span class="number">10</span>, label=<span class="string">"instance"</span>)</span><br><span class="line">plt.plot(t_instance[<span class="number">1</span>:], time_series(t_instance[<span class="number">1</span>:]),</span><br><span class="line">        <span class="string">"w*"</span>, markersize=<span class="number">10</span>, label=<span class="string">"target"</span>)</span><br><span class="line">plt.plot(t_instance[<span class="number">1</span>:], y_pred[<span class="number">0</span>, :, <span class="number">0</span>], <span class="string">"r."</span>,</span><br><span class="line">        markersize=<span class="number">10</span>, label=<span class="string">"prediction"</span>)</span><br><span class="line">plt.legend(loc=<span class="string">"upper left"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/28/Recurrent-Neural-Networks/Recurrent%20Neural%20Networks_61_0.png" alt="png"></p><h3 id="不使用OutputProjectionWrapper"><a href="#不使用OutputProjectionWrapper" class="headerlink" title="不使用OutputProjectionWrapper()"></a>不使用OutputProjectionWrapper()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_steps = <span class="number">20</span></span><br><span class="line">n_inputs = <span class="number">1</span></span><br><span class="line">n_neurons = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_steps, n_inputs])</span><br><span class="line">y = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_steps, n_outputs])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu)</span><br><span class="line">rnn_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">n_outputs = <span class="number">1</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">stacked_rnn_outputs = tf.reshape(rnn_outputs, [<span class="number">-1</span>, n_neurons])</span><br><span class="line">stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)</span><br><span class="line">outputs = tf.reshape(stacked_outputs, [<span class="number">-1</span>, n_steps, n_outputs])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss = tf.reduce_mean(tf.square(outputs - y))</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">n_iterations = <span class="number">1500</span></span><br><span class="line">batch_size = <span class="number">50</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_iterations):</span><br><span class="line">        X_batch, y_batch = next_batch(batch_size, n_steps)</span><br><span class="line">        sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        <span class="keyword">if</span> iteration % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            mse = loss.eval(feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">            print(iteration, <span class="string">"\tMSE:"</span>, mse)</span><br><span class="line"></span><br><span class="line">    X_new  = time_series(np.array(t_instance[:<span class="number">-1</span>].reshape(<span class="number">-1</span>, n_steps, n_inputs)))</span><br><span class="line">    y_pred = sess.run(outputs, feed_dict=&#123;X: X_new&#125;)</span><br><span class="line">    saver.save(sess, <span class="string">"rnn/my_time_series_model"</span>)</span><br></pre></td></tr></table></figure><pre><code>0     MSE: 13.907029100     MSE: 0.5056698200     MSE: 0.19735886300     MSE: 0.101214476400     MSE: 0.06850145500     MSE: 0.06291986600     MSE: 0.055129297700     MSE: 0.049436502800     MSE: 0.050434686900     MSE: 0.04820071000     MSE: 0.048098681100     MSE: 0.049825011200     MSE: 0.0419125451300     MSE: 0.0492929781400     MSE: 0.043140374</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred</span><br></pre></td></tr></table></figure><pre><code>array([[[-3.4332483],        [-2.4594698],        [-1.1081185],        [ 0.6882153],        [ 2.1105688],        [ 3.0585155],        [ 3.5144088],        [ 3.3531117],        [ 2.808016 ],        [ 2.1606152],        [ 1.662645 ],        [ 1.5578941],        [ 1.9173537],        [ 2.7210245],        [ 3.8667865],        [ 5.100083 ],        [ 6.099999 ],        [ 6.6480975],        [ 6.6147423],        [ 6.022089 ]]], dtype=float32)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">"Testing the model"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.plot(t_instance[:<span class="number">-1</span>], time_series(t_instance[:<span class="number">-1</span>]),</span><br><span class="line">         <span class="string">"bo"</span>, markersize=<span class="number">10</span>, label=<span class="string">"instance"</span>)</span><br><span class="line">plt.plot(t_instance[<span class="number">1</span>:], time_series(t_instance[<span class="number">1</span>:]),</span><br><span class="line">        <span class="string">"w*"</span>, markersize=<span class="number">10</span>, label=<span class="string">"target"</span>)</span><br><span class="line">plt.plot(t_instance[<span class="number">1</span>:], y_pred[<span class="number">0</span>, :, <span class="number">0</span>], <span class="string">"r."</span>,</span><br><span class="line">        markersize=<span class="number">10</span>, label=<span class="string">"prediction"</span>)</span><br><span class="line">plt.legend(loc=<span class="string">"upper left"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/28/Recurrent-Neural-Networks/Recurrent%20Neural%20Networks_70_0.png" alt="png"></p><h2 id="生成一个创造性的序列"><a href="#生成一个创造性的序列" class="headerlink" title="生成一个创造性的序列"></a>生成一个创造性的序列</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, <span class="string">"rnn/my_time_series_model"</span>)</span><br><span class="line"></span><br><span class="line">    sequence = [<span class="number">0.</span>] * n_steps</span><br><span class="line">    <span class="keyword">for</span> iteration <span class="keyword">in</span> range(<span class="number">300</span>):</span><br><span class="line">        X_batch = np.array(sequence[-n_steps:]).reshape(<span class="number">1</span>, n_steps, <span class="number">1</span>)</span><br><span class="line">        y_pred = sess.run(outputs, feed_dict=&#123;X: X_batch&#125;)</span><br><span class="line">        sequence.append(y_pred[<span class="number">0</span>, <span class="number">-1</span>, <span class="number">0</span>])</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from rnn/my_time_series_model</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">4</span>))</span><br><span class="line">plt.plot(np.arange(len(sequence)), sequence, <span class="string">"b-"</span>)</span><br><span class="line">plt.plot(t[:n_steps], sequence[:n_steps], <span class="string">"b--"</span>, linewidth=<span class="number">3</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Value"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/28/Recurrent-Neural-Networks/Recurrent%20Neural%20Networks_73_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, <span class="string">"rnn/my_time_series_model"</span>)</span><br><span class="line"></span><br><span class="line">    sequence1 = [<span class="number">0.</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(n_steps)]</span><br><span class="line">    <span class="keyword">for</span> iteration <span class="keyword">in</span> range(len(t) - n_steps):</span><br><span class="line">        X_batch = np.array(sequence1[-n_steps:]).reshape(<span class="number">1</span>, n_steps, <span class="number">1</span>)</span><br><span class="line">        y_pred = sess.run(outputs, feed_dict=&#123;X: X_batch&#125;)</span><br><span class="line">        sequence1.append(y_pred[<span class="number">0</span>, <span class="number">-1</span>, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    sequence2 = [time_series(i * resolution + t_min + (t_max - t_min/<span class="number">3</span>))</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> range(n_steps)]</span><br><span class="line">    <span class="keyword">for</span> iteration <span class="keyword">in</span> range(len(t) - n_steps):</span><br><span class="line">        X_batch = np.array(sequence2[-n_steps:]).reshape(<span class="number">1</span>, n_steps, <span class="number">1</span>)</span><br><span class="line">        y_pred = sess.run(outputs, feed_dict=&#123;X: X_batch&#125;)</span><br><span class="line">        sequence2.append(y_pred[<span class="number">0</span>, <span class="number">-1</span>, <span class="number">0</span>])</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from rnn/my_time_series_model</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">11</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line">plt.plot(t, sequence1, <span class="string">"b-"</span>)</span><br><span class="line">plt.plot(t[:n_steps], sequence1[:n_steps], <span class="string">"b-"</span>, linewidth=<span class="number">3</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Value"</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line">plt.plot(t, sequence2, <span class="string">"b-"</span>)</span><br><span class="line">plt.plot(t[:n_steps], sequence2[:n_steps], <span class="string">"b-"</span>, linewidth=<span class="number">3</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/28/Recurrent-Neural-Networks/Recurrent%20Neural%20Networks_75_0.png" alt="png"></p><h1 id="Deep-RNN"><a href="#Deep-RNN" class="headerlink" title="Deep RNN"></a>Deep RNN</h1><h2 id="MultiRNNCell"><a href="#MultiRNNCell" class="headerlink" title="MultiRNNCell"></a>MultiRNNCell</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">2</span></span><br><span class="line">n_steps = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_steps, n_inputs])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">n_neurons = <span class="number">100</span></span><br><span class="line">n_layers = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">layers = [tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)</span><br><span class="line">         <span class="keyword">for</span> layer <span class="keyword">in</span> range(n_layers)]</span><br><span class="line"></span><br><span class="line">multi_layer_cell = tf.nn.rnn_cell.MultiRNNCell(layers)</span><br><span class="line">outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_batch = np.random.rand(<span class="number">2</span>, n_steps, n_inputs)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    outputs_val, states_val = sess.run([outputs, states], feed_dict=&#123;X: X_batch&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">outputs_val.shape</span><br></pre></td></tr></table></figure><pre><code>(2, 5, 100)</code></pre><h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">1</span></span><br><span class="line">n_neurons = <span class="number">100</span></span><br><span class="line">n_layers = <span class="number">3</span></span><br><span class="line">n_steps = <span class="number">20</span></span><br><span class="line">n_outputs = <span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_steps, n_inputs])</span><br><span class="line">y = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_steps, n_outputs])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">keep_prob = tf.placeholder_with_default(<span class="number">1.0</span>, shape=())</span><br><span class="line">cells = [tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)</span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> range(n_layers)]</span><br><span class="line">cells_drop = [tf.nn.rnn_cell.DropoutWrapper(cell, input_keep_prob=keep_prob)</span><br><span class="line">             <span class="keyword">for</span> cell <span class="keyword">in</span> cells]</span><br><span class="line">multi_layer_cell = tf.nn.rnn_cell.MultiRNNCell(cells_drop)</span><br><span class="line">rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">stacked_rnn_outputs = tf.reshape(rnn_outputs, [<span class="number">-1</span>, n_neurons])</span><br><span class="line">stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)</span><br><span class="line">outputs = tf.reshape(stacked_outputs, [<span class="number">-1</span>, n_steps, n_outputs])</span><br><span class="line"></span><br><span class="line">loss = tf.reduce_mean(tf.square(outputs - y))</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">n_iterations = <span class="number">1500</span></span><br><span class="line">batch_size = <span class="number">50</span></span><br><span class="line">train_keep_prob = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> iteration <span class="keyword">in</span> range(n_iterations):</span><br><span class="line">        X_batch, y_batch = next_batch(batch_size, n_steps)</span><br><span class="line">        _, mse = sess.run([training_op, loss],</span><br><span class="line">                          feed_dict=&#123;</span><br><span class="line">                              X: X_batch,</span><br><span class="line">                              y: y_batch,</span><br><span class="line">                              keep_prob: train_keep_prob</span><br><span class="line">                          &#125;)</span><br><span class="line">        <span class="keyword">if</span> iteration % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            print(iteration, <span class="string">"Training MSE:"</span>, mse)</span><br><span class="line">    saver.save(sess,<span class="string">"rnn/my_dropout_time_series_model"</span>)</span><br></pre></td></tr></table></figure><pre><code>0 Training MSE: 16.10992100 Training MSE: 4.2036242200 Training MSE: 3.7243023300 Training MSE: 3.8051453400 Training MSE: 3.1154072500 Training MSE: 3.4736195600 Training MSE: 3.4444861700 Training MSE: 3.3598778800 Training MSE: 4.1624136900 Training MSE: 4.2632991000 Training MSE: 3.50788331100 Training MSE: 4.20513151200 Training MSE: 2.74437481300 Training MSE: 4.5834991400 Training MSE: 5.121917</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, <span class="string">"rnn/my_dropout_time_series_model"</span>)</span><br><span class="line"></span><br><span class="line">    X_new  = time_series(np.array(t_instance[:<span class="number">-1</span>].reshape(<span class="number">-1</span>, n_steps, n_inputs)))</span><br><span class="line">    y_pred = sess.run(outputs, feed_dict=&#123;X: X_new&#125;)</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from rnn/my_dropout_time_series_model</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">"Testing the model"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.plot(t_instance[:<span class="number">-1</span>], time_series(t_instance[:<span class="number">-1</span>]),</span><br><span class="line">         <span class="string">"bo"</span>, markersize=<span class="number">10</span>, label=<span class="string">"instance"</span>)</span><br><span class="line">plt.plot(t_instance[<span class="number">1</span>:], time_series(t_instance[<span class="number">1</span>:]),</span><br><span class="line">        <span class="string">"w*"</span>, markersize=<span class="number">10</span>, label=<span class="string">"target"</span>)</span><br><span class="line">plt.plot(t_instance[<span class="number">1</span>:], y_pred[<span class="number">0</span>, :, <span class="number">0</span>], <span class="string">"r."</span>,</span><br><span class="line">        markersize=<span class="number">10</span>, label=<span class="string">"prediction"</span>)</span><br><span class="line">plt.legend(loc=<span class="string">"upper left"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Time"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/28/Recurrent-Neural-Networks/Recurrent%20Neural%20Networks_91_0.png" alt="png"></p><h1 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">lstm_cell = tf.nn.rnn_cell.LSTMCell(name=<span class="string">"basic_lstm_cell"</span>,</span><br><span class="line">                                   num_units=n_neurons)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">n_steps = <span class="number">28</span></span><br><span class="line">n_inputs = <span class="number">28</span></span><br><span class="line">n_neurons = <span class="number">150</span></span><br><span class="line">n_outputs = <span class="number">10</span></span><br><span class="line">n_layers = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_steps, n_inputs])</span><br><span class="line">y = tf.placeholder(tf.int32, [<span class="keyword">None</span>])</span><br><span class="line"></span><br><span class="line">lstm_cells = [tf.nn.rnn_cell.LSTMCell(num_units=n_neurons, name=<span class="string">"basic_lstm_cell"</span>)</span><br><span class="line">             <span class="keyword">for</span> layer <span class="keyword">in</span> range(n_layers)]</span><br><span class="line">multi_cell = tf.nn.rnn_cell.MultiRNNCell(lstm_cells)</span><br><span class="line">outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)</span><br><span class="line">top_layer_h_state = states[<span class="number">-1</span>][<span class="number">1</span>]</span><br><span class="line">logits = tf.layers.dense(top_layer_h_state, n_outputs, name=<span class="string">"softmax"</span>)</span><br><span class="line">xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">loss = tf.reduce_mean(xentropy, name=<span class="string">"loss"</span>)</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">training_op = optimizer.minimize(loss)</span><br><span class="line">correct = tf.nn.in_top_k(logits, y, <span class="number">1</span>)</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">states</span><br></pre></td></tr></table></figure><pre><code>(LSTMStateTuple(c=&lt;tf.Tensor &#39;rnn/while/Exit_3:0&#39; shape=(?, 150) dtype=float32&gt;, h=&lt;tf.Tensor &#39;rnn/while/Exit_4:0&#39; shape=(?, 150) dtype=float32&gt;), LSTMStateTuple(c=&lt;tf.Tensor &#39;rnn/while/Exit_5:0&#39; shape=(?, 150) dtype=float32&gt;, h=&lt;tf.Tensor &#39;rnn/while/Exit_6:0&#39; shape=(?, 150) dtype=float32&gt;), LSTMStateTuple(c=&lt;tf.Tensor &#39;rnn/while/Exit_7:0&#39; shape=(?, 150) dtype=float32&gt;, h=&lt;tf.Tensor &#39;rnn/while/Exit_8:0&#39; shape=(?, 150) dtype=float32&gt;))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top_layer_h_state</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor &#39;rnn/while/Exit_8:0&#39; shape=(?, 150) dtype=float32&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">150</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> shuffle_batch(X_train, y_train, batch_size):</span><br><span class="line">            X_batch = X_batch.reshape((<span class="number">-1</span>, n_steps, n_inputs))</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        acc_batch = accuracy.eval(feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        acc_test = accuracy.eval(feed_dict=&#123;X: X_test, y: y_test&#125;)</span><br><span class="line">        print(epoch, <span class="string">"Last batch accuracy:"</span>, acc_batch, <span class="string">"Test accuracy:"</span>, acc_test)</span><br></pre></td></tr></table></figure><pre><code>0 Last batch accuracy: 0.9533333 Test accuracy: 0.94811 Last batch accuracy: 0.96 Test accuracy: 0.96992 Last batch accuracy: 0.96 Test accuracy: 0.96393 Last batch accuracy: 1.0 Test accuracy: 0.98084 Last batch accuracy: 0.9866667 Test accuracy: 0.98265 Last batch accuracy: 1.0 Test accuracy: 0.9866 Last batch accuracy: 1.0 Test accuracy: 0.98727 Last batch accuracy: 0.99333334 Test accuracy: 0.98828 Last batch accuracy: 1.0 Test accuracy: 0.98379 Last batch accuracy: 0.99333334 Test accuracy: 0.9883</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units=n_neurons, use_peepholes=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gru_cell = tf.nn.rnn_cell.GRUCell(num_units=n_neurons)</span><br></pre></td></tr></table></figure><h1 id="嵌入向量"><a href="#嵌入向量" class="headerlink" title="嵌入向量"></a>嵌入向量</h1><h2 id="获取数据"><a href="#获取数据" class="headerlink" title="获取数据"></a>获取数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> six.moves <span class="keyword">import</span> urllib</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> errno</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"></span><br><span class="line">WORDS_PATH = <span class="string">"datasets/words"</span></span><br><span class="line">WORDS_URL = <span class="string">"http://mattmahoney.net/dc/text8.zip"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mkdir_p</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        os.makedirs(path=path)</span><br><span class="line">    <span class="keyword">except</span> OSError <span class="keyword">as</span> exc:</span><br><span class="line">        <span class="keyword">if</span> esc.errno == errno.EEXIST <span class="keyword">and</span> os.path.isdir(path):</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetch_words_data</span><span class="params">(words_rul=WORDS_URL, words_path=WORDS_PATH)</span>:</span></span><br><span class="line">    os.makedirs(words_path, exist_ok=<span class="keyword">True</span>)</span><br><span class="line">    zip_path = os.path.join(words_path, <span class="string">"words.zip"</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(zip_path):</span><br><span class="line">        urllib.request.urlretrieve(words_rul, zip_path)</span><br><span class="line">    <span class="keyword">with</span> zipfile.ZipFile(zip_path) <span class="keyword">as</span> f:</span><br><span class="line">        data = f.read(f.namelist()[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">return</span> data.decode(<span class="string">"ascii"</span>).split()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">words = fetch_words_data()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">words[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><pre><code>[&#39;anarchism&#39;, &#39;originated&#39;, &#39;as&#39;, &#39;a&#39;, &#39;term&#39;]</code></pre><h2 id="建立字典"><a href="#建立字典" class="headerlink" title="建立字典"></a>建立字典</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line">vocabulary_size = <span class="number">50000</span></span><br><span class="line"></span><br><span class="line">vocabulary = [(<span class="string">"UNK"</span>, <span class="keyword">None</span>)] + Counter(words).most_common(vocabulary_size - <span class="number">1</span>)</span><br><span class="line">vocabulary = np.array([word <span class="keyword">for</span> word, _ <span class="keyword">in</span> vocabulary])</span><br><span class="line">dictionary = &#123;word: code <span class="keyword">for</span> code, word <span class="keyword">in</span> enumerate(vocabulary)&#125;</span><br><span class="line">data = np.array([dictionary.get(word, <span class="number">0</span>) <span class="keyword">for</span> word <span class="keyword">in</span> words])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">" "</span>.join(words[:<span class="number">9</span>]), data[:<span class="number">9</span>]</span><br></pre></td></tr></table></figure><pre><code>(&#39;anarchism originated as a term of abuse first used&#39;, array([5234, 3081,   12,    6,  195,    2, 3134,   46,   59]))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">" "</span>.join(vocabulary[word_index]</span><br><span class="line">         <span class="keyword">for</span> word_index <span class="keyword">in</span> [<span class="number">5234</span>, <span class="number">3081</span>,   <span class="number">12</span>,    <span class="number">6</span>,  <span class="number">195</span>,    <span class="number">2</span>, <span class="number">3134</span>,   <span class="number">46</span>,   <span class="number">59</span>])</span><br></pre></td></tr></table></figure><pre><code>&#39;anarchism originated as a term of abuse first used&#39;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">words[<span class="number">24</span>], data[<span class="number">24</span>]</span><br></pre></td></tr></table></figure><pre><code>(&#39;culottes&#39;, 0)</code></pre><h2 id="Generate-batches"><a href="#Generate-batches" class="headerlink" title="Generate batches"></a>Generate batches</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_batch</span><span class="params">(batch_size, num_skips, skip_window)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> data_index</span><br><span class="line">    <span class="keyword">assert</span> batch_size % num_skips == <span class="number">0</span></span><br><span class="line">    <span class="keyword">assert</span> num_skips &lt;= <span class="number">2</span> * skip_window</span><br><span class="line">    batch = np.ndarray(shape=[batch_size], dtype=np.int32)</span><br><span class="line">    labels = np.ndarray(shape=[batch_size, <span class="number">1</span>], dtype=np.int32)</span><br><span class="line">    span = <span class="number">2</span> * skip_window + <span class="number">1</span></span><br><span class="line">    buffer = deque(maxlen=span)</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(span):</span><br><span class="line">        buffer.append(data[data_index])</span><br><span class="line">        data_index = (data_index + <span class="number">1</span>) % len(data)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(batch_size // num_skips):</span><br><span class="line">        target = skip_window</span><br><span class="line">        targets_to_avoid = [skip_window]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(num_skips):</span><br><span class="line">            <span class="keyword">while</span> target <span class="keyword">in</span> targets_to_avoid:</span><br><span class="line">                target = np.random.randint(<span class="number">0</span>, span)</span><br><span class="line">            targets_to_avoid.append(target)</span><br><span class="line">            batch[i * num_skips + j] = buffer[skip_window]</span><br><span class="line">            labels[i * num_skips + j] = buffer[target]</span><br><span class="line">        buffer.append(data[data_index])</span><br><span class="line">        data_index = (data_index + <span class="number">1</span>) % len(data)</span><br><span class="line">    <span class="keyword">return</span> batch, labels</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">42</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data_index = <span class="number">0</span></span><br><span class="line">batch, labels = generate_batch(<span class="number">8</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">batch, [vocabulary[word] <span class="keyword">for</span> word <span class="keyword">in</span> batch]</span><br></pre></td></tr></table></figure><pre><code>(array([3081, 3081,   12,   12,    6,    6,  195,  195]), [&#39;originated&#39;, &#39;originated&#39;, &#39;as&#39;, &#39;as&#39;, &#39;a&#39;, &#39;a&#39;, &#39;term&#39;, &#39;term&#39;])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">labels, [vocabulary[word] <span class="keyword">for</span> word <span class="keyword">in</span> labels[:, <span class="number">0</span>]]</span><br></pre></td></tr></table></figure><pre><code>(array([[  12],        [5234],        [   6],        [3081],        [  12],        [ 195],        [   2],        [   6]]), [&#39;as&#39;, &#39;anarchism&#39;, &#39;a&#39;, &#39;originated&#39;, &#39;as&#39;, &#39;term&#39;, &#39;of&#39;, &#39;a&#39;])</code></pre><h2 id="创建模型"><a href="#创建模型" class="headerlink" title="创建模型"></a>创建模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">embedding_size = <span class="number">128</span></span><br><span class="line">skip_window = <span class="number">1</span></span><br><span class="line">num_skips = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">valid_size = <span class="number">16</span></span><br><span class="line">valid_window = <span class="number">100</span></span><br><span class="line">valid_examples = np.random.choice(valid_window, valid_size, replace=<span class="keyword">False</span>)</span><br><span class="line">num_sampled = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">train_labels = tf.placeholder(tf.int32, shape=[batch_size, <span class="number">1</span>])</span><br><span class="line">valid_dataset = tf.constant(valid_examples, dtype=tf.int32)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vocabulary_size = <span class="number">50000</span></span><br><span class="line">embedding_size = <span class="number">150</span></span><br><span class="line"></span><br><span class="line">init_embeds = tf.random_uniform([vocabulary_size, embedding_size], <span class="number">-1.0</span>, <span class="number">1.0</span>)</span><br><span class="line">embeddings = tf.Variable(init_embeds)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_inputs = tf.placeholder(tf.int32, shape=[<span class="keyword">None</span>])</span><br><span class="line">embed = tf.nn.embedding_lookup(embeddings, train_inputs)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nce_weights = tf.Variable(</span><br><span class="line">    tf.truncated_normal([vocabulary_size, embedding_size],</span><br><span class="line">                       stddev= <span class="number">1.0</span> / np.sqrt(embedding_size))</span><br><span class="line">)</span><br><span class="line">nce_biases = tf.Variable(tf.zeros([vocabulary_size]))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">loss = tf.reduce_mean(</span><br><span class="line">    tf.nn.nce_loss(nce_weights, nce_biases, train_labels, embed,</span><br><span class="line">                  num_sampled, vocabulary_size)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">norm = tf.sqrt(tf.reduce_mean(tf.square(embeddings), axis=<span class="number">1</span>, keepdims=<span class="keyword">True</span>))</span><br><span class="line">normalized_embedding = embeddings / norm</span><br><span class="line">valid_embeddings = tf.nn.embedding_lookup(normalized_embedding, valid_dataset)</span><br><span class="line">similarity = tf.matmul(valid_embeddings, normalized_embedding, transpose_b=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">num_steps = <span class="number">10001</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line"></span><br><span class="line">    average_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(num_steps):</span><br><span class="line">        print(<span class="string">"\rIteration:&#123;&#125;"</span>.format(step), end=<span class="string">""</span>)</span><br><span class="line">        batch_inputs, batch_labels = generate_batch(batch_size,num_skips, skip_window)</span><br><span class="line">        feed_dict = &#123;train_inputs: batch_inputs, train_labels: batch_labels&#125;</span><br><span class="line"></span><br><span class="line">        _, loss_val = sess.run([training_op, loss], feed_dict=feed_dict)</span><br><span class="line">        average_loss += loss_val</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">2000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> step &gt; <span class="number">0</span>:</span><br><span class="line">                average_loss /= <span class="number">2000</span></span><br><span class="line">            print(<span class="string">"Average loss at step"</span>, step, <span class="string">":"</span>, average_loss)</span><br><span class="line">            average_loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">10000</span> == <span class="number">0</span>:</span><br><span class="line">            sim = similarity.eval()</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(valid_size):</span><br><span class="line">                valid_word = vocabulary[valid_examples[i]]</span><br><span class="line">                top_k = <span class="number">8</span></span><br><span class="line">                nearest = (-sim[i, :]).argsort()[<span class="number">1</span>: top_k+<span class="number">1</span>]</span><br><span class="line">                log_str = <span class="string">"Nearest to %s"</span> % valid_word</span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> range(top_k):</span><br><span class="line">                    close_word = vocabulary[nearest[k]]</span><br><span class="line">                    log_str = <span class="string">"%s %s,"</span> % (log_str, close_word)</span><br><span class="line">                print(log_str)</span><br><span class="line">        final_embeddings = normalized_embedding.eval()</span><br></pre></td></tr></table></figure><pre><code>Iteration:0Average loss at step 0 : 290.5275573730469Nearest to over tt, tuned, manichaeans, fractional, cambridge, balaguer, fluoride, strenuously,Nearest to one imagines, tijuana, hindrance, steadfastly, motorcyclist, lords, letting, adolfo,Nearest to were bezier, antibodies, nicknamed, panthers, compiler, tao, smarter, busy,Nearest to may failure, rna, efficacious, aspirin, lecompton, definitive, geese, amphibious,Nearest to two annihilate, bettors, wir, cindy, epinephrine, team, voluntarily, crystallize,Nearest to its knob, abeokuta, bracelet, bastards, ivens, objectivity, blanton, cold,Nearest to than lame, watts, stones, sram, elves, zarqawi, applets, cloves,Nearest to these pedro, condoned, neck, ssn, supervising, doug, thereto, melton,Nearest to they lowly, deportation, shrewd, reznor, tojo, decadent, occured, risotto,Nearest to is interests, golfers, dropouts, richards, egyptians, legionnaires, leonel, opener,Nearest to up clair, drives, steadfast, missed, nashville, kilowatts, anal, vinland,Nearest to he transitioned, winchell, resh, goldsmiths, standardised, markings, pursued, satirized,Nearest to people blissymbolics, mike, buffers, untouchables, carolingian, posted, ville, hypertalk,Nearest to more cactus, sta, reformation, poets, diligently, rsc, ravaged, nabokov,Nearest to was russo, rammed, investiture, glucagon, heck, adventurer, sharada, homing,Nearest to UNK reykjav, fi, rosalyn, mainline, archaeologist, armstrong, stevenage, ean,Iteration:2000Average loss at step 2000 : 133.45819056224823Iteration:4000Average loss at step 4000 : 62.97674214935303Iteration:6000Average loss at step 6000 : 40.385357957839965Iteration:8000Average loss at step 8000 : 31.5875605533123Iteration:10000Average loss at step 10000 : 25.615500225067137Nearest to over tikal, seal, scriptores, felony, bougainville, chapter, dubrovnik, valdemar,Nearest to one eight, nine, six, two, seven, four, three, five,Nearest to were was, logan, antlia, anaximenes, songs, by, aga, hood,Nearest to may zero, to, theism, eight, can, packing, would, creativity,Nearest to two zero, one, five, four, six, three, eight, nine,Nearest to its the, mechanisms, antipope, alcmene, alemanni, alexandra, alder, topped,Nearest to than lit, but, quantity, barbados, asmara, proxima, constructing, floors,Nearest to these nur, antipopes, floors, nightclubs, mainly, and, other, aurelianus,Nearest to they that, cain, angilbert, nine, autoerotic, alexandrovich, three, some,Nearest to is yahya, are, tt, but, was, stamp, ttt, politican,Nearest to up refrigerant, incompleteness, rensselaer, four, persistence, astor, lumped, assigned,Nearest to he campylobacter, his, but, eight, later, antigens, UNK, in,Nearest to people autoerotic, stained, trigonometry, satrap, rijndael, equality, fiesta, songs,Nearest to more less, ahmad, ski, conjectures, zyklon, physically, rarely, ah,Nearest to was became, calcite, is, were, had, asphyxiation, suffixes, nmt,Nearest to UNK and, one, the, dmt, a, bromide, ananda, tile,</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.save(<span class="string">"rnn/my_final_embeddings.npy"</span>, final_embeddings)</span><br></pre></td></tr></table></figure><h2 id="plot-the-embeddings"><a href="#plot-the-embeddings" class="headerlink" title="plot the embeddings"></a>plot the embeddings</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_with_labels</span><span class="params">(low_dim_embs, labels)</span>:</span></span><br><span class="line">    <span class="keyword">assert</span> low_dim_embs.shape[<span class="number">0</span>] &gt;= len(labels) , <span class="string">"More labels than embeddings"</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">18</span>, <span class="number">18</span>))</span><br><span class="line">    <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(labels):</span><br><span class="line">        x, y = low_dim_embs[i, :]</span><br><span class="line">        plt.scatter(x, y)</span><br><span class="line">        plt.annotate(label,</span><br><span class="line">                    xy=(x, y),</span><br><span class="line">                    xytext=(<span class="number">5</span>, <span class="number">2</span>),</span><br><span class="line">                    textcoords=<span class="string">'offset points'</span>,</span><br><span class="line">                    ha=<span class="string">'right'</span>,</span><br><span class="line">                    va=<span class="string">'bottom'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"></span><br><span class="line">tsne = TSNE(perplexity=<span class="number">30</span>, n_components=<span class="number">2</span>, init=<span class="string">"pca"</span>, n_iter=<span class="number">5000</span>)</span><br><span class="line">plot_only = <span class="number">500</span></span><br><span class="line">low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only, :])</span><br><span class="line">labels = [vocabulary[i] <span class="keyword">for</span> i <span class="keyword">in</span> range(plot_only)]</span><br><span class="line">plot_with_labels(low_dim_embs, labels)</span><br></pre></td></tr></table></figure><p><img src="/2018/12/28/Recurrent-Neural-Networks/Recurrent%20Neural%20Networks_128_0.png" alt="png"></p><h2 id="Machine-Translation"><a href="#Machine-Translation" class="headerlink" title="Machine Translation"></a>Machine Translation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_steps = <span class="number">50</span></span><br><span class="line">n_neurons = <span class="number">200</span></span><br><span class="line">n_layers = <span class="number">3</span></span><br><span class="line">num_encoder_symbols = <span class="number">20000</span></span><br><span class="line">num_decoder_symbols = <span class="number">20000</span></span><br><span class="line">embedding_size = <span class="number">150</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.int32, [<span class="keyword">None</span>, n_steps])</span><br><span class="line">Y = tf.placeholder(tf.int32, [<span class="keyword">None</span>, n_steps])</span><br><span class="line">W = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_steps - <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">Y_input = Y[:, :<span class="number">-1</span>]</span><br><span class="line">Y_target = Y[:, <span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">encoder_inputs = tf.unstack(tf.transpose(X))</span><br><span class="line">decoder_inputs = tf.unstack(tf.transpose(Y_input))</span><br><span class="line"></span><br><span class="line">lstm_cells = [tf.nn.rnn_cell.LSTMCell(num_units=n_neurons, name=<span class="string">"basic_lstm_cell"</span>)</span><br><span class="line">            <span class="keyword">for</span> layer <span class="keyword">in</span> range(n_layers)]</span><br><span class="line">cell = tf.nn.rnn_cell.MultiRNNCell(lstm_cells)</span><br><span class="line"></span><br><span class="line">outputs_seqs, states = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(</span><br><span class="line">    encoder_inputs,</span><br><span class="line">    decoder_inputs,</span><br><span class="line">    cell,</span><br><span class="line">    num_encoder_symbols,</span><br><span class="line">    num_decoder_symbols,</span><br><span class="line">    embedding_size</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">logits = tf.transpose(tf.unstack(outputs_seqs), perm=[<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">logits_flat = tf.reshape(logits, [<span class="number">-1</span>, num_decoder_symbols])</span><br><span class="line">Y_target_flat = tf.reshape(Y_target, [<span class="number">-1</span>])</span><br><span class="line">W_flat = tf.reshape(W, [<span class="number">-1</span>])</span><br><span class="line">xentropy = W_flat * tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y_target_flat,</span><br><span class="line">                                                                   logits=logits_flat)</span><br><span class="line">loss = tf.reduce_mean(xentropy)</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">traninig_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><hr><p><a href="https://github.com/coldJune/machineLearning/blob/master/handson-ml/Recurrent%20Neural%20Networks.ipynb" target="_blank" rel="noopener">源文件</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;准备&quot;&gt;&lt;a href=&quot;#准备&quot; class=&quot;headerlink&quot; title=&quot;准备&quot;&gt;&lt;/a&gt;准备&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span
      
    
    </summary>
    
      <category term="机器学习" scheme="http://coldjune.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow" scheme="http://coldjune.com/tags/tensorflow/"/>
    
      <category term="Hands-On Machine Learning with Scikit-Learn and TensorFlow" scheme="http://coldjune.com/tags/Hands-On-Machine-Learning-with-Scikit-Learn-and-TensorFlow/"/>
    
      <category term="神经网络" scheme="http://coldjune.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Convolutional Neural Networks</title>
    <link href="http://coldjune.com/2018/12/24/Convolutional-Neural-Networks/"/>
    <id>http://coldjune.com/2018/12/24/Convolutional-Neural-Networks/</id>
    <published>2018-12-24T07:59:07.000Z</published>
    <updated>2018-12-27T14:12:15.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_image</span><span class="params">(image)</span>:</span></span><br><span class="line">    plt.imshow(image, cmap=<span class="string">"gray"</span>, interpolation=<span class="string">"nearest"</span>)</span><br><span class="line">    plt.axis(<span class="string">"off"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_color_image</span><span class="params">(image)</span>:</span></span><br><span class="line">    plt.imshow(image.astype(np.uint8), interpolation=<span class="string">"nearest"</span>)</span><br><span class="line">    plt.axis(<span class="string">"off"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reset_graph</span><span class="params">(seed=<span class="number">42</span>)</span>:</span></span><br><span class="line">    tf.reset_default_graph()</span><br><span class="line">    tf.set_random_seed(seed)</span><br><span class="line">    np.random.seed(seed)</span><br></pre></td></tr></table></figure><h1 id="卷积层-Convolutional-Layer"><a href="#卷积层-Convolutional-Layer" class="headerlink" title="卷积层(Convolutional Layer)"></a>卷积层(Convolutional Layer)</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_sample_image</span><br><span class="line"></span><br><span class="line">china = load_sample_image(<span class="string">"china.jpg"</span>)</span><br><span class="line">flower = load_sample_image(<span class="string">"flower.jpg"</span>)</span><br><span class="line"></span><br><span class="line">image = china[<span class="number">150</span>:<span class="number">220</span>, <span class="number">130</span>:<span class="number">250</span>]</span><br><span class="line"></span><br><span class="line">height, width, channels = image.shape</span><br><span class="line"></span><br><span class="line">image_gray_scale = image.mean(axis=<span class="number">2</span>).astype(np.float32)</span><br><span class="line">images = image_gray_scale.reshape(<span class="number">1</span>, height, width, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fmap = np.zeros(shape=(<span class="number">7</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">2</span>), dtype=np.float32)</span><br><span class="line">fmap[:, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">fmap[<span class="number">3</span>, :, <span class="number">0</span>, <span class="number">1</span>] = <span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_image(fmap[:, :, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/24/Convolutional-Neural-Networks/Convolutional%20Neural%20Networks_6_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_image(fmap[:, :, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/24/Convolutional-Neural-Networks/Convolutional%20Neural%20Networks_7_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, height, width, <span class="number">1</span>))</span><br><span class="line">feature_maps = tf.constant(fmap)</span><br><span class="line">covolution = tf.nn.conv2d(X, feature_maps, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">"SAME"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    output = covolution.eval(feed_dict=&#123;X: images&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_image(images[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/24/Convolutional-Neural-Networks/Convolutional%20Neural%20Networks_10_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_image(output[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/24/Convolutional-Neural-Networks/Convolutional%20Neural%20Networks_11_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_image(output[<span class="number">0</span>, :, :, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/24/Convolutional-Neural-Networks/Convolutional%20Neural%20Networks_12_0.png" alt="png"></p><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_sample_images</span><br><span class="line"></span><br><span class="line">china = load_sample_image(<span class="string">"china.jpg"</span>)</span><br><span class="line">flower = load_sample_image(<span class="string">"flower.jpg"</span>)</span><br><span class="line">dataset = np.array([china, flower], dtype=np.float32)</span><br><span class="line">batch_size, height, width, channels = dataset.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建两个过滤器</span></span><br><span class="line">filters = np.zeros(shape=(<span class="number">7</span>, <span class="number">7</span>, channels, <span class="number">2</span>), dtype=np.float32)</span><br><span class="line">filters[:, <span class="number">3</span>, :, <span class="number">0</span>] = <span class="number">1</span> <span class="comment">#垂直</span></span><br><span class="line">filters[<span class="number">3</span>, :, :, <span class="number">1</span>] = <span class="number">1</span> <span class="comment">#水平</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, height, width, channels))</span><br><span class="line">convolution = tf.nn.conv2d(X, filters, strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">"SAME"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    output = sess.run(convolution, feed_dict=&#123;X: dataset&#125;)</span><br><span class="line"></span><br><span class="line">plt.imshow(output[<span class="number">0</span>, :, :, <span class="number">1</span>], cmap=<span class="string">"gray"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/24/Convolutional-Neural-Networks/Convolutional%20Neural%20Networks_14_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> image_index <span class="keyword">in</span> (<span class="number">0</span>, <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> feature_map_index <span class="keyword">in</span> (<span class="number">0</span>, <span class="number">1</span>):</span><br><span class="line">        plot_image(output[image_index, :, :, feature_map_index ])</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/24/Convolutional-Neural-Networks/Convolutional%20Neural%20Networks_15_0.png" alt="png"></p><p><img src="/2018/12/24/Convolutional-Neural-Networks/Convolutional%20Neural%20Networks_15_1.png" alt="png"></p><p><img src="/2018/12/24/Convolutional-Neural-Networks/Convolutional%20Neural%20Networks_15_2.png" alt="png"></p><p><img src="/2018/12/24/Convolutional-Neural-Networks/Convolutional%20Neural%20Networks_15_3.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(shape=(<span class="keyword">None</span>, height, width, channels), dtype=np.float32)</span><br><span class="line">conv = tf.layers.conv2d(X, filters=<span class="number">2</span>, kernel_size=<span class="number">7</span>, strides=[<span class="number">2</span>, <span class="number">2</span>], padding=<span class="string">"SAME"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    output = sess.run(conv, feed_dict=&#123;X: dataset&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(output[<span class="number">0</span>, :, :, <span class="number">1</span>], cmap=<span class="string">"gray"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/24/Convolutional-Neural-Networks/Convolutional%20Neural%20Networks_18_0.png" alt="png"></p><h2 id="VALID-和-SAME填充"><a href="#VALID-和-SAME填充" class="headerlink" title="VALID 和 SAME填充"></a>VALID 和 SAME填充</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">filter_primes = np.array([<span class="number">2.</span>, <span class="number">3.</span>, <span class="number">5.</span>, <span class="number">7.</span>, <span class="number">11.</span>, <span class="number">13.</span>], dtype=np.float32)</span><br><span class="line">x = tf.constant(np.arange(<span class="number">1</span>, <span class="number">14</span>, dtype=np.float32).reshape([<span class="number">1</span>, <span class="number">1</span>, <span class="number">13</span>, <span class="number">1</span>]))</span><br><span class="line">filters = tf.constant(filter_primes.reshape(<span class="number">1</span>, <span class="number">6</span>, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">valid_conv = tf.nn.conv2d(x, filters, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">1</span>], padding=<span class="string">"VALID"</span>)</span><br><span class="line">same_conv = tf.nn.conv2d(x, filters, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">1</span>], padding=<span class="string">"SAME"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(<span class="string">"VALID:\n"</span>, valid_conv.eval())</span><br><span class="line">    print(<span class="string">"SAME:\n"</span>, same_conv.eval())</span><br></pre></td></tr></table></figure><pre><code>VALID: [[[[184.]   [389.]]]]SAME: [[[[143.]   [348.]   [204.]]]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"VALID:"</span>)</span><br><span class="line">print(np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]).T.dot(filter_primes))</span><br><span class="line">print(np.array([<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>]).T.dot(filter_primes))</span><br><span class="line"></span><br><span class="line">print(<span class="string">"SAME:"</span>)</span><br><span class="line">print(np.array([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]).T.dot(filter_primes))</span><br><span class="line">print(np.array([<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>]).T.dot(filter_primes))</span><br><span class="line">print(np.array([<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>,<span class="number">13</span>,<span class="number">0</span>,<span class="number">0</span>]).T.dot(filter_primes))</span><br></pre></td></tr></table></figure><pre><code>VALID:184.0389.0SAME:143.0348.0204.0</code></pre><h1 id="池化层-Pooling-layer"><a href="#池化层-Pooling-layer" class="headerlink" title="池化层(Pooling layer)"></a>池化层(Pooling layer)</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">batch_size, height, width, channels = dataset.shape</span><br><span class="line"></span><br><span class="line">filters = np.zeros(shape=(<span class="number">7</span>, <span class="number">7</span>, channels, <span class="number">2</span>), dtype=np.float32)</span><br><span class="line">filters[:, <span class="number">3</span>, :, <span class="number">0</span>] = <span class="number">1</span> <span class="comment">#垂直</span></span><br><span class="line">filters[<span class="number">3</span>, :, :, <span class="number">1</span>] = <span class="number">1</span> <span class="comment">#水平</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, height, width, channels))</span><br><span class="line">max_pool = tf.nn.max_pool(X, ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>], strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>], padding=<span class="string">"VALID"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    output = sess.run(max_pool, feed_dict=&#123;X: dataset&#125;)</span><br><span class="line"></span><br><span class="line">plt.imshow(output[<span class="number">0</span>].astype(np.uint8))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/24/Convolutional-Neural-Networks/Convolutional%20Neural%20Networks_24_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_color_image(dataset[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/24/Convolutional-Neural-Networks/Convolutional%20Neural%20Networks_25_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_color_image(output[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/24/Convolutional-Neural-Networks/Convolutional%20Neural%20Networks_26_0.png" alt="png"></p><h1 id="MNIST"><a href="#MNIST" class="headerlink" title="MNIST"></a>MNIST</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line">height = <span class="number">28</span></span><br><span class="line">width = <span class="number">28</span></span><br><span class="line">channels = <span class="number">1</span></span><br><span class="line">n_inputs = height * width</span><br><span class="line"></span><br><span class="line">conv1_fmaps = <span class="number">32</span></span><br><span class="line">conv1_ksize = <span class="number">3</span></span><br><span class="line">conv1_stride = <span class="number">1</span></span><br><span class="line">conv1_pad = <span class="string">"SAME"</span></span><br><span class="line"></span><br><span class="line">conv2_fmaps = <span class="number">64</span></span><br><span class="line">conv2_ksize = <span class="number">3</span></span><br><span class="line">conv2_stride = <span class="number">2</span></span><br><span class="line">conv2_pad = <span class="string">"SAME"</span></span><br><span class="line"></span><br><span class="line">pool3_fmaps = conv2_fmaps</span><br><span class="line"></span><br><span class="line">n_fcl = <span class="number">64</span></span><br><span class="line">n_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"inputs"</span>):</span><br><span class="line">    X =  tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, n_inputs], name=<span class="string">"X"</span>)</span><br><span class="line">    X_reshaped = tf.reshape(X, shape=[<span class="number">-1</span>, height, width, channels])</span><br><span class="line">    y = tf.placeholder(tf.int32, shape=[<span class="keyword">None</span>], name=<span class="string">"y"</span>)</span><br><span class="line"></span><br><span class="line">conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,</span><br><span class="line">                        strides=conv1_stride, padding=conv1_pad, activation=tf.nn.relu,</span><br><span class="line">                        name=<span class="string">"conv1"</span>)</span><br><span class="line">conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,</span><br><span class="line">                        strides=conv2_stride, padding=conv2_pad, activation=tf.nn.relu,</span><br><span class="line">                        name=<span class="string">"conv2"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"pool3"</span>):</span><br><span class="line">    pool3 = tf.nn.max_pool(conv2, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">"VALID"</span>)</span><br><span class="line">    pool3_flat = tf.reshape(pool3, shape=[<span class="number">-1</span>, pool3_fmaps * <span class="number">7</span> * <span class="number">7</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"fc1"</span>):</span><br><span class="line">    fc1 = tf.layers.dense(pool3_flat, n_fcl, activation=tf.nn.relu, name=<span class="string">"fc1"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"output"</span>):</span><br><span class="line">    logits = tf.layers.dense(fc1, n_outputs, name=<span class="string">"output"</span>)</span><br><span class="line">    Y_proba = tf.nn.softmax(logits, name=<span class="string">"Y_proba"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"train"</span>):</span><br><span class="line">    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)</span><br><span class="line">    loss = tf.reduce_mean(xentropy)</span><br><span class="line">    optimizer = tf.train.AdamOptimizer()</span><br><span class="line">    training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"eval"</span>):</span><br><span class="line">    correct = tf.nn.in_top_k(logits, y, <span class="number">1</span>)</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"init_and_save"</span>):</span><br><span class="line">    init = tf.global_variables_initializer()</span><br><span class="line">    saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"./tmp/data"</span>)</span><br></pre></td></tr></table></figure><pre><code>WARNING:tensorflow:From &lt;ipython-input-24-5263d3034815&gt;:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.Instructions for updating:Please use alternatives such as official/mnist/dataset.py from tensorflow/models.WARNING:tensorflow:From e:\python\python36\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.Instructions for updating:Please write your own downloading logic.WARNING:tensorflow:From e:\python\python36\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.Instructions for updating:Please use tf.data to implement this functionality.Extracting ./tmp/data\train-images-idx3-ubyte.gzWARNING:tensorflow:From e:\python\python36\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.Instructions for updating:Please use tf.data to implement this functionality.Extracting ./tmp/data\train-labels-idx1-ubyte.gzWARNING:tensorflow:From e:\python\python36\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\base.py:252: _internal_retry.&lt;locals&gt;.wrap.&lt;locals&gt;.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.Instructions for updating:Please use urllib or similar directly.Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.Extracting ./tmp/data\t10k-images-idx3-ubyte.gzSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.Extracting ./tmp/data\t10k-labels-idx1-ubyte.gzWARNING:tensorflow:From e:\python\python36\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.Instructions for updating:Please use alternatives such as official/mnist/dataset.py from tensorflow/models.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">for</span> iteration <span class="keyword">in</span> range(mnist.train.num_examples // batch_size):</span><br><span class="line">            X_batch, y_batch = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        acc_train = accuracy.eval(feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        acc_test = accuracy.eval(feed_dict=&#123;X: mnist.test.images, y: mnist.test.labels&#125;)</span><br><span class="line">        print(epoch, <span class="string">"Training accuracy:"</span>, acc_train, <span class="string">"Test accuracy:"</span>, acc_test)</span><br><span class="line"></span><br><span class="line">        save_path = saver.save(sess, <span class="string">"./cnn/my_mnist_mode"</span>)</span><br></pre></td></tr></table></figure><pre><code>0 Training accuracy: 0.99 Test accuracy: 0.97711 Training accuracy: 0.96 Test accuracy: 0.982 Training accuracy: 1.0 Test accuracy: 0.9863 Training accuracy: 0.99 Test accuracy: 0.98714 Training accuracy: 1.0 Test accuracy: 0.98825 Training accuracy: 0.99 Test accuracy: 0.99036 Training accuracy: 1.0 Test accuracy: 0.98827 Training accuracy: 0.99 Test accuracy: 0.98928 Training accuracy: 1.0 Test accuracy: 0.98849 Training accuracy: 1.0 Test accuracy: 0.9882</code></pre><hr><p><a href="https://github.com/coldJune/machineLearning/blob/master/handson-ml/Convolutional%20Neural%20Networks.ipynb" target="_blank" rel="noopener">源文件</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;准备&quot;&gt;&lt;a href=&quot;#准备&quot; class=&quot;headerlink&quot; title=&quot;准备&quot;&gt;&lt;/a&gt;准备&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span
      
    
    </summary>
    
      <category term="机器学习" scheme="http://coldjune.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow" scheme="http://coldjune.com/tags/tensorflow/"/>
    
      <category term="Hands-On Machine Learning with Scikit-Learn and TensorFlow" scheme="http://coldjune.com/tags/Hands-On-Machine-Learning-with-Scikit-Learn-and-TensorFlow/"/>
    
      <category term="神经网络" scheme="http://coldjune.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="卷积神经网络" scheme="http://coldjune.com/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Training Deep Neural Nets</title>
    <link href="http://coldjune.com/2018/12/20/Training-Deep-Neural-Nets/"/>
    <id>http://coldjune.com/2018/12/20/Training-Deep-Neural-Nets/</id>
    <published>2018-12-20T03:18:36.000Z</published>
    <updated>2018-12-27T14:12:15.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reset_graph</span><span class="params">(seed=<span class="number">42</span>)</span>:</span></span><br><span class="line">    tf.reset_default_graph()</span><br><span class="line">    tf.set_random_seed(seed)</span><br><span class="line">    np.random.seed(seed)</span><br></pre></td></tr></table></figure><h1 id="Vanishing-Exploding-Gradients-Problems"><a href="#Vanishing-Exploding-Gradients-Problems" class="headerlink" title="Vanishing/Exploding Gradients Problems"></a>Vanishing/Exploding Gradients Problems</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logit</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">z = np.linspace(<span class="number">-5</span>, <span class="number">5</span>, <span class="number">200</span>)</span><br><span class="line"></span><br><span class="line">plt.plot([<span class="number">-5</span>, <span class="number">5</span>], [<span class="number">0</span>, <span class="number">0</span>], <span class="string">'k-'</span>)</span><br><span class="line">plt.plot([<span class="number">-5</span>, <span class="number">5</span>], [<span class="number">1</span>, <span class="number">1</span>], <span class="string">'k--'</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">0</span>], [<span class="number">-0.2</span>, <span class="number">1.2</span>], <span class="string">'k-'</span>)</span><br><span class="line">plt.plot([<span class="number">-5</span>, <span class="number">5</span>], [<span class="number">-3</span>/<span class="number">4</span>, <span class="number">7</span>/<span class="number">4</span>], <span class="string">'g--'</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(z, logit(z), <span class="string">'b--'</span>, linewidth=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">props = dict(facecolor=<span class="string">'black'</span>, shrink=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">plt.annotate(<span class="string">'Saturating'</span>, xytext=(<span class="number">3.5</span>, <span class="number">0.7</span>), xy=(<span class="number">5</span>, <span class="number">1</span>),</span><br><span class="line">             arrowprops=props, fontsize=<span class="number">14</span>, ha=<span class="string">'center'</span>)</span><br><span class="line">plt.annotate(<span class="string">'Saturating'</span>, xytext=(<span class="number">-3.5</span>, <span class="number">0.3</span>), xy=(<span class="number">-5</span>, <span class="number">0</span>),</span><br><span class="line">             arrowprops=props, fontsize=<span class="number">14</span>, ha=<span class="string">'center'</span>)</span><br><span class="line">plt.annotate(<span class="string">'Linear'</span>, xytext=(<span class="number">2</span>, <span class="number">0.2</span>), xy=(<span class="number">0</span>, <span class="number">0.5</span>),</span><br><span class="line">             arrowprops=props, fontsize=<span class="number">14</span>, ha=<span class="string">'center'</span>)</span><br><span class="line"></span><br><span class="line">plt.grid(<span class="keyword">True</span>)</span><br><span class="line">plt.title(<span class="string">"Sigmoid activation function"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.axis([<span class="number">-5</span>, <span class="number">5</span>, <span class="number">-0.2</span>, <span class="number">1.2</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/20/Training-Deep-Neural-Nets/Training%20Deep%20Neural%20Nets_4_0.png" alt="png"></p><h2 id="Xavier和-He-初始化"><a href="#Xavier和-He-初始化" class="headerlink" title="Xavier和 He 初始化"></a>Xavier和 He 初始化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">reset_graph()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs), name=<span class="string">"X"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">he_init = tf.variance_scaling_initializer()</span><br><span class="line">hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,</span><br><span class="line">                         kernel_initializer=he_init, name=<span class="string">"hidden1"</span>)</span><br></pre></td></tr></table></figure><h2 id="不饱和激活函数"><a href="#不饱和激活函数" class="headerlink" title="不饱和激活函数"></a>不饱和激活函数</h2><h3 id="Leaky-ReLU"><a href="#Leaky-ReLU" class="headerlink" title="Leaky ReLU"></a>Leaky ReLU</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">leaky_relu</span><span class="params">(z, alpha=<span class="number">0.01</span>)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.maximum(alpha*z, z)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(z, leaky_relu(z,<span class="number">0.05</span>), <span class="string">'b-'</span>, linewidth=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">plt.plot([<span class="number">-5</span>, <span class="number">5</span>], [<span class="number">0</span>, <span class="number">0</span>], <span class="string">'k-'</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">0</span>], [<span class="number">-0.5</span>, <span class="number">4.2</span>], <span class="string">'k-'</span>)</span><br><span class="line"></span><br><span class="line">plt.annotate(<span class="string">'Leak'</span>, xytext=(<span class="number">-4.5</span>, <span class="number">0.5</span>), xy=(<span class="number">-5</span>, <span class="number">-0.2</span>), arrowprops=props, ha=<span class="string">"center"</span>)</span><br><span class="line">plt.title(<span class="string">"Leaky ReLU activation function"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.axis([<span class="number">-5</span>, <span class="number">5</span>, <span class="number">-0.5</span>, <span class="number">4.2</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/20/Training-Deep-Neural-Nets/Training%20Deep%20Neural%20Nets_12_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs), name=<span class="string">"X"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">leaky_relu</span><span class="params">(z, name=None)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.maximum(<span class="number">0.01</span> * z, z, name=name)</span><br><span class="line"></span><br><span class="line">hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=<span class="string">"hidden1"</span>)</span><br></pre></td></tr></table></figure><ul><li>使用Leaky ReLU训练MNIST</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line">n_hidden2 = <span class="number">100</span></span><br><span class="line">n_outputs = <span class="number">10</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs), name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.placeholder(tf.int32, shape=(<span class="keyword">None</span>), name=<span class="string">"y"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"dnn"</span>):</span><br><span class="line">    hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=<span class="string">"hidden1"</span>)</span><br><span class="line">    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=leaky_relu, name=<span class="string">"hidden2"</span>)</span><br><span class="line">    logits = tf.layers.dense(hidden2, n_outputs, name=<span class="string">"outputs"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"loss"</span>):</span><br><span class="line">    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">    loss = tf.reduce_mean(xentropy, name=<span class="string">"loss"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"train"</span>):</span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate)</span><br><span class="line">    training_op = optimizer.minimize(loss)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span>  tf.name_scope(<span class="string">"eval"</span>):</span><br><span class="line">    correct = tf.nn.in_top_k(logits, y, <span class="number">1</span>)</span><br><span class="line">    accurancy = tf.reduce_mean(tf.cast(correct, tf.float32))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><ul><li>加载数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line">X_train = X_train.astype(np.float32).reshape(<span class="number">-1</span>, <span class="number">28</span>*<span class="number">28</span>) / <span class="number">255.0</span></span><br><span class="line">X_test = X_test.astype(np.float32).reshape(<span class="number">-1</span>, <span class="number">28</span>*<span class="number">28</span>) / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">y_train = y_train.astype(np.int32)</span><br><span class="line">y_test = y_test.astype(np.int32)</span><br><span class="line"></span><br><span class="line">X_valid, X_train = X_train[:<span class="number">5000</span>], X_train[<span class="number">5000</span>:]</span><br><span class="line">y_valid, y_train = y_train[:<span class="number">5000</span>], y_train[<span class="number">5000</span>:]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shuffle_batch</span><span class="params">(X, y, batch_size)</span>:</span></span><br><span class="line">    rnd_idx = np.random.permutation(len(X))</span><br><span class="line">    n_batches = len(X) // batch_size</span><br><span class="line">    <span class="keyword">for</span> batch_idx <span class="keyword">in</span> np.array_split(rnd_idx, n_batches):</span><br><span class="line">        X_batch, y_batch = X[batch_idx], y[batch_idx]</span><br><span class="line">        <span class="keyword">yield</span> X_batch, y_batch</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">40</span></span><br><span class="line">batch_size = <span class="number">50</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> shuffle_batch(X_train, y_train, batch_size):</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">            acc_batch = accurancy.eval(feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">            acc_valid = accurancy.eval(feed_dict=&#123;X: X_valid, y: y_valid&#125;)</span><br><span class="line">            print(epoch, <span class="string">"Batch accuracy:"</span>, acc_batch, <span class="string">"Validation accurancy:"</span>, acc_valid)</span><br><span class="line">    save_path = saver.save(sess, <span class="string">"dnn/leaky_relu_model_final.ckpt"</span>)</span><br><span class="line">file_write = tf.summary.FileWriter(<span class="string">"dnn/leaky_relu"</span>, tf.get_default_graph())</span><br></pre></td></tr></table></figure><pre><code>0 Batch accuracy: 0.86 Validation accurancy: 0.90445 Batch accuracy: 0.94 Validation accurancy: 0.949410 Batch accuracy: 0.92 Validation accurancy: 0.965615 Batch accuracy: 0.94 Validation accurancy: 0.97120 Batch accuracy: 1.0 Validation accurancy: 0.976225 Batch accuracy: 1.0 Validation accurancy: 0.977230 Batch accuracy: 0.98 Validation accurancy: 0.978235 Batch accuracy: 1.0 Validation accurancy: 0.9788</code></pre><h3 id="ELU"><a href="#ELU" class="headerlink" title="ELU"></a>ELU</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">elu</span><span class="params">(z, alpha=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.where(z &lt; <span class="number">0</span>, alpha * (np.exp(z)<span class="number">-1</span>), z)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(z, elu(z), <span class="string">"b-"</span>, linewidth=<span class="number">2</span>)</span><br><span class="line">plt.plot([<span class="number">-5</span>, <span class="number">5</span>], [<span class="number">0</span>, <span class="number">0</span>], <span class="string">"k-"</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">0</span>], [<span class="number">-2.2</span>, <span class="number">3.2</span>], <span class="string">"k-"</span>)</span><br><span class="line">plt.plot([<span class="number">-5</span>, <span class="number">5</span>], [<span class="number">-1</span>, <span class="number">-1</span>], <span class="string">"k--"</span>)</span><br><span class="line">plt.title(<span class="string">r"ELU activation funtion($\alpha=1$)"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.axis([<span class="number">-5</span>, <span class="number">5</span>, <span class="number">-2.2</span>, <span class="number">3.2</span>])</span><br><span class="line">plt.grid(<span class="keyword">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/12/20/Training-Deep-Neural-Nets/Training%20Deep%20Neural%20Nets_29_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs), name=<span class="string">"X"</span>)</span><br><span class="line"></span><br><span class="line">hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.elu, name=<span class="string">"hidden1"</span>)</span><br></pre></td></tr></table></figure><h2 id="批量标准化-Batch-Normalization"><a href="#批量标准化-Batch-Normalization" class="headerlink" title="批量标准化(Batch Normalization)"></a>批量标准化(Batch Normalization)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line">n_hidden2 = <span class="number">100</span></span><br><span class="line">n_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs), name=<span class="string">"X"</span>)</span><br><span class="line">training = tf.placeholder_with_default(<span class="keyword">False</span>, shape=(), name=<span class="string">"training"</span>)</span><br><span class="line"></span><br><span class="line">hidden1 = tf.layers.dense(X, n_hidden1, name=<span class="string">"hidden1"</span>)</span><br><span class="line">bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=<span class="number">0.9</span>)</span><br><span class="line">bn1_act = tf.nn.elu(bn1)</span><br><span class="line"></span><br><span class="line">hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=<span class="string">"hidden2"</span>)</span><br><span class="line">bn2 = tf.layers.batch_normalization(hidden2, training=training, momentum=<span class="number">0.9</span>)</span><br><span class="line">bn2_act = tf.nn.elu(bn2)</span><br><span class="line"></span><br><span class="line">logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=<span class="string">"outputs"</span>)</span><br><span class="line">logits = tf.layers.batch_normalization(logits_before_bn, training=training, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs), name=<span class="string">"X"</span>)</span><br><span class="line">training = tf.placeholder_with_default(<span class="keyword">False</span>, shape=(), name=<span class="string">"training"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"></span><br><span class="line">my_batch_norm_layer = partial(tf.layers.batch_normalization,</span><br><span class="line">                             training=training, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">hidden1 = tf.layers.dense(X, n_hidden1, name=<span class="string">"hidden1"</span>)</span><br><span class="line">bn1 = my_batch_norm_layer(hidden1)</span><br><span class="line">bn1_act = tf.nn.elu(bn1)</span><br><span class="line"></span><br><span class="line">hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=<span class="string">"hidden2"</span>)</span><br><span class="line">bn2 = my_batch_norm_layer(hidden2)</span><br><span class="line">bn2_act = tf.nn.elu(bn2)</span><br><span class="line"></span><br><span class="line">logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=<span class="string">"outputs"</span>)</span><br><span class="line">logits = my_batch_norm_layer(logits_before_bn)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">batch_norm_momentum = <span class="number">0.9</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs), name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.placeholder(tf.int32, shape=(<span class="keyword">None</span>), name=<span class="string">"y"</span>)</span><br><span class="line">training = tf.placeholder_with_default(<span class="keyword">False</span>, shape=(), name=<span class="string">"training"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"dnn"</span>):</span><br><span class="line">    he_init = tf.variance_scaling_initializer()</span><br><span class="line"></span><br><span class="line">    my_batch_norm_layer = partial(</span><br><span class="line">        tf.layers.batch_normalization,</span><br><span class="line">        training=training,</span><br><span class="line">        momentum=batch_norm_momentum</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    my_dense_layer = partial(</span><br><span class="line">        tf.layers.dense,</span><br><span class="line">        kernel_initializer=he_init</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    hidden1 = my_dense_layer(X, n_hidden1, name=<span class="string">"hidden1"</span>)</span><br><span class="line">    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1))</span><br><span class="line"></span><br><span class="line">    hidden2 = my_dense_layer(bn1, n_hidden2, name=<span class="string">"hidden2"</span>)</span><br><span class="line">    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))</span><br><span class="line"></span><br><span class="line">    logits_before_bn = my_dense_layer(bn2, n_outputs, name=<span class="string">"outputs"</span>)</span><br><span class="line">    logits = my_batch_norm_layer(logits_before_bn)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"loss"</span>):</span><br><span class="line">    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">    loss = tf.reduce_mean(xentropy, name=<span class="string">"loss"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"train"</span>):</span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate)</span><br><span class="line">    training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"eval"</span>):</span><br><span class="line">    correct = tf.nn.in_top_k(logits, y, <span class="number">1</span>)</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">200</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> shuffle_batch(X_train, y_train, batch_size):</span><br><span class="line">            sess.run([training_op, extra_update_ops],</span><br><span class="line">                     feed_dict=&#123;training: <span class="keyword">True</span>, X: X_batch, y: y_batch&#125;)</span><br><span class="line">        accuracy_val = accuracy.eval(feed_dict=&#123;X: X_valid, y: y_valid&#125;)</span><br><span class="line">        print(epoch, <span class="string">"Validation accuracy:"</span>, accuracy_val)</span><br><span class="line">    save_path = saver.save(sess, <span class="string">"dnn/elu_model_final.ckpt"</span>)</span><br><span class="line">    file_writer = tf.summary.FileWriter(<span class="string">"dnn/elu"</span>, tf.get_default_graph())</span><br></pre></td></tr></table></figure><pre><code>0 Validation accuracy: 0.89521 Validation accuracy: 0.92022 Validation accuracy: 0.93183 Validation accuracy: 0.94224 Validation accuracy: 0.94685 Validation accuracy: 0.9546 Validation accuracy: 0.95687 Validation accuracy: 0.968 Validation accuracy: 0.9629 Validation accuracy: 0.963810 Validation accuracy: 0.966211 Validation accuracy: 0.968212 Validation accuracy: 0.967213 Validation accuracy: 0.969614 Validation accuracy: 0.970615 Validation accuracy: 0.970416 Validation accuracy: 0.971817 Validation accuracy: 0.972618 Validation accuracy: 0.973819 Validation accuracy: 0.9742</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[v.name <span class="keyword">for</span> v <span class="keyword">in</span> tf.trainable_variables()]</span><br></pre></td></tr></table></figure><pre><code>[&#39;hidden1/kernel:0&#39;, &#39;hidden1/bias:0&#39;, &#39;batch_normalization/gamma:0&#39;, &#39;batch_normalization/beta:0&#39;, &#39;hidden2/kernel:0&#39;, &#39;hidden2/bias:0&#39;, &#39;batch_normalization_1/gamma:0&#39;, &#39;batch_normalization_1/beta:0&#39;, &#39;outputs/kernel:0&#39;, &#39;outputs/bias:0&#39;, &#39;batch_normalization_2/gamma:0&#39;, &#39;batch_normalization_2/beta:0&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[v.name <span class="keyword">for</span> v <span class="keyword">in</span> tf.global_variables()]</span><br></pre></td></tr></table></figure><pre><code>[&#39;hidden1/kernel:0&#39;, &#39;hidden1/bias:0&#39;, &#39;batch_normalization/gamma:0&#39;, &#39;batch_normalization/beta:0&#39;, &#39;batch_normalization/moving_mean:0&#39;, &#39;batch_normalization/moving_variance:0&#39;, &#39;hidden2/kernel:0&#39;, &#39;hidden2/bias:0&#39;, &#39;batch_normalization_1/gamma:0&#39;, &#39;batch_normalization_1/beta:0&#39;, &#39;batch_normalization_1/moving_mean:0&#39;, &#39;batch_normalization_1/moving_variance:0&#39;, &#39;outputs/kernel:0&#39;, &#39;outputs/bias:0&#39;, &#39;batch_normalization_2/gamma:0&#39;, &#39;batch_normalization_2/beta:0&#39;, &#39;batch_normalization_2/moving_mean:0&#39;, &#39;batch_normalization_2/moving_variance:0&#39;]</code></pre><h2 id="梯度裁剪"><a href="#梯度裁剪" class="headerlink" title="梯度裁剪"></a>梯度裁剪</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line">n_hidden2 = <span class="number">50</span></span><br><span class="line">n_hidden3 = <span class="number">50</span></span><br><span class="line">n_hidden4 = <span class="number">50</span></span><br><span class="line">n_hidden5 = <span class="number">50</span></span><br><span class="line">n_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs), name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.placeholder(tf.int32, shape=(<span class="keyword">None</span>), name=<span class="string">"y"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"dnn"</span>):</span><br><span class="line">    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=<span class="string">"hidden1"</span>)</span><br><span class="line">    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=<span class="string">"hidden2"</span>)</span><br><span class="line">    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=<span class="string">"hidden3"</span>)</span><br><span class="line">    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=<span class="string">"hidden4"</span>)</span><br><span class="line">    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=<span class="string">"hidden5"</span>)</span><br><span class="line">    logits = tf.layers.dense(hidden5, n_outputs, name=<span class="string">"outputs"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"loss"</span>):</span><br><span class="line">    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">    loss = tf.reduce_mean(xentropy, name=<span class="string">"loss"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = <span class="number">0.01</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">threhold = <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate)</span><br><span class="line">grads_and_vars = optimizer.compute_gradients(loss)</span><br><span class="line">capped_gvs = [(tf.clip_by_value(grad, -threhold, threhold), var)</span><br><span class="line">             <span class="keyword">for</span> grad, var <span class="keyword">in</span> grads_and_vars]</span><br><span class="line">training_op = optimizer.apply_gradients(capped_gvs)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"eval"</span>):</span><br><span class="line">    correct = tf.nn.in_top_k(logits, y, <span class="number">1</span>)</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=<span class="string">"accuracy"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">200</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> shuffle_batch(X_train, y_train, batch_size):</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        accuracy_val = accuracy.eval(feed_dict=&#123;X: X_valid, y: y_valid&#125;)</span><br><span class="line">        print(epoch, <span class="string">"Validation accuracy:"</span>, accuracy_val)</span><br><span class="line"></span><br><span class="line">    save_path = saver.save(sess, <span class="string">"dnn/clip_model_final.ckpt"</span>)</span><br><span class="line">filewriter = tf.summary.FileWriter(<span class="string">"dnn/clip"</span>, tf.get_default_graph())</span><br></pre></td></tr></table></figure><pre><code>0 Validation accuracy: 0.29061 Validation accuracy: 0.7952 Validation accuracy: 0.88363 Validation accuracy: 0.90684 Validation accuracy: 0.91365 Validation accuracy: 0.92326 Validation accuracy: 0.937 Validation accuracy: 0.93428 Validation accuracy: 0.93849 Validation accuracy: 0.94410 Validation accuracy: 0.945411 Validation accuracy: 0.947212 Validation accuracy: 0.951613 Validation accuracy: 0.953214 Validation accuracy: 0.954215 Validation accuracy: 0.956216 Validation accuracy: 0.957217 Validation accuracy: 0.959618 Validation accuracy: 0.958819 Validation accuracy: 0.9616</code></pre><h1 id="重利用之前训练的层"><a href="#重利用之前训练的层" class="headerlink" title="重利用之前训练的层"></a>重利用之前训练的层</h1><h2 id="重利用TensorFlow模型"><a href="#重利用TensorFlow模型" class="headerlink" title="重利用TensorFlow模型"></a>重利用TensorFlow模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line">saver = tf.train.import_meta_graph(<span class="string">"dnn/clip_model_final.ckpt.meta"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> op <span class="keyword">in</span> tf.get_default_graph().get_operations():</span><br><span class="line">    print(op.name)</span><br></pre></td></tr></table></figure><pre><code>Xyhidden1/kernel/Initializer/random_uniform/shapehidden1/kernel/Initializer/random_uniform/minhidden1/kernel/Initializer/random_uniform/maxhidden1/kernel/Initializer/random_uniform/RandomUniformhidden1/kernel/Initializer/random_uniform/subhidden1/kernel/Initializer/random_uniform/mulhidden1/kernel/Initializer/random_uniformhidden1/kernelhidden1/kernel/Assignhidden1/kernel/readhidden1/bias/Initializer/zeroshidden1/biashidden1/bias/Assignhidden1/bias/readdnn/hidden1/MatMuldnn/hidden1/BiasAdddnn/hidden1/Reluhidden2/kernel/Initializer/random_uniform/shapehidden2/kernel/Initializer/random_uniform/minhidden2/kernel/Initializer/random_uniform/maxhidden2/kernel/Initializer/random_uniform/RandomUniformhidden2/kernel/Initializer/random_uniform/subhidden2/kernel/Initializer/random_uniform/mulhidden2/kernel/Initializer/random_uniformhidden2/kernelhidden2/kernel/Assignhidden2/kernel/readhidden2/bias/Initializer/zeroshidden2/biashidden2/bias/Assignhidden2/bias/readdnn/hidden2/MatMuldnn/hidden2/BiasAdddnn/hidden2/Reluhidden3/kernel/Initializer/random_uniform/shapehidden3/kernel/Initializer/random_uniform/minhidden3/kernel/Initializer/random_uniform/maxhidden3/kernel/Initializer/random_uniform/RandomUniformhidden3/kernel/Initializer/random_uniform/subhidden3/kernel/Initializer/random_uniform/mulhidden3/kernel/Initializer/random_uniformhidden3/kernelhidden3/kernel/Assignhidden3/kernel/readhidden3/bias/Initializer/zeroshidden3/biashidden3/bias/Assignhidden3/bias/readdnn/hidden3/MatMuldnn/hidden3/BiasAdddnn/hidden3/Reluhidden4/kernel/Initializer/random_uniform/shapehidden4/kernel/Initializer/random_uniform/minhidden4/kernel/Initializer/random_uniform/maxhidden4/kernel/Initializer/random_uniform/RandomUniformhidden4/kernel/Initializer/random_uniform/subhidden4/kernel/Initializer/random_uniform/mulhidden4/kernel/Initializer/random_uniformhidden4/kernelhidden4/kernel/Assignhidden4/kernel/readhidden4/bias/Initializer/zeroshidden4/biashidden4/bias/Assignhidden4/bias/readdnn/hidden4/MatMuldnn/hidden4/BiasAdddnn/hidden4/Reluhidden5/kernel/Initializer/random_uniform/shapehidden5/kernel/Initializer/random_uniform/minhidden5/kernel/Initializer/random_uniform/maxhidden5/kernel/Initializer/random_uniform/RandomUniformhidden5/kernel/Initializer/random_uniform/subhidden5/kernel/Initializer/random_uniform/mulhidden5/kernel/Initializer/random_uniformhidden5/kernelhidden5/kernel/Assignhidden5/kernel/readhidden5/bias/Initializer/zeroshidden5/biashidden5/bias/Assignhidden5/bias/readdnn/hidden5/MatMuldnn/hidden5/BiasAdddnn/hidden5/Reluoutputs/kernel/Initializer/random_uniform/shapeoutputs/kernel/Initializer/random_uniform/minoutputs/kernel/Initializer/random_uniform/maxoutputs/kernel/Initializer/random_uniform/RandomUniformoutputs/kernel/Initializer/random_uniform/suboutputs/kernel/Initializer/random_uniform/muloutputs/kernel/Initializer/random_uniformoutputs/kerneloutputs/kernel/Assignoutputs/kernel/readoutputs/bias/Initializer/zerosoutputs/biasoutputs/bias/Assignoutputs/bias/readdnn/outputs/MatMuldnn/outputs/BiasAddloss/SparseSoftmaxCrossEntropyWithLogits/Shapeloss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogitsloss/Constloss/lossgradients/Shapegradients/grad_ys_0gradients/Fillgradients/loss/loss_grad/Reshape/shapegradients/loss/loss_grad/Reshapegradients/loss/loss_grad/Shapegradients/loss/loss_grad/Tilegradients/loss/loss_grad/Shape_1gradients/loss/loss_grad/Shape_2gradients/loss/loss_grad/Constgradients/loss/loss_grad/Prodgradients/loss/loss_grad/Const_1gradients/loss/loss_grad/Prod_1gradients/loss/loss_grad/Maximum/ygradients/loss/loss_grad/Maximumgradients/loss/loss_grad/floordivgradients/loss/loss_grad/Castgradients/loss/loss_grad/truedivgradients/zeros_likegradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradientgradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dimgradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDimsgradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mulgradients/dnn/outputs/BiasAdd_grad/BiasAddGradgradients/dnn/outputs/BiasAdd_grad/tuple/group_depsgradients/dnn/outputs/BiasAdd_grad/tuple/control_dependencygradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1gradients/dnn/outputs/MatMul_grad/MatMulgradients/dnn/outputs/MatMul_grad/MatMul_1gradients/dnn/outputs/MatMul_grad/tuple/group_depsgradients/dnn/outputs/MatMul_grad/tuple/control_dependencygradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1gradients/dnn/hidden5/Relu_grad/ReluGradgradients/dnn/hidden5/BiasAdd_grad/BiasAddGradgradients/dnn/hidden5/BiasAdd_grad/tuple/group_depsgradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependencygradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1gradients/dnn/hidden5/MatMul_grad/MatMulgradients/dnn/hidden5/MatMul_grad/MatMul_1gradients/dnn/hidden5/MatMul_grad/tuple/group_depsgradients/dnn/hidden5/MatMul_grad/tuple/control_dependencygradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1gradients/dnn/hidden4/Relu_grad/ReluGradgradients/dnn/hidden4/BiasAdd_grad/BiasAddGradgradients/dnn/hidden4/BiasAdd_grad/tuple/group_depsgradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependencygradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1gradients/dnn/hidden4/MatMul_grad/MatMulgradients/dnn/hidden4/MatMul_grad/MatMul_1gradients/dnn/hidden4/MatMul_grad/tuple/group_depsgradients/dnn/hidden4/MatMul_grad/tuple/control_dependencygradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1gradients/dnn/hidden3/Relu_grad/ReluGradgradients/dnn/hidden3/BiasAdd_grad/BiasAddGradgradients/dnn/hidden3/BiasAdd_grad/tuple/group_depsgradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependencygradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1gradients/dnn/hidden3/MatMul_grad/MatMulgradients/dnn/hidden3/MatMul_grad/MatMul_1gradients/dnn/hidden3/MatMul_grad/tuple/group_depsgradients/dnn/hidden3/MatMul_grad/tuple/control_dependencygradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1gradients/dnn/hidden2/Relu_grad/ReluGradgradients/dnn/hidden2/BiasAdd_grad/BiasAddGradgradients/dnn/hidden2/BiasAdd_grad/tuple/group_depsgradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependencygradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1gradients/dnn/hidden2/MatMul_grad/MatMulgradients/dnn/hidden2/MatMul_grad/MatMul_1gradients/dnn/hidden2/MatMul_grad/tuple/group_depsgradients/dnn/hidden2/MatMul_grad/tuple/control_dependencygradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1gradients/dnn/hidden1/Relu_grad/ReluGradgradients/dnn/hidden1/BiasAdd_grad/BiasAddGradgradients/dnn/hidden1/BiasAdd_grad/tuple/group_depsgradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependencygradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1gradients/dnn/hidden1/MatMul_grad/MatMulgradients/dnn/hidden1/MatMul_grad/MatMul_1gradients/dnn/hidden1/MatMul_grad/tuple/group_depsgradients/dnn/hidden1/MatMul_grad/tuple/control_dependencygradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1clip_by_value/Minimum/yclip_by_value/Minimumclip_by_value/yclip_by_valueclip_by_value_1/Minimum/yclip_by_value_1/Minimumclip_by_value_1/yclip_by_value_1clip_by_value_2/Minimum/yclip_by_value_2/Minimumclip_by_value_2/yclip_by_value_2clip_by_value_3/Minimum/yclip_by_value_3/Minimumclip_by_value_3/yclip_by_value_3clip_by_value_4/Minimum/yclip_by_value_4/Minimumclip_by_value_4/yclip_by_value_4clip_by_value_5/Minimum/yclip_by_value_5/Minimumclip_by_value_5/yclip_by_value_5clip_by_value_6/Minimum/yclip_by_value_6/Minimumclip_by_value_6/yclip_by_value_6clip_by_value_7/Minimum/yclip_by_value_7/Minimumclip_by_value_7/yclip_by_value_7clip_by_value_8/Minimum/yclip_by_value_8/Minimumclip_by_value_8/yclip_by_value_8clip_by_value_9/Minimum/yclip_by_value_9/Minimumclip_by_value_9/yclip_by_value_9clip_by_value_10/Minimum/yclip_by_value_10/Minimumclip_by_value_10/yclip_by_value_10clip_by_value_11/Minimum/yclip_by_value_11/Minimumclip_by_value_11/yclip_by_value_11GradientDescent/learning_rateGradientDescent/update_hidden1/kernel/ApplyGradientDescentGradientDescent/update_hidden1/bias/ApplyGradientDescentGradientDescent/update_hidden2/kernel/ApplyGradientDescentGradientDescent/update_hidden2/bias/ApplyGradientDescentGradientDescent/update_hidden3/kernel/ApplyGradientDescentGradientDescent/update_hidden3/bias/ApplyGradientDescentGradientDescent/update_hidden4/kernel/ApplyGradientDescentGradientDescent/update_hidden4/bias/ApplyGradientDescentGradientDescent/update_hidden5/kernel/ApplyGradientDescentGradientDescent/update_hidden5/bias/ApplyGradientDescentGradientDescent/update_outputs/kernel/ApplyGradientDescentGradientDescent/update_outputs/bias/ApplyGradientDescentGradientDescenteval/in_top_k/InTopKV2/keval/in_top_k/InTopKV2eval/Casteval/Consteval/accuracyinitsave/Constsave/SaveV2/tensor_namessave/SaveV2/shape_and_slicessave/SaveV2save/control_dependencysave/RestoreV2/tensor_namessave/RestoreV2/shape_and_slicessave/RestoreV2save/Assignsave/Assign_1save/Assign_2save/Assign_3save/Assign_4save/Assign_5save/Assign_6save/Assign_7save/Assign_8save/Assign_9save/Assign_10save/Assign_11save/restore_all</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#选择需要的</span></span><br><span class="line">X = tf.get_default_graph().get_tensor_by_name(<span class="string">"X:0"</span>)</span><br><span class="line">y = tf.get_default_graph().get_tensor_by_name(<span class="string">"y:0"</span>)</span><br><span class="line"></span><br><span class="line">accuracy = tf.get_default_graph().get_tensor_by_name(<span class="string">"eval/accuracy:0"</span>)</span><br><span class="line"></span><br><span class="line">training_op = tf.get_default_graph().get_operation_by_name(<span class="string">"GradientDescent"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将重要的操作放在单独的集合中</span></span><br><span class="line"><span class="keyword">for</span> op <span class="keyword">in</span> (X, y, accuracy, training_op):</span><br><span class="line">    tf.add_to_collection(<span class="string">"my_important_ops"</span>, op)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 或许这些操作</span></span><br><span class="line">X, y, accuracy, training_op = tf.get_collection(<span class="string">"my_important_ops"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, <span class="string">"dnn/clip_model_final.ckpt"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> shuffle_batch(X_train, y_train, batch_size):</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        accuracy_val = accuracy.eval(feed_dict=&#123;X: X_valid, y: y_valid&#125;)</span><br><span class="line">        print(epoch, <span class="string">"Validation accuracy:"</span>, accuracy_val)</span><br><span class="line">    save_path = saver.save(sess, <span class="string">"dnn/my_new_model_final.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from dnn/clip_model_final.ckpt0 Validation accuracy: 0.96261 Validation accuracy: 0.9632 Validation accuracy: 0.96323 Validation accuracy: 0.96584 Validation accuracy: 0.9655 Validation accuracy: 0.96286 Validation accuracy: 0.9667 Validation accuracy: 0.96788 Validation accuracy: 0.96729 Validation accuracy: 0.967810 Validation accuracy: 0.9711 Validation accuracy: 0.9712 Validation accuracy: 0.96613 Validation accuracy: 0.970614 Validation accuracy: 0.97215 Validation accuracy: 0.970816 Validation accuracy: 0.972417 Validation accuracy: 0.970618 Validation accuracy: 0.97219 Validation accuracy: 0.9684</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重利用低层</span></span><br><span class="line">reset_graph()</span><br><span class="line">n_hidden4 = <span class="number">20</span></span><br><span class="line">n_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">saver = tf.train.import_meta_graph(<span class="string">"dnn/clip_model_final.ckpt.meta"</span>)</span><br><span class="line"></span><br><span class="line">X = tf.get_default_graph().get_tensor_by_name(<span class="string">"X:0"</span>)</span><br><span class="line">y = tf.get_default_graph().get_tensor_by_name(<span class="string">"y:0"</span>)</span><br><span class="line"></span><br><span class="line">hidden3 = tf.get_default_graph().get_tensor_by_name(<span class="string">"dnn/hidden3/Relu:0"</span>)</span><br><span class="line"></span><br><span class="line">new_hidden4 = tf.layers.dense(hidden3, n_hidden4,</span><br><span class="line">                              activation=tf.nn.relu, name=<span class="string">"new_hidden4"</span>)</span><br><span class="line">new_logits = tf.layers.dense(new_hidden4, n_outputs, name=<span class="string">"new_outputs"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"new_loss"</span>):</span><br><span class="line">    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=new_logits)</span><br><span class="line">    loss = tf.reduce_mean(xentropy, name=<span class="string">"losss"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"new_eval"</span>):</span><br><span class="line">    correct = tf.nn.in_top_k(new_logits, y, <span class="number">1</span>)</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=<span class="string">"accuracy"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"new_train"</span>):</span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate)</span><br><span class="line">    training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">new_saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    saver.restore(sess, <span class="string">"dnn/clip_model_final.ckpt"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> shuffle_batch(X_train, y_train, batch_size):</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        accuracy_val = accuracy.eval(feed_dict=&#123;X: X_valid, y: y_valid&#125;)</span><br><span class="line">        print(epoch, <span class="string">"Validation accuracy:"</span>, accuracy_val)</span><br><span class="line">    save_path = new_saver.save(sess, <span class="string">"dnn/my_new_low_layer_model_final.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from dnn/clip_model_final.ckpt0 Validation accuracy: 0.91721 Validation accuracy: 0.93942 Validation accuracy: 0.94643 Validation accuracy: 0.954 Validation accuracy: 0.9555 Validation accuracy: 0.95226 Validation accuracy: 0.95667 Validation accuracy: 0.95988 Validation accuracy: 0.96089 Validation accuracy: 0.960810 Validation accuracy: 0.962811 Validation accuracy: 0.962212 Validation accuracy: 0.964613 Validation accuracy: 0.964814 Validation accuracy: 0.965415 Validation accuracy: 0.966816 Validation accuracy: 0.967617 Validation accuracy: 0.966218 Validation accuracy: 0.968419 Validation accuracy: 0.968</code></pre><h2 id="冻结低层"><a href="#冻结低层" class="headerlink" title="冻结低层"></a>冻结低层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line">n_hidden2 = <span class="number">50</span></span><br><span class="line">n_hidden3 = <span class="number">50</span></span><br><span class="line">n_hidden4 = <span class="number">20</span></span><br><span class="line">n_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs), name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.placeholder(tf.int32, shape=(<span class="keyword">None</span>), name=<span class="string">"y"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"dnn"</span>):</span><br><span class="line">    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=<span class="string">"hidden1"</span>)</span><br><span class="line">    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=<span class="string">"hidden2"</span>)</span><br><span class="line">    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=<span class="string">"hidden3"</span>)</span><br><span class="line">    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=<span class="string">"hidden4"</span>)</span><br><span class="line">    logits = tf.layers.dense(hidden4, n_outputs, name=<span class="string">"outputs"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"loss"</span>):</span><br><span class="line">    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">    loss = tf.reduce_mean(xentropy, name=<span class="string">"loss"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"eval"</span>):</span><br><span class="line">    correct = tf.nn.in_top_k(logits, y, <span class="number">1</span>)</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=<span class="string">"accuracy"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"train"</span>):</span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate)</span><br><span class="line">    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,</span><br><span class="line">                                   scope=<span class="string">"hidden[34]|outputs"</span>)</span><br><span class="line">    training_op = optimizer.minimize(loss, var_list=train_vars)</span><br><span class="line"></span><br><span class="line">init  = tf.global_variables_initializer()</span><br><span class="line">new_saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=<span class="string">"hidden[123]"</span>)</span><br><span class="line">restore_saver = tf.train.Saver(reuse_vars)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    restore_saver.restore(sess, <span class="string">"dnn/clip_model_final.ckpt"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> shuffle_batch(X_train, y_train, batch_size):</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        accuracy_val = accuracy.eval(feed_dict=&#123;X: X_valid, y: y_valid&#125;)</span><br><span class="line">        print(epoch, <span class="string">"Validation accuracy:"</span>, accuracy_val)</span><br><span class="line">    save_path = new_saver.save(sess, <span class="string">"dnn/my_new_freeze_low_layer_model_final.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from dnn/clip_model_final.ckpt0 Validation accuracy: 0.8931 Validation accuracy: 0.92342 Validation accuracy: 0.93583 Validation accuracy: 0.9414 Validation accuracy: 0.9475 Validation accuracy: 0.94846 Validation accuracy: 0.957 Validation accuracy: 0.9548 Validation accuracy: 0.95429 Validation accuracy: 0.95410 Validation accuracy: 0.95511 Validation accuracy: 0.954812 Validation accuracy: 0.957213 Validation accuracy: 0.95714 Validation accuracy: 0.956415 Validation accuracy: 0.95716 Validation accuracy: 0.957617 Validation accuracy: 0.95818 Validation accuracy: 0.958619 Validation accuracy: 0.9582</code></pre><h2 id="缓冲冻结的层"><a href="#缓冲冻结的层" class="headerlink" title="缓冲冻结的层"></a>缓冲冻结的层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line">n_hidden2 = <span class="number">50</span></span><br><span class="line">n_hidden3 = <span class="number">50</span></span><br><span class="line">n_hidden4 = <span class="number">20</span></span><br><span class="line">n_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs), name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.placeholder(tf.int32, shape=(<span class="keyword">None</span>), name=<span class="string">"y"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"dnn"</span>):</span><br><span class="line">    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=<span class="string">"hidden1"</span>)</span><br><span class="line">    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=<span class="string">"hidden2"</span>)</span><br><span class="line">    hidden2_stop = tf.stop_gradient(hidden2)</span><br><span class="line">    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu, name=<span class="string">"hidden3"</span>)</span><br><span class="line">    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=<span class="string">"hidden4"</span>)</span><br><span class="line">    logits = tf.layers.dense(hidden4, n_outputs, name=<span class="string">"outputs"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"loss"</span>):</span><br><span class="line">    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">    loss = tf.reduce_mean(xentropy, name=<span class="string">"loss"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"eval"</span>):</span><br><span class="line">    correct = tf.nn.in_top_k(logits, y, <span class="number">1</span>)</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=<span class="string">"accuracy"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"train"</span>):</span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate)</span><br><span class="line">    training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=<span class="string">"hidden[123]"</span>)</span><br><span class="line">restore_saver = tf.train.Saver(reuse_vars)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">n_batches = len(X_train) // batch_size</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    restore_saver.restore(sess, <span class="string">"dnn/clip_model_final.ckpt"</span>)</span><br><span class="line"></span><br><span class="line">    h2_cache = sess.run(hidden2, feed_dict=&#123;X: X_train&#125;)</span><br><span class="line">    h2_cache_valid = sess.run(hidden2, feed_dict=&#123;X: X_valid&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        shuffled_idx = np.random.permutation(len(X_train))</span><br><span class="line">        hidden2_batches = np.array_split(h2_cache[shuffled_idx], n_batches)</span><br><span class="line">        y_batches = np.array_split(y_train[shuffled_idx], n_batches)</span><br><span class="line">        <span class="keyword">for</span> hidden2_batch, y_batch <span class="keyword">in</span> zip(hidden2_batches, y_batches):</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;hidden2:hidden2_batch, y:y_batch&#125;)</span><br><span class="line">        accuracy_val = accuracy.eval(feed_dict=&#123;hidden2: h2_cache_valid, y: y_valid&#125;)</span><br><span class="line">        print(epoch, <span class="string">"Validation accuracy:"</span>, accuracy_val)</span><br><span class="line">    save_path = saver.save(sess, <span class="string">"dnn/my_new_cache_freeze_low_layer_model_final.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from dnn/clip_model_final.ckpt0 Validation accuracy: 0.90061 Validation accuracy: 0.93462 Validation accuracy: 0.94443 Validation accuracy: 0.94784 Validation accuracy: 0.95165 Validation accuracy: 0.9526 Validation accuracy: 0.95227 Validation accuracy: 0.95328 Validation accuracy: 0.95469 Validation accuracy: 0.955810 Validation accuracy: 0.95511 Validation accuracy: 0.955412 Validation accuracy: 0.955813 Validation accuracy: 0.957214 Validation accuracy: 0.95715 Validation accuracy: 0.957216 Validation accuracy: 0.956817 Validation accuracy: 0.959218 Validation accuracy: 0.95819 Validation accuracy: 0.9598</code></pre><h1 id="更快的优化器"><a href="#更快的优化器" class="headerlink" title="更快的优化器"></a>更快的优化器</h1><h2 id="Momentum-optimization"><a href="#Momentum-optimization" class="headerlink" title="Momentum optimization"></a>Momentum optimization</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><h2 id="Nesterov-Accelerated-Gradient"><a href="#Nesterov-Accelerated-Gradient" class="headerlink" title="Nesterov Accelerated Gradient"></a>Nesterov Accelerated Gradient</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,</span><br><span class="line">                                       momentum=<span class="number">0.9</span>, use_nesterov=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><h2 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)</span><br></pre></td></tr></table></figure><h2 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate, momentum=<span class="number">0.9</span>,</span><br><span class="line">                                     decay=<span class="number">0.9</span>, epsilon=<span class="number">1e-10</span>)</span><br></pre></td></tr></table></figure><h2 id="Adam-Optimization"><a href="#Adam-Optimization" class="headerlink" title="Adam Optimization"></a>Adam Optimization</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br></pre></td></tr></table></figure><h2 id="Learning-Rate-Scheduling"><a href="#Learning-Rate-Scheduling" class="headerlink" title="Learning Rate Scheduling"></a>Learning Rate Scheduling</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line">n_hidden2 = <span class="number">50</span></span><br><span class="line">n_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs), name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.placeholder(tf.int32, shape=(<span class="keyword">None</span>), name=<span class="string">"y"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"dnn"</span>):</span><br><span class="line">    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=<span class="string">"hidden1"</span>)</span><br><span class="line">    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=<span class="string">"hidden2"</span>)</span><br><span class="line">    logits = tf.layers.dense(hidden2, n_outputs, name=<span class="string">"outputs"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"loss"</span>):</span><br><span class="line">    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">    loss = tf.reduce_mean(xentropy, name=<span class="string">"loss"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"eval"</span>):</span><br><span class="line">    correct = tf.nn.in_top_k(logits, y, <span class="number">1</span>)</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=<span class="string">"accuracy"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"train"</span>):</span><br><span class="line">    initial_learning_rate = <span class="number">0.1</span></span><br><span class="line">    decay_steps = <span class="number">10000</span></span><br><span class="line">    decay_rate = <span class="number">1</span>/<span class="number">10</span></span><br><span class="line">    global_step = tf.Variable(<span class="number">0</span>, trainable=<span class="keyword">False</span>, name=<span class="string">"global_step"</span>)</span><br><span class="line">    learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step,</span><br><span class="line">                                              decay_steps, decay_rate)</span><br><span class="line">    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=<span class="number">0.9</span>)</span><br><span class="line">    training_op = optimizer.minimize(loss, global_step=global_step)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line">n_epochs = <span class="number">5</span></span><br><span class="line">batch_size = <span class="number">50</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> shuffle_batch(X_train, y_train, batch_size):</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        accuracy_val = accuracy.eval(feed_dict=&#123;X: X_valid, y: y_valid&#125;)</span><br><span class="line">        print(epoch, <span class="string">"Validation accuracy:"</span>, accuracy_val)</span><br><span class="line"></span><br><span class="line">    save_path = saver.save(sess, <span class="string">"dnn/learning_rate_scheduling_model_final.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>0 Validation accuracy: 0.95741 Validation accuracy: 0.97162 Validation accuracy: 0.9733 Validation accuracy: 0.97984 Validation accuracy: 0.9816</code></pre><h1 id="通过正规化避免过拟合"><a href="#通过正规化避免过拟合" class="headerlink" title="通过正规化避免过拟合"></a>通过正规化避免过拟合</h1><h2 id="l-1-和-l-2-正规化"><a href="#l-1-和-l-2-正规化" class="headerlink" title="$l_1$ 和 $l_2$ 正规化"></a>$l_1$ 和 $l_2$ 正规化</h2><ul><li>手动实现 $l_1$ 正规化</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line">n_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs), name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.placeholder(tf.int32, shape=(<span class="keyword">None</span>), name=<span class="string">"y"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"dnn"</span>):</span><br><span class="line">    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=<span class="string">"hidden1"</span>)</span><br><span class="line">    logits = tf.layers.dense(hidden1, n_outputs, name=<span class="string">"outputs"</span>)</span><br><span class="line"></span><br><span class="line">W1 = tf.get_default_graph().get_tensor_by_name(<span class="string">"hidden1/kernel:0"</span>)</span><br><span class="line">W2 = tf.get_default_graph().get_tensor_by_name(<span class="string">"outputs/kernel:0"</span>)</span><br><span class="line"></span><br><span class="line">scale = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"loss"</span>):</span><br><span class="line">    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">    base_loss = tf.reduce_mean(xentropy, name=<span class="string">"avg_xentropy"</span>)</span><br><span class="line">    reg_losses = tf.reduce_sum(tf.abs(W1)) + tf.reduce_sum(tf.abs(W2))</span><br><span class="line">    loss = tf.add(base_loss, scale * reg_losses, name=<span class="string">"loss"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"eval"</span>):</span><br><span class="line">    correct = tf.nn.in_top_k(logits, y, <span class="number">1</span>)</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=<span class="string">"accuracy"</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"train"</span>):</span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate)</span><br><span class="line">    training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">n_epoches = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">200</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epoches):</span><br><span class="line">        <span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> shuffle_batch(X_train, y_train, batch_size):</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        accuracy_val = accuracy.eval(feed_dict=&#123;X: X_valid, y: y_valid&#125;)</span><br><span class="line">        print(epoch, <span class="string">"Validation accuracy:"</span>, accuracy_val)</span><br><span class="line">    save_path = saver.save(sess,<span class="string">"dnn/l_1_model_final.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>0 Validation accuracy: 0.8311 Validation accuracy: 0.8712 Validation accuracy: 0.88383 Validation accuracy: 0.89344 Validation accuracy: 0.89665 Validation accuracy: 0.89886 Validation accuracy: 0.90167 Validation accuracy: 0.90448 Validation accuracy: 0.90589 Validation accuracy: 0.90610 Validation accuracy: 0.906811 Validation accuracy: 0.905412 Validation accuracy: 0.90713 Validation accuracy: 0.908414 Validation accuracy: 0.908815 Validation accuracy: 0.906416 Validation accuracy: 0.906817 Validation accuracy: 0.906618 Validation accuracy: 0.906619 Validation accuracy: 0.9052</code></pre><ul><li>使用正规化方法</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line">n_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs), name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.placeholder(tf.int32, shape=(<span class="keyword">None</span>), name=<span class="string">"y"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"dnn"</span>):</span><br><span class="line">    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=<span class="string">"hidden1"</span>)</span><br><span class="line">    logits = tf.layers.dense(hidden1, n_outputs, name=<span class="string">"outputs"</span>)</span><br><span class="line"></span><br><span class="line">W1 = tf.get_default_graph().get_tensor_by_name(<span class="string">"hidden1/kernel:0"</span>)</span><br><span class="line">W2 = tf.get_default_graph().get_tensor_by_name(<span class="string">"outputs/kernel:0"</span>)</span><br><span class="line"></span><br><span class="line">scale = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"loss"</span>):</span><br><span class="line">    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">    base_loss = tf.reduce_mean(xentropy, name=<span class="string">"avg_xentropy"</span>)</span><br><span class="line">    reg_losses = tf.reduce_sum(tf.abs(W1)) + tf.reduce_sum(tf.abs(W2))</span><br><span class="line">    loss = tf.add(base_loss, scale * reg_losses, name=<span class="string">"loss"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"eval"</span>):</span><br><span class="line">    correct = tf.nn.in_top_k(logits, y, <span class="number">1</span>)</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=<span class="string">"accuracy"</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"train"</span>):</span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate)</span><br><span class="line">    training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">n_epoches = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">200</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epoches):</span><br><span class="line">        <span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> shuffle_batch(X_train, y_train, batch_size):</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        accuracy_val = accuracy.eval(feed_dict=&#123;X: X_valid, y: y_valid&#125;)</span><br><span class="line">        print(epoch, <span class="string">"Validation accuracy:"</span>, accuracy_val)</span><br><span class="line">    save_path = saver.save(sess,<span class="string">"dnn/l_1_model_final.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>0 Validation accuracy: 0.8311 Validation accuracy: 0.8712 Validation accuracy: 0.88383 Validation accuracy: 0.89344 Validation accuracy: 0.89665 Validation accuracy: 0.89886 Validation accuracy: 0.90167 Validation accuracy: 0.90448 Validation accuracy: 0.90589 Validation accuracy: 0.90610 Validation accuracy: 0.906811 Validation accuracy: 0.905412 Validation accuracy: 0.90713 Validation accuracy: 0.908414 Validation accuracy: 0.908815 Validation accuracy: 0.906416 Validation accuracy: 0.906817 Validation accuracy: 0.906618 Validation accuracy: 0.906619 Validation accuracy: 0.9052</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line">n_hidden2 = <span class="number">50</span></span><br><span class="line">n_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs), name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.placeholder(tf.int32, shape=(<span class="keyword">None</span>), name=<span class="string">"y"</span>)</span><br><span class="line">scale = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line">my_dense_layer = partial(</span><br><span class="line">    tf.layers.dense,</span><br><span class="line">    activation=tf.nn.relu,</span><br><span class="line">    kernel_regularizer=tf.contrib.layers.l1_regularizer(scale)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"dnn"</span>):</span><br><span class="line">    hidden1 = my_dense_layer(X, n_hidden1, name=<span class="string">"hidden1"</span>)</span><br><span class="line">    hidden2 = my_dense_layer(hidden1, n_hidden2, name=<span class="string">"hidden2"</span>)</span><br><span class="line">    logits = my_dense_layer(hidden2, n_outputs, activation=<span class="keyword">None</span>, name=<span class="string">"outputs"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"loss"</span>):</span><br><span class="line">    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">    base_loss = tf.reduce_mean(xentropy, name=<span class="string">"avg_xentropy"</span>)</span><br><span class="line">    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)</span><br><span class="line">    loss = tf.add_n([base_loss] + reg_losses, name=<span class="string">"loss"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"eval"</span>):</span><br><span class="line">    correct = tf.nn.in_top_k(logits, y, <span class="number">1</span>)</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=<span class="string">"accuracy"</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"train"</span>):</span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate)</span><br><span class="line">    training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">n_epoches = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">200</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epoches):</span><br><span class="line">        <span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> shuffle_batch(X_train, y_train, batch_size):</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        accuracy_val = accuracy.eval(feed_dict=&#123;X: X_valid, y: y_valid&#125;)</span><br><span class="line">        print(epoch, <span class="string">"Validation accuracy:"</span>, accuracy_val)</span><br><span class="line">    save_path = saver.save(sess,<span class="string">"dnn/l_1_function_model_final.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>0 Validation accuracy: 0.82741 Validation accuracy: 0.87662 Validation accuracy: 0.89523 Validation accuracy: 0.90164 Validation accuracy: 0.9085 Validation accuracy: 0.90966 Validation accuracy: 0.91247 Validation accuracy: 0.91548 Validation accuracy: 0.91789 Validation accuracy: 0.91910 Validation accuracy: 0.9211 Validation accuracy: 0.922412 Validation accuracy: 0.921213 Validation accuracy: 0.922814 Validation accuracy: 0.922215 Validation accuracy: 0.921816 Validation accuracy: 0.921817 Validation accuracy: 0.922818 Validation accuracy: 0.921619 Validation accuracy: 0.9214</code></pre><h2 id="DropOut"><a href="#DropOut" class="headerlink" title="DropOut"></a>DropOut</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs), name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.placeholder(tf.int32, shape=(<span class="keyword">None</span>), name=<span class="string">"y"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">training = tf.placeholder_with_default(<span class="keyword">False</span>, shape=(), name=<span class="string">"training"</span>)</span><br><span class="line"></span><br><span class="line">dropout_rate = <span class="number">0.5</span></span><br><span class="line">X_drop = tf.layers.dropout(X, dropout_rate, training=training)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"dnn"</span>):</span><br><span class="line">    hidden1 = tf.layers.dense(X_drop, n_hidden1, activation=tf.nn.relu,</span><br><span class="line">                             name=<span class="string">"hidden1"</span>)</span><br><span class="line">    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)</span><br><span class="line"></span><br><span class="line">    hidden2 = tf.layers.dense(hidden1_drop, n_hidden2, activation=tf.nn.relu,</span><br><span class="line">                             name=<span class="string">"hidden2"</span>)</span><br><span class="line">    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)</span><br><span class="line"></span><br><span class="line">    logits = tf.layers.dense(hidden2_drop, n_outputs, name=<span class="string">"outputs"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"loss"</span>):</span><br><span class="line">    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">    loss = tf.reduce_mean(xentropy, name=<span class="string">"loss"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"train"</span>):</span><br><span class="line">    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=<span class="number">0.9</span>)</span><br><span class="line">    training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"eval"</span>):</span><br><span class="line">    correct = tf.nn.in_top_k(logits, y, <span class="number">1</span>)</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">n_epoches = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">200</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epoches):</span><br><span class="line">        <span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> shuffle_batch(X_train, y_train, batch_size):</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        accuracy_val = accuracy.eval(feed_dict=&#123;X: X_valid, y: y_valid&#125;)</span><br><span class="line">        print(epoch, <span class="string">"Validation accuracy:"</span>, accuracy_val)</span><br><span class="line">    save_path = saver.save(sess,<span class="string">"dnn/dropout_model_final.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>0 Validation accuracy: 0.9231 Validation accuracy: 0.94382 Validation accuracy: 0.95043 Validation accuracy: 0.9614 Validation accuracy: 0.96545 Validation accuracy: 0.96946 Validation accuracy: 0.97267 Validation accuracy: 0.97368 Validation accuracy: 0.97569 Validation accuracy: 0.97510 Validation accuracy: 0.976811 Validation accuracy: 0.978212 Validation accuracy: 0.97613 Validation accuracy: 0.978814 Validation accuracy: 0.977615 Validation accuracy: 0.980216 Validation accuracy: 0.979617 Validation accuracy: 0.980218 Validation accuracy: 0.980619 Validation accuracy: 0.9806</code></pre><h2 id="Max-Norm"><a href="#Max-Norm" class="headerlink" title="Max Norm"></a>Max Norm</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_norm_regularizer</span><span class="params">(threshold, axes=<span class="number">1</span>, name=<span class="string">"max_norm"</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                        collection=<span class="string">"max_norm"</span>)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">max_norm</span><span class="params">(weights)</span>:</span></span><br><span class="line">        clipped = tf.clip_by_norm(weights, clip_norm=threshold, axes=axes)</span><br><span class="line">        clip_weights = tf.assign(weights, clipped, name=name)</span><br><span class="line">        tf.add_to_collection(collection, clip_weights)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">return</span> max_norm</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">reset_graph()</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line">n_hidden2 = <span class="number">50</span></span><br><span class="line">n_outputs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">momentum = <span class="number">0.9</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs), name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.placeholder(tf.int32, shape=(<span class="keyword">None</span>), name=<span class="string">"y"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">max_norm_reg = max_norm_regularizer(threshold=<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"dnn"</span>):</span><br><span class="line">    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,</span><br><span class="line">                             kernel_regularizer=max_norm_reg, name=<span class="string">"hidden1"</span>)</span><br><span class="line">    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,</span><br><span class="line">                             kernel_regularizer=max_norm_reg, name=<span class="string">"hidden2"</span>)</span><br><span class="line">    logits = tf.layers.dense(hidden2, n_outputs, name=<span class="string">"outputs"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"loss"</span>):</span><br><span class="line">    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">    loss = tf.reduce_mean(xentropy, name=<span class="string">"loss"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"train"</span>):</span><br><span class="line">    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)</span><br><span class="line">    training_op = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"eval"</span>):</span><br><span class="line">    correct = tf.nn.in_top_k(logits, y, <span class="number">1</span>)</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">n_epoches = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">50</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">clip_all_weights = tf.get_collection(<span class="string">"max_norm"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epoches):</span><br><span class="line">        <span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> shuffle_batch(X_train, y_train, batch_size):</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">            sess.run(clip_all_weights)</span><br><span class="line">        acc_valid = accuracy.eval(feed_dict=&#123;X:X_valid, y: y_valid&#125;)</span><br><span class="line">        print(epoch, <span class="string">"Validation accuracy:"</span>, acc_valid)</span><br><span class="line">    save_path = saver.save(sess, <span class="string">"dnn/max_norm_model_final.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>0 Validation accuracy: 0.95561 Validation accuracy: 0.972 Validation accuracy: 0.9733 Validation accuracy: 0.97584 Validation accuracy: 0.97625 Validation accuracy: 0.97886 Validation accuracy: 0.987 Validation accuracy: 0.98248 Validation accuracy: 0.98169 Validation accuracy: 0.98110 Validation accuracy: 0.98311 Validation accuracy: 0.98212 Validation accuracy: 0.980813 Validation accuracy: 0.982814 Validation accuracy: 0.98215 Validation accuracy: 0.982416 Validation accuracy: 0.982417 Validation accuracy: 0.982418 Validation accuracy: 0.98219 Validation accuracy: 0.9824</code></pre><hr><p> <a href="https://github.com/coldJune/machineLearning/blob/master/handson-ml/Training%20Deep%20Neural%20Nets.ipynb" target="_blank" rel="noopener">源文件</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;准备&quot;&gt;&lt;a href=&quot;#准备&quot; class=&quot;headerlink&quot; title=&quot;准备&quot;&gt;&lt;/a&gt;准备&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span
      
    
    </summary>
    
      <category term="机器学习" scheme="http://coldjune.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow" scheme="http://coldjune.com/tags/tensorflow/"/>
    
      <category term="Hands-On Machine Learning with Scikit-Learn and TensorFlow" scheme="http://coldjune.com/tags/Hands-On-Machine-Learning-with-Scikit-Learn-and-TensorFlow/"/>
    
      <category term="神经网络" scheme="http://coldjune.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Introduction to Artificial Neural Networks</title>
    <link href="http://coldjune.com/2018/12/17/Introduction-to-Artificial-Neural-Networks/"/>
    <id>http://coldjune.com/2018/12/17/Introduction-to-Artificial-Neural-Networks/</id>
    <published>2018-12-17T03:13:40.000Z</published>
    <updated>2018-12-17T10:56:33.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="感知器"><a href="#感知器" class="headerlink" title="感知器"></a>感知器</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Perceptron</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, (<span class="number">2</span>, <span class="number">3</span>)].astype(np.float32)</span><br><span class="line">y = (iris.target == <span class="number">0</span>).astype(np.int)</span><br><span class="line"></span><br><span class="line">per_clf = Perceptron(random_state=<span class="number">42</span>, max_iter=<span class="number">50</span>, tol=<span class="number">1e-3</span>)</span><br><span class="line">per_clf.fit(X, y)</span><br><span class="line">y_pred = per_clf.predict([[<span class="number">2</span>, <span class="number">0.5</span>]])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred</span><br></pre></td></tr></table></figure><pre><code>array([1])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line"></span><br><span class="line">sgd_clf = SGDClassifier(loss=<span class="string">"perceptron"</span>, learning_rate=<span class="string">"constant"</span>,</span><br><span class="line">                        eta0=<span class="number">1</span>, penalty=<span class="keyword">None</span>, max_iter=<span class="number">50</span>, tol=<span class="number">1e-3</span>)</span><br><span class="line">sgd_clf.fit(X, y)</span><br><span class="line">y_pred = per_clf.predict([[<span class="number">2</span>, <span class="number">0.5</span>]])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred</span><br></pre></td></tr></table></figure><pre><code>array([1])</code></pre><h1 id="使用TensorFlow高级API"><a href="#使用TensorFlow高级API" class="headerlink" title="使用TensorFlow高级API"></a>使用TensorFlow高级API</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">(X_train, y_train),(X_test, y_test) = tf.keras.datasets.mnist.load_data()</span><br><span class="line">X_train = X_train.astype(np.float32).reshape(<span class="number">-1</span>, <span class="number">28</span>*<span class="number">28</span>) / <span class="number">255.0</span></span><br><span class="line">X_test = X_test.astype(np.float32).reshape(<span class="number">-1</span>, <span class="number">28</span>*<span class="number">28</span>) / <span class="number">255.0</span></span><br><span class="line">y_train = y_train.astype(np.int32)</span><br><span class="line">y_test = y_test.astype(np.int32)</span><br><span class="line">X_valid, X_train = X_train[:<span class="number">5000</span>], X_train[<span class="number">5000</span>:]</span><br><span class="line">y_valid, y_train = y_train[:<span class="number">5000</span>], y_train[<span class="number">5000</span>:]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">feature_columns = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)</span><br><span class="line">dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[<span class="number">300</span>, <span class="number">100</span>], n_classes=<span class="number">10</span>,</span><br><span class="line">                                        feature_columns=feature_columns)</span><br><span class="line">dnn_clf.fit(X_train, y_train, batch_size=<span class="number">50</span>, steps=<span class="number">40000</span>)</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Using default config.WARNING:tensorflow:Using temporary folder as model directory: C:\Users\deng.xj\AppData\Local\Temp\tmpoqlzthawINFO:tensorflow:Using config: {&#39;_task_type&#39;: None, &#39;_task_id&#39;: 0, &#39;_cluster_spec&#39;: &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x000001BB66D724A8&gt;, &#39;_master&#39;: &#39;&#39;, &#39;_num_ps_replicas&#39;: 0, &#39;_num_worker_replicas&#39;: 0, &#39;_environment&#39;: &#39;local&#39;, &#39;_is_chief&#39;: True, &#39;_evaluation_master&#39;: &#39;&#39;, &#39;_train_distribute&#39;: None, &#39;_eval_distribute&#39;: None, &#39;_device_fn&#39;: None, &#39;_tf_config&#39;: gpu_options {  per_process_gpu_memory_fraction: 1.0}, &#39;_tf_random_seed&#39;: None, &#39;_save_summary_steps&#39;: 100, &#39;_save_checkpoints_secs&#39;: 600, &#39;_log_step_count_steps&#39;: 100, &#39;_protocol&#39;: None, &#39;_session_config&#39;: None, &#39;_save_checkpoints_steps&#39;: None, &#39;_keep_checkpoint_max&#39;: 5, &#39;_keep_checkpoint_every_n_hours&#39;: 10000, &#39;_model_dir&#39;: &#39;C:\\Users\\deng.xj\\AppData\\Local\\Temp\\tmpoqlzthaw&#39;}WARNING:tensorflow:From &lt;ipython-input-6-90ea1841712a&gt;:4: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.Instructions for updating:Estimator is decoupled from Scikit Learn interface by moving intoseparate class SKCompat. Arguments x, y and batch_size are onlyavailable in the SKCompat class, Estimator will only accept input_fn.Example conversion:  est = Estimator(...) -&gt; est = SKCompat(Estimator(...))WARNING:tensorflow:From &lt;ipython-input-6-90ea1841712a&gt;:4: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.Instructions for updating:Estimator is decoupled from Scikit Learn interface by moving intoseparate class SKCompat. Arguments x, y and batch_size are onlyavailable in the SKCompat class, Estimator will only accept input_fn.Example conversion:  est = Estimator(...) -&gt; est = SKCompat(Estimator(...))WARNING:tensorflow:From &lt;ipython-input-6-90ea1841712a&gt;:4: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.Instructions for updating:Estimator is decoupled from Scikit Learn interface by moving intoseparate class SKCompat. Arguments x, y and batch_size are onlyavailable in the SKCompat class, Estimator will only accept input_fn.Example conversion:  est = Estimator(...) -&gt; est = SKCompat(Estimator(...))WARNING:tensorflow:From e:\python\python36\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\estimator.py:509: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.Instructions for updating:Please switch to the Estimator interface.WARNING:tensorflow:From e:\python\python36\lib\site-packages\tensorflow\contrib\learn\python\learn\learn_io\data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.Instructions for updating:Please access pandas data directly.WARNING:tensorflow:From e:\python\python36\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.Instructions for updating:When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.INFO:tensorflow:Create CheckpointSaverHook.INFO:tensorflow:Graph was finalized.INFO:tensorflow:Running local_init_op.INFO:tensorflow:Done running local_init_op.INFO:tensorflow:Saving checkpoints for 0 into C:\Users\deng.xj\AppData\Local\Temp\tmpoqlzthaw\model.ckpt.INFO:tensorflow:loss = 2.292883, step = 1INFO:tensorflow:global_step/sec: 238.165INFO:tensorflow:loss = 0.32534814, step = 101 (0.422 sec)INFO:tensorflow:global_step/sec: 338.742...INFO:tensorflow:loss = 0.0007182892, step = 39601 (0.298 sec)INFO:tensorflow:global_step/sec: 333.114INFO:tensorflow:loss = 0.00014897775, step = 39701 (0.300 sec)INFO:tensorflow:global_step/sec: 342.208INFO:tensorflow:loss = 0.0010287359, step = 39801 (0.292 sec)INFO:tensorflow:global_step/sec: 333.116INFO:tensorflow:loss = 0.0009217943, step = 39901 (0.300 sec)INFO:tensorflow:Saving checkpoints for 40000 into C:\Users\deng.xj\AppData\Local\Temp\tmpoqlzthaw\model.ckpt.INFO:tensorflow:Loss for final step: 0.00035940565.DNNClassifier(params={&#39;head&#39;: &lt;tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x000001BB6821B668&gt;, &#39;hidden_units&#39;: [300, 100], &#39;feature_columns&#39;: (_RealValuedColumn(column_name=&#39;&#39;, dimension=784, default_value=None, dtype=tf.float32, normalizer=None),), &#39;optimizer&#39;: None, &#39;activation_fn&#39;: &lt;function relu at 0x000001BB6378FF28&gt;, &#39;dropout&#39;: None, &#39;gradient_clip_norm&#39;: None, &#39;embedding_lr_multipliers&#39;: None, &#39;input_layer_min_slice_size&#39;: None})</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">y_pred = list(dnn_clf.predict(X_test))</span><br><span class="line">accuracy_score(y_test,y_pred)</span><br></pre></td></tr></table></figure><pre><code>WARNING:tensorflow:From e:\python\python36\lib\site-packages\tensorflow\python\util\deprecation.py:553: calling DNNClassifier.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.Instructions for updating:Please switch to predict_classes, or set `outputs` argument.WARNING:tensorflow:From e:\python\python36\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\dnn.py:463: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.Instructions for updating:Estimator is decoupled from Scikit Learn interface by moving intoseparate class SKCompat. Arguments x, y and batch_size are onlyavailable in the SKCompat class, Estimator will only accept input_fn.Example conversion:  est = Estimator(...) -&gt; est = SKCompat(Estimator(...))INFO:tensorflow:Graph was finalized.INFO:tensorflow:Restoring parameters from C:\Users\deng.xj\AppData\Local\Temp\tmpoqlzthaw\model.ckpt-40000INFO:tensorflow:Running local_init_op.INFO:tensorflow:Done running local_init_op.0.9814</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dnn_clf.evaluate(X_test, y_test)</span><br></pre></td></tr></table></figure><pre><code>WARNING:tensorflow:From &lt;ipython-input-8-862f84b3278e&gt;:1: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.Instructions for updating:Estimator is decoupled from Scikit Learn interface by moving intoseparate class SKCompat. Arguments x, y and batch_size are onlyavailable in the SKCompat class, Estimator will only accept input_fn.Example conversion:  est = Estimator(...) -&gt; est = SKCompat(Estimator(...))WARNING:tensorflow:From &lt;ipython-input-8-862f84b3278e&gt;:1: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.Instructions for updating:Estimator is decoupled from Scikit Learn interface by moving intoseparate class SKCompat. Arguments x, y and batch_size are onlyavailable in the SKCompat class, Estimator will only accept input_fn.Example conversion:  est = Estimator(...) -&gt; est = SKCompat(Estimator(...))INFO:tensorflow:Starting evaluation at 2018-12-17-02:39:23INFO:tensorflow:Graph was finalized.INFO:tensorflow:Restoring parameters from C:\Users\deng.xj\AppData\Local\Temp\tmpoqlzthaw\model.ckpt-40000INFO:tensorflow:Running local_init_op.INFO:tensorflow:Done running local_init_op.INFO:tensorflow:Finished evaluation at 2018-12-17-02:39:23INFO:tensorflow:Saving dict for global step 40000: accuracy = 0.9814, global_step = 40000, loss = 0.07299631{&#39;accuracy&#39;: 0.9814, &#39;global_step&#39;: 40000, &#39;loss&#39;: 0.07299631}</code></pre><h1 id="手写DNN"><a href="#手写DNN" class="headerlink" title="手写DNN"></a>手写DNN</h1><h2 id="数据构造"><a href="#数据构造" class="headerlink" title="数据构造"></a>数据构造</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.reset_default_graph()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorboard <span class="keyword">as</span> tb</span><br><span class="line"></span><br><span class="line">n_inputs = <span class="number">28</span>*<span class="number">28</span></span><br><span class="line">n_hidden1 = <span class="number">300</span></span><br><span class="line">n_hidden2 = <span class="number">100</span></span><br><span class="line">n_outputs = <span class="number">10</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_inputs), name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.placeholder(tf.int32, shape=(<span class="keyword">None</span>), name=<span class="string">"y"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">neuron_layer</span><span class="params">(X, n_neurons, name, activation=None)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(name):</span><br><span class="line">        <span class="comment"># 每一层建立一个名字空间</span></span><br><span class="line">        n_inputs = int(X.get_shape()[<span class="number">1</span>])<span class="comment"># 获取特征数</span></span><br><span class="line">        stddev = <span class="number">2</span> / np.sqrt(n_inputs)</span><br><span class="line">        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)</span><br><span class="line">        W = tf.Variable(init, name=<span class="string">"weights"</span>)</span><br><span class="line">        b = tf.Variable(tf.zeros([n_neurons]), name=<span class="string">"biases"</span>)</span><br><span class="line">        z = tf.matmul(X, W) + b</span><br><span class="line">        <span class="keyword">if</span> activation==<span class="string">"relu"</span>:</span><br><span class="line">            <span class="keyword">return</span> tf.nn.relu(z)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> z</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"dnn"</span>):</span><br><span class="line">    hidden1 = neuron_layer(X, n_hidden1, <span class="string">"hidden1"</span>, activation=<span class="string">"relu"</span>)</span><br><span class="line">    hidden2 = neuron_layer(hidden1, n_hidden2, <span class="string">"hidden2"</span>, activation=<span class="string">"relu"</span>)</span><br><span class="line">    logits =neuron_layer(hidden2, n_outputs, <span class="string">"outputs"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"loss"</span>):</span><br><span class="line">    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)</span><br><span class="line">    loss = tf.reduce_mean(xentropy, name=<span class="string">"loss"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"train"</span>):</span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate)</span><br><span class="line">    training_op = optimizer.minimize(loss)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"eval"</span>):</span><br><span class="line">    correct = tf.nn.in_top_k(logits, y, <span class="number">1</span>)</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure><h2 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">40</span></span><br><span class="line">batch_size = <span class="number">50</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shuffle_batch</span><span class="params">(X, y, batch_size)</span>:</span></span><br><span class="line">    rnd_idx = np.random.permutation(len(X))</span><br><span class="line">    n_batches = len(X) // batch_size</span><br><span class="line">    <span class="keyword">for</span> batch_idx <span class="keyword">in</span> np.array_split(rnd_idx, n_batches):</span><br><span class="line">        X_batch, y_batch = X[batch_idx], y[batch_idx]</span><br><span class="line">        <span class="keyword">yield</span> X_batch, y_batch</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> shuffle_batch(X_train, y_train, batch_size):</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        acc_batch = accuracy.eval(feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">        acc_val = accuracy.eval(feed_dict=&#123;X: X_valid, y: y_valid&#125;)</span><br><span class="line">        print(epoch, <span class="string">"Batch accuracy:"</span>, acc_batch, <span class="string">"Val accuracy:"</span>, acc_val)</span><br><span class="line">    save_path = saver.save(sess, <span class="string">"./dnn/my_model_final.ckpt"</span>)</span><br></pre></td></tr></table></figure><pre><code>0 Batch accuracy: 0.94 Val accuracy: 0.9111 Batch accuracy: 1.0 Val accuracy: 0.93162 Batch accuracy: 0.9 Val accuracy: 0.9433 Batch accuracy: 0.92 Val accuracy: 0.94844 Batch accuracy: 0.92 Val accuracy: 0.95285 Batch accuracy: 0.94 Val accuracy: 0.95566 Batch accuracy: 0.98 Val accuracy: 0.9577 Batch accuracy: 0.94 Val accuracy: 0.9618 Batch accuracy: 0.98 Val accuracy: 0.96369 Batch accuracy: 1.0 Val accuracy: 0.966210 Batch accuracy: 0.98 Val accuracy: 0.96611 Batch accuracy: 0.98 Val accuracy: 0.968812 Batch accuracy: 1.0 Val accuracy: 0.970213 Batch accuracy: 0.96 Val accuracy: 0.970614 Batch accuracy: 0.98 Val accuracy: 0.972415 Batch accuracy: 0.98 Val accuracy: 0.97216 Batch accuracy: 1.0 Val accuracy: 0.972417 Batch accuracy: 0.96 Val accuracy: 0.975218 Batch accuracy: 1.0 Val accuracy: 0.974619 Batch accuracy: 1.0 Val accuracy: 0.973620 Batch accuracy: 0.98 Val accuracy: 0.976621 Batch accuracy: 0.98 Val accuracy: 0.97622 Batch accuracy: 0.98 Val accuracy: 0.977823 Batch accuracy: 0.98 Val accuracy: 0.97624 Batch accuracy: 1.0 Val accuracy: 0.97625 Batch accuracy: 1.0 Val accuracy: 0.976826 Batch accuracy: 0.98 Val accuracy: 0.97627 Batch accuracy: 0.98 Val accuracy: 0.977428 Batch accuracy: 1.0 Val accuracy: 0.978229 Batch accuracy: 1.0 Val accuracy: 0.977230 Batch accuracy: 0.98 Val accuracy: 0.976431 Batch accuracy: 0.98 Val accuracy: 0.977832 Batch accuracy: 0.98 Val accuracy: 0.979233 Batch accuracy: 1.0 Val accuracy: 0.977634 Batch accuracy: 0.98 Val accuracy: 0.978635 Batch accuracy: 1.0 Val accuracy: 0.97936 Batch accuracy: 1.0 Val accuracy: 0.978237 Batch accuracy: 1.0 Val accuracy: 0.979838 Batch accuracy: 1.0 Val accuracy: 0.979239 Batch accuracy: 1.0 Val accuracy: 0.9788</code></pre><h2 id="使用神经网络"><a href="#使用神经网络" class="headerlink" title="使用神经网络"></a>使用神经网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, <span class="string">"./dnn/my_model_final.ckpt"</span>)</span><br><span class="line">    X_new_scaled = X_test[:<span class="number">20</span>]</span><br><span class="line">    Z = logits.eval(feed_dict=&#123;X: X_new_scaled&#125;)</span><br><span class="line">    y_pred = np.argmax(Z, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from ./dnn/my_model_final.ckpt</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Predicted classes:"</span>, y_pred)</span><br><span class="line">print(<span class="string">"Actual classes:"</span>, y_test[:<span class="number">20</span>])</span><br></pre></td></tr></table></figure><pre><code>Predicted classes: [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]Actual classes: [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]</code></pre><hr><p><a href="https://github.com/coldJune/machineLearning/blob/master/handson-ml/Introduction%20of%20Artificial%20Neural%20Networks.ipynb" target="_blank" rel="noopener">源文件</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;感知器&quot;&gt;&lt;a href=&quot;#感知器&quot; class=&quot;headerlink&quot; title=&quot;感知器&quot;&gt;&lt;/a&gt;感知器&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;
      
    
    </summary>
    
      <category term="机器学习" scheme="http://coldjune.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow" scheme="http://coldjune.com/tags/tensorflow/"/>
    
      <category term="Hands-On Machine Learning with Scikit-Learn and TensorFlow" scheme="http://coldjune.com/tags/Hands-On-Machine-Learning-with-Scikit-Learn-and-TensorFlow/"/>
    
      <category term="神经网络" scheme="http://coldjune.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Up and Runing with TensorFlow</title>
    <link href="http://coldjune.com/2018/12/13/Up-and-Runing-with-TensorFlow/"/>
    <id>http://coldjune.com/2018/12/13/Up-and-Runing-with-TensorFlow/</id>
    <published>2018-12-13T09:28:38.000Z</published>
    <updated>2018-12-17T10:56:33.000Z</updated>
    
    <content type="html"><![CDATA[<hr><h1 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 非立即执行而是创建一个图</span></span><br><span class="line">x = tf.Variable(<span class="number">3</span>, name=<span class="string">"x"</span>)</span><br><span class="line">y = tf.Variable(<span class="number">4</span>, name=<span class="string">"y"</span>)</span><br><span class="line">f = x*x*y + y + <span class="number">2</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打开session执行</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(x.initializer)</span><br><span class="line">sess.run(y.initializer)</span><br><span class="line">result = sess.run(f)</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure><pre><code>42</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭session</span></span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用块结构运行</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    x.initializer.run()</span><br><span class="line">    y.initializer.run()</span><br><span class="line">    result = f.eval()</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure><pre><code>42</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用global_variables_initialzer创建全局初始化</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init.run()</span><br><span class="line">    result = f.eval()</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure><pre><code>42</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用交互式session</span></span><br><span class="line">sess = tf.InteractiveSession()</span><br><span class="line">init.run()</span><br><span class="line">result = f.eval()</span><br><span class="line">print(result)</span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure><pre><code>42</code></pre><h1 id="管理图"><a href="#管理图" class="headerlink" title="管理图"></a>管理图</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x1 = tf.Variable(<span class="number">1</span>)</span><br><span class="line">x1.graph <span class="keyword">is</span> tf.get_default_graph()</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建独立的图</span></span><br><span class="line">graph = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> graph.as_default():</span><br><span class="line">    x2 = tf.Variable(<span class="number">2</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x2.graph <span class="keyword">is</span> graph</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x2.graph <span class="keyword">is</span> tf.get_default_graph()</span><br></pre></td></tr></table></figure><pre><code>False</code></pre><h1 id="节点的生命周期"><a href="#节点的生命周期" class="headerlink" title="节点的生命周期"></a>节点的生命周期</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">w = tf.constant(<span class="number">3</span>)</span><br><span class="line">x = w + <span class="number">2</span></span><br><span class="line">y = x + <span class="number">5</span></span><br><span class="line">z = x + <span class="number">3</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#未重复利用结果w和x</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(y.eval())</span><br><span class="line">    print(z.eval())</span><br></pre></td></tr></table></figure><pre><code>108</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将y和z放在同一个图中以重复利用w和x</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    y_val, z_val = sess.run([y, z])</span><br><span class="line">    print(y_val)</span><br><span class="line">    print(z_val)</span><br></pre></td></tr></table></figure><pre><code>108</code></pre><h1 id="使用TensorFlow训练线性回归"><a href="#使用TensorFlow训练线性回归" class="headerlink" title="使用TensorFlow训练线性回归"></a>使用TensorFlow训练线性回归</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_california_housing</span><br><span class="line"></span><br><span class="line">housing = fetch_california_housing()</span><br><span class="line">m, n = housing.data.shape</span><br><span class="line">housing_data_plus_bias = np.c_[np.ones((m, <span class="number">1</span>)), housing.data]</span><br><span class="line"></span><br><span class="line">X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.constant(housing.target.reshape(<span class="number">-1</span>,<span class="number">1</span>), dtype=tf.float32, name=<span class="string">"y"</span>)</span><br><span class="line">XT = tf.transpose(X)</span><br><span class="line"><span class="comment"># 使用正规方程计算theta</span></span><br><span class="line">theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    theta_value = theta.eval()</span><br><span class="line">    print(theta_value[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure><pre><code>[[-3.7185181e+01] [ 4.3633747e-01] [ 9.3952334e-03] [-1.0711310e-01] [ 6.4479220e-01]]</code></pre><h1 id="实现梯度下降"><a href="#实现梯度下降" class="headerlink" title="实现梯度下降"></a>实现梯度下降</h1><h2 id="手动计算梯度"><a href="#手动计算梯度" class="headerlink" title="手动计算梯度"></a>手动计算梯度</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">scale_housing_data = scaler.fit_transform(housing.data)</span><br><span class="line">scale_housing_data_bias = np.c_[np.ones((m, <span class="number">1</span>)), scale_housing_data]</span><br><span class="line"></span><br><span class="line">n_epochs = <span class="number">1000</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line">X = tf.constant(scale_housing_data_bias, dtype=tf.float32, name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.constant(housing.target.reshape(<span class="number">-1</span>,<span class="number">1</span>), dtype=tf.float32, name=<span class="string">"y"</span>)</span><br><span class="line">theta = tf.Variable(tf.random_normal([n+<span class="number">1</span>, <span class="number">1</span>], <span class="number">-1.0</span>, <span class="number">1.0</span>), name=<span class="string">"theta"</span>)</span><br><span class="line">y_pred = tf.matmul(X, theta, name=<span class="string">"predictions"</span>)</span><br><span class="line">error = y_pred - y</span><br><span class="line">mse = tf.reduce_mean(tf.square(error), name=<span class="string">"mse"</span>)</span><br><span class="line">gradients = <span class="number">2</span>/m * tf.matmul(tf.transpose(X), error)</span><br><span class="line">training_op = tf.assign(theta, theta-learning_rate*gradients)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Epoch"</span>, epoch, <span class="string">"MSE="</span>, mse.eval())</span><br><span class="line">        sess.run(training_op)</span><br><span class="line"></span><br><span class="line">    best_theta = theta.eval()</span><br><span class="line">    print(best_theta[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure><pre><code>Epoch 0 MSE= 8.3278Epoch 100 MSE= 0.78606343Epoch 200 MSE= 0.64422286Epoch 300 MSE= 0.6223913Epoch 400 MSE= 0.6058846Epoch 500 MSE= 0.59219676Epoch 600 MSE= 0.58081675Epoch 700 MSE= 0.57135147Epoch 800 MSE= 0.5634769Epoch 900 MSE= 0.5569242[[2.0685523 ] [0.6491688 ] [0.08126644] [0.06857597] [0.03242581]]</code></pre><h2 id="使用自动微分"><a href="#使用自动微分" class="headerlink" title="使用自动微分"></a>使用自动微分</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gradients = tf.gradients(mse, [theta])[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><h2 id="使用优化器"><a href="#使用优化器" class="headerlink" title="使用优化器"></a>使用优化器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 梯度下降优化器</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)</span><br><span class="line">training_op = optimizer.minimize(mse)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 动量优化器</span></span><br><span class="line">optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><h1 id="输送数据"><a href="#输送数据" class="headerlink" title="输送数据"></a>输送数据</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用占位符</span></span><br><span class="line">A = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, <span class="number">3</span>))</span><br><span class="line">B = A + <span class="number">5</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    B_val_1 = B.eval(feed_dict=&#123;A: [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]]&#125;)</span><br><span class="line">    B_val_2 = B.eval(feed_dict=&#123;A: [[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]]&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(B_val_1)</span><br></pre></td></tr></table></figure><pre><code>[[6. 7. 8.]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(B_val_2)</span><br></pre></td></tr></table></figure><pre><code>[[ 9. 10. 11.] [12. 13. 14.]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 小批量梯度下降</span></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n+<span class="number">1</span>), name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, <span class="number">1</span>), name=<span class="string">"y"</span>)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">n_batches = int(np.ceil(m / batch_size))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetch_batch</span><span class="params">(epoch, batch_index, batch_size)</span>:</span></span><br><span class="line">    np.random.seed(epoch * n_batches + batch_index)</span><br><span class="line">    indices = np.random.randint(m, size=batch_size)</span><br><span class="line">    X_batch = scale_housing_data_bias[indices]</span><br><span class="line">    y_batch = housing.target.reshape(<span class="number">-1</span>, <span class="number">1</span>)[indices]</span><br><span class="line">    <span class="keyword">return</span> X_batch, y_batch</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">for</span> batch_index <span class="keyword">in</span> range(n_batches):</span><br><span class="line">            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line"></span><br><span class="line">    best_theta = theta.eval()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_theta</span><br></pre></td></tr></table></figure><pre><code>array([[ 2.0685525 ],       [ 0.8296056 ],       [ 0.11874896],       [-0.26550332],       [ 0.3056771 ],       [-0.00450377],       [-0.03932568],       [-0.89991784],       [-0.87057173]], dtype=float32)</code></pre><h1 id="保存和加载模型"><a href="#保存和加载模型" class="headerlink" title="保存和加载模型"></a>保存和加载模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">1000</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line">X = tf.constant(scale_housing_data_bias, dtype=tf.float32, name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.constant(housing.target.reshape(<span class="number">-1</span>, <span class="number">1</span>), dtype=tf.float32, name=<span class="string">"y"</span>)</span><br><span class="line">theta = tf.Variable(tf.random_normal([n+<span class="number">1</span>, <span class="number">1</span>], <span class="number">-1.0</span>, <span class="number">1.0</span>, seed=<span class="number">42</span>), name=<span class="string">"theta"</span>)</span><br><span class="line">y_pred = tf.matmul(X, theta, name=<span class="string">"predictions"</span>)</span><br><span class="line">error = y_pred - y</span><br><span class="line">mse = tf.reduce_mean(tf.square(error), name=<span class="string">"mse"</span>)</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)</span><br><span class="line">training_op = optimizer.minimize(mse)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"epoch"</span>, epoch, <span class="string">"MSE="</span>, mse.eval())</span><br><span class="line">            save_path = saver.save(sess, <span class="string">"tmp/my_model.ckpt"</span>)</span><br><span class="line">        sess.run(training_op)</span><br><span class="line"></span><br><span class="line">    best_theta = theta.eval()</span><br><span class="line">    save_path = saver.save(sess, <span class="string">'tmp/my_model_final.ckpt'</span>)</span><br></pre></td></tr></table></figure><pre><code>epoch 0 MSE= 34.112576epoch 100 MSE= 1.2404147epoch 200 MSE= 0.62713087epoch 300 MSE= 0.58235973epoch 400 MSE= 0.5691915epoch 500 MSE= 0.5602364epoch 600 MSE= 0.55325645epoch 700 MSE= 0.54772204epoch 800 MSE= 0.54330814epoch 900 MSE= 0.53977317</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_theta</span><br></pre></td></tr></table></figure><pre><code>array([[ 2.0685523 ],       [ 0.68664634],       [ 0.10857289],       [ 0.03570269],       [ 0.04292491],       [-0.00635225],       [-0.0354162 ],       [-1.1083173 ],       [-1.0608274 ]], dtype=float32)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, <span class="string">"tmp/my_model_final.ckpt"</span>)</span><br><span class="line">    best_theta_restored = theta.eval()</span><br></pre></td></tr></table></figure><pre><code>INFO:tensorflow:Restoring parameters from tmp/my_model_final.ckpt</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.allclose(best_theta, best_theta_restored)</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#保存指定变量</span></span><br><span class="line">saver = tf.train.Saver(&#123;<span class="string">"weights"</span>: theta&#125;)</span><br></pre></td></tr></table></figure><h1 id="使用TensorBoard"><a href="#使用TensorBoard" class="headerlink" title="使用TensorBoard"></a>使用TensorBoard</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">now = datetime.utcnow().strftime(<span class="string">"%Y%m%d%H%M%S"</span>)</span><br><span class="line">root_logdir = <span class="string">"tf_logs"</span></span><br><span class="line">logdir = <span class="string">"&#123;&#125;/run-&#123;&#125;/"</span>.format(root_logdir, now)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">1000</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n + <span class="number">1</span>), name=<span class="string">"X"</span>)</span><br><span class="line">y = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, <span class="number">1</span>), name=<span class="string">"y"</span>)</span><br><span class="line">theta = tf.Variable(tf.random_uniform([n + <span class="number">1</span>, <span class="number">1</span>], <span class="number">-1.0</span>, <span class="number">1.0</span>, seed=<span class="number">42</span>), name=<span class="string">"theta"</span>)</span><br><span class="line">y_pred = tf.matmul(X, theta, name=<span class="string">"predictions"</span>)</span><br><span class="line">error = y_pred - y</span><br><span class="line">mse = tf.reduce_mean(tf.square(error), name=<span class="string">"mse"</span>)</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)</span><br><span class="line">training_op = optimizer.minimize(mse)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mse_summary = tf.summary.scalar(<span class="string">"MSE"</span>, mse)</span><br><span class="line">file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">n_batches = int(np.ceil(m / batch_size))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">        <span class="keyword">for</span> batch_index <span class="keyword">in</span> range(n_batches):</span><br><span class="line">            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)</span><br><span class="line">            <span class="keyword">if</span> batch_index% <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">                summary_str = mse_summary.eval(feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">                step = epoch * n_batches + batch_index</span><br><span class="line">                file_writer.add_summary(summary_str, step)</span><br><span class="line">            sess.run(training_op, feed_dict=&#123;X: X_batch, y: y_batch&#125;)</span><br><span class="line">    best_theta = theta.eval()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">file_writer.close()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_theta</span><br></pre></td></tr></table></figure><pre><code>array([[ 2.070016  ],       [ 0.8204561 ],       [ 0.1173173 ],       [-0.22739051],       [ 0.3113402 ],       [ 0.00353193],       [-0.01126994],       [-0.91643935],       [-0.8795008 ]], dtype=float32)</code></pre><h1 id="名称作用域"><a href="#名称作用域" class="headerlink" title="名称作用域"></a>名称作用域</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"loss"</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    error = y_pred - y</span><br><span class="line">    mse = tf.reduce_mean(tf.square(error), name=<span class="string">"mse"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(error.op.name)</span><br></pre></td></tr></table></figure><pre><code>loss/sub</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(mse.op.name)</span><br></pre></td></tr></table></figure><pre><code>loss/mse</code></pre><h1 id="模块性"><a href="#模块性" class="headerlink" title="模块性"></a>模块性</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.reset_default_graph()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">n_features = <span class="number">3</span></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_features), name=<span class="string">"X"</span>)</span><br><span class="line"></span><br><span class="line">w1 = tf.Variable(tf.random_normal((n_features, <span class="number">1</span>)), name=<span class="string">"weights1"</span>)</span><br><span class="line">w2 = tf.Variable(tf.random_normal((n_features, <span class="number">1</span>)), name=<span class="string">"weights2"</span>)</span><br><span class="line">b1 = tf.Variable(<span class="number">0.0</span>, name=<span class="string">"bias1"</span>)</span><br><span class="line">b2 = tf.Variable(<span class="number">0.0</span>, name=<span class="string">"bias2"</span>)</span><br><span class="line"></span><br><span class="line">z1 = tf.add(tf.matmul(X, w1), b1, name=<span class="string">"z1"</span>)</span><br><span class="line">z2 = tf.add(tf.matmul(X, w2), b2, name=<span class="string">"z2"</span>)</span><br><span class="line"></span><br><span class="line">relu1 = tf.maximum(z1, <span class="number">0</span>, name=<span class="string">"relu1"</span>)</span><br><span class="line">relu2 = tf.maximum(z2, <span class="number">0</span>, name=<span class="string">"relu2"</span>)</span><br><span class="line"></span><br><span class="line">output = tf.add(relu1, relu2, name=<span class="string">"output"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Don't Repeat Yourself</span></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(X)</span>:</span></span><br><span class="line">    w_shape = (int(X.get_shape()[<span class="number">1</span>]), <span class="number">1</span>)</span><br><span class="line">    w = tf.Variable(tf.random_normal(w_shape), name=<span class="string">"weights"</span>)</span><br><span class="line">    b = tf.Variable(<span class="number">0.0</span>, name=<span class="string">"bias"</span>)</span><br><span class="line">    z = tf.add(tf.matmul(X, w), b, name=<span class="string">"z"</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.maximum(z, <span class="number">0</span>, name=<span class="string">"relu"</span>)</span><br><span class="line"></span><br><span class="line">n_features = <span class="number">3</span></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_features), name=<span class="string">"X"</span>)</span><br><span class="line">relus = [relu(X) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>)]</span><br><span class="line">output = tf.add_n(relus, name=<span class="string">"output"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">file_writer = tf.summary.FileWriter(<span class="string">"logs/relu1"</span>, tf.get_default_graph())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">tf.reset_default_graph()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(X)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">"relu"</span>):</span><br><span class="line">        w_shape = (int(X.get_shape()[<span class="number">1</span>]), <span class="number">1</span>)</span><br><span class="line">        w = tf.Variable(tf.random_normal(w_shape), name=<span class="string">"weights"</span>)</span><br><span class="line">        b = tf.Variable(<span class="number">0.0</span>, name=<span class="string">"bias"</span>)</span><br><span class="line">        z = tf.add(tf.matmul(X, w), b, name=<span class="string">"z"</span>)</span><br><span class="line">        <span class="keyword">return</span> tf.maximum(z, <span class="number">0</span>, name=<span class="string">"max"</span>)</span><br><span class="line"></span><br><span class="line">n_features = <span class="number">3</span></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_features), name=<span class="string">"X"</span>)</span><br><span class="line">relus = [relu(X) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>)]</span><br><span class="line">output = tf.add_n(relus, name=<span class="string">"output"</span>)</span><br><span class="line">file_writer = tf.summary.FileWriter(<span class="string">"logs/relu2"</span>, tf.get_default_graph())</span><br></pre></td></tr></table></figure><h1 id="共享变量"><a href="#共享变量" class="headerlink" title="共享变量"></a>共享变量</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">tf.reset_default_graph()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(X, threshold)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">"relu"</span>):</span><br><span class="line">        w_shape = (int(X.get_shape()[<span class="number">1</span>]), <span class="number">1</span>)</span><br><span class="line">        w = tf.Variable(tf.random_normal(w_shape), name=<span class="string">"weights"</span>)</span><br><span class="line">        b = tf.Variable(<span class="number">0.0</span>, name=<span class="string">"bias"</span>)</span><br><span class="line">        z = tf.add(tf.matmul(X, w), b, name=<span class="string">"z"</span>)</span><br><span class="line">        <span class="keyword">return</span> tf.maximum(z, threshold, name=<span class="string">"max"</span>)</span><br><span class="line"></span><br><span class="line">threshold = tf.Variable(<span class="number">0.0</span>, name=<span class="string">"threshold"</span>)</span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_features), name=<span class="string">"X"</span>)</span><br><span class="line">relus = [relu(X, threshold) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>)]</span><br><span class="line">output = tf.add_n(relus, name=<span class="string">"output"</span>)</span><br><span class="line"></span><br><span class="line">file_writer = tf.summary.FileWriter(<span class="string">"logs/relu_threshold"</span>, tf.get_default_graph())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"relu"</span>):</span><br><span class="line">    threshold = tf.get_variable(<span class="string">"threshold"</span>, shape=(), initializer=tf.constant_initializer(<span class="number">0.0</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"relu"</span>, reuse=<span class="keyword">True</span>):<span class="comment">#重复使用</span></span><br><span class="line">    threshold = tf.get_variable(<span class="string">"threshold"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"relu"</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    scope.reuse_variables()</span><br><span class="line">    threshold = tf.get_variable(<span class="string">"threshold"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(X)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">"relu"</span>, reuse=<span class="keyword">True</span>):</span><br><span class="line">        threshold = tf.get_variable(<span class="string">"threshold"</span>)</span><br><span class="line">        w_shape = int(X.get_shape()[<span class="number">1</span>]), <span class="number">1</span></span><br><span class="line">        w = tf.Variable(tf.random_normal(w_shape), name=<span class="string">"weights"</span>)</span><br><span class="line">        b = tf.Variable(<span class="number">0.0</span>, name=<span class="string">'bias'</span>)</span><br><span class="line">        z = tf.add(tf.matmul(X, w), b, name=<span class="string">'z'</span>)</span><br><span class="line">        <span class="keyword">return</span> tf.maximum(z, threshold, name=<span class="string">"max"</span>)</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_features), name=<span class="string">"X"</span>)</span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"relu"</span>):</span><br><span class="line">    threshold = tf.get_variable(<span class="string">"threshold"</span>, shape=(), initializer=tf.constant_initializer(<span class="number">0.0</span>))</span><br><span class="line"></span><br><span class="line">relus = [relu(X) <span class="keyword">for</span> relu_index <span class="keyword">in</span> range(<span class="number">5</span>)]</span><br><span class="line">output = tf.add_n(relus, name=<span class="string">"output"</span>)</span><br><span class="line">file_writer = tf.summary.FileWriter(<span class="string">"logs/relu6"</span>, tf.get_default_graph())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(X)</span>:</span></span><br><span class="line">    threshold = tf.get_variable(<span class="string">"threshold"</span>, shape=(), initializer=tf.constant_initializer())</span><br><span class="line">    w_shape = int(X.get_shape()[<span class="number">1</span>]), <span class="number">1</span></span><br><span class="line">    w = tf.Variable(tf.random_normal(w_shape), name=<span class="string">"weights"</span>)</span><br><span class="line">    b = tf.Variable(<span class="number">0.0</span>, name=<span class="string">'bias'</span>)</span><br><span class="line">    z = tf.add(tf.matmul(X, w), b, name=<span class="string">'z'</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.maximum(z, threshold, name=<span class="string">"max"</span>)</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, n_features), name=<span class="string">"X"</span>)</span><br><span class="line">relus = []</span><br><span class="line"><span class="keyword">for</span> relu_index <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">"relu"</span>, reuse=(relu_index &gt;= <span class="number">1</span>)) <span class="keyword">as</span> scope:</span><br><span class="line">        relus.append(relu(X))</span><br><span class="line">output = tf.add_n(relus, name=<span class="string">"output"</span>)</span><br><span class="line">file_writer = tf.summary.FileWriter(<span class="string">"logs/relu7"</span>, tf.get_default_graph())</span><br></pre></td></tr></table></figure><hr><p><a href="https://github.com/coldJune/machineLearning/blob/master/handson-ml/Up%20and%20Runing%20with%20TensorFlow.ipynb" target="_blank" rel="noopener">源文件</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;hr&gt;
&lt;h1 id=&quot;Hello-World&quot;&gt;&lt;a href=&quot;#Hello-World&quot; class=&quot;headerlink&quot; title=&quot;Hello World&quot;&gt;&lt;/a&gt;Hello World&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;
      
    
    </summary>
    
      <category term="机器学习" scheme="http://coldjune.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Hands-On Machine Learning with Scikit-Learn and TensorFlow" scheme="http://coldjune.com/tags/Hands-On-Machine-Learning-with-Scikit-Learn-and-TensorFlow/"/>
    
      <category term="TensorFlow" scheme="http://coldjune.com/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>Dimensionality Reduction</title>
    <link href="http://coldjune.com/2018/12/12/Dimensionality-Reduction/"/>
    <id>http://coldjune.com/2018/12/12/Dimensionality-Reduction/</id>
    <published>2018-12-12T07:56:43.000Z</published>
    <updated>2018-12-12T12:49:19.000Z</updated>
    
    <content type="html"><![CDATA[<hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">4</span>)</span><br><span class="line">m = <span class="number">60</span></span><br><span class="line">w1, w2 = <span class="number">0.1</span>, <span class="number">0.3</span></span><br><span class="line">noise = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">angles = np.random.rand(m) * <span class="number">3</span> * np.pi / <span class="number">2</span> - <span class="number">0.5</span></span><br><span class="line">X = np.empty((m, <span class="number">3</span>))</span><br><span class="line">X[:, <span class="number">0</span>] = np.cos(angles) + np.sin(angles)/<span class="number">2</span> + noise * np.random.randn(m) / <span class="number">2</span></span><br><span class="line">X[:, <span class="number">1</span>] = np.sin(angles) * <span class="number">0.7</span> + noise * np.random.randn(m) / <span class="number">2</span></span><br><span class="line">X[:, <span class="number">2</span>] = X[:, <span class="number">0</span>] * w1 + X[:, <span class="number">1</span>] * w2 + noise * np.random.randn(m)</span><br></pre></td></tr></table></figure><h1 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a><a href="http://coldjune.com/2018/05/30/PCA/">PCA</a></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X_centred = X - X.mean(axis=<span class="number">0</span>)</span><br><span class="line">U, s, V = np.linalg.svd(X_centred)</span><br><span class="line">c1 = V.T[:, <span class="number">0</span>]</span><br><span class="line">c2 = V.T[:, <span class="number">1</span>]</span><br></pre></td></tr></table></figure><h2 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">W2 = V.T[:, :<span class="number">2</span>]</span><br><span class="line">X2D = X_centred.dot(W2)</span><br><span class="line">X2D[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><pre><code>array([[-1.26203346, -0.42067648],       [ 0.08001485,  0.35272239],       [-1.17545763, -0.36085729],       [-0.89305601,  0.30862856],       [-0.73016287,  0.25404049]])</code></pre><h2 id="使用sklearn"><a href="#使用sklearn" class="headerlink" title="使用sklearn"></a>使用sklearn</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">X2D = pca.fit_transform(X)</span><br><span class="line">X2D[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><pre><code>array([[ 1.26203346,  0.42067648],       [-0.08001485, -0.35272239],       [ 1.17545763,  0.36085729],       [ 0.89305601, -0.30862856],       [ 0.73016287, -0.25404049]])</code></pre><h2 id="可释方差"><a href="#可释方差" class="headerlink" title="可释方差"></a>可释方差</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(pca.explained_variance_ratio_)</span><br></pre></td></tr></table></figure><pre><code>[0.84248607 0.14631839]</code></pre><h2 id="选择正确的维度"><a href="#选择正确的维度" class="headerlink" title="选择正确的维度"></a>选择正确的维度</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA()</span><br><span class="line">pca.fit(X)</span><br><span class="line">cumsum = np.cumsum(pca.explained_variance_ratio_)</span><br><span class="line">d = np.argmax(cumsum &gt;= <span class="number">0.95</span>) + <span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA(n_components=<span class="number">0.95</span>)</span><br><span class="line">X_reduced = pca.fit_transform(X)</span><br></pre></td></tr></table></figure><h2 id="PCA压缩"><a href="#PCA压缩" class="headerlink" title="PCA压缩"></a>PCA压缩</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> six.moves <span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_mldata</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mnist = fetch_mldata(<span class="string">"MNIST original"</span>, data_home=<span class="string">'./datasets/'</span>)</span><br><span class="line"></span><br><span class="line">X = mnist[<span class="string">"data"</span>]</span><br><span class="line">y = mnist[<span class="string">"target"</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA(n_components=<span class="number">154</span>)</span><br><span class="line">X_mnist_reduced = pca.fit_transform(X_train)</span><br><span class="line">X_mnist_recovered = pca.fit_transform(X_mnist_reduced)</span><br></pre></td></tr></table></figure><h2 id="增量PCA"><a href="#增量PCA" class="headerlink" title="增量PCA"></a>增量PCA</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> IncrementalPCA</span><br><span class="line"></span><br><span class="line">n_batches = <span class="number">100</span></span><br><span class="line">inc_pca = IncrementalPCA(n_components=<span class="number">154</span>)</span><br><span class="line"><span class="keyword">for</span> X_batch <span class="keyword">in</span> np.array_split(X_train, n_batches):</span><br><span class="line">    inc_pca.partial_fit(X_batch)</span><br><span class="line"></span><br><span class="line">X_mnist_reduced = inc_pca.transform(X_train)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">filename = <span class="string">"my_mnist.data"</span></span><br><span class="line">m, n = X_train.shape</span><br><span class="line"></span><br><span class="line">X_mm = np.memmap(filename, dtype=<span class="string">'float32'</span>, mode=<span class="string">'write'</span>, shape=(m, n))</span><br><span class="line">X_mm[:] = X_train</span><br><span class="line"><span class="keyword">del</span> X_mm</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X_mm = np.memmap(filename, dtype=<span class="string">'float32'</span>, mode=<span class="string">'readonly'</span>, shape=(m, n))</span><br><span class="line"></span><br><span class="line">batch_size = m // n_batches</span><br><span class="line">inc_pca = IncrementalPCA(n_components=<span class="number">154</span>, batch_size=batch_size)</span><br><span class="line">inc_pca.fit(X_mm)</span><br></pre></td></tr></table></figure><pre><code>IncrementalPCA(batch_size=525, copy=True, n_components=154, whiten=False)</code></pre><h2 id="随机PCA"><a href="#随机PCA" class="headerlink" title="随机PCA"></a>随机PCA</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rnd_pca = PCA(n_components=<span class="number">154</span>, svd_solver=<span class="string">'randomized'</span>)</span><br><span class="line">X_reduced = rnd_pca.fit_transform(X_train)</span><br></pre></td></tr></table></figure><h1 id="Kernel-PCA"><a href="#Kernel-PCA" class="headerlink" title="Kernel PCA"></a>Kernel PCA</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用径向核函数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> KernelPCA</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_swiss_roll</span><br><span class="line">X, t = make_swiss_roll(n_samples=<span class="number">1000</span>, noise=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line">y = t &gt; <span class="number">6.9</span></span><br><span class="line">rbf_pca = KernelPCA(n_components=<span class="number">2</span>, kernel=<span class="string">'rbf'</span>, gamma=<span class="number">0.04</span>)</span><br><span class="line">X_reduced = rbf_pca.fit_transform(X)</span><br></pre></td></tr></table></figure><h2 id="选取核函数和调整超参数"><a href="#选取核函数和调整超参数" class="headerlink" title="选取核函数和调整超参数"></a>选取核函数和调整超参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line">clf = Pipeline([</span><br><span class="line">    (<span class="string">"kpca"</span>, KernelPCA(n_components=<span class="number">2</span>)),</span><br><span class="line">    (<span class="string">"log_reg"</span>, LogisticRegression(solver=<span class="string">'lbfgs'</span>))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">param_grid = [&#123;</span><br><span class="line">    <span class="string">"kpca__gamma"</span>: np.linspace(<span class="number">0.03</span>, <span class="number">0.05</span>, <span class="number">10</span>),</span><br><span class="line">    <span class="string">"kpca__kernel"</span>: [<span class="string">"rbf"</span>, <span class="string">"sigmoid"</span>]</span><br><span class="line">&#125;]</span><br><span class="line"></span><br><span class="line">grid_search = GridSearchCV(clf, param_grid, cv=<span class="number">3</span>)</span><br><span class="line">grid_search.fit(X, y)</span><br></pre></td></tr></table></figure><pre><code>GridSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,       estimator=Pipeline(memory=None,     steps=[(&#39;kpca&#39;, KernelPCA(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver=&#39;auto&#39;,     fit_inverse_transform=False, gamma=None, kernel=&#39;linear&#39;,     kernel_params=None, max_iter=None, n_components=2, n_jobs=None,     random_state=None, remove_zero_eig=False, tol=0)), (&#39;log_reg&#39;, LogisticRe...enalty=&#39;l2&#39;, random_state=None, solver=&#39;lbfgs&#39;,          tol=0.0001, verbose=0, warm_start=False))]),       fit_params=None, iid=&#39;warn&#39;, n_jobs=None,       param_grid=[{&#39;kpca__gamma&#39;: array([0.03   , 0.03222, 0.03444, 0.03667, 0.03889, 0.04111, 0.04333,       0.04556, 0.04778, 0.05   ]), &#39;kpca__kernel&#39;: [&#39;rbf&#39;, &#39;sigmoid&#39;]}],       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,       scoring=None, verbose=0)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(grid_search.best_params_)</span><br></pre></td></tr></table></figure><pre><code>{&#39;kpca__gamma&#39;: 0.043333333333333335, &#39;kpca__kernel&#39;: &#39;rbf&#39;}</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 恢复</span></span><br><span class="line">rbf_pca = KernelPCA(n_components=<span class="number">2</span>, kernel=<span class="string">'rbf'</span>, gamma=<span class="number">0.0433</span>, fit_inverse_transform=<span class="keyword">True</span>)</span><br><span class="line">X_reduced = rbf_pca.fit_transform(X)</span><br><span class="line">X_preimage = rbf_pca.inverse_transform(X_reduced)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line">mean_squared_error(X, X_preimage)</span><br></pre></td></tr></table></figure><pre><code>32.78630879576614</code></pre><h1 id="LLE"><a href="#LLE" class="headerlink" title="LLE"></a>LLE</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> LocallyLinearEmbedding</span><br><span class="line"></span><br><span class="line">lle = LocallyLinearEmbedding(n_components=<span class="number">2</span>, n_neighbors=<span class="number">10</span>)</span><br><span class="line">X_reduced = lle.fit_transform(X)</span><br></pre></td></tr></table></figure><hr><p><a href="https://github.com/coldJune/machineLearning/blob/master/handson-ml/Dimensionality%20Reduction.ipynb" target="_blank" rel="noopener">源文件</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;hr&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span
      
    
    </summary>
    
      <category term="机器学习" scheme="http://coldjune.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Hands-On Machine Learning with Scikit-Learn and TensorFlow" scheme="http://coldjune.com/tags/Hands-On-Machine-Learning-with-Scikit-Learn-and-TensorFlow/"/>
    
      <category term="sklearn" scheme="http://coldjune.com/tags/sklearn/"/>
    
      <category term="PCA" scheme="http://coldjune.com/tags/PCA/"/>
    
      <category term="维度约简" scheme="http://coldjune.com/tags/%E7%BB%B4%E5%BA%A6%E7%BA%A6%E7%AE%80/"/>
    
  </entry>
  
  <entry>
    <title>Ensemble Learning and Random Forests</title>
    <link href="http://coldjune.com/2018/12/11/Ensemble-Learning-and-Random-Forests/"/>
    <id>http://coldjune.com/2018/12/11/Ensemble-Learning-and-Random-Forests/</id>
    <published>2018-12-11T07:38:30.000Z</published>
    <updated>2018-12-12T12:49:19.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="选举式分类器"><a href="#选举式分类器" class="headerlink" title="选举式分类器"></a>选举式分类器</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_moons</span><br><span class="line"></span><br><span class="line">X, y = make_moons(n_samples=<span class="number">500</span>, noise=<span class="number">0.30</span>, random_state=<span class="number">42</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y , random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> VotingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line">log_clf = LogisticRegression(solver=<span class="string">'lbfgs'</span>)</span><br><span class="line">rnd_clf = RandomForestClassifier(n_estimators=<span class="number">10</span>)</span><br><span class="line">svm_clf = SVC(gamma=<span class="string">'auto'</span>)</span><br><span class="line"></span><br><span class="line">voting_clf = VotingClassifier(</span><br><span class="line">    estimators=[(<span class="string">'lr'</span>, log_clf), (<span class="string">'rf'</span>, rnd_clf), (<span class="string">'svc'</span>, svm_clf)],</span><br><span class="line">    voting=<span class="string">'hard'</span></span><br><span class="line">)</span><br><span class="line">voting_clf.fit(X_train, y_train)</span><br></pre></td></tr></table></figure><pre><code>VotingClassifier(estimators=[(&#39;lr&#39;, LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,          intercept_scaling=1, max_iter=100, multi_class=&#39;warn&#39;,          n_jobs=None, penalty=&#39;l2&#39;, random_state=None, solver=&#39;lbfgs&#39;,          tol=0.0001, verbose=0, warm_start=False)), (&#39;rf&#39;, RandomF...,  max_iter=-1, probability=False, random_state=None, shrinking=True,  tol=0.001, verbose=False))],         flatten_transform=None, n_jobs=None, voting=&#39;hard&#39;, weights=None)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> clf <span class="keyword">in</span> (log_clf, rnd_clf, svm_clf, voting_clf):</span><br><span class="line">    clf.fit(X_train, y_train)</span><br><span class="line">    y_pred = clf.predict(X_test)</span><br><span class="line">    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure><pre><code>LogisticRegression 0.864RandomForestClassifier 0.896SVC 0.888VotingClassifier 0.896</code></pre><h1 id="放回取样和不放回取样"><a href="#放回取样和不放回取样" class="headerlink" title="放回取样和不放回取样"></a>放回取样和不放回取样</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> BaggingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">bag_clf = BaggingClassifier(</span><br><span class="line">    DecisionTreeClassifier(), n_estimators=<span class="number">500</span>,</span><br><span class="line">    max_samples=<span class="number">100</span>, bootstrap=<span class="keyword">True</span>, n_jobs=<span class="number">-1</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">bag_clf.fit(X_train, y_train)</span><br><span class="line">y_pred = bag_clf.predict(X_test)</span><br><span class="line">print(accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure><pre><code>0.92</code></pre><h1 id="out-of-bag-评估"><a href="#out-of-bag-评估" class="headerlink" title="out-of-bag 评估"></a>out-of-bag 评估</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bag_clf = BaggingClassifier(</span><br><span class="line">    DecisionTreeClassifier(), n_estimators=<span class="number">500</span>,</span><br><span class="line">    bootstrap=<span class="keyword">True</span>, n_jobs=<span class="number">-1</span>, oob_score=<span class="keyword">True</span></span><br><span class="line">)</span><br><span class="line">bag_clf.fit(X_train, y_train)</span><br><span class="line">bag_clf.oob_score_</span><br></pre></td></tr></table></figure><pre><code>0.8986666666666666</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred = bag_clf.predict(X_test)</span><br><span class="line">accuracy_score(y_test, y_pred)</span><br></pre></td></tr></table></figure><pre><code>0.888</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bag_clf.oob_decision_function_</span><br></pre></td></tr></table></figure><pre><code>array([[0.4010989 , 0.5989011 ],        ....       [0.04278075, 0.95721925],       [0.98876404, 0.01123596],       [1.        , 0.        ],       [0.03664921, 0.96335079],       [0.62285714, 0.37714286]])</code></pre><h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line">rnd_clf = RandomForestClassifier(n_estimators=<span class="number">500</span>, max_leaf_nodes=<span class="number">16</span>, n_jobs=<span class="number">-1</span>)</span><br><span class="line">rnd_clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred_rf = rnd_clf.predict(X_test)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bag_clf = BaggingClassifier(</span><br><span class="line">    DecisionTreeClassifier(splitter=<span class="string">'random'</span>, max_leaf_nodes=<span class="number">16</span>),</span><br><span class="line">    n_estimators=<span class="number">500</span>, max_samples=<span class="number">1.0</span>, bootstrap=<span class="keyword">True</span>, n_jobs=<span class="number">-1</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="特征重要性"><a href="#特征重要性" class="headerlink" title="特征重要性"></a>特征重要性</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">rnd_clf = RandomForestClassifier(n_estimators=<span class="number">500</span>, n_jobs=<span class="number">-1</span>)</span><br><span class="line">rnd_clf.fit(iris[<span class="string">"data"</span>], iris[<span class="string">"target"</span>])</span><br><span class="line"><span class="keyword">for</span> name, score <span class="keyword">in</span> zip(iris[<span class="string">"feature_names"</span>], rnd_clf.feature_importances_):</span><br><span class="line">    print(name, score)</span><br></pre></td></tr></table></figure><pre><code>sepal length (cm) 0.10154330050026057sepal width (cm) 0.02620789074908215petal length (cm) 0.4514173964983005petal width (cm) 0.42083141225235715</code></pre><h1 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a><a href="http://coldjune.com/2018/05/23/AdaBoost%E5%85%83%E7%AE%97%E6%B3%95/">Boosting</a></h1><h2 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> AdaBoostClassifier</span><br><span class="line"></span><br><span class="line">ada_clf = AdaBoostClassifier(</span><br><span class="line">    DecisionTreeClassifier(max_depth=<span class="number">1</span>), n_estimators=<span class="number">200</span>,</span><br><span class="line">    algorithm=<span class="string">"SAMME.R"</span>, learning_rate=<span class="number">0.5</span></span><br><span class="line">)</span><br><span class="line">ada_clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = ada_clf.predict(X_test)</span><br><span class="line">accuracy_score(y_test, y_pred)</span><br></pre></td></tr></table></figure><pre><code>0.896</code></pre><h2 id="梯度Boosting"><a href="#梯度Boosting" class="headerlink" title="梯度Boosting"></a>梯度Boosting</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"></span><br><span class="line">tree_reg1 = DecisionTreeRegressor(max_depth=<span class="number">2</span>)</span><br><span class="line">tree_reg1.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y2 = y_train - tree_reg1.predict(X_train)</span><br><span class="line">tree_reg2 = DecisionTreeRegressor(max_depth=<span class="number">2</span>)</span><br><span class="line">tree_reg2.fit(X_train, y2)</span><br><span class="line"></span><br><span class="line">y3 = y2 - tree_reg2.predict(X_train)</span><br><span class="line">tree_reg3 = DecisionTreeRegressor(max_depth=<span class="number">2</span>)</span><br><span class="line">tree_reg3.fit(X_train,  y3)</span><br><span class="line"></span><br><span class="line">y_pred = sum(tree.predict(X_test) <span class="keyword">for</span> tree <span class="keyword">in</span> (tree_reg1, tree_reg2, tree_reg3))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingRegressor</span><br><span class="line"></span><br><span class="line">gbrt = GradientBoostingRegressor(max_depth=<span class="number">2</span>, n_estimators=<span class="number">3</span>, learning_rate=<span class="number">1.0</span>)</span><br><span class="line">gbrt.fit(X,y)</span><br></pre></td></tr></table></figure><pre><code>GradientBoostingRegressor(alpha=0.9, criterion=&#39;friedman_mse&#39;, init=None,             learning_rate=1.0, loss=&#39;ls&#39;, max_depth=2, max_features=None,             max_leaf_nodes=None, min_impurity_decrease=0.0,             min_impurity_split=None, min_samples_leaf=1,             min_samples_split=2, min_weight_fraction_leaf=0.0,             n_estimators=3, n_iter_no_change=None, presort=&#39;auto&#39;,             random_state=None, subsample=1.0, tol=0.0001,             validation_fraction=0.1, verbose=0, warm_start=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 防止过拟合，提前终止</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line">X_train, X_val, y_train, y_val = train_test_split(X, y)</span><br><span class="line"></span><br><span class="line">gbrt = GradientBoostingRegressor(max_depth=<span class="number">2</span>, n_estimators=<span class="number">120</span>)</span><br><span class="line">gbrt.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">errors = [mean_squared_error(y_val, y_pred)</span><br><span class="line">          <span class="keyword">for</span> y_pred <span class="keyword">in</span> gbrt.staged_predict(X_val)]</span><br><span class="line">bst_n_estimators = np.argmin(errors)</span><br><span class="line"></span><br><span class="line">gbrt_best = GradientBoostingRegressor(max_depth=<span class="number">2</span>, n_estimators=bst_n_estimators)</span><br><span class="line">gbrt_best.fit(X_train, y_train)</span><br></pre></td></tr></table></figure><pre><code>GradientBoostingRegressor(alpha=0.9, criterion=&#39;friedman_mse&#39;, init=None,             learning_rate=0.1, loss=&#39;ls&#39;, max_depth=2, max_features=None,             max_leaf_nodes=None, min_impurity_decrease=0.0,             min_impurity_split=None, min_samples_leaf=1,             min_samples_split=2, min_weight_fraction_leaf=0.0,             n_estimators=65, n_iter_no_change=None, presort=&#39;auto&#39;,             random_state=None, subsample=1.0, tol=0.0001,             validation_fraction=0.1, verbose=0, warm_start=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">gbrt = GradientBoostingRegressor(max_depth=<span class="number">2</span>, warm_start=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">min_val_error = float(<span class="string">"inf"</span>)</span><br><span class="line">error_going_up = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> n_estimators <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">120</span>):</span><br><span class="line">    gbrt.n_estimators = n_estimators</span><br><span class="line">    gbrt.fit(X_train, y_train)</span><br><span class="line">    y_pred = gbrt.predict(X_val)</span><br><span class="line">    val_error = mean_squared_error(y_val, y_pred)</span><br><span class="line">    <span class="keyword">if</span> val_error &lt; min_val_error:</span><br><span class="line">        min_val_error = val_error</span><br><span class="line">        error_going_up = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        error_going_up += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> error_going_up == <span class="number">5</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure><hr><p><a href="https://github.com/coldJune/machineLearning/blob/master/handson-ml/Ensemble%20Learning%20and%20Random%20Forests.ipynb" target="_blank" rel="noopener">源文件</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;选举式分类器&quot;&gt;&lt;a href=&quot;#选举式分类器&quot; class=&quot;headerlink&quot; title=&quot;选举式分类器&quot;&gt;&lt;/a&gt;选举式分类器&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gu
      
    
    </summary>
    
      <category term="机器学习" scheme="http://coldjune.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Hands-On Machine Learning with Scikit-Learn and TensorFlow" scheme="http://coldjune.com/tags/Hands-On-Machine-Learning-with-Scikit-Learn-and-TensorFlow/"/>
    
      <category term="sklearn" scheme="http://coldjune.com/tags/sklearn/"/>
    
      <category term="AdaBoost" scheme="http://coldjune.com/tags/AdaBoost/"/>
    
      <category term="随机森林" scheme="http://coldjune.com/tags/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/"/>
    
  </entry>
  
  <entry>
    <title>Decision Tree</title>
    <link href="http://coldjune.com/2018/12/10/Decision-Tree/"/>
    <id>http://coldjune.com/2018/12/10/Decision-Tree/</id>
    <published>2018-12-10T07:05:16.000Z</published>
    <updated>2018-12-12T12:49:19.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="训练和显示决策树"><a href="#训练和显示决策树" class="headerlink" title="训练和显示决策树"></a>训练和显示决策树</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, <span class="number">2</span>:]</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line">tree_clf = DecisionTreeClassifier(max_depth=<span class="number">2</span>)</span><br><span class="line">tree_clf.fit(X, y)</span><br></pre></td></tr></table></figure><pre><code>DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=2,            max_features=None, max_leaf_nodes=None,            min_impurity_decrease=0.0, min_impurity_split=None,            min_samples_leaf=1, min_samples_split=2,            min_weight_fraction_leaf=0.0, presort=False, random_state=None,            splitter=&#39;best&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成dot文件</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> export_graphviz</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">image_path</span><span class="params">(fig_id)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> os.path.join(<span class="string">'.'</span>, <span class="string">"images"</span>, <span class="string">"decision_trees"</span>, fig_id)</span><br><span class="line"></span><br><span class="line">export_graphviz(</span><br><span class="line">    tree_clf,</span><br><span class="line">    out_file=image_path(<span class="string">'iris_tree.dot'</span>),</span><br><span class="line">    feature_names=iris.feature_names[<span class="number">2</span>:],</span><br><span class="line">    class_names=iris.target_names,</span><br><span class="line">    rounded=<span class="keyword">True</span>,</span><br><span class="line">    filled=<span class="keyword">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="安装graphviz"><a href="#安装graphviz" class="headerlink" title="安装graphviz"></a><a href="https://graphviz.gitlab.io/download/" target="_blank" rel="noopener">安装graphviz</a></h2><blockquote><p>dot -Tpng .\images\decision_trees\iris_tree.dot -o .\images\decision_trees\iris_tree.png</p></blockquote><p><img src="/2018/12/10/Decision-Tree/iris_tree.png" alt="决策树"></p><h1 id="预测和评估分类可能性"><a href="#预测和评估分类可能性" class="headerlink" title="预测和评估分类可能性"></a>预测和评估分类可能性</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tree_clf.predict_proba([[<span class="number">5</span>, <span class="number">1.5</span>]])</span><br></pre></td></tr></table></figure><pre><code>array([[0.        , 0.90740741, 0.09259259]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tree_clf.predict([[<span class="number">5</span>, <span class="number">1.5</span>]])</span><br></pre></td></tr></table></figure><pre><code>array([1])</code></pre><h1 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"></span><br><span class="line">tree_reg = DecisionTreeRegressor(max_depth=<span class="number">2</span>)</span><br><span class="line">tree_reg.fit(X, y)</span><br></pre></td></tr></table></figure><pre><code>DecisionTreeRegressor(criterion=&#39;mse&#39;, max_depth=2, max_features=None,           max_leaf_nodes=None, min_impurity_decrease=0.0,           min_impurity_split=None, min_samples_leaf=1,           min_samples_split=2, min_weight_fraction_leaf=0.0,           presort=False, random_state=None, splitter=&#39;best&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">export_graphviz(</span><br><span class="line">    tree_clf,</span><br><span class="line">    out_file=image_path(<span class="string">'iris_tree_regression.dot'</span>),</span><br><span class="line">    feature_names=iris.feature_names[<span class="number">2</span>:],</span><br><span class="line">    class_names=iris.target_names,</span><br><span class="line">    rounded=<span class="keyword">True</span>,</span><br><span class="line">    filled=<span class="keyword">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p><img src="/2018/12/10/Decision-Tree/iris_tree_regression.png" alt="回归决策树"></p><hr><p><a href="https://github.com/coldJune/machineLearning/blob/master/handson-ml/Decision%20Trees.ipynb" target="_blank" rel="noopener">源文件</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;训练和显示决策树&quot;&gt;&lt;a href=&quot;#训练和显示决策树&quot; class=&quot;headerlink&quot; title=&quot;训练和显示决策树&quot;&gt;&lt;/a&gt;训练和显示决策树&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td c
      
    
    </summary>
    
      <category term="机器学习" scheme="http://coldjune.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="分类" scheme="http://coldjune.com/tags/%E5%88%86%E7%B1%BB/"/>
    
      <category term="Hands-On Machine Learning with Scikit-Learn and TensorFlow" scheme="http://coldjune.com/tags/Hands-On-Machine-Learning-with-Scikit-Learn-and-TensorFlow/"/>
    
      <category term="sklearn" scheme="http://coldjune.com/tags/sklearn/"/>
    
      <category term="决策树" scheme="http://coldjune.com/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    
  </entry>
  
</feed>
